{
  "file": "src/ai/providers/openAIProvider.ts",
  "role": "Core Logic",
  "purpose": "Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application",
  "userVisibleActions": [
    "Receives AI-generated text responses to user prompts",
    "Gets structured JSON responses when requesting formatted data",
    "Experiences AI conversation with system prompts guiding behavior",
    "Receives streaming responses for real-time AI text generation"
  ],
  "developerVisibleActions": [
    "Configure OpenAI API key through configuration manager",
    "Send chat completion requests with custom models and prompts",
    "Request structured JSON outputs from AI responses",
    "Stream AI responses in real-time chunks",
    "Check if OpenAI provider is properly configured before use",
    "Handle API errors and timeout scenarios (5 minute timeout)",
    "Extract JSON from AI responses that may contain markdown formatting"
  ],
  "keyFunctions": [
    {
      "name": "isConfigured",
      "desc": "Checks if OpenAI API key is set and client is ready",
      "inputs": "none",
      "outputs": "boolean indicating configuration status"
    },
    {
      "name": "getName",
      "desc": "Returns the provider identifier",
      "inputs": "none",
      "outputs": "string 'openai'"
    },
    {
      "name": "sendRequest",
      "desc": "Sends a chat completion request to OpenAI and returns the response",
      "inputs": "LLMRequestOptions (model, messages, system prompt, response format)",
      "outputs": "LLMResponse with content and finish reason"
    },
    {
      "name": "sendStructuredRequest",
      "desc": "Requests a JSON-formatted response and extracts structured data",
      "inputs": "LLMRequestOptions with JSON response format",
      "outputs": "StructuredOutputResponse with parsed JSON data"
    },
    {
      "name": "streamRequest",
      "desc": "Streams AI responses in real-time chunks as they are generated",
      "inputs": "LLMRequestOptions and callback function for each chunk",
      "outputs": "complete response content after streaming finishes"
    }
  ],
  "dependencies": [
    "openai",
    "ILLMProvider",
    "configurationManager",
    "jsonExtractor"
  ],
  "intent": "This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses to user prompts\",\n    \"Gets structured JSON responses when requesting formatted data\",\n    \"Experiences AI conversation with system prompts guiding behavior\",\n    \"Receives streaming responses for real-time AI text generation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager\",\n    \"Send chat completion requests with custom models and prompts\",\n    \"Request structured JSON outputs from AI responses\",\n    \"Stream AI responses in real-time chunks\",\n    \"Check if OpenAI provider is properly configured before use\",\n    \"Handle API errors and timeout scenarios (5 minute timeout)\",\n    \"Extract JSON from AI responses that may contain markdown formatting\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI API key is set and client is ready\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, system prompt, response format)\",\n      \"outputs\": \"LLMResponse with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Requests a JSON-formatted response and extracts structured data\",\n      \"inputs\": \"LLMRequestOptions with JSON response format\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams AI responses in real-time chunks as they are generated\",\n      \"inputs\": \"LLMRequestOptions and callback function for each chunk\",\n      \"outputs\": \"complete response content after streaming finishes\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T00:49:09.923Z"
  }
}