{
  "overview": "Shadow Watch is a VS Code extension that provides AI-powered code intelligence and automated testing capabilities for software development teams. The extension analyzes your codebase to generate comprehensive documentation, identify code quality issues, and create unit tests automatically. Users interact with the extension through multiple sidebar panels, command palette actions, and inline diagnostics that appear directly in the editor as you work.\n\nThe extension connects to AI language models (OpenAI GPT-4 or Anthropic Claude) to understand your code at multiple levels - from individual functions to entire product architecture. It automatically generates documentation describing what your application does, how components relate to each other, and what problems your code solves. The extension watches your files for changes and can automatically re-analyze your code as you save, keeping documentation and insights up to date.\n\nShadow Watch transforms time-consuming manual tasks into automated workflows. Instead of manually writing documentation, reviewing code for quality issues, or creating unit tests from scratch, users can generate these artifacts with a few clicks. The extension presents all analysis results in organized tree views, exports documentation in multiple formats optimized for different AI assistants, and provides detailed reports that help teams understand and improve their codebase.",
  "whatItDoes": [
    "Generates comprehensive product documentation automatically by analyzing your entire codebase",
    "Creates detailed architecture insights describing system components and their relationships",
    "Identifies code quality issues like large files, orphaned code, circular dependencies, and complexity problems",
    "Generates unit tests automatically for your functions with AI-powered test planning",
    "Executes test suites and automatically fixes failing tests using AI assistance",
    "Provides interactive tree views for navigating code structure, dependencies, and entry points",
    "Displays inline diagnostics showing code issues directly in the editor with squiggly underlines",
    "Exports analysis results in multiple formats (Markdown, JSON) optimized for Cursor, ChatGPT, and other AI tools",
    "Watches files for changes and automatically re-analyzes code when you save",
    "Searches codebases using grep patterns to find specific code elements",
    "Caches analysis results for 24 hours to provide instant access across sessions",
    "Detects test framework configuration and generates setup instructions if needed",
    "Creates prioritized test plans based on function complexity, dependencies, and risk",
    "Generates tests in small batches with real-time progress tracking",
    "Validates generated tests by running them and captures detailed results"
  ],
  "userPerspective": {
    "gui": [
      "Browse code structure through interactive tree views showing products, analyses, insights, and test results",
      "View AI-generated architecture insights in a dedicated sidebar panel",
      "Navigate from high-level components down to specific functions with single clicks",
      "See code quality issues highlighted with inline squiggly underlines in the editor",
      "Monitor analysis progress through status bar indicators showing current operations",
      "View comprehensive reports in webview panels displaying formatted documentation",
      "Access detailed information about functions, API endpoints, and dependencies in popup panels",
      "Track test generation progress with real-time updates showing completed and failed tests",
      "Review test execution results with pass/fail counts and error details",
      "Copy analysis results, insights, and documentation to clipboard for sharing"
    ],
    "cli": [
      "Execute workspace analysis through VS Code command palette",
      "Trigger file-specific analysis for currently open files",
      "Generate product documentation on demand",
      "Clear cached analysis data to force fresh analysis",
      "Switch between OpenAI and Claude AI providers",
      "Configure extension settings through VS Code preferences",
      "Export analysis results in different formats",
      "Access test generation and validation workflows"
    ],
    "api": [
      "Integrates with OpenAI GPT-4 API for AI-powered code analysis",
      "Connects to Anthropic Claude API as alternative AI provider",
      "Handles API rate limiting automatically to prevent quota violations",
      "Retries failed API requests with intelligent backoff strategies",
      "Supports streaming responses for real-time AI text generation",
      "Validates API credentials and provider availability before use"
    ],
    "cicd": [
      "Generates test suites that integrate with existing test frameworks (Jest, Mocha, Vitest, Pytest, JUnit, Google Test)",
      "Detects test environment configuration automatically",
      "Creates setup instructions for missing test dependencies",
      "Executes tests and captures results for CI/CD pipeline integration",
      "Exports analysis results in standardized formats for automated workflows",
      "Validates generated tests to ensure they run successfully"
    ]
  },
  "workflowIntegration": [
    "Code review workflow: Analyze files to identify quality issues before committing changes",
    "Documentation workflow: Generate comprehensive product and architecture documentation automatically",
    "Testing workflow: Create test plans, generate unit tests, execute tests, and fix failures in one automated flow",
    "Refactoring workflow: Analyze function dependencies and complexity to plan safe code reorganization",
    "Onboarding workflow: Generate architecture insights and documentation to help new team members understand the codebase",
    "AI-assisted development: Export analysis results in formats optimized for Cursor, ChatGPT, and other AI coding assistants",
    "Quality monitoring: Continuously track code quality through automatic re-analysis on file save",
    "Test coverage workflow: Identify untested functions and generate tests to improve coverage",
    "Cross-language testing: Support multiple programming languages and testing frameworks in polyglot projects"
  ],
  "problemsSolved": [
    "Eliminates manual documentation writing by automatically generating comprehensive product and architecture documentation",
    "Reduces time spent understanding unfamiliar codebases through AI-generated insights and navigation tools",
    "Catches code quality issues early by identifying large files, orphaned code, and circular dependencies automatically",
    "Accelerates test creation by generating unit tests with AI assistance instead of writing them manually",
    "Reduces debugging time by automatically fixing failing tests through AI-powered retry attempts",
    "Prevents API quota violations through automatic rate limiting when calling AI services",
    "Maintains up-to-date documentation through automatic re-analysis when code changes",
    "Streamlines code reviews by highlighting quality issues with inline diagnostics",
    "Simplifies test environment setup by detecting configuration and generating setup instructions",
    "Improves test coverage by prioritizing which functions need tests based on complexity and risk",
    "Enables efficient code navigation through interactive tree views showing dependencies and relationships",
    "Reduces context switching by keeping analysis results accessible for 24 hours across sessions",
    "Supports diverse workflows by exporting results in multiple formats for different tools",
    "Handles temporary API failures gracefully through intelligent retry logic",
    "Provides consistent AI interactions across multiple providers (OpenAI, Claude) through unified interface"
  ],
  "architecture": "Shadow Watch follows a layered architecture with distinct separation between user interface, domain logic, infrastructure services, and AI integration. The user interface layer consists of multiple VS Code tree view providers and webview panels that present analysis results, insights, and reports. These views receive data from the domain layer and respond to user commands through registered command handlers. The extension bootstrapper initializes all components during activation and establishes the communication pathways between layers.\n\nThe domain layer contains the core business logic organized into specialized services. The analysis services parse code files to extract structure, dependencies, and function information. The testing services orchestrate the complete test generation workflow from planning through execution and validation. The prompt builders construct structured instructions for AI models based on analysis requirements. The formatting services transform raw analysis data into human-readable documentation. All domain services coordinate with each other through well-defined interfaces and data structures.\n\nThe infrastructure layer provides foundational capabilities that support the domain logic. The file system services handle efficient file reading, caching, and watching operations. The persistence layer manages storage and retrieval of analysis results in a timestamped directory structure. The AI provider layer abstracts interactions with different language models (OpenAI, Claude) behind a common interface. Rate limiting, retry logic, and response parsing ensure reliable AI interactions. The configuration manager centralizes all user preferences and broadcasts changes to interested components. This layered design enables each component to focus on its specific responsibility while maintaining clean boundaries and testability.",
  "titles": [
    "Shadow Watch Extension",
    "Code Analysis",
    "Architecture Insights",
    "Product Documentation",
    "Test Generation Workflow",
    "Test Planning Service",
    "Test Setup Service",
    "Test Execution Service",
    "Test Validation Service",
    "Interactive Tree Views",
    "Analysis Viewer",
    "Insights Viewer",
    "Static Analysis Viewer",
    "Unit Tests Navigator",
    "Product Navigator",
    "Reports Tree Provider",
    "Inline Diagnostics",
    "Command Palette Integration",
    "LLM Service",
    "AI Provider Factory",
    "Rate Limiter",
    "Retry Handler",
    "Response Parser",
    "File Watcher Service",
    "Incremental Analysis Service",
    "Configuration Manager",
    "Documentation Formatter",
    "Navigation Handler",
    "Prompt Builder",
    "Refactoring Prompt Builder",
    "Test Prompts",
    "File Cache",
    "File Processor",
    "Analysis Result Repository",
    "Progress Service",
    "Enhanced Analyzer",
    "Function Analyzer",
    "Insight Generator",
    "File Access Helper",
    "LLM State Manager",
    "Incremental Storage",
    "Reports Viewer",
    "Error Handler",
    "JSON Extractor"
  ],
  "descriptions": [
    {
      "title": "Shadow Watch Extension",
      "description": "The main VS Code extension that provides AI-powered code analysis, documentation generation, and automated testing capabilities through multiple integrated views and commands",
      "category": "feature"
    },
    {
      "title": "Code Analysis",
      "description": "Analyzes source code files to extract structure, functions, dependencies, entry points, and relationships for comprehensive codebase understanding",
      "category": "feature"
    },
    {
      "title": "Architecture Insights",
      "description": "AI-generated insights describing the high-level architecture, component relationships, system themes, and design patterns used in the codebase",
      "category": "feature"
    },
    {
      "title": "Product Documentation",
      "description": "Comprehensive documentation automatically generated from code analysis that describes what the application does from a user perspective, including features, workflows, and problems solved",
      "category": "feature"
    },
    {
      "title": "Test Generation Workflow",
      "description": "End-to-end automated workflow that analyzes code, creates test plans, generates unit tests with AI assistance, executes tests, and fixes failures automatically",
      "category": "workflow"
    },
    {
      "title": "Interactive Tree Views",
      "description": "Sidebar panels that display code structure, analysis results, insights, and test information in an organized, navigable tree format with interactive actions",
      "category": "feature"
    },
    {
      "title": "Inline Diagnostics",
      "description": "Code quality issues displayed directly in the editor as squiggly underlines with detailed problem descriptions in the problems panel",
      "category": "feature"
    },
    {
      "title": "Command Palette Integration",
      "description": "All extension features accessible through VS Code's command palette for quick access to analysis, documentation, testing, and configuration actions",
      "category": "integration"
    },
    {
      "title": "LLM Service",
      "description": "AI-powered analysis service that generates insights, documentation, and code understanding by interfacing with OpenAI GPT-4 or Anthropic Claude language models",
      "category": "module"
    },
    {
      "title": "File Watcher Service",
      "description": "Monitors workspace files for changes and automatically triggers re-analysis when files are saved, keeping documentation and insights up to date",
      "category": "module"
    },
    {
      "title": "Configuration Manager",
      "description": "Centralized management of all user preferences including AI provider selection, API credentials, analysis triggers, and display options",
      "category": "module"
    },
    {
      "title": "Test Planning Service",
      "description": "Analyzes code functions and creates prioritized test plans based on complexity, dependencies, and risk factors using AI guidance",
      "category": "module"
    },
    {
      "title": "Test Setup Service",
      "description": "Detects existing test framework configuration and generates setup instructions including required dependencies and configuration files",
      "category": "module"
    },
    {
      "title": "Test Execution Service",
      "description": "Runs test suites using the appropriate testing framework and captures detailed results including pass/fail status, errors, and execution timing",
      "category": "module"
    },
    {
      "title": "Test Validation Service",
      "description": "Validates generated tests by executing them and automatically fixes failures through AI-powered retry attempts",
      "category": "module"
    },
    {
      "title": "Enhanced Analyzer",
      "description": "Deep code analysis engine that parses Abstract Syntax Trees to extract detailed function metadata, control flow, dependencies, and behavioral patterns",
      "category": "component"
    },
    {
      "title": "Function Analyzer",
      "description": "Extracts comprehensive function information from large code files to support refactoring analysis including signatures, dependencies, and complexity metrics",
      "category": "component"
    },
    {
      "title": "Insight Generator",
      "description": "Identifies code quality issues like large files, orphaned code, circular dependencies, and complexity problems with severity-based categorization",
      "category": "component"
    },
    {
      "title": "Documentation Formatter",
      "description": "Transforms raw analysis data into well-structured Markdown documentation organized by user perspective and technical considerations",
      "category": "component"
    },
    {
      "title": "Navigation Handler",
      "description": "Enables navigation to specific code locations and displays detailed information about functions, API endpoints, and dependencies in webview panels",
      "category": "component"
    },
    {
      "title": "Prompt Builder",
      "description": "Constructs specialized prompts for different types of AI analysis including architecture documentation, refactoring plans, and test generation",
      "category": "component"
    },
    {
      "title": "AI Provider Factory",
      "description": "Creates and manages AI language model provider instances ensuring single instance per provider type and supporting OpenAI and Claude",
      "category": "component"
    },
    {
      "title": "Rate Limiter",
      "description": "Prevents API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
      "category": "component"
    },
    {
      "title": "Retry Handler",
      "description": "Handles automatic retries of failed AI requests with intelligent exponential backoff for temporary errors like rate limits or network issues",
      "category": "component"
    },
    {
      "title": "Response Parser",
      "description": "Extracts structured data from AI text responses and converts them into standardized documentation formats",
      "category": "component"
    },
    {
      "title": "File Cache",
      "description": "Optimizes file operations by caching file contents and automatically invalidating cached data when files change",
      "category": "component"
    },
    {
      "title": "File Processor",
      "description": "Provides parallel file processing with automatic filtering of non-source directories like node_modules and build outputs",
      "category": "component"
    },
    {
      "title": "Analysis Result Repository",
      "description": "Manages persistent storage of analysis results in timestamped directory structures with automatic maintenance of latest reference links",
      "category": "component"
    },
    {
      "title": "Progress Service",
      "description": "Displays standardized progress notifications to users during long-running operations with support for cancellation",
      "category": "component"
    },
    {
      "title": "Analysis Viewer",
      "description": "Tree view that displays code structure organized by files, functions, dependencies, and entry points with navigation support",
      "category": "feature"
    },
    {
      "title": "Insights Viewer",
      "description": "Tree view showing AI-generated architecture insights including system purpose, component relationships, and organizational patterns",
      "category": "feature"
    },
    {
      "title": "Static Analysis Viewer",
      "description": "Tree view presenting code quality issues identified by static analysis with severity indicators and recommendations",
      "category": "feature"
    },
    {
      "title": "Unit Tests Navigator",
      "description": "Tree view for browsing and navigating unit tests in the codebase with links to test files and source code",
      "category": "feature"
    },
    {
      "title": "Product Navigator",
      "description": "Tree view showing high-level product structure and enabling navigation between documentation and source code",
      "category": "feature"
    },
    {
      "title": "Reports Tree Provider",
      "description": "Tree view displaying generated reports including documentation, test results, and analysis summaries",
      "category": "feature"
    },
    {
      "title": "Incremental Analysis Service",
      "description": "Orchestrates multi-round AI conversations that progressively gather information through file reads and searches until analysis is complete",
      "category": "module"
    },
    {
      "title": "Test Configuration Service",
      "description": "Automatically detects which testing framework is in use and validates that all required dependencies and configuration are present",
      "category": "module"
    },
    {
      "title": "Export Formats",
      "description": "Multiple output formats optimized for different AI assistants including Cursor (tree structure), ChatGPT (detailed markdown), Generic (standard format), and Compact (minimal format)",
      "category": "feature"
    },
    {
      "title": "Grep Search",
      "description": "Pattern-based code search that finds specific elements across the codebase using regex patterns with configurable file filters",
      "category": "feature"
    },
    {
      "title": "Context Builder",
      "description": "Converts analysis results into formats suitable for LLM context and saves them to persistent storage for future use",
      "category": "component"
    },
    {
      "title": "LLM State Manager",
      "description": "Manages the state of LLM operations including tracking active requests, handling cancellations, and coordinating multi-step workflows",
      "category": "component"
    },
    {
      "title": "Incremental Storage",
      "description": "Provides incremental saving of analysis results allowing partial results to be stored and accessed during long-running analysis operations",
      "category": "component"
    }
  ],
  "relevantFunctions": [
    {
      "name": "analyzeWorkspace",
      "description": "Analyzes the entire workspace codebase to generate comprehensive documentation, insights, and structural information",
      "file": "src/extension.ts",
      "module": "Extension"
    },
    {
      "name": "analyzeFile",
      "description": "Analyzes a single code file to extract its structure, functions, dependencies, and generates file-level documentation",
      "file": "src/analyzer.ts",
      "module": "Analyzer"
    },
    {
      "name": "generateProductDocs",
      "description": "Creates complete product documentation by analyzing the codebase and using AI to generate user-facing descriptions",
      "file": "src/llmIntegration.ts",
      "module": "LLM Integration"
    },
    {
      "name": "generateArchitectureInsights",
      "description": "Produces high-level architecture insights describing system components, relationships, and design patterns",
      "file": "src/llmIntegration.ts",
      "module": "LLM Integration"
    },
    {
      "name": "generateTests",
      "description": "Orchestrates the complete test generation workflow including planning, generation, and validation",
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "module": "Test Generation"
    },
    {
      "name": "createTestPlan",
      "description": "Analyzes code functions and creates a prioritized test plan based on complexity and dependencies",
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "module": "Test Planning"
    },
    {
      "name": "detectTestSetup",
      "description": "Automatically detects test framework configuration and identifies missing dependencies or setup requirements",
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "module": "Test Setup"
    },
    {
      "name": "executeTests",
      "description": "Runs test suites using the appropriate testing framework and captures detailed execution results",
      "file": "src/domain/services/testing/testExecutionService.ts",
      "module": "Test Execution"
    },
    {
      "name": "validateAndFixTests",
      "description": "Validates generated tests by running them and automatically fixes failures using AI assistance",
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "module": "Test Validation"
    },
    {
      "name": "analyzeFunction",
      "description": "Performs deep analysis on a function by parsing its AST to extract metadata, dependencies, and behavioral patterns",
      "file": "src/analysis/enhancedAnalyzer.ts",
      "module": "Enhanced Analyzer"
    },
    {
      "name": "extractFunctionInfo",
      "description": "Extracts detailed function information from large code files to support refactoring analysis",
      "file": "src/analysis/functionAnalyzer.ts",
      "module": "Function Analyzer"
    },
    {
      "name": "generateInsights",
      "description": "Identifies code quality issues like large files, orphaned code, and complexity problems with severity ratings",
      "file": "src/insightGenerator.ts",
      "module": "Insight Generator"
    },
    {
      "name": "navigateToLocation",
      "description": "Opens a file at a specific line number in the VS Code editor",
      "file": "src/domain/handlers/navigationHandler.ts",
      "module": "Navigation Handler"
    },
    {
      "name": "showItemDetails",
      "description": "Displays detailed information about code items (functions, endpoints) in a webview panel",
      "file": "src/domain/handlers/navigationHandler.ts",
      "module": "Navigation Handler"
    },
    {
      "name": "buildPrompt",
      "description": "Constructs specialized prompts for different types of AI analysis tasks based on analysis requirements",
      "file": "src/domain/prompts/promptBuilder.ts",
      "module": "Prompt Builder"
    },
    {
      "name": "buildRefactoringPrompt",
      "description": "Creates detailed prompts for AI-powered code refactoring including extraction plans and migration steps",
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "module": "Refactoring Prompts"
    },
    {
      "name": "formatDocumentation",
      "description": "Transforms raw analysis data into well-structured Markdown documentation",
      "file": "src/domain/formatters/documentationFormatter.ts",
      "module": "Documentation Formatter"
    },
    {
      "name": "parseResponse",
      "description": "Extracts structured data from AI text responses and converts them into standardized documentation formats",
      "file": "src/ai/llmResponseParser.ts",
      "module": "Response Parser"
    },
    {
      "name": "enforceRateLimit",
      "description": "Tracks and enforces API rate limits to prevent exceeding provider quotas",
      "file": "src/ai/llmRateLimiter.ts",
      "module": "Rate Limiter"
    },
    {
      "name": "retryWithBackoff",
      "description": "Automatically retries failed AI requests with exponential backoff for temporary errors",
      "file": "src/ai/llmRetryHandler.ts",
      "module": "Retry Handler"
    },
    {
      "name": "getCachedFile",
      "description": "Retrieves file contents from cache or reads from disk if not cached",
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "module": "File Cache"
    },
    {
      "name": "processFiles",
      "description": "Processes multiple files in parallel with automatic filtering of non-source directories",
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "module": "File Processor"
    },
    {
      "name": "saveAnalysisResults",
      "description": "Persists analysis results to disk in a timestamped directory structure",
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "module": "Analysis Repository"
    },
    {
      "name": "watchFiles",
      "description": "Monitors workspace files for changes and triggers callbacks when files are modified or saved",
      "file": "src/domain/services/fileWatcherService.ts",
      "module": "File Watcher"
    },
    {
      "name": "performIncrementalAnalysis",
      "description": "Conducts multi-round AI analysis by iteratively requesting files and searches based on previous results",
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "module": "Incremental Analysis"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "FileDocumentation",
      "description": "Represents documentation for a single file including summary, capabilities, functions, and dependencies",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "ModuleDocumentation",
      "description": "Represents documentation for a module including overview, capabilities, and contained files",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "ProductDocumentation",
      "description": "Comprehensive product-level documentation including overview, features, workflows, architecture, and user perspectives",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "CodeInsight",
      "description": "Represents a code quality issue with title, description, severity, category, and affected files",
      "type": "interface",
      "file": "src/insightGenerator.ts"
    },
    {
      "name": "AnalysisResult",
      "description": "Complete analysis result for a workspace including files, modules, products, insights, and statistics",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "TestPlan",
      "description": "Structured test plan containing functions to test, priorities, and generation configuration",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestGenerationProgress",
      "description": "Tracks progress of test generation including phase, completed count, and failure information",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestExecutionResult",
      "description": "Results from test execution including pass/fail counts, errors, and execution timing",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestSetupConfiguration",
      "description": "Configuration for test environment including framework, dependencies, and setup instructions",
      "type": "interface",
      "file": "src/domain/services/testing/types/testSetupTypes.ts"
    },
    {
      "name": "FunctionAnalysis",
      "description": "Detailed analysis of a function including signature, dependencies, complexity, and behavioral hints",
      "type": "interface",
      "file": "src/analysis/enhancedAnalyzer.ts"
    },
    {
      "name": "ArchitectureInsight",
      "description": "AI-generated insight about system architecture including purpose, relationships, and design patterns",
      "type": "interface",
      "file": "src/llmService.ts"
    },
    {
      "name": "LLMResponse",
      "description": "Structured response from AI language model including generated content and metadata",
      "type": "interface",
      "file": "src/ai/llmResponseParser.ts"
    },
    {
      "name": "RateLimitConfig",
      "description": "Configuration for API rate limiting including requests per minute and time window",
      "type": "interface",
      "file": "src/ai/llmRateLimiter.ts"
    },
    {
      "name": "NavigationTarget",
      "description": "Represents a code location to navigate to including file path and line number",
      "type": "interface",
      "file": "src/domain/handlers/navigationHandler.ts"
    },
    {
      "name": "ExportFormat",
      "description": "Enumeration of supported export formats (Cursor, ChatGPT, Generic, Compact)",
      "type": "type",
      "file": "src/llmFormatter.ts"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Main extension activation and command registration",
      "purpose": "Initializes all extension components, registers commands, and coordinates analysis workflows",
      "role": "Entry point"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "LLM-powered analysis orchestration",
      "purpose": "Manages AI-powered documentation generation and code analysis features",
      "role": "Core feature"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Code analysis engine",
      "purpose": "Analyzes source code files to extract structure, functions, and dependencies",
      "role": "Core feature"
    },
    {
      "path": "src/insightGenerator.ts",
      "description": "Code quality analysis",
      "purpose": "Identifies code quality issues and generates recommendations",
      "role": "Core feature"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Test generation orchestration",
      "purpose": "Coordinates the complete test generation workflow from planning to validation",
      "role": "Core feature"
    },
    {
      "path": "src/domain/services/testing/llmTestPlanningService.ts",
      "description": "Test planning",
      "purpose": "Analyzes code and creates prioritized test plans",
      "role": "Core feature"
    },
    {
      "path": "src/domain/services/testing/testExecutionService.ts",
      "description": "Test execution",
      "purpose": "Runs test suites and captures detailed execution results",
      "role": "Core feature"
    },
    {
      "path": "src/analysis/enhancedAnalyzer.ts",
      "description": "Deep code analysis",
      "purpose": "Performs AST-based analysis to extract function metadata and behavioral patterns",
      "role": "Core component"
    },
    {
      "path": "src/ai/providers/providerFactory.ts",
      "description": "AI provider management",
      "purpose": "Creates and manages AI language model provider instances",
      "role": "Infrastructure"
    },
    {
      "path": "src/domain/prompts/promptBuilder.ts",
      "description": "AI prompt construction",
      "purpose": "Builds specialized prompts for different types of AI analysis",
      "role": "Core component"
    },
    {
      "path": "src/domain/formatters/documentationFormatter.ts",
      "description": "Documentation formatting",
      "purpose": "Transforms analysis data into readable Markdown documentation",
      "role": "Core component"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Code navigation",
      "purpose": "Handles navigation to code locations and displays item details",
      "role": "Core feature"
    },
    {
      "path": "src/config/configurationManager.ts",
      "description": "Settings management",
      "purpose": "Manages all user preferences and broadcasts configuration changes",
      "role": "Infrastructure"
    },
    {
      "path": "src/infrastructure/persistence/analysisResultRepository.ts",
      "description": "Analysis storage",
      "purpose": "Persists and retrieves analysis results with timestamped versioning",
      "role": "Infrastructure"
    },
    {
      "path": "src/domain/services/fileWatcherService.ts",
      "description": "File monitoring",
      "purpose": "Watches workspace files and triggers re-analysis on changes",
      "role": "Infrastructure"
    },
    {
      "path": "src/analysisViewer.ts",
      "description": "Code structure tree view",
      "purpose": "Displays code structure in an interactive sidebar tree view",
      "role": "User interface"
    },
    {
      "path": "src/insightsViewer.ts",
      "description": "Architecture insights tree view",
      "purpose": "Displays AI-generated architecture insights in a sidebar panel",
      "role": "User interface"
    },
    {
      "path": "src/insightsTreeView.ts",
      "description": "Insights and reports tree view",
      "purpose": "Shows code insights, documentation status, and generated reports",
      "role": "User interface"
    }
  ],
  "exampleInput": {
    "description": "Example input showing a request to analyze a workspace and generate product documentation. This represents the type of data the extension receives when users trigger analysis through commands.",
    "json": "{\"command\":\"shadowwatch.analyzeWorkspace\",\"workspace\":{\"rootPath\":\"/users/developer/projects/myapp\",\"name\":\"myapp\"},\"options\":{\"generateProductDocs\":true,\"generateArchitectureInsights\":true,\"includeTestCoverage\":true,\"llmProvider\":\"openai\",\"exportFormat\":\"cursor\",\"minSeverity\":\"warning\"}}"
  },
  "exampleOutput": {
    "description": "Example output showing a complete analysis result with product documentation, architecture insights, and code quality findings. This represents the structured data the extension generates and displays to users.",
    "json": "{\"product\":{\"name\":\"MyApp\",\"overview\":\"MyApp is a web application that helps users manage their tasks and projects...\",\"whatItDoes\":[\"Create and organize tasks with priorities and due dates\",\"Track project progress with visual dashboards\"],\"userPerspective\":{\"gui\":[\"Users can drag and drop tasks between project boards\",\"Visual progress indicators show completion status\"],\"api\":[\"REST API allows external systems to create and update tasks\",\"Webhook notifications alert external services of task changes\"]},\"architecture\":\"MyApp follows a three-tier architecture with a React frontend, Node.js backend, and PostgreSQL database...\"},\"insights\":[{\"title\":\"Large API Handler File\",\"description\":\"The main API handler file contains 1500 lines and handles multiple concerns\",\"severity\":\"warning\",\"category\":\"maintainability\",\"files\":[\"src/api/handlers.ts\"],\"recommendation\":\"Consider splitting into separate handler files per resource type\"},{\"title\":\"Circular Dependency Detected\",\"description\":\"Task service and project service have circular dependencies\",\"severity\":\"error\",\"category\":\"architecture\",\"files\":[\"src/services/taskService.ts\",\"src/services/projectService.ts\"],\"recommendation\":\"Extract shared logic to a common utilities module\"}],\"statistics\":{\"totalFiles\":127,\"totalLines\":45823,\"filesAnalyzed\":115,\"insightsGenerated\":12,\"analysisTimeMs\":8934},\"timestamp\":\"2024-01-15T10:30:45.123Z\"}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Provides automated testing infrastructure for the VSCode extension",
        "Enables TypeScript-based test execution with proper module resolution",
        "Supports test coverage reporting and analysis",
        "Facilitates continuous integration and quality assurance workflows"
      ],
      "summary": "This module configures the testing infrastructure for the VSCode extension, enabling developers to write and execute automated tests. It establishes the testing environment with TypeScript support, ensuring that the extension's functionality can be validated through comprehensive test suites.\n\nThe configuration supports the development workflow by providing a standardized testing framework that integrates seamlessly with the extension's build process. This ensures code quality and helps catch regressions early in the development cycle, ultimately delivering a more reliable extension to end users.\n\nWhile users don't directly interact with this testing configuration, it underpins the quality and reliability of the extension features they use daily. The testing infrastructure validates that extension commands, UI interactions, and core functionality work as expected across different scenarios and edge cases.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest testing framework for TypeScript testing in a VSCode extension project",
          "userVisibleActions": [
            "Users do not directly interact with this file - it supports the extension's testing infrastructure"
          ],
          "developerVisibleActions": [
            "Developers run tests using Jest with TypeScript support enabled",
            "Developers can execute tests from files matching patterns like *.test.ts or *.spec.ts",
            "Developers receive test coverage reports in text, lcov, and HTML formats",
            "Developers can run tests in the Node.js environment with a 10-second timeout",
            "Developers see test results from both src/ and UnitTests/ directories",
            "Developers get code coverage data for TypeScript files in the src/ directory"
          ],
          "keyFunctions": [
            {
              "name": "preset",
              "desc": "Configures Jest to use ts-jest preset for TypeScript testing",
              "inputs": "None",
              "outputs": "ts-jest configuration"
            },
            {
              "name": "testMatch",
              "desc": "Defines file patterns for test discovery",
              "inputs": "None",
              "outputs": "Array of glob patterns matching test files"
            },
            {
              "name": "transform",
              "desc": "Transpiles TypeScript files using ts-jest with specific compiler options",
              "inputs": "TypeScript files",
              "outputs": "Compiled JavaScript for testing"
            },
            {
              "name": "collectCoverageFrom",
              "desc": "Specifies which files to include/exclude from coverage reports",
              "inputs": "None",
              "outputs": "Array of file patterns for coverage collection"
            },
            {
              "name": "moduleNameMapper",
              "desc": "Mocks the vscode module for testing purposes",
              "inputs": "None",
              "outputs": "Mock implementation path"
            }
          ],
          "dependencies": [
            "ts-jest",
            "jest"
          ],
          "intent": "This file exists to provide Jest testing configuration that enables TypeScript testing in a Node.js environment with proper VSCode module mocking, code coverage reporting, and TypeScript compilation settings. It solves the problem of setting up a reliable testing infrastructure for a TypeScript-based VSCode extension.",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript testing in a VSCode extension project\",\n  \"userVisibleActions\": [\n    \"Users do not directly interact with this file - it supports the extension's testing infrastructure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers run tests using Jest with TypeScript support enabled\",\n    \"Developers can execute tests from files matching patterns like *.test.ts or *.spec.ts\",\n    \"Developers receive test coverage reports in text, lcov, and HTML formats\",\n    \"Developers can run tests in the Node.js environment with a 10-second timeout\",\n    \"Developers see test results from both src/ and UnitTests/ directories\",\n    \"Developers get code coverage data for TypeScript files in the src/ directory\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"preset\",\n      \"desc\": \"Configures Jest to use ts-jest preset for TypeScript testing\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ts-jest configuration\"\n    },\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Defines file patterns for test discovery\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Array of glob patterns matching test files\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Transpiles TypeScript files using ts-jest with specific compiler options\",\n      \"inputs\": \"TypeScript files\",\n      \"outputs\": \"Compiled JavaScript for testing\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which files to include/exclude from coverage reports\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Array of file patterns for coverage collection\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Mocks the vscode module for testing purposes\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Mock implementation path\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\"\n  ],\n  \"intent\": \"This file exists to provide Jest testing configuration that enables TypeScript testing in a Node.js environment with proper VSCode module mocking, code coverage reporting, and TypeScript compilation settings. It solves the problem of setting up a reliable testing infrastructure for a TypeScript-based VSCode extension.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Automatically manages AI API request rates to prevent exceeding provider limits",
        "Intelligently retries failed AI requests with exponential backoff",
        "Parses and structures AI-generated documentation into standardized formats",
        "Converts natural language AI responses into organized documentation components",
        "Provides seamless error handling and recovery for temporary API failures",
        "Ensures reliable AI interactions even under rate limiting or network issues"
      ],
      "summary": "This module provides robust AI request management infrastructure that ensures reliable and compliant interactions with LLM providers. It handles the complete lifecycle of AI requests from rate limiting to response processing, protecting users from API quota violations while maintaining a smooth experience.\n\nThe module automatically throttles outgoing requests to stay within provider rate limits, preventing errors before they occur. When temporary failures do happen (network issues, rate limits, transient errors), the retry handler automatically recovers with intelligent backoff strategies. Once responses arrive, the parser extracts and structures the AI-generated content into standardized documentation formats including file summaries, module descriptions, and product-level documentation.\n\nUsers experience seamless AI-powered documentation generation without needing to understand or manage API limitations, retry logic, or response formatting. The module handles all complexity behind the scenes, ensuring requests succeed when possible and fail gracefully when necessary, while always delivering structured, usable documentation output.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
          "userVisibleActions": [
            "User's AI requests are automatically throttled to prevent exceeding API limits",
            "User experiences prevented errors when too many AI requests are made too quickly",
            "User's requests are blocked when rate limits are reached within a time window"
          ],
          "developerVisibleActions": [
            "Developer checks if an AI request can be made before calling the API",
            "Developer records each successful AI request to update rate limit tracking",
            "Developer configures custom rate limits for different LLM providers (OpenAI, Claude)",
            "Developer receives boolean feedback on whether a request is allowed",
            "Developer sees default limits: OpenAI (60 req/min), Claude (50 req/min)"
          ],
          "keyFunctions": [
            {
              "name": "canMakeRequest",
              "desc": "Checks if a new request is allowed based on recent request history and configured limits",
              "inputs": "provider: LLMProvider ('openai' or 'claude')",
              "outputs": "boolean - true if request can proceed, false if rate limit reached"
            },
            {
              "name": "recordRequest",
              "desc": "Records a timestamp for a completed request to track usage against rate limits",
              "inputs": "provider: LLMProvider ('openai' or 'claude')",
              "outputs": "void - updates internal request history"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limit configuration for a specific LLM provider",
              "inputs": "provider: LLMProvider, config: RateLimitConfig (maxRequests, windowMs)",
              "outputs": "void - updates provider configuration"
            }
          ],
          "dependencies": [],
          "intent": "Protects the application from exceeding LLM API rate limits by implementing a sliding window rate limiter that tracks request timestamps per provider and enforces configured quotas, preventing API errors and service interruptions",
          "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\n  \"userVisibleActions\": [\n    \"User's AI requests are automatically throttled to prevent exceeding API limits\",\n    \"User experiences prevented errors when too many AI requests are made too quickly\",\n    \"User's requests are blocked when rate limits are reached within a time window\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer checks if an AI request can be made before calling the API\",\n    \"Developer records each successful AI request to update rate limit tracking\",\n    \"Developer configures custom rate limits for different LLM providers (OpenAI, Claude)\",\n    \"Developer receives boolean feedback on whether a request is allowed\",\n    \"Developer sees default limits: OpenAI (60 req/min), Claude (50 req/min)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on recent request history and configured limits\",\n      \"inputs\": \"provider: LLMProvider ('openai' or 'claude')\",\n      \"outputs\": \"boolean - true if request can proceed, false if rate limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a timestamp for a completed request to track usage against rate limits\",\n      \"inputs\": \"provider: LLMProvider ('openai' or 'claude')\",\n      \"outputs\": \"void - updates internal request history\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider: LLMProvider, config: RateLimitConfig (maxRequests, windowMs)\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Protects the application from exceeding LLM API rate limits by implementing a sliding window rate limiter that tracks request timestamps per provider and enforces configured quotas, preventing API errors and service interruptions\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Parses and extracts structured data from LLM text responses into standardized documentation formats",
          "userVisibleActions": [
            "Receives natural language analysis from AI and converts it into organized documentation",
            "Displays parsed file summaries showing what each code file does",
            "Shows module-level documentation describing groups of related files",
            "Presents product-level documentation explaining overall system purpose",
            "Provides fallback text parsing when AI responses aren't in expected JSON format"
          ],
          "developerVisibleActions": [
            "Call parseFileSummary() to convert LLM text into FileSummary objects",
            "Call parseModuleSummary() to extract module-level documentation",
            "Call parseProductDocumentation() to get high-level product analysis",
            "Call parseLLMInsights() to extract AI-generated insights about code",
            "Call parseProductPurpose() to understand overall product goals",
            "Get structured data with fallback text extraction when JSON parsing fails",
            "Extract sections from text using pattern matching for 'purpose', 'userVisibleActions', 'dependencies', etc.",
            "Extract list items from markdown-style bullet points in LLM responses",
            "Handle parsing errors gracefully with default values"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into a structured FileSummary object",
              "inputs": "content (LLM response text), filePath (file being analyzed), role (file's role in system)",
              "outputs": "FileSummary object with purpose, actions, functions, dependencies, and intent"
            },
            {
              "name": "parseModuleSummary",
              "desc": "Extracts module-level documentation from LLM response",
              "inputs": "content (LLM response text), moduleName (name of module being analyzed)",
              "outputs": "ModuleSummary object describing the module's purpose and components"
            },
            {
              "name": "parseProductDocumentation",
              "desc": "Parses high-level product documentation from LLM response",
              "inputs": "content (LLM response text)",
              "outputs": "EnhancedProductDocumentation object with product overview and architecture"
            },
            {
              "name": "parseLLMInsights",
              "desc": "Extracts AI-generated insights about code quality and patterns",
              "inputs": "content (LLM response text)",
              "outputs": "LLMInsights object with analysis findings"
            },
            {
              "name": "parseProductPurpose",
              "desc": "Extracts the overall purpose and goals of the product from LLM analysis",
              "inputs": "content (LLM response text), context (analysis context)",
              "outputs": "ProductPurposeAnalysis object describing what the product does"
            },
            {
              "name": "extractSection",
              "desc": "Finds and extracts a specific section from text response",
              "inputs": "content (text to search), sectionName (section identifier)",
              "outputs": "Extracted section text or empty string"
            },
            {
              "name": "extractListSection",
              "desc": "Extracts bullet-point lists from text responses",
              "inputs": "content (text to search), sectionName (list identifier)",
              "outputs": "Array of list items"
            }
          ],
          "dependencies": [
            "../fileDocumentation",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between unstructured AI responses and structured documentation data. LLMs return natural language text, but the application needs consistent, typed data structures. This parser handles the messy reality of parsing AI output - trying JSON first, falling back to text extraction, and ensuring the application always gets valid documentation objects even when AI responses are malformed.",
          "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into standardized documentation formats\",\n  \"userVisibleActions\": [\n    \"Receives natural language analysis from AI and converts it into organized documentation\",\n    \"Displays parsed file summaries showing what each code file does\",\n    \"Shows module-level documentation describing groups of related files\",\n    \"Presents product-level documentation explaining overall system purpose\",\n    \"Provides fallback text parsing when AI responses aren't in expected JSON format\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM text into FileSummary objects\",\n    \"Call parseModuleSummary() to extract module-level documentation\",\n    \"Call parseProductDocumentation() to get high-level product analysis\",\n    \"Call parseLLMInsights() to extract AI-generated insights about code\",\n    \"Call parseProductPurpose() to understand overall product goals\",\n    \"Get structured data with fallback text extraction when JSON parsing fails\",\n    \"Extract sections from text using pattern matching for 'purpose', 'userVisibleActions', 'dependencies', etc.\",\n    \"Extract list items from markdown-style bullet points in LLM responses\",\n    \"Handle parsing errors gracefully with default values\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a structured FileSummary object\",\n      \"inputs\": \"content (LLM response text), filePath (file being analyzed), role (file's role in system)\",\n      \"outputs\": \"FileSummary object with purpose, actions, functions, dependencies, and intent\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level documentation from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName (name of module being analyzed)\",\n      \"outputs\": \"ModuleSummary object describing the module's purpose and components\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Parses high-level product documentation from LLM response\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"EnhancedProductDocumentation object with product overview and architecture\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts AI-generated insights about code quality and patterns\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"LLMInsights object with analysis findings\"\n    },\n    {\n      \"name\": \"parseProductPurpose\",\n      \"desc\": \"Extracts the overall purpose and goals of the product from LLM analysis\",\n      \"inputs\": \"content (LLM response text), context (analysis context)\",\n      \"outputs\": \"ProductPurposeAnalysis object describing what the product does\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Finds and extracts a specific section from text response\",\n      \"inputs\": \"content (text to search), sectionName (section identifier)\",\n      \"outputs\": \"Extracted section text or empty string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts bullet-point lists from text responses\",\n      \"inputs\": \"content (text to search), sectionName (list identifier)\",\n      \"outputs\": \"Array of list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured AI responses and structured documentation data. LLMs return natural language text, but the application needs consistent, typed data structures. This parser handles the messy reality of parsing AI output - trying JSON first, falling back to text extraction, and ensuring the application always gets valid documentation objects even when AI responses are malformed.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles automatic retries of LLM API requests when they fail due to temporary errors like rate limits or network issues",
          "userVisibleActions": [
            "When an AI request fails temporarily, the system automatically retries it without user intervention",
            "Requests that fail due to rate limits or network issues are automatically retried with increasing delays between attempts",
            "Failed requests are retried up to a maximum number of times before finally failing",
            "Users experience seamless AI interactions even when temporary API issues occur"
          ],
          "developerVisibleActions": [
            "Configure maximum retry attempts, delay timings, and backoff multipliers for API requests",
            "Specify which error types should trigger automatic retries (rate limits, timeouts, network errors)",
            "Receive callbacks on each retry attempt with attempt number and error details",
            "Get retry metadata including total number of attempts made for successful requests",
            "Classify errors as retryable or non-retryable based on error messages and codes",
            "Apply exponential backoff delays between retry attempts to avoid overwhelming services",
            "Non-retryable errors (like authentication failures) are immediately thrown without retry"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an async operation with automatic retry logic and exponential backoff",
              "inputs": "operation function to execute, retry options (maxRetries, delays, retryable errors, callback)",
              "outputs": "Promise resolving to operation result with attempt count metadata"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines if an error should trigger a retry attempt based on error type and message",
              "inputs": "error object, list of retryable error patterns",
              "outputs": "boolean indicating if the error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Provides resilience for LLM API requests by automatically retrying temporary failures like rate limits, timeouts, and network errors with exponential backoff, ensuring a more reliable AI experience without requiring user or developer intervention for transient issues",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of LLM API requests when they fail due to temporary errors like rate limits or network issues\",\n  \"userVisibleActions\": [\n    \"When an AI request fails temporarily, the system automatically retries it without user intervention\",\n    \"Requests that fail due to rate limits or network issues are automatically retried with increasing delays between attempts\",\n    \"Failed requests are retried up to a maximum number of times before finally failing\",\n    \"Users experience seamless AI interactions even when temporary API issues occur\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum retry attempts, delay timings, and backoff multipliers for API requests\",\n    \"Specify which error types should trigger automatic retries (rate limits, timeouts, network errors)\",\n    \"Receive callbacks on each retry attempt with attempt number and error details\",\n    \"Get retry metadata including total number of attempts made for successful requests\",\n    \"Classify errors as retryable or non-retryable based on error messages and codes\",\n    \"Apply exponential backoff delays between retry attempts to avoid overwhelming services\",\n    \"Non-retryable errors (like authentication failures) are immediately thrown without retry\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation function to execute, retry options (maxRetries, delays, retryable errors, callback)\",\n      \"outputs\": \"Promise resolving to operation result with attempt count metadata\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry attempt based on error type and message\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating if the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API requests by automatically retrying temporary failures like rate limits, timeouts, and network errors with exponential backoff, ensuring a more reliable AI experience without requiring user or developer intervention for transient issues\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Connect to multiple AI language model providers (OpenAI GPT-4, Anthropic Claude) through a unified interface",
        "Generate text responses from AI models based on user prompts and system instructions",
        "Request structured JSON outputs from AI providers following specific schemas for automated data processing",
        "Automatically manage AI provider instances ensuring single instance per provider type",
        "Validate AI provider availability and credential configuration before use",
        "Support streaming responses for real-time AI text generation",
        "Configure and switch between different AI providers based on user preferences",
        "Handle provider-specific token limits and model configurations (Claude: 8192 tokens output, GPT-4 models)"
      ],
      "summary": "This module provides a unified abstraction layer for integrating multiple AI language model providers into the application. Users can interact with different AI services (OpenAI's GPT models and Anthropic's Claude models) through a consistent interface without needing to understand provider-specific implementations. The module handles provider selection, credential validation, and instance management automatically based on user configuration.\n\nUsers can generate both free-form text responses and structured JSON outputs from AI models, enabling both conversational AI features and automated data processing workflows. The factory pattern ensures efficient resource usage by maintaining single instances of each provider, while the common interface allows seamless switching between providers. The module supports advanced features like streaming responses for real-time interaction and system prompts for guiding AI behavior, making it suitable for a wide range of AI-powered features within the extension.",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system",
          "userVisibleActions": [
            "Receives AI-generated text responses from different language model providers",
            "Gets structured JSON data from AI providers for automated processing",
            "System checks if an AI provider is available before attempting to use it"
          ],
          "developerVisibleActions": [
            "Implement this interface to add support for new LLM providers",
            "Send text prompts to AI providers and receive formatted responses",
            "Request structured JSON output from AI models with optional schema validation",
            "Configure provider-specific settings like model, temperature, and token limits",
            "Handle system prompts, conversation history, and response formatting",
            "Request file searches or grep operations from AI providers as follow-up actions"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if the provider has valid credentials and is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating if provider is configured"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt to the AI provider and receives a text response",
              "inputs": "LLMRequestOptions with messages, model settings, temperature, and token limits",
              "outputs": "LLMResponse with generated text content and metadata"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt expecting structured JSON output with optional follow-up requests",
              "inputs": "LLMRequestOptions and optional schema for validation",
              "outputs": "StructuredOutputResponse with parsed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the provider's identifying name",
              "inputs": "none",
              "outputs": "string name of the provider"
            }
          ],
          "dependencies": [],
          "intent": "This interface exists to abstract away differences between AI provider APIs (OpenAI, Anthropic Claude, custom endpoints) so the application can work with multiple LLM services interchangeably. It standardizes how the system communicates with different AI providers, enabling provider switching without code changes and supporting both conversational and structured data extraction use cases.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses from different language model providers\",\n    \"Gets structured JSON data from AI providers for automated processing\",\n    \"System checks if an AI provider is available before attempting to use it\"\n  ],\n  \"developerVisibleActions\": [\n    \"Implement this interface to add support for new LLM providers\",\n    \"Send text prompts to AI providers and receive formatted responses\",\n    \"Request structured JSON output from AI models with optional schema validation\",\n    \"Configure provider-specific settings like model, temperature, and token limits\",\n    \"Handle system prompts, conversation history, and response formatting\",\n    \"Request file searches or grep operations from AI providers as follow-up actions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has valid credentials and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the AI provider and receives a text response\",\n      \"inputs\": \"LLMRequestOptions with messages, model settings, temperature, and token limits\",\n      \"outputs\": \"LLMResponse with generated text content and metadata\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt expecting structured JSON output with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional schema for validation\",\n      \"outputs\": \"StructuredOutputResponse with parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider's identifying name\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string name of the provider\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between AI provider APIs (OpenAI, Anthropic Claude, custom endpoints) so the application can work with multiple LLM services interchangeably. It standardizes how the system communicates with different AI providers, enabling provider switching without code changes and supporting both conversational and structured data extraction use cases.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides an interface to Anthropic's Claude AI model for generating text responses and structured JSON outputs within the extension",
          "userVisibleActions": [
            "Sends prompts to Claude AI and receives text responses",
            "Generates structured JSON outputs from Claude based on schemas",
            "Uses Claude models (like claude-sonnet-4-5) for AI-powered features",
            "Experiences AI responses with up to 8192 tokens of output",
            "May see errors if Claude API key is not configured"
          ],
          "developerVisibleActions": [
            "Configure Claude API key through extension settings to enable the provider",
            "Send text prompts with system prompts and conversation history to Claude",
            "Request structured JSON outputs by providing schemas and instructions",
            "Handle automatic JSON extraction from Claude responses",
            "Receive error messages when API key is missing or invalid",
            "Use consistent provider interface compatible with other LLM providers"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is configured and client is ready",
              "inputs": "none",
              "outputs": "boolean indicating if provider is ready to use"
            },
            {
              "name": "getName",
              "desc": "Returns the identifier name for this provider",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a text prompt to Claude and returns the response",
              "inputs": "LLMRequestOptions (messages, model, system prompt, max tokens)",
              "outputs": "LLMResponse with generated text and token counts"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Requests structured JSON output from Claude based on a schema",
              "inputs": "LLMRequestOptions with schema and output instructions",
              "outputs": "StructuredOutputResponse with parsed JSON object"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Anthropic client with API key from configuration",
              "inputs": "none (reads from config manager)",
              "outputs": "void (initializes client or sets to null)"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "ILLMProvider",
            "configurationManager",
            "jsonExtractor"
          ],
          "intent": "This file exists to integrate Anthropic's Claude AI models into the extension, providing an implementation of the LLM provider interface that handles Claude-specific message formatting, API communication, and JSON response parsing while maintaining compatibility with the extension's provider abstraction layer.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides an interface to Anthropic's Claude AI model for generating text responses and structured JSON outputs within the extension\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives text responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Uses Claude models (like claude-sonnet-4-5) for AI-powered features\",\n    \"Experiences AI responses with up to 8192 tokens of output\",\n    \"May see errors if Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through extension settings to enable the provider\",\n    \"Send text prompts with system prompts and conversation history to Claude\",\n    \"Request structured JSON outputs by providing schemas and instructions\",\n    \"Handle automatic JSON extraction from Claude responses\",\n    \"Receive error messages when API key is missing or invalid\",\n    \"Use consistent provider interface compatible with other LLM providers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and client is ready\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name for this provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text prompt to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions (messages, model, system prompt, max tokens)\",\n      \"outputs\": \"LLMResponse with generated text and token counts\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests structured JSON output from Claude based on a schema\",\n      \"inputs\": \"LLMRequestOptions with schema and output instructions\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON object\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"void (initializes client or sets to null)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to integrate Anthropic's Claude AI models into the extension, providing an implementation of the LLM provider interface that handles Claude-specific message formatting, API communication, and JSON response parsing while maintaining compatibility with the extension's provider abstraction layer.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application",
          "userVisibleActions": [
            "Receives AI-generated text responses to user prompts",
            "Gets structured JSON responses when requesting formatted data",
            "Experiences AI conversation with system prompts guiding behavior",
            "Receives streaming responses for real-time AI text generation"
          ],
          "developerVisibleActions": [
            "Configure OpenAI API key through configuration manager",
            "Send chat completion requests with custom models and prompts",
            "Request structured JSON outputs from AI responses",
            "Stream AI responses in real-time chunks",
            "Check if OpenAI provider is properly configured before use",
            "Handle API errors and timeout scenarios (5 minute timeout)",
            "Extract JSON from AI responses that may contain markdown formatting"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if OpenAI API key is set and client is ready",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "none",
              "outputs": "string 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a chat completion request to OpenAI and returns the response",
              "inputs": "LLMRequestOptions (model, messages, system prompt, response format)",
              "outputs": "LLMResponse with content and finish reason"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Requests a JSON-formatted response and extracts structured data",
              "inputs": "LLMRequestOptions with JSON response format",
              "outputs": "StructuredOutputResponse with parsed JSON data"
            },
            {
              "name": "streamRequest",
              "desc": "Streams AI responses in real-time chunks as they are generated",
              "inputs": "LLMRequestOptions and callback function for each chunk",
              "outputs": "complete response content after streaming finishes"
            }
          ],
          "dependencies": [
            "openai",
            "ILLMProvider",
            "configurationManager",
            "jsonExtractor"
          ],
          "intent": "This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses to user prompts\",\n    \"Gets structured JSON responses when requesting formatted data\",\n    \"Experiences AI conversation with system prompts guiding behavior\",\n    \"Receives streaming responses for real-time AI text generation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager\",\n    \"Send chat completion requests with custom models and prompts\",\n    \"Request structured JSON outputs from AI responses\",\n    \"Stream AI responses in real-time chunks\",\n    \"Check if OpenAI provider is properly configured before use\",\n    \"Handle API errors and timeout scenarios (5 minute timeout)\",\n    \"Extract JSON from AI responses that may contain markdown formatting\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI API key is set and client is ready\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, system prompt, response format)\",\n      \"outputs\": \"LLMResponse with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Requests a JSON-formatted response and extracts structured data\",\n      \"inputs\": \"LLMRequestOptions with JSON response format\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams AI responses in real-time chunks as they are generated\",\n      \"inputs\": \"LLMRequestOptions and callback function for each chunk\",\n      \"outputs\": \"complete response content after streaming finishes\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Creates and manages AI provider instances (OpenAI or Claude) based on configuration, ensuring only one instance of each provider exists at a time.",
          "userVisibleActions": [
            "Automatically switches between OpenAI and Claude AI providers based on user configuration",
            "Validates that the selected AI provider has valid credentials before use",
            "Shows only configured AI providers as available options"
          ],
          "developerVisibleActions": [
            "Provides a single factory to access any AI provider without managing instances directly",
            "Ensures singleton pattern for each provider type to avoid duplicate connections",
            "Exposes methods to check provider configuration status before attempting AI operations",
            "Returns list of all properly configured providers for UI display"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns the provider instance for a specific AI service (openai or claude)",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the currently active AI provider based on user configuration",
              "inputs": "none",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks if a specific AI provider has valid configuration and credentials",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "boolean (true if configured)"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns list of all AI providers that are properly configured and ready to use",
              "inputs": "none",
              "outputs": "array of provider names ['openai', 'claude']"
            }
          ],
          "dependencies": [
            "ILLMProvider",
            "OpenAIProvider",
            "AnthropicProvider",
            "configurationManager"
          ],
          "intent": "Centralizes AI provider creation and lifecycle management, ensuring developers don't need to manually instantiate or track provider instances, and providing a single point to query provider availability and configuration status.",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI provider instances (OpenAI or Claude) based on configuration, ensuring only one instance of each provider exists at a time.\",\n  \"userVisibleActions\": [\n    \"Automatically switches between OpenAI and Claude AI providers based on user configuration\",\n    \"Validates that the selected AI provider has valid credentials before use\",\n    \"Shows only configured AI providers as available options\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a single factory to access any AI provider without managing instances directly\",\n    \"Ensures singleton pattern for each provider type to avoid duplicate connections\",\n    \"Exposes methods to check provider configuration status before attempting AI operations\",\n    \"Returns list of all properly configured providers for UI display\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the provider instance for a specific AI service (openai or claude)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the currently active AI provider based on user configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific AI provider has valid configuration and credentials\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean (true if configured)\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all AI providers that are properly configured and ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"array of provider names ['openai', 'claude']\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and lifecycle management, ensuring developers don't need to manually instantiate or track provider instances, and providing a single point to query provider availability and configuration status.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Deep code analysis through Abstract Syntax Tree (AST) parsing to extract comprehensive function metadata",
        "Function signature and dependency extraction for refactoring analysis",
        "Control flow and execution path analysis to identify code complexity",
        "Behavioral pattern recognition to classify function purposes (validation, transformation, API calls, etc.)",
        "State mutation and side effect detection across functions",
        "Large file analysis to identify refactoring candidates and their relationships",
        "Dependency graph generation showing function interdependencies"
      ],
      "summary": "The analysis module provides comprehensive code intelligence capabilities that help developers understand, refactor, and improve their codebase. It performs deep static analysis on source code files by parsing their Abstract Syntax Trees to extract detailed information about functions, their behaviors, complexities, and relationships.\n\nUsers can analyze individual functions or entire large files to receive insights about code structure, control flow branches, dependencies, and behavioral patterns. The module identifies what functions do (such as validation, transformation, or API interactions), how they modify application state, and which external dependencies they rely on. This information is particularly valuable for automated refactoring workflows, where understanding function responsibilities and their dependency chains is critical.\n\nThe module supports refactoring decisions by highlighting which functions in large files need attention, showing their signatures, listing their dependencies (both incoming and outgoing), and providing behavioral hints. This enables developers to make informed decisions about code splitting, function extraction, and architectural improvements while understanding the full impact of potential changes.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed function metadata, control flow branches, dependencies, and behavioral patterns from source code files.",
          "userVisibleActions": [
            "Receives detailed analysis of code functions including their complexity, dependencies, and behavior patterns",
            "Gets insights into how functions modify state and interact with external dependencies",
            "Views control flow analysis showing different execution paths and branches in code",
            "Sees behavioral hints about what functions do (e.g., validation, transformation, API calls)"
          ],
          "developerVisibleActions": [
            "Calls analyzeFileMetadata() to analyze an entire file and get metadata for all functions",
            "Receives structured FunctionMetadata objects containing branches, dependencies, state mutations, and behavioral hints",
            "Gets TypeScript/JavaScript AST-based analysis for deeper insights compared to regex-based analysis",
            "Accesses branch information showing conditional logic paths and complexity metrics",
            "Retrieves dependency information showing external module usage and side effects",
            "Obtains state mutation tracking showing what variables and properties are modified",
            "Receives behavioral hints categorizing function purposes (validators, transformers, API handlers, etc.)"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes all functions in a file and returns detailed metadata for each",
              "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
              "outputs": "Map<string, FunctionMetadata> containing analysis results for each function"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis on TypeScript/JavaScript functions for detailed insights",
              "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
              "outputs": "FunctionMetadata with branches, dependencies, mutations, and behavioral hints"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Fallback analysis method using pattern matching for non-TypeScript languages",
              "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
              "outputs": "FunctionMetadata with basic analysis from regex patterns"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the source code content for a specific function by line numbers",
              "inputs": "content (string), startLine (number), endLine (number)",
              "outputs": "String containing the function's source code"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)"
          ],
          "intent": "This file exists to provide advanced code intelligence beyond basic parsing. It solves the problem of understanding code behavior at a semantic level by analyzing control flow, tracking state changes, identifying dependencies, and categorizing function purposes. This enables smarter test generation, documentation creation, and code understanding tools.",
          "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed function metadata, control flow branches, dependencies, and behavioral patterns from source code files.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including their complexity, dependencies, and behavior patterns\",\n    \"Gets insights into how functions modify state and interact with external dependencies\",\n    \"Views control flow analysis showing different execution paths and branches in code\",\n    \"Sees behavioral hints about what functions do (e.g., validation, transformation, API calls)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFileMetadata() to analyze an entire file and get metadata for all functions\",\n    \"Receives structured FunctionMetadata objects containing branches, dependencies, state mutations, and behavioral hints\",\n    \"Gets TypeScript/JavaScript AST-based analysis for deeper insights compared to regex-based analysis\",\n    \"Accesses branch information showing conditional logic paths and complexity metrics\",\n    \"Retrieves dependency information showing external module usage and side effects\",\n    \"Obtains state mutation tracking showing what variables and properties are modified\",\n    \"Receives behavioral hints categorizing function purposes (validators, transformers, API handlers, etc.)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes all functions in a file and returns detailed metadata for each\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing analysis results for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions for detailed insights\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata with branches, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Fallback analysis method using pattern matching for non-TypeScript languages\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata with basic analysis from regex patterns\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content for a specific function by line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)\"\n  ],\n  \"intent\": \"This file exists to provide advanced code intelligence beyond basic parsing. It solves the problem of understanding code behavior at a semantic level by analyzing control flow, tracking state changes, identifying dependencies, and categorizing function purposes. This enables smarter test generation, documentation creation, and code understanding tools.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Extracts detailed function information from large code files to support automated refactoring analysis and reporting.",
          "userVisibleActions": [
            "Receives analysis reports showing which functions in large files need refactoring",
            "Gets function signatures, dependencies, and responsibilities listed in refactoring suggestions",
            "Views which functions depend on or are depended upon by target functions"
          ],
          "developerVisibleActions": [
            "Calls analyzeFunctions() to scan large files and extract function metadata for refactoring reports",
            "Processes function signatures, dependencies, and call relationships from TypeScript source files",
            "Integrates with existing CodeAnalysis infrastructure to build comprehensive function analysis",
            "Filters files by size threshold to focus refactoring efforts on large files",
            "Receives FunctionAnalysis objects containing function details, dependencies, and responsibilities"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in files exceeding a size threshold and returns detailed function information",
              "inputs": "CodeAnalysis object, optional size threshold in lines (default 500)",
              "outputs": "Array of FunctionAnalysis objects containing function details"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs deep analysis on a single function to extract its signature, dependencies, and relationships",
              "inputs": "File path, FunctionInfo object, CodeAnalysis context",
              "outputs": "FunctionAnalysis object or null if analysis fails"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves relative file paths to absolute paths for file access",
              "inputs": "File path string, CodeAnalysis context",
              "outputs": "Resolved absolute file path"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to support automated code refactoring by extracting detailed function-level information from large files, enabling the system to understand function boundaries, dependencies, and responsibilities to generate meaningful refactoring recommendations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Extracts detailed function information from large code files to support automated refactoring analysis and reporting.\",\n  \"userVisibleActions\": [\n    \"Receives analysis reports showing which functions in large files need refactoring\",\n    \"Gets function signatures, dependencies, and responsibilities listed in refactoring suggestions\",\n    \"Views which functions depend on or are depended upon by target functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to scan large files and extract function metadata for refactoring reports\",\n    \"Processes function signatures, dependencies, and call relationships from TypeScript source files\",\n    \"Integrates with existing CodeAnalysis infrastructure to build comprehensive function analysis\",\n    \"Filters files by size threshold to focus refactoring efforts on large files\",\n    \"Receives FunctionAnalysis objects containing function details, dependencies, and responsibilities\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files exceeding a size threshold and returns detailed function information\",\n      \"inputs\": \"CodeAnalysis object, optional size threshold in lines (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing function details\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs deep analysis on a single function to extract its signature, dependencies, and relationships\",\n      \"inputs\": \"File path, FunctionInfo object, CodeAnalysis context\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file access\",\n      \"inputs\": \"File path string, CodeAnalysis context\",\n      \"outputs\": \"Resolved absolute file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to support automated code refactoring by extracting detailed function-level information from large files, enabling the system to understand function boundaries, dependencies, and responsibilities to generate meaningful refactoring recommendations.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "Automated code analysis and structure extraction from entire codebase or individual files",
        "Interactive tree view navigation of code architecture, dependencies, and entry points",
        "AI-powered code insights generation with severity-based categorization and recommendations",
        "Real-time diagnostics display showing code quality issues as inline squiggles and problem panel entries",
        "LLM-assisted documentation generation for files, modules, and product-level architecture",
        "Code quality monitoring with detection of large files, orphaned code, circular dependencies, and complexity issues",
        "Persistent caching of analysis results with automatic 24-hour expiration",
        "File watching with automatic re-analysis on save",
        "Multiple export formats (Markdown, JSON) optimized for different LLM tools (Cursor, ChatGPT)",
        "Test coverage mapping and unit test navigation",
        "Grep-based code search for pattern discovery",
        "Structured documentation hierarchy from file-level to product-level"
      ],
      "summary": "The src module provides a comprehensive VS Code extension for intelligent code analysis and documentation. It combines static code analysis with AI-powered insights to help developers understand, navigate, and improve their codebase. The extension analyzes code structure, extracts dependencies, identifies entry points, and detects quality issues like complexity, orphaned files, and circular dependencies.\n\nUsers interact with the analysis through multiple integrated views: a tree-based code structure browser, an insights panel showing categorized issues with severity levels, and inline diagnostics that appear as squiggly underlines in the editor. The extension supports both manual and automatic analysis workflows, with file watching capabilities that trigger re-analysis on save. Analysis results are cached for 24 hours to provide instant access when reopening workspaces.\n\nThe module leverages LLM services (OpenAI/Claude) to generate intelligent documentation at file, module, and product levels. It formats analysis results in multiple ways optimized for different AI assistants, provides structured schemas for consistent LLM responses, and offers grep-based search capabilities for iterative code exploration. All user actionsfrom viewing insights to generating documentationare logged with timestamps for debugging and audit purposes.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view interface in VSCode's sidebar to browse and navigate code analysis results organized by files, functions, dependencies, and entry points.",
          "userVisibleActions": [
            "View a tree structure showing code analysis results in the sidebar",
            "See summary statistics (total files, functions, dependencies, entry points)",
            "Browse files organized by directory structure",
            "Expand files to see their functions, imports, and exports",
            "View function details including parameters and complexity metrics",
            "See detected entry points in the codebase",
            "Click on items to jump to specific code locations in the editor",
            "View complexity warnings and dependency information",
            "See file roles (config, test, component, etc.) with icons",
            "Navigate through nested directory structures",
            "View 'No analysis available' message when no analysis has been run"
          ],
          "developerVisibleActions": [
            "Tree view populates with code analysis data after running workspace analysis",
            "Analysis results are displayed in a hierarchical tree structure",
            "Files are grouped by directory with appropriate icons and counts",
            "Functions show their signatures, line counts, and complexity scores",
            "Entry points are listed with their types (HTTP, CLI, event handlers, etc.)",
            "Dependencies show import/export relationships between files",
            "Items are clickable and navigate to corresponding code locations",
            "Tree automatically refreshes when new analysis data is provided",
            "Complex functions (complexity > 10) are flagged with warning icons"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the tree view with new analysis results",
              "inputs": "CodeAnalysis object or null",
              "outputs": "void (triggers tree refresh)"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the tree item representation for display",
              "inputs": "AnalysisItem element",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node or root items if no element provided",
              "inputs": "optional AnalysisItem element",
              "outputs": "Promise<AnalysisItem[]>"
            },
            {
              "name": "getRootItems",
              "desc": "Creates the top-level tree items (statistics, files, functions, dependencies, entry points)",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Creates tree items showing analysis statistics counts",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getFilesItems",
              "desc": "Creates tree items for files and directories organized hierarchically",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getFileDetails",
              "desc": "Creates tree items showing details of a specific file (functions, imports, exports)",
              "inputs": "AnalysisItem representing a file",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getFunctionsItems",
              "desc": "Creates tree items listing all functions across the codebase",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getDependenciesItems",
              "desc": "Creates tree items showing file dependency relationships",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "getEntryPointsItems",
              "desc": "Creates tree items for detected application entry points",
              "inputs": "none",
              "outputs": "AnalysisItem[] array"
            },
            {
              "name": "createFileLocation",
              "desc": "Creates a vscode.Location object for navigating to specific code positions",
              "inputs": "file path, optional line/column numbers",
              "outputs": "vscode.Location object"
            }
          ],
          "dependencies": [
            "vscode",
            "CodeAnalysis (from ./analyzer)",
            "FileInfo (from ./analyzer)",
            "FunctionInfo (from ./analyzer)",
            "EntryPoint (from ./analyzer)",
            "path"
          ],
          "intent": "This file exists to provide a visual, navigable tree interface for developers to explore code analysis results, making it easy to understand codebase structure, identify entry points, review function complexity, and navigate to specific code locations directly from the analysis view.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface in VSCode's sidebar to browse and navigate code analysis results organized by files, functions, dependencies, and entry points.\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code analysis results in the sidebar\",\n    \"See summary statistics (total files, functions, dependencies, entry points)\",\n    \"Browse files organized by directory structure\",\n    \"Expand files to see their functions, imports, and exports\",\n    \"View function details including parameters and complexity metrics\",\n    \"See detected entry points in the codebase\",\n    \"Click on items to jump to specific code locations in the editor\",\n    \"View complexity warnings and dependency information\",\n    \"See file roles (config, test, component, etc.) with icons\",\n    \"Navigate through nested directory structures\",\n    \"View 'No analysis available' message when no analysis has been run\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view populates with code analysis data after running workspace analysis\",\n    \"Analysis results are displayed in a hierarchical tree structure\",\n    \"Files are grouped by directory with appropriate icons and counts\",\n    \"Functions show their signatures, line counts, and complexity scores\",\n    \"Entry points are listed with their types (HTTP, CLI, event handlers, etc.)\",\n    \"Dependencies show import/export relationships between files\",\n    \"Items are clickable and navigate to corresponding code locations\",\n    \"Tree automatically refreshes when new analysis data is provided\",\n    \"Complex functions (complexity > 10) are flagged with warning icons\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void (triggers tree refresh)\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"optional AnalysisItem element\",\n      \"outputs\": \"Promise<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Creates the top-level tree items (statistics, files, functions, dependencies, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing analysis statistics counts\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Creates tree items for files and directories organized hierarchically\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Creates tree items showing details of a specific file (functions, imports, exports)\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFunctionsItems\",\n      \"desc\": \"Creates tree items listing all functions across the codebase\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getDependenciesItems\",\n      \"desc\": \"Creates tree items showing file dependency relationships\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getEntryPointsItems\",\n      \"desc\": \"Creates tree items for detected application entry points\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"createFileLocation\",\n      \"desc\": \"Creates a vscode.Location object for navigating to specific code positions\",\n      \"inputs\": \"file path, optional line/column numbers\",\n      \"outputs\": \"vscode.Location object\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalysis (from ./analyzer)\",\n    \"FileInfo (from ./analyzer)\",\n    \"FunctionInfo (from ./analyzer)\",\n    \"EntryPoint (from ./analyzer)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide a visual, navigable tree interface for developers to explore code analysis results, making it easy to understand codebase structure, identify entry points, review function complexity, and navigate to specific code locations directly from the analysis view.\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code files to extract structure, dependencies, functions, and relationships for codebase understanding and visualization",
          "userVisibleActions": [
            "View total file count, line count, and function count statistics",
            "See list of large files that may need refactoring",
            "View all functions with their metadata and locations",
            "See import relationships between files",
            "Identify orphaned files not imported by others",
            "Find entry points (files not importing others)",
            "Detect duplicate code blocks across the codebase",
            "View risk levels (high/medium/low) for functions",
            "See test coverage mapping for source files and functions",
            "Identify uncovered functions without tests"
          ],
          "developerVisibleActions": [
            "Call analyzer to scan directory and extract code structure",
            "Get structured data about functions including parameters, return types, visibility",
            "Access function dependencies (database, HTTP, filesystem, etc.)",
            "Retrieve branch information (if/else, loops, try/catch)",
            "Track state mutations (assignments, modifications, deletions)",
            "Query import/export relationships between files",
            "Use caching system to speed up repeated analysis",
            "Map test files to source files they test",
            "Filter analysis results by file type or pattern",
            "Export analysis results in structured format"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main data structure containing complete analysis results",
              "inputs": "N/A (interface)",
              "outputs": "Object with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping, etc."
            },
            {
              "name": "FunctionMetadata",
              "desc": "Detailed metadata about a single function",
              "inputs": "N/A (interface)",
              "outputs": "Object with symbolName, parameters, returnType, visibility, branches, dependencies, riskLevel, docstring"
            },
            {
              "name": "BranchInfo",
              "desc": "Information about conditional branches and control flow",
              "inputs": "N/A (interface)",
              "outputs": "Object with type (if/loop/try/etc), condition description, lineNumber"
            },
            {
              "name": "DependencyInfo",
              "desc": "Tracks external and internal dependencies",
              "inputs": "N/A (interface)",
              "outputs": "Object with dependency name, type (db/http/filesystem/etc), isInternal flag"
            },
            {
              "name": "StateMutationInfo",
              "desc": "Tracks where and how state is modified",
              "inputs": "N/A (interface)",
              "outputs": "Object with target name, mutationType (assign/modify/delete/read), lineNumber"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source files and functions to their test files",
              "inputs": "N/A (interface)",
              "outputs": "Object with sourceFileToTests map, functionToTests map, uncoveredFunctions list"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache (AnalysisCache)"
          ],
          "intent": "This file defines the core data structures and interfaces for code analysis results. It exists to provide a standardized way to represent codebase structure, function metadata, dependencies, test coverage, and code quality metrics. Developers use these interfaces to understand code relationships, identify technical debt, assess risk, and improve test coverage.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code files to extract structure, dependencies, functions, and relationships for codebase understanding and visualization\",\n  \"userVisibleActions\": [\n    \"View total file count, line count, and function count statistics\",\n    \"See list of large files that may need refactoring\",\n    \"View all functions with their metadata and locations\",\n    \"See import relationships between files\",\n    \"Identify orphaned files not imported by others\",\n    \"Find entry points (files not importing others)\",\n    \"Detect duplicate code blocks across the codebase\",\n    \"View risk levels (high/medium/low) for functions\",\n    \"See test coverage mapping for source files and functions\",\n    \"Identify uncovered functions without tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzer to scan directory and extract code structure\",\n    \"Get structured data about functions including parameters, return types, visibility\",\n    \"Access function dependencies (database, HTTP, filesystem, etc.)\",\n    \"Retrieve branch information (if/else, loops, try/catch)\",\n    \"Track state mutations (assignments, modifications, deletions)\",\n    \"Query import/export relationships between files\",\n    \"Use caching system to speed up repeated analysis\",\n    \"Map test files to source files they test\",\n    \"Filter analysis results by file type or pattern\",\n    \"Export analysis results in structured format\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main data structure containing complete analysis results\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping, etc.\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with symbolName, parameters, returnType, visibility, branches, dependencies, riskLevel, docstring\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Information about conditional branches and control flow\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with type (if/loop/try/etc), condition description, lineNumber\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Tracks external and internal dependencies\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with dependency name, type (db/http/filesystem/etc), isInternal flag\"\n    },\n    {\n      \"name\": \"StateMutationInfo\",\n      \"desc\": \"Tracks where and how state is modified\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with target name, mutationType (assign/modify/delete/read), lineNumber\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their test files\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with sourceFileToTests map, functionToTests map, uncoveredFunctions list\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file defines the core data structures and interfaces for code analysis results. It exists to provide a standardized way to represent codebase structure, function metadata, dependencies, test coverage, and code quality metrics. Developers use these interfaces to understand code relationships, identify technical debt, assess risk, and improve test coverage.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration after 24 hours",
          "userVisibleActions": [
            "Analysis results are loaded instantly when reopening a previously analyzed workspace",
            "Analysis results become stale and are automatically refreshed after 24 hours",
            "Cache storage is automatically created in the workspace on first use",
            "Old analysis data can be cleared to free up disk space"
          ],
          "developerVisibleActions": [
            "Store code analysis results to disk for future retrieval",
            "Retrieve previously cached analysis results for a workspace",
            "Clear all cached analysis data across workspaces",
            "Invalidate outdated cache entries automatically after 24 hours",
            "Generate unique cache keys for different workspace paths"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes the cache manager with a storage location",
              "inputs": "storagePath (string) - base directory for cache storage",
              "outputs": "AnalysisCache instance"
            },
            {
              "name": "getCacheKey",
              "desc": "Converts a workspace path into a safe filename for cache storage",
              "inputs": "workspaceRoot (string) - workspace directory path",
              "outputs": "string - base64-encoded safe filename"
            },
            {
              "name": "get",
              "desc": "Retrieves cached analysis results if they exist and are not expired",
              "inputs": "workspaceRoot (string) - workspace directory path",
              "outputs": "Promise<CodeAnalysis | null> - cached analysis or null if expired/missing"
            },
            {
              "name": "set",
              "desc": "Saves analysis results to cache with current timestamp",
              "inputs": "workspaceRoot (string), data (CodeAnalysis) - workspace path and analysis to cache",
              "outputs": "Promise<void>"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis files from storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "This file exists to speed up the extension by avoiding repeated analysis of unchanged codebases. It solves the performance problem of re-analyzing large projects every time VS Code is opened by persisting analysis results to disk with a time-based expiration strategy.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration after 24 hours\",\n  \"userVisibleActions\": [\n    \"Analysis results are loaded instantly when reopening a previously analyzed workspace\",\n    \"Analysis results become stale and are automatically refreshed after 24 hours\",\n    \"Cache storage is automatically created in the workspace on first use\",\n    \"Old analysis data can be cleared to free up disk space\"\n  ],\n  \"developerVisibleActions\": [\n    \"Store code analysis results to disk for future retrieval\",\n    \"Retrieve previously cached analysis results for a workspace\",\n    \"Clear all cached analysis data across workspaces\",\n    \"Invalidate outdated cache entries automatically after 24 hours\",\n    \"Generate unique cache keys for different workspace paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the cache manager with a storage location\",\n      \"inputs\": \"storagePath (string) - base directory for cache storage\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Converts a workspace path into a safe filename for cache storage\",\n      \"inputs\": \"workspaceRoot (string) - workspace directory path\",\n      \"outputs\": \"string - base64-encoded safe filename\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results if they exist and are not expired\",\n      \"inputs\": \"workspaceRoot (string) - workspace directory path\",\n      \"outputs\": \"Promise<CodeAnalysis | null> - cached analysis or null if expired/missing\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot (string), data (CodeAnalysis) - workspace path and analysis to cache\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to speed up the extension by avoiding repeated analysis of unchanged codebases. It solves the performance problem of re-analyzing large projects every time VS Code is opened by persisting analysis results to disk with a time-based expiration strategy.\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Manages the display of code insights as inline diagnostics (squiggly underlines and problems panel entries) in the VS Code editor.",
          "userVisibleActions": [
            "See squiggly underlines in code where insights are detected",
            "View insights in the Problems panel with severity indicators (error, warning, info)",
            "Click on problems to navigate to the corresponding code location",
            "See 'Shadow Watch' as the source of diagnostic messages",
            "View insight descriptions as diagnostic messages",
            "Have diagnostics automatically cleared when insights are updated"
          ],
          "developerVisibleActions": [
            "Provide insights to be displayed as diagnostics in the editor",
            "Update diagnostics for all files or a specific file",
            "Clear all diagnostics from the Problems panel",
            "Dispose of the diagnostics collection when extension deactivates",
            "Diagnostics are automatically grouped by file",
            "Each insight is converted to a VS Code diagnostic with appropriate severity"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Updates diagnostics for all files based on provided insights",
              "inputs": "Array of Insight objects",
              "outputs": "Void - displays diagnostics in editor and Problems panel"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostics for a specific file",
              "inputs": "File URI and array of Insight objects for that file",
              "outputs": "Void - displays diagnostics for the specified file"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostics from the editor and Problems panel",
              "inputs": "None",
              "outputs": "Void"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts an insight into a VS Code diagnostic with severity, message, and location",
              "inputs": "Insight object",
              "outputs": "VS Code Diagnostic object"
            },
            {
              "name": "dispose",
              "desc": "Cleans up the diagnostics collection when no longer needed",
              "inputs": "None",
              "outputs": "Void"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "This file exists to bridge the gap between Shadow Watch's insight generation system and VS Code's native diagnostics UI. It translates insights into the standard VS Code problems/diagnostics format so users can see issues directly in their code with familiar VS Code UI patterns (squiggles, Problems panel). It solves the problem of how to visually communicate detected insights to users in an intuitive, IDE-native way.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages the display of code insights as inline diagnostics (squiggly underlines and problems panel entries) in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"See squiggly underlines in code where insights are detected\",\n    \"View insights in the Problems panel with severity indicators (error, warning, info)\",\n    \"Click on problems to navigate to the corresponding code location\",\n    \"See 'Shadow Watch' as the source of diagnostic messages\",\n    \"View insight descriptions as diagnostic messages\",\n    \"Have diagnostics automatically cleared when insights are updated\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provide insights to be displayed as diagnostics in the editor\",\n    \"Update diagnostics for all files or a specific file\",\n    \"Clear all diagnostics from the Problems panel\",\n    \"Dispose of the diagnostics collection when extension deactivates\",\n    \"Diagnostics are automatically grouped by file\",\n    \"Each insight is converted to a VS Code diagnostic with appropriate severity\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates diagnostics for all files based on provided insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"Void - displays diagnostics in editor and Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file\",\n      \"inputs\": \"File URI and array of Insight objects for that file\",\n      \"outputs\": \"Void - displays diagnostics for the specified file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the editor and Problems panel\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic with severity, message, and location\",\n      \"inputs\": \"Insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up the diagnostics collection when no longer needed\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between Shadow Watch's insight generation system and VS Code's native diagnostics UI. It translates insights into the standard VS Code problems/diagnostics format so users can see issues directly in their code with familiar VS Code UI patterns (squiggles, Problems panel). It solves the problem of how to visually communicate detected insights to users in an intuitive, IDE-native way.\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "Activates and orchestrates the VS Code extension for code analysis, providing commands, views, and integrations for analyzing codebases and generating insights.",
          "userVisibleActions": [
            "Trigger full codebase analysis through command palette or status bar",
            "Analyze currently open file for structure and insights",
            "View analyzed code insights in tree view sidebar",
            "Format analysis output for LLM consumption",
            "Navigate to specific code elements (functions, classes, entry points) from analysis views",
            "Export analysis results to markdown or JSON files",
            "View code analysis diagnostics and warnings in Problems panel",
            "Clear analysis cache to force fresh analysis",
            "View product navigation tree showing project structure",
            "View static analysis results in dedicated panel",
            "View unit tests organization in test navigator",
            "See analysis progress in status bar with clickable indicator"
          ],
          "developerVisibleActions": [
            "Extension initializes on VS Code startup and registers all commands and providers",
            "File watcher monitors workspace for changes and triggers automatic re-analysis",
            "Analysis results are cached to improve performance on subsequent requests",
            "Multiple webview providers display different aspects of analysis (insights, static analysis, unit tests)",
            "Command handlers process user actions and coordinate between analyzer, generators, and UI components",
            "Diagnostics provider updates Problems panel with code issues found during analysis",
            "Status bar item shows current analysis state and provides quick access to analysis commands",
            "Extension uses bootstrapper pattern to initialize components in correct dependency order",
            "Configuration manager provides centralized access to extension settings",
            "Error handler catches and displays user-friendly error messages for analysis failures"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Entry point that initializes the extension, sets up all providers, registers commands, and starts file watching",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "void (registers disposables in context)"
            },
            {
              "name": "deactivate",
              "desc": "Cleanup function called when extension is disabled or VS Code closes",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Analyzes entire workspace codebase and updates all views with results",
              "inputs": "none (uses workspace folders)",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeCurrentFile",
              "desc": "Analyzes the currently active editor file and displays results",
              "inputs": "none (uses active text editor)",
              "outputs": "Promise<void>"
            },
            {
              "name": "formatForLLM",
              "desc": "Formats analysis output in LLM-friendly format and displays in editor",
              "inputs": "none (uses cached analysis)",
              "outputs": "Promise<void>"
            },
            {
              "name": "exportAnalysis",
              "desc": "Exports current analysis results to file (markdown or JSON format)",
              "inputs": "format: 'markdown' | 'json'",
              "outputs": "Promise<void>"
            },
            {
              "name": "clearCache",
              "desc": "Clears analysis cache and forces fresh analysis on next request",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "navigateToElement",
              "desc": "Opens file and jumps to specific code element location from analysis view",
              "inputs": "item: TreeItem | AnalysisItem | InsightItem | StaticAnalysisItem",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./productNavigator",
            "./analysisViewer",
            "./insightsViewer",
            "./staticAnalysisViewer",
            "./unitTestsNavigator",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler"
          ],
          "intent": "This file exists as the main entry point and orchestrator for the VS Code extension. It solves the problem of coordinating multiple subsystems (analysis, UI, caching, file watching) into a cohesive user experience, registering all commands and views that users interact with, and managing the lifecycle of extension components from activation to deactivation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Activates and orchestrates the VS Code extension for code analysis, providing commands, views, and integrations for analyzing codebases and generating insights.\",\n  \"userVisibleActions\": [\n    \"Trigger full codebase analysis through command palette or status bar\",\n    \"Analyze currently open file for structure and insights\",\n    \"View analyzed code insights in tree view sidebar\",\n    \"Format analysis output for LLM consumption\",\n    \"Navigate to specific code elements (functions, classes, entry points) from analysis views\",\n    \"Export analysis results to markdown or JSON files\",\n    \"View code analysis diagnostics and warnings in Problems panel\",\n    \"Clear analysis cache to force fresh analysis\",\n    \"View product navigation tree showing project structure\",\n    \"View static analysis results in dedicated panel\",\n    \"View unit tests organization in test navigator\",\n    \"See analysis progress in status bar with clickable indicator\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension initializes on VS Code startup and registers all commands and providers\",\n    \"File watcher monitors workspace for changes and triggers automatic re-analysis\",\n    \"Analysis results are cached to improve performance on subsequent requests\",\n    \"Multiple webview providers display different aspects of analysis (insights, static analysis, unit tests)\",\n    \"Command handlers process user actions and coordinate between analyzer, generators, and UI components\",\n    \"Diagnostics provider updates Problems panel with code issues found during analysis\",\n    \"Status bar item shows current analysis state and provides quick access to analysis commands\",\n    \"Extension uses bootstrapper pattern to initialize components in correct dependency order\",\n    \"Configuration manager provides centralized access to extension settings\",\n    \"Error handler catches and displays user-friendly error messages for analysis failures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Entry point that initializes the extension, sets up all providers, registers commands, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void (registers disposables in context)\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleanup function called when extension is disabled or VS Code closes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes entire workspace codebase and updates all views with results\",\n      \"inputs\": \"none (uses workspace folders)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Analyzes the currently active editor file and displays results\",\n      \"inputs\": \"none (uses active text editor)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatForLLM\",\n      \"desc\": \"Formats analysis output in LLM-friendly format and displays in editor\",\n      \"inputs\": \"none (uses cached analysis)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportAnalysis\",\n      \"desc\": \"Exports current analysis results to file (markdown or JSON format)\",\n      \"inputs\": \"format: 'markdown' | 'json'\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears analysis cache and forces fresh analysis on next request\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"navigateToElement\",\n      \"desc\": \"Opens file and jumps to specific code element location from analysis view\",\n      \"inputs\": \"item: TreeItem | AnalysisItem | InsightItem | StaticAnalysisItem\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./staticAnalysisViewer\",\n    \"./unitTestsNavigator\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file exists as the main entry point and orchestrator for the VS Code extension. It solves the problem of coordinating multiple subsystems (analysis, UI, caching, file watching) into a cohesive user experience, registering all commands and views that users interact with, and managing the lifecycle of extension components from activation to deactivation.\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and grep search functionality to enable iterative LLM analysis of code workspaces",
          "userVisibleActions": [
            "Search for code patterns across project files using grep",
            "View file contents on demand during analysis",
            "See search results with line numbers and context",
            "Get organized file listings by folder structure"
          ],
          "developerVisibleActions": [
            "Request specific files by path to read their contents",
            "Search for text patterns across the codebase with optional file filtering",
            "Limit search results to prevent overwhelming output",
            "Receive structured responses with file paths, line numbers, and content",
            "Get file listings organized by directory with metadata (lines, language)",
            "Process batch requests for multiple files or searches",
            "Handle workspace-relative file paths automatically"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Returns organized directory structure of files",
              "inputs": "Array of file objects with path, lines, and language",
              "outputs": "Formatted string showing files grouped by folder"
            },
            {
              "name": "processRequests",
              "desc": "Handles batch file reading and grep search requests",
              "inputs": "Array of FileRequest or GrepRequest objects",
              "outputs": "Array of FileResponse or GrepResponse objects"
            },
            {
              "name": "readFile",
              "desc": "Reads a single file and returns its content with metadata",
              "inputs": "File path string",
              "outputs": "FileResponse with content, line count, and exists flag"
            },
            {
              "name": "grepFiles",
              "desc": "Searches files for text patterns with optional filtering",
              "inputs": "Search pattern, file pattern (glob), max results limit",
              "outputs": "GrepResponse with matches, line numbers, and context"
            },
            {
              "name": "getFileContent",
              "desc": "Retrieves raw file content",
              "inputs": "File path",
              "outputs": "String content or error"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to give LLMs the ability to explore codebases iteratively - instead of loading all files at once, the LLM can request specific files or search for patterns as needed during analysis, making the process more efficient and token-conscious",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative LLM analysis of code workspaces\",\n  \"userVisibleActions\": [\n    \"Search for code patterns across project files using grep\",\n    \"View file contents on demand during analysis\",\n    \"See search results with line numbers and context\",\n    \"Get organized file listings by folder structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path to read their contents\",\n    \"Search for text patterns across the codebase with optional file filtering\",\n    \"Limit search results to prevent overwhelming output\",\n    \"Receive structured responses with file paths, line numbers, and content\",\n    \"Get file listings organized by directory with metadata (lines, language)\",\n    \"Process batch requests for multiple files or searches\",\n    \"Handle workspace-relative file paths automatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Returns organized directory structure of files\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files grouped by folder\"\n    },\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Handles batch file reading and grep search requests\",\n      \"inputs\": \"Array of FileRequest or GrepRequest objects\",\n      \"outputs\": \"Array of FileResponse or GrepResponse objects\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a single file and returns its content with metadata\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"FileResponse with content, line count, and exists flag\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches files for text patterns with optional filtering\",\n      \"inputs\": \"Search pattern, file pattern (glob), max results limit\",\n      \"outputs\": \"GrepResponse with matches, line numbers, and context\"\n    },\n    {\n      \"name\": \"getFileContent\",\n      \"desc\": \"Retrieves raw file content\",\n      \"inputs\": \"File path\",\n      \"outputs\": \"String content or error\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to give LLMs the ability to explore codebases iteratively - instead of loading all files at once, the LLM can request specific files or search for patterns as needed during analysis, making the process more efficient and token-conscious\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines the structured data models and type definitions for organizing code documentation at file, module, and product levels.",
          "userVisibleActions": [
            "User can view file-level summaries showing what each code file does",
            "User can see module-level rollups grouping related files by functionality",
            "User can browse product-level documentation with architecture diagrams",
            "User can access API endpoints, CLI commands, and worker job flows",
            "User can view dependency graphs showing how components relate"
          ],
          "developerVisibleActions": [
            "Developer defines file summaries with role, purpose, and key functions",
            "Developer organizes files into modules (API, CLI, workers, core, GUI)",
            "Developer documents user-facing actions separately from internal behavior",
            "Developer creates structured metadata for endpoints, commands, and workers",
            "Developer generates product documentation with overview and architecture",
            "Developer tracks dependencies between files and components",
            "Developer stores raw LLM responses alongside structured data"
          ],
          "keyFunctions": [
            {
              "name": "FileSummary",
              "desc": "Represents a single file's documentation including role, purpose, actions, and dependencies",
              "inputs": "file path, role, purpose, actions, functions, dependencies, intent",
              "outputs": "Structured file documentation object"
            },
            {
              "name": "ModuleSummary",
              "desc": "Aggregates multiple files into a module with capabilities, endpoints, commands, or workers",
              "inputs": "module path, type, capabilities, files array, optional endpoints/commands/workers",
              "outputs": "Module-level documentation object"
            },
            {
              "name": "EnhancedProductDocumentation",
              "desc": "Top-level product documentation with overview, user perspectives, architecture, and workflow integration",
              "inputs": "overview, capabilities, user perspectives (GUI/CLI/API/CI-CD), architecture, diagrams, metadata",
              "outputs": "Complete product documentation structure"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "This file exists to establish a hierarchical documentation structure that transforms raw code analysis into user-friendly documentation at three levels: individual files, functional modules, and complete product overview. It separates user-visible behavior from developer-facing implementation details, enabling stakeholders at different levels to understand the codebase from their perspective.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the structured data models and type definitions for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"User can view file-level summaries showing what each code file does\",\n    \"User can see module-level rollups grouping related files by functionality\",\n    \"User can browse product-level documentation with architecture diagrams\",\n    \"User can access API endpoints, CLI commands, and worker job flows\",\n    \"User can view dependency graphs showing how components relate\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file summaries with role, purpose, and key functions\",\n    \"Developer organizes files into modules (API, CLI, workers, core, GUI)\",\n    \"Developer documents user-facing actions separately from internal behavior\",\n    \"Developer creates structured metadata for endpoints, commands, and workers\",\n    \"Developer generates product documentation with overview and architecture\",\n    \"Developer tracks dependencies between files and components\",\n    \"Developer stores raw LLM responses alongside structured data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"FileSummary\",\n      \"desc\": \"Represents a single file's documentation including role, purpose, actions, and dependencies\",\n      \"inputs\": \"file path, role, purpose, actions, functions, dependencies, intent\",\n      \"outputs\": \"Structured file documentation object\"\n    },\n    {\n      \"name\": \"ModuleSummary\",\n      \"desc\": \"Aggregates multiple files into a module with capabilities, endpoints, commands, or workers\",\n      \"inputs\": \"module path, type, capabilities, files array, optional endpoints/commands/workers\",\n      \"outputs\": \"Module-level documentation object\"\n    },\n    {\n      \"name\": \"EnhancedProductDocumentation\",\n      \"desc\": \"Top-level product documentation with overview, user perspectives, architecture, and workflow integration\",\n      \"inputs\": \"overview, capabilities, user perspectives (GUI/CLI/API/CI-CD), architecture, diagrams, metadata\",\n      \"outputs\": \"Complete product documentation structure\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a hierarchical documentation structure that transforms raw code analysis into user-friendly documentation at three levels: individual files, functional modules, and complete product overview. It separates user-visible behavior from developer-facing implementation details, enabling stakeholders at different levels to understand the codebase from their perspective.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file changes in the workspace and triggers automatic code analysis when files are saved",
          "userVisibleActions": [
            "Automatically analyzes code when files are saved in the editor",
            "Shows analysis progress indicator during file analysis",
            "Updates diagnostics and insights view after file changes",
            "Respects user's 'analyze on save' configuration setting"
          ],
          "developerVisibleActions": [
            "Starts/stops file watching based on configuration settings",
            "Debounces analysis requests to prevent multiple simultaneous analyses",
            "Handles document save events and triggers analysis pipeline",
            "Manages analysis state to prevent concurrent analyses",
            "Cleans up resources when stopping the watcher"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins watching for file save events if analyze-on-save is enabled",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops watching for file changes and cleans up resources",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save events and triggers debounced analysis",
              "inputs": "document (TextDocument)",
              "outputs": "Promise<void>"
            },
            {
              "name": "shouldAnalyzeFile",
              "desc": "Determines if a file should be analyzed based on file type and configuration",
              "inputs": "document (TextDocument)",
              "outputs": "boolean"
            },
            {
              "name": "triggerAnalysis",
              "desc": "Executes the full analysis pipeline for a document",
              "inputs": "document (TextDocument)",
              "outputs": "Promise<void>"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all resources and event listeners",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "ConfigurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of having to manually trigger analysis by automatically detecting file changes and running the analysis pipeline, while preventing duplicate analyses through debouncing and state management.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and triggers automatic code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when files are saved in the editor\",\n    \"Shows analysis progress indicator during file analysis\",\n    \"Updates diagnostics and insights view after file changes\",\n    \"Respects user's 'analyze on save' configuration setting\"\n  ],\n  \"developerVisibleActions\": [\n    \"Starts/stops file watching based on configuration settings\",\n    \"Debounces analysis requests to prevent multiple simultaneous analyses\",\n    \"Handles document save events and triggers analysis pipeline\",\n    \"Manages analysis state to prevent concurrent analyses\",\n    \"Cleans up resources when stopping the watcher\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events if analyze-on-save is enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file changes and cleans up resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and triggers debounced analysis\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"shouldAnalyzeFile\",\n      \"desc\": \"Determines if a file should be analyzed based on file type and configuration\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline for a document\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all resources and event listeners\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of having to manually trigger analysis by automatically detecting file changes and running the analysis pipeline, while preventing duplicate analyses through debouncing and state management.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Generates code quality insights and recommendations by analyzing code files for issues like large files, orphaned code, circular dependencies, and complexity problems.",
          "userVisibleActions": [
            "Displays warnings when files exceed 500 lines of code",
            "Shows alerts for orphaned files that aren't imported anywhere",
            "Highlights missing entry points in the project",
            "Reports potential circular dependency issues",
            "Identifies 'god objects' (files with too many exports or responsibilities)",
            "Flags potential dead code that may not be used",
            "Provides file organization recommendations",
            "Reports overly complex functions that need refactoring",
            "Shows code snippets with specific issues",
            "Displays severity levels (error, warning, info) for each insight",
            "Provides actionable suggestions for fixing each issue"
          ],
          "developerVisibleActions": [
            "Call generateInsights() with code analysis to get all insights for a project",
            "Call generateInsightsForFile() to get insights for a specific file path",
            "Receive structured Insight objects containing id, title, description, severity, category, file location, line number, suggestion, and optional code snippet",
            "Use insights to improve code quality through automated analysis",
            "Filter insights by severity (error, warning, info) or category",
            "Integrate insight generation into code review or CI/CD workflows"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Analyzes entire codebase and returns all quality insights",
              "inputs": "CodeAnalysis object containing file and function information",
              "outputs": "Array of Insight objects with detected issues and recommendations"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Analyzes a specific file and returns insights only for that file",
              "inputs": "CodeAnalysis object and file path string",
              "outputs": "Array of Insight objects specific to the requested file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Detects files exceeding recommended line count",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for large files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Finds files that aren't imported or used anywhere",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for orphaned files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Verifies project has proper entry points",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Detects potential circular import dependencies",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for circular dependencies"
            },
            {
              "name": "checkGodObjects",
              "desc": "Identifies files with too many responsibilities or exports",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for god objects"
            },
            {
              "name": "checkDeadCode",
              "desc": "Finds code that may not be actively used",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for potential dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Evaluates project structure and organization",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for organization issues"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Analyzes function complexity and size",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for overly complex functions"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to provide automated code quality analysis and actionable recommendations to developers. It solves the problem of manually identifying code smells, architectural issues, and maintainability concerns by automatically scanning code and generating structured insights with severity levels, categories, and improvement suggestions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates code quality insights and recommendations by analyzing code files for issues like large files, orphaned code, circular dependencies, and complexity problems.\",\n  \"userVisibleActions\": [\n    \"Displays warnings when files exceed 500 lines of code\",\n    \"Shows alerts for orphaned files that aren't imported anywhere\",\n    \"Highlights missing entry points in the project\",\n    \"Reports potential circular dependency issues\",\n    \"Identifies 'god objects' (files with too many exports or responsibilities)\",\n    \"Flags potential dead code that may not be used\",\n    \"Provides file organization recommendations\",\n    \"Reports overly complex functions that need refactoring\",\n    \"Shows code snippets with specific issues\",\n    \"Displays severity levels (error, warning, info) for each insight\",\n    \"Provides actionable suggestions for fixing each issue\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateInsights() with code analysis to get all insights for a project\",\n    \"Call generateInsightsForFile() to get insights for a specific file path\",\n    \"Receive structured Insight objects containing id, title, description, severity, category, file location, line number, suggestion, and optional code snippet\",\n    \"Use insights to improve code quality through automated analysis\",\n    \"Filter insights by severity (error, warning, info) or category\",\n    \"Integrate insight generation into code review or CI/CD workflows\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all quality insights\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with detected issues and recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights only for that file\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Detects files exceeding recommended line count\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for large files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that aren't imported or used anywhere\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for orphaned files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies project has proper entry points\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular import dependencies\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with too many responsibilities or exports\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds code that may not be actively used\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potential dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and organization\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organization issues\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity and size\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for overly complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to provide automated code quality analysis and actionable recommendations to developers. It solves the problem of manually identifying code smells, architectural issues, and maintainability concerns by automatically scanning code and generating structured insights with severity levels, categories, and improvement suggestions.\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in the VS Code sidebar that displays code insights, documentation status, analysis results, and generated reports with interactive actions.",
          "userVisibleActions": [
            "View a tree of code analysis insights organized by severity (critical, high, medium, low)",
            "See status indicators for product documentation generation (idle, generating, complete)",
            "See status indicators for insights generation and unit test generation",
            "Click on insights to navigate to the relevant code location",
            "Refresh the insights tree to update displayed information",
            "Generate product documentation from the tree view",
            "Generate architecture documentation from the tree view",
            "Generate unit tests from the tree view",
            "Open generated report files (workspace, product, architecture, unit test, static analysis)",
            "View timestamp information showing when reports were generated",
            "Copy insight text to clipboard",
            "Expand/collapse insight categories and details",
            "See a 'No insights available' message when no analysis has been performed",
            "View detailed insight information including file path, line number, and recommendations"
          ],
          "developerVisibleActions": [
            "Tree view updates automatically when insights are generated or refreshed",
            "Status changes are reflected in real-time (generating, complete, idle)",
            "Reports are saved to workspace storage and persist across sessions",
            "Tree items show contextual actions based on their type (generate, open, refresh)",
            "LLM-generated insights are displayed alongside traditional code insights",
            "Timestamps are persisted and restored when VS Code restarts",
            "Tree structure adapts based on available data (insights, reports, documentation)",
            "Context values enable conditional command visibility in the tree"
          ],
          "keyFunctions": [
            {
              "name": "setInsights",
              "desc": "Updates the tree view with new code insights",
              "inputs": "Array of Insight objects",
              "outputs": "Triggers tree refresh"
            },
            {
              "name": "setLLMInsights",
              "desc": "Updates the tree view with LLM-generated insights and documentation status",
              "inputs": "LLMInsights object containing status and generated content",
              "outputs": "Triggers tree refresh and saves timestamps"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts a tree item into a VS Code tree item for display",
              "inputs": "TreeItem object",
              "outputs": "vscode.TreeItem with display properties"
            },
            {
              "name": "getChildren",
              "desc": "Provides the hierarchical structure of tree items",
              "inputs": "Optional parent TreeItem",
              "outputs": "Array of child TreeItem objects"
            },
            {
              "name": "setReportPath",
              "desc": "Saves the path to a generated report file",
              "inputs": "Report file path and type (workspace, product, architecture, unit test)",
              "outputs": "Updates tree display with report availability"
            },
            {
              "name": "refresh",
              "desc": "Forces the tree view to reload and display updated data",
              "inputs": "Optional TreeItem to refresh specific branch",
              "outputs": "Tree view refresh event"
            },
            {
              "name": "setStaticAnalysisViewer",
              "desc": "Associates the static analysis viewer with the tree view",
              "inputs": "Static analysis viewer instance",
              "outputs": "Enables static analysis report display"
            },
            {
              "name": "loadPersistedState",
              "desc": "Restores saved report paths and timestamps from previous sessions",
              "inputs": "Reads from extension context storage",
              "outputs": "Restores tree state with persisted data"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator",
            "./llmFormatter",
            "./llmService"
          ],
          "intent": "This file exists to provide a visual, interactive sidebar panel in VS Code where users can view code analysis results, track documentation generation progress, access generated reports, and trigger various code analysis and documentation actions without leaving the editor.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in the VS Code sidebar that displays code insights, documentation status, analysis results, and generated reports with interactive actions.\",\n  \"userVisibleActions\": [\n    \"View a tree of code analysis insights organized by severity (critical, high, medium, low)\",\n    \"See status indicators for product documentation generation (idle, generating, complete)\",\n    \"See status indicators for insights generation and unit test generation\",\n    \"Click on insights to navigate to the relevant code location\",\n    \"Refresh the insights tree to update displayed information\",\n    \"Generate product documentation from the tree view\",\n    \"Generate architecture documentation from the tree view\",\n    \"Generate unit tests from the tree view\",\n    \"Open generated report files (workspace, product, architecture, unit test, static analysis)\",\n    \"View timestamp information showing when reports were generated\",\n    \"Copy insight text to clipboard\",\n    \"Expand/collapse insight categories and details\",\n    \"See a 'No insights available' message when no analysis has been performed\",\n    \"View detailed insight information including file path, line number, and recommendations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when insights are generated or refreshed\",\n    \"Status changes are reflected in real-time (generating, complete, idle)\",\n    \"Reports are saved to workspace storage and persist across sessions\",\n    \"Tree items show contextual actions based on their type (generate, open, refresh)\",\n    \"LLM-generated insights are displayed alongside traditional code insights\",\n    \"Timestamps are persisted and restored when VS Code restarts\",\n    \"Tree structure adapts based on available data (insights, reports, documentation)\",\n    \"Context values enable conditional command visibility in the tree\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the tree view with new code insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"Triggers tree refresh\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the tree view with LLM-generated insights and documentation status\",\n      \"inputs\": \"LLMInsights object containing status and generated content\",\n      \"outputs\": \"Triggers tree refresh and saves timestamps\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts a tree item into a VS Code tree item for display\",\n      \"inputs\": \"TreeItem object\",\n      \"outputs\": \"vscode.TreeItem with display properties\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Provides the hierarchical structure of tree items\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of child TreeItem objects\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Saves the path to a generated report file\",\n      \"inputs\": \"Report file path and type (workspace, product, architecture, unit test)\",\n      \"outputs\": \"Updates tree display with report availability\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces the tree view to reload and display updated data\",\n      \"inputs\": \"Optional TreeItem to refresh specific branch\",\n      \"outputs\": \"Tree view refresh event\"\n    },\n    {\n      \"name\": \"setStaticAnalysisViewer\",\n      \"desc\": \"Associates the static analysis viewer with the tree view\",\n      \"inputs\": \"Static analysis viewer instance\",\n      \"outputs\": \"Enables static analysis report display\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved report paths and timestamps from previous sessions\",\n      \"inputs\": \"Reads from extension context storage\",\n      \"outputs\": \"Restores tree state with persisted data\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive sidebar panel in VS Code where users can view code analysis results, track documentation generation progress, access generated reports, and trigger various code analysis and documentation actions without leaving the editor.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, including purpose, relationships, and file organization.",
          "userVisibleActions": [
            "View architecture insights in a tree view panel showing project purpose, file relationships, and directory structure",
            "Click on files in the insights tree to open them in the editor",
            "See color-coded file roles (Model, View, Controller, Service, etc.) with icons",
            "Browse files grouped by their architectural purpose",
            "Refresh the insights view to reload analysis results",
            "See file summaries and purposes when hovering or selecting items",
            "View metadata like LOC (lines of code) and programming language for each file",
            "Access insights even when files are missing from the workspace",
            "See real-time updates when insights.json or project-purpose.md files change"
          ],
          "developerVisibleActions": [
            "Tree view automatically refreshes when .shadow/docs/insights.json is modified",
            "Tree view updates when .shadow/project-purpose.md changes",
            "Files are organized by their architectural role (GUI, Model, Service, Controller, etc.)",
            "Clicking a file item navigates to that file in the editor",
            "Insights data is loaded from the .shadow/docs directory",
            "File watcher service monitors changes to insights and purpose files",
            "Tree provider implements VS Code TreeDataProvider interface for rendering",
            "Handles missing files gracefully by showing them in the tree with appropriate styling"
          ],
          "keyFunctions": [
            {
              "name": "refresh",
              "desc": "Reloads insights data from the file system and updates the tree view",
              "inputs": "insightsData (optional LLMInsights object)",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts an InsightItem into a VS Code TreeItem for display in the tree view",
              "inputs": "element (InsightItem)",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node (categories, files, or metadata)",
              "inputs": "element (optional InsightItem)",
              "outputs": "Promise<InsightItem[]>"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Creates file system watchers to monitor changes to insights.json and project-purpose.md",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getRoleIcon",
              "desc": "Returns the appropriate icon name for a file based on its architectural role",
              "inputs": "role (string)",
              "outputs": "string (icon name)"
            },
            {
              "name": "getRoleColor",
              "desc": "Returns a color code for displaying files based on their role category",
              "inputs": "role (string)",
              "outputs": "string (color code)"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file watchers and other resources when the provider is destroyed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs",
            "./llmService (LLMInsights type)",
            "./domain/services/fileWatcherService"
          ],
          "intent": "This file exists to visualize AI-generated architecture insights in VS Code's sidebar, helping developers understand their codebase structure by showing how files relate to each other, what roles they play, and what purpose they serve. It solves the problem of navigating and understanding large codebases by providing an architectural overview that auto-updates as the analysis changes.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, including purpose, relationships, and file organization.\",\n  \"userVisibleActions\": [\n    \"View architecture insights in a tree view panel showing project purpose, file relationships, and directory structure\",\n    \"Click on files in the insights tree to open them in the editor\",\n    \"See color-coded file roles (Model, View, Controller, Service, etc.) with icons\",\n    \"Browse files grouped by their architectural purpose\",\n    \"Refresh the insights view to reload analysis results\",\n    \"See file summaries and purposes when hovering or selecting items\",\n    \"View metadata like LOC (lines of code) and programming language for each file\",\n    \"Access insights even when files are missing from the workspace\",\n    \"See real-time updates when insights.json or project-purpose.md files change\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when .shadow/docs/insights.json is modified\",\n    \"Tree view updates when .shadow/project-purpose.md changes\",\n    \"Files are organized by their architectural role (GUI, Model, Service, Controller, etc.)\",\n    \"Clicking a file item navigates to that file in the editor\",\n    \"Insights data is loaded from the .shadow/docs directory\",\n    \"File watcher service monitors changes to insights and purpose files\",\n    \"Tree provider implements VS Code TreeDataProvider interface for rendering\",\n    \"Handles missing files gracefully by showing them in the tree with appropriate styling\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights data from the file system and updates the tree view\",\n      \"inputs\": \"insightsData (optional LLMInsights object)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem for display in the tree view\",\n      \"inputs\": \"element (InsightItem)\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node (categories, files, or metadata)\",\n      \"inputs\": \"element (optional InsightItem)\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers to monitor changes to insights.json and project-purpose.md\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getRoleIcon\",\n      \"desc\": \"Returns the appropriate icon name for a file based on its architectural role\",\n      \"inputs\": \"role (string)\",\n      \"outputs\": \"string (icon name)\"\n    },\n    {\n      \"name\": \"getRoleColor\",\n      \"desc\": \"Returns a color code for displaying files based on their role category\",\n      \"inputs\": \"role (string)\",\n      \"outputs\": \"string (color code)\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and other resources when the provider is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"./llmService (LLMInsights type)\",\n    \"./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to visualize AI-generated architecture insights in VS Code's sidebar, helping developers understand their codebase structure by showing how files relate to each other, what roles they play, and what purpose they serve. It solves the problem of navigating and understanding large codebases by providing an architectural overview that auto-updates as the analysis changes.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different output styles optimized for various LLM tools and display contexts.",
          "userVisibleActions": [
            "View architecture issues organized by severity (Critical, Warnings, Informational)",
            "See formatted output optimized for Cursor AI assistant",
            "See formatted output optimized for ChatGPT",
            "View compact format for quick scanning of issues",
            "Read generic formatted output compatible with any LLM",
            "See emoji indicators (, , ) for issue severity levels",
            "View actionable guidance on what help is needed from the LLM"
          ],
          "developerVisibleActions": [
            "Choose output format (cursor, chatgpt, compact, generic) when formatting insights",
            "Pass array of Insight objects to be formatted",
            "Receive formatted markdown string ready for display or LLM consumption",
            "Get insights automatically grouped by severity level",
            "Get structured output with clear sections for issue categories",
            "Get prompts embedded in output to guide LLM responses"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Routes insights to appropriate formatter based on specified format type",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "Formatted string in requested style"
            },
            {
              "name": "formatForCursor",
              "desc": "Creates Cursor AI-optimized output with severity grouping and action requests",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string with sections for errors, warnings, info, and guidance prompts"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Creates ChatGPT-optimized output formatted as a conversation starter",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string formatted as a help request to ChatGPT"
            },
            {
              "name": "formatCompact",
              "desc": "Creates condensed output showing only essential information",
              "inputs": "insights: Insight[]",
              "outputs": "Compact markdown string with minimal formatting"
            },
            {
              "name": "formatGeneric",
              "desc": "Creates standard output compatible with any LLM or display context",
              "inputs": "insights: Insight[]",
              "outputs": "Generic markdown string with basic structure"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats individual insight with file location, issue details, and suggestions",
              "inputs": "insight: Insight",
              "outputs": "Formatted markdown section for single insight"
            }
          ],
          "dependencies": [
            "./insightGenerator"
          ],
          "intent": "Transforms technical code analysis insights into human-readable, LLM-friendly formats that prompt effective assistance from AI coding tools. Solves the problem of presenting architecture issues in a way that maximizes helpful responses from different AI assistants by tailoring the output format and embedded prompts to each tool's strengths.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output styles optimized for various LLM tools and display contexts.\",\n  \"userVisibleActions\": [\n    \"View architecture issues organized by severity (Critical, Warnings, Informational)\",\n    \"See formatted output optimized for Cursor AI assistant\",\n    \"See formatted output optimized for ChatGPT\",\n    \"View compact format for quick scanning of issues\",\n    \"Read generic formatted output compatible with any LLM\",\n    \"See emoji indicators (, , ) for issue severity levels\",\n    \"View actionable guidance on what help is needed from the LLM\"\n  ],\n  \"developerVisibleActions\": [\n    \"Choose output format (cursor, chatgpt, compact, generic) when formatting insights\",\n    \"Pass array of Insight objects to be formatted\",\n    \"Receive formatted markdown string ready for display or LLM consumption\",\n    \"Get insights automatically grouped by severity level\",\n    \"Get structured output with clear sections for issue categories\",\n    \"Get prompts embedded in output to guide LLM responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Routes insights to appropriate formatter based on specified format type\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string in requested style\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized output with severity grouping and action requests\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with sections for errors, warnings, info, and guidance prompts\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT-optimized output formatted as a conversation starter\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string formatted as a help request to ChatGPT\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates condensed output showing only essential information\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with minimal formatting\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard output compatible with any LLM or display context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown string with basic structure\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file location, issue details, and suggestions\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown section for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Transforms technical code analysis insights into human-readable, LLM-friendly formats that prompt effective assistance from AI coding tools. Solves the problem of presenting architecture issues in a way that maximizes helpful responses from different AI assistants by tailoring the output format and embedded prompts to each tool's strengths.\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Manages LLM-powered code analysis features, including initializing services, generating documentation, analyzing code, and handling user interactions with AI-generated insights.",
          "userVisibleActions": [
            "Generate documentation for code files and products",
            "View AI-generated insights about code structure and behavior",
            "Navigate through analyzed code via tree views",
            "See analysis progress and status messages in output channel",
            "Access generated documentation in webview panels",
            "View code analysis results including entry points and components",
            "Receive notifications when analysis completes or fails",
            "See API configuration status and warnings"
          ],
          "developerVisibleActions": [
            "Initialize LLM service on extension startup",
            "Trigger code analysis for workspace files",
            "Generate product documentation from analysis results",
            "Request AI insights for specific code contexts",
            "Refresh tree views when analysis data changes",
            "Save and load analysis results from cache",
            "Handle API key configuration and validation",
            "Manage analysis state across sessions",
            "Convert code analysis to LLM context format",
            "Display documentation in formatted webview",
            "Register commands for documentation and analysis actions",
            "Handle errors and display user-friendly messages",
            "Coordinate between analysis services and UI providers"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Sets up LLM service and loads saved analysis data on startup",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "generateDocumentation",
              "desc": "Creates AI-generated documentation for code files or entire products",
              "inputs": "file paths, analysis context",
              "outputs": "EnhancedProductDocumentation"
            },
            {
              "name": "analyzeCode",
              "desc": "Performs deep code analysis using LLM to extract structure and behavior",
              "inputs": "workspace paths, file list",
              "outputs": "CodeAnalysis with entry points and insights"
            },
            {
              "name": "requestInsights",
              "desc": "Gets AI-generated insights about code patterns and architecture",
              "inputs": "AnalysisContext",
              "outputs": "LLMInsights"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists analysis results to cache for future sessions",
              "inputs": "CodeAnalysis object",
              "outputs": "void"
            },
            {
              "name": "loadSavedCodeAnalysis",
              "desc": "Retrieves previously saved analysis from cache",
              "inputs": "workspace identifier",
              "outputs": "CodeAnalysis or null"
            },
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms code analysis into format suitable for LLM processing",
              "inputs": "CodeAnalysis",
              "outputs": "AnalysisContext"
            },
            {
              "name": "showDocumentation",
              "desc": "Displays generated documentation in webview panel",
              "inputs": "documentation object",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "llmService",
            "insightsTreeView",
            "fileDocumentation",
            "analyzer",
            "productNavigator",
            "analysisViewer",
            "insightsViewer",
            "unitTestsNavigator",
            "logger",
            "llmStateManager",
            "analysisContextBuilder",
            "documentationFormatter",
            "analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between VS Code extension UI and LLM analysis capabilities, coordinating all AI-powered features like documentation generation, code insights, and intelligent navigation. It solves the problem of managing complex interactions between user actions, background analysis, state persistence, and AI service calls in a unified way.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages LLM-powered code analysis features, including initializing services, generating documentation, analyzing code, and handling user interactions with AI-generated insights.\",\n  \"userVisibleActions\": [\n    \"Generate documentation for code files and products\",\n    \"View AI-generated insights about code structure and behavior\",\n    \"Navigate through analyzed code via tree views\",\n    \"See analysis progress and status messages in output channel\",\n    \"Access generated documentation in webview panels\",\n    \"View code analysis results including entry points and components\",\n    \"Receive notifications when analysis completes or fails\",\n    \"See API configuration status and warnings\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service on extension startup\",\n    \"Trigger code analysis for workspace files\",\n    \"Generate product documentation from analysis results\",\n    \"Request AI insights for specific code contexts\",\n    \"Refresh tree views when analysis data changes\",\n    \"Save and load analysis results from cache\",\n    \"Handle API key configuration and validation\",\n    \"Manage analysis state across sessions\",\n    \"Convert code analysis to LLM context format\",\n    \"Display documentation in formatted webview\",\n    \"Register commands for documentation and analysis actions\",\n    \"Handle errors and display user-friendly messages\",\n    \"Coordinate between analysis services and UI providers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up LLM service and loads saved analysis data on startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates AI-generated documentation for code files or entire products\",\n      \"inputs\": \"file paths, analysis context\",\n      \"outputs\": \"EnhancedProductDocumentation\"\n    },\n    {\n      \"name\": \"analyzeCode\",\n      \"desc\": \"Performs deep code analysis using LLM to extract structure and behavior\",\n      \"inputs\": \"workspace paths, file list\",\n      \"outputs\": \"CodeAnalysis with entry points and insights\"\n    },\n    {\n      \"name\": \"requestInsights\",\n      \"desc\": \"Gets AI-generated insights about code patterns and architecture\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"LLMInsights\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to cache for future sessions\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis from cache\",\n      \"inputs\": \"workspace identifier\",\n      \"outputs\": \"CodeAnalysis or null\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis into format suitable for LLM processing\",\n      \"inputs\": \"CodeAnalysis\",\n      \"outputs\": \"AnalysisContext\"\n    },\n    {\n      \"name\": \"showDocumentation\",\n      \"desc\": \"Displays generated documentation in webview panel\",\n      \"inputs\": \"documentation object\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"llmStateManager\",\n    \"analysisContextBuilder\",\n    \"documentationFormatter\",\n    \"analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between VS Code extension UI and LLM analysis capabilities, coordinating all AI-powered features like documentation generation, code insights, and intelligent navigation. It solves the problem of managing complex interactions between user actions, background analysis, state persistence, and AI service calls in a unified way.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure and validate LLM responses to ensure consistent, parseable output formats for code analysis tasks.",
          "userVisibleActions": [
            "Receives structured analysis of product purpose and architecture rationale",
            "Gets organized lists of design decisions and user goals from code analysis",
            "Views categorized code issues with titles, descriptions, and relevant files",
            "Sees risk assessments with severity levels and impact descriptions",
            "Receives actionable recommendations with priorities and effort estimates",
            "Gets structured summaries of codebase analysis results"
          ],
          "developerVisibleActions": [
            "Provides JSON schemas to LLM API calls to guarantee response structure",
            "Ensures LLM responses conform to expected formats without manual parsing",
            "Defines validation rules for product purpose analysis output",
            "Specifies required fields and data types for issue detection",
            "Enforces consistent format for risk assessments and recommendations",
            "Validates that all LLM responses include mandatory properties"
          ],
          "keyFunctions": [
            {
              "name": "productPurposeAnalysisSchema",
              "desc": "Schema for analyzing product purpose, architecture rationale, and design decisions",
              "inputs": "None (exported constant schema object)",
              "outputs": "JSON schema with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
            },
            {
              "name": "issueItemSchema",
              "desc": "Schema for individual code issues with title, description, and relevant files/functions",
              "inputs": "None (nested schema definition)",
              "outputs": "JSON schema with title, description, relevantFiles, relevantFunctions properties"
            }
          ],
          "dependencies": [],
          "intent": "Ensures Claude AI responses for code analysis are consistently structured and machine-parseable, eliminating the need for fragile text parsing and guaranteeing that all required information fields are present in every response.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate LLM responses to ensure consistent, parseable output formats for code analysis tasks.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and architecture rationale\",\n    \"Gets organized lists of design decisions and user goals from code analysis\",\n    \"Views categorized code issues with titles, descriptions, and relevant files\",\n    \"Sees risk assessments with severity levels and impact descriptions\",\n    \"Receives actionable recommendations with priorities and effort estimates\",\n    \"Gets structured summaries of codebase analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides JSON schemas to LLM API calls to guarantee response structure\",\n    \"Ensures LLM responses conform to expected formats without manual parsing\",\n    \"Defines validation rules for product purpose analysis output\",\n    \"Specifies required fields and data types for issue detection\",\n    \"Enforces consistent format for risk assessments and recommendations\",\n    \"Validates that all LLM responses include mandatory properties\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose, architecture rationale, and design decisions\",\n      \"inputs\": \"None (exported constant schema object)\",\n      \"outputs\": \"JSON schema with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema for individual code issues with title, description, and relevant files/functions\",\n      \"inputs\": \"None (nested schema definition)\",\n      \"outputs\": \"JSON schema with title, description, relevantFiles, relevantFunctions properties\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Ensures Claude AI responses for code analysis are consistently structured and machine-parseable, eliminating the need for fragile text parsing and guaranteeing that all required information fields are present in every response.\"\n}\n```"
        },
        {
          "file": "src/llmService.ts",
          "role": "Core Logic",
          "purpose": "Provides LLM-powered AI analysis services to generate intelligent insights, documentation, and code analysis by interfacing with OpenAI/Claude APIs.",
          "userVisibleActions": [
            "Generate intelligent insights about codebase purpose and architecture",
            "Create comprehensive product documentation from code analysis",
            "Analyze code quality and provide improvement suggestions",
            "Generate unit test plans for functions",
            "Get AI-powered refactoring suggestions for complex functions",
            "Receive explanations of what the product does and why it was built",
            "View AI-generated module summaries and relationships",
            "See incremental analysis results as codebase changes",
            "Get file-level and function-level documentation generated by AI"
          ],
          "developerVisibleActions": [
            "Call LLM service to analyze codebase structure and purpose",
            "Request AI-generated documentation for entire product",
            "Trigger AI analysis of code quality and architecture",
            "Generate test plans using AI understanding of functions",
            "Request refactoring suggestions for complex code",
            "Use incremental analysis to only analyze changed files",
            "Configure LLM provider (OpenAI, Claude, or local models)",
            "Set custom system prompts for AI analysis",
            "Control token budgets and rate limiting for API calls",
            "Handle retries and errors from LLM API responses",
            "Parse structured AI responses into usable data structures",
            "Access file summaries and module groupings from AI analysis"
          ],
          "keyFunctions": [
            {
              "name": "analyzePurpose",
              "desc": "Analyzes the codebase to determine product purpose, architecture rationale, and key features using AI",
              "inputs": "AnalysisContext with file structure, imports, and entry points",
              "outputs": "ProductPurposeAnalysis with product purpose, architecture, and design patterns"
            },
            {
              "name": "generateEnhancedDocumentation",
              "desc": "Generates comprehensive product documentation including purpose, features, architecture, and user scenarios using AI",
              "inputs": "CodeAnalysis and AnalysisContext",
              "outputs": "EnhancedProductDocumentation with full product overview and technical details"
            },
            {
              "name": "generateLLMInsights",
              "desc": "Generates intelligent insights about code quality, patterns, and improvement suggestions using AI",
              "inputs": "CodeAnalysis with code metrics and structure",
              "outputs": "LLM insights with code quality assessment and recommendations"
            },
            {
              "name": "generateUnitTestPlan",
              "desc": "Creates a comprehensive unit test plan for a specific function using AI analysis",
              "inputs": "Function metadata, file content, and function name",
              "outputs": "Unit test plan with test cases, setup, assertions, and edge cases"
            },
            {
              "name": "generateRefactoringSuggestions",
              "desc": "Provides AI-powered refactoring suggestions for complex or problematic functions",
              "inputs": "Function code, metrics (complexity, length, nesting), and surrounding context",
              "outputs": "Refactoring suggestions with specific improvements and code examples"
            },
            {
              "name": "analyzeIncrementally",
              "desc": "Performs incremental AI analysis only on files that have changed since last analysis",
              "inputs": "Changed file URIs and analysis context",
              "outputs": "Updated insights and documentation for changed files only"
            },
            {
              "name": "callLLM",
              "desc": "Makes API calls to configured LLM provider with rate limiting, retries, and error handling",
              "inputs": "System prompt, user prompt, optional schema for structured output",
              "outputs": "Parsed LLM response with requested analysis or documentation"
            },
            {
              "name": "generateFileSummary",
              "desc": "Creates AI-generated summary of a single file's purpose, functionality, and role",
              "inputs": "File path, content, and role in codebase",
              "outputs": "FileSummary with description, key functions, and relationships"
            },
            {
              "name": "generateModuleSummary",
              "desc": "Creates AI-generated summary of a module's purpose and file organization",
              "inputs": "Module name, list of files, and module type",
              "outputs": "ModuleSummary with module purpose and file descriptions"
            }
          ],
          "dependencies": [
            "vscode",
            "./fileDocumentation",
            "./analyzer",
            "./analysis/enhancedAnalyzer",
            "./llmSchemas",
            "./fileAccessHelper",
            "./logger",
            "./config/configurationManager",
            "./ai/providers/providerFactory",
            "./ai/llmResponseParser",
            "./ai/llmRateLimiter",
            "./ai/llmRetryHandler",
            "./domain/prompts/promptBuilder",
            "./domain/services/incrementalAnalysisService",
            "./domain/prompts/refactoringPromptBuilder",
            "./analysis/functionAnalyzer"
          ],
          "intent": "This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by using LLMs to generate human-readable documentation, identify architectural patterns, suggest improvements, and create test plans. It abstracts away the complexity of calling different LLM providers (OpenAI, Claude, local models) and handles rate limiting, retries, and response parsing so developers can get AI insights without managing API details.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides LLM-powered AI analysis services to generate intelligent insights, documentation, and code analysis by interfacing with OpenAI/Claude APIs.\",\n  \"userVisibleActions\": [\n    \"Generate intelligent insights about codebase purpose and architecture\",\n    \"Create comprehensive product documentation from code analysis\",\n    \"Analyze code quality and provide improvement suggestions\",\n    \"Generate unit test plans for functions\",\n    \"Get AI-powered refactoring suggestions for complex functions\",\n    \"Receive explanations of what the product does and why it was built\",\n    \"View AI-generated module summaries and relationships\",\n    \"See incremental analysis results as codebase changes\",\n    \"Get file-level and function-level documentation generated by AI\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call LLM service to analyze codebase structure and purpose\",\n    \"Request AI-generated documentation for entire product\",\n    \"Trigger AI analysis of code quality and architecture\",\n    \"Generate test plans using AI understanding of functions\",\n    \"Request refactoring suggestions for complex code\",\n    \"Use incremental analysis to only analyze changed files\",\n    \"Configure LLM provider (OpenAI, Claude, or local models)\",\n    \"Set custom system prompts for AI analysis\",\n    \"Control token budgets and rate limiting for API calls\",\n    \"Handle retries and errors from LLM API responses\",\n    \"Parse structured AI responses into usable data structures\",\n    \"Access file summaries and module groupings from AI analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzePurpose\",\n      \"desc\": \"Analyzes the codebase to determine product purpose, architecture rationale, and key features using AI\",\n      \"inputs\": \"AnalysisContext with file structure, imports, and entry points\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture, and design patterns\"\n    },\n    {\n      \"name\": \"generateEnhancedDocumentation\",\n      \"desc\": \"Generates comprehensive product documentation including purpose, features, architecture, and user scenarios using AI\",\n      \"inputs\": \"CodeAnalysis and AnalysisContext\",\n      \"outputs\": \"EnhancedProductDocumentation with full product overview and technical details\"\n    },\n    {\n      \"name\": \"generateLLMInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and improvement suggestions using AI\",\n      \"inputs\": \"CodeAnalysis with code metrics and structure\",\n      \"outputs\": \"LLM insights with code quality assessment and recommendations\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a comprehensive unit test plan for a specific function using AI analysis\",\n      \"inputs\": \"Function metadata, file content, and function name\",\n      \"outputs\": \"Unit test plan with test cases, setup, assertions, and edge cases\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Provides AI-powered refactoring suggestions for complex or problematic functions\",\n      \"inputs\": \"Function code, metrics (complexity, length, nesting), and surrounding context\",\n      \"outputs\": \"Refactoring suggestions with specific improvements and code examples\"\n    },\n    {\n      \"name\": \"analyzeIncrementally\",\n      \"desc\": \"Performs incremental AI analysis only on files that have changed since last analysis\",\n      \"inputs\": \"Changed file URIs and analysis context\",\n      \"outputs\": \"Updated insights and documentation for changed files only\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Makes API calls to configured LLM provider with rate limiting, retries, and error handling\",\n      \"inputs\": \"System prompt, user prompt, optional schema for structured output\",\n      \"outputs\": \"Parsed LLM response with requested analysis or documentation\"\n    },\n    {\n      \"name\": \"generateFileSummary\",\n      \"desc\": \"Creates AI-generated summary of a single file's purpose, functionality, and role\",\n      \"inputs\": \"File path, content, and role in codebase\",\n      \"outputs\": \"FileSummary with description, key functions, and relationships\"\n    },\n    {\n      \"name\": \"generateModuleSummary\",\n      \"desc\": \"Creates AI-generated summary of a module's purpose and file organization\",\n      \"inputs\": \"Module name, list of files, and module type\",\n      \"outputs\": \"ModuleSummary with module purpose and file descriptions\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by using LLMs to generate human-readable documentation, identify architectural patterns, suggest improvements, and create test plans. It abstracts away the complexity of calling different LLM providers (OpenAI, Claude, local models) and handles rate limiting, retries, and response parsing so developers can get AI insights without managing API details.\"\n}\n```"
        },
        {
          "file": "src/logger.ts",
          "role": "Core Logic",
          "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
          "userVisibleActions": [
            "Log files are automatically created in .shadow/logs/shadow-watch.log in the workspace root",
            "All logged events are timestamped with ISO format timestamps",
            "Log sections are visually separated with header lines for easier reading"
          ],
          "developerVisibleActions": [
            "Developers can log messages that appear in .shadow/logs/shadow-watch.log",
            "Developers can create section headers in the log file to organize different parts of execution",
            "Logging fails silently if the workspace is not available or errors occur",
            "The .shadow/logs directory is automatically created if it doesn't exist"
          ],
          "keyFunctions": [
            {
              "name": "log",
              "desc": "Writes a timestamped message to the log file",
              "inputs": "message (string) - the text to log",
              "outputs": "void - writes to file system"
            },
            {
              "name": "section",
              "desc": "Creates a formatted section header in the log file with surrounding equals signs",
              "inputs": "title (string) - the section header text",
              "outputs": "void - writes to file system"
            },
            {
              "name": "getLogPath",
              "desc": "Determines the file path where logs should be written",
              "inputs": "none",
              "outputs": "string | null - path to log file or null if no workspace"
            },
            {
              "name": "ensureDir",
              "desc": "Creates a directory if it doesn't already exist",
              "inputs": "dir (string) - directory path to create",
              "outputs": "void - modifies file system"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "vscode"
          ],
          "intent": "This file exists to provide a centralized, file-based logging system for the extension, allowing developers to track extension behavior and debug issues by writing timestamped logs to a consistent location in the workspace",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are automatically created in .shadow/logs/shadow-watch.log in the workspace root\",\n    \"All logged events are timestamped with ISO format timestamps\",\n    \"Log sections are visually separated with header lines for easier reading\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can log messages that appear in .shadow/logs/shadow-watch.log\",\n    \"Developers can create section headers in the log file to organize different parts of execution\",\n    \"Logging fails silently if the workspace is not available or errors occur\",\n    \"The .shadow/logs directory is automatically created if it doesn't exist\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the log file\",\n      \"inputs\": \"message (string) - the text to log\",\n      \"outputs\": \"void - writes to file system\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a formatted section header in the log file with surrounding equals signs\",\n      \"inputs\": \"title (string) - the section header text\",\n      \"outputs\": \"void - writes to file system\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - path to log file or null if no workspace\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory if it doesn't already exist\",\n      \"inputs\": \"dir (string) - directory path to create\",\n      \"outputs\": \"void - modifies file system\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, file-based logging system for the extension, allowing developers to track extension behavior and debug issues by writing timestamped logs to a consistent location in the workspace\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadow-watch.analyzeWorkspace",
          "description": "Trigger full codebase analysis to extract structure, dependencies, functions, and generate insights"
        },
        {
          "command": "shadow-watch.analyzeCurrentFile",
          "description": "Analyze only the currently open file for structure and quality issues"
        },
        {
          "command": "shadow-watch.formatForLLM",
          "description": "Export analysis results in LLM-optimized format (Cursor, ChatGPT, or generic)"
        },
        {
          "command": "shadow-watch.exportToMarkdown",
          "description": "Export analysis results as a Markdown file"
        },
        {
          "command": "shadow-watch.exportToJSON",
          "description": "Export analysis results as a structured JSON file"
        },
        {
          "command": "shadow-watch.clearCache",
          "description": "Clear cached analysis data to force fresh analysis"
        },
        {
          "command": "shadow-watch.generateProductDocumentation",
          "description": "Generate AI-powered product-level documentation including architecture and purpose"
        },
        {
          "command": "shadow-watch.generateArchitectureDocumentation",
          "description": "Generate AI-powered architecture documentation with diagrams and relationships"
        },
        {
          "command": "shadow-watch.generateUnitTests",
          "description": "Generate AI-powered unit test plans for functions"
        },
        {
          "command": "shadow-watch.refreshInsights",
          "description": "Refresh the insights tree view to update displayed analysis results"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized management of all Shadow Watch extension settings",
        "Type-safe access to user preferences across the extension",
        "Real-time notification system for configuration changes",
        "Support for multiple LLM providers (OpenAI and Claude)",
        "Configurable analysis behavior and output formatting",
        "Flexible filtering and display options for detected issues",
        "Performance tuning through file size limits and timeout settings"
      ],
      "summary": "The config module serves as the central configuration hub for the Shadow Watch extension, managing all user preferences and settings. It provides a type-safe interface for accessing configuration values such as LLM provider selection, API credentials, analysis triggers, and display preferences. The module ensures that any component in the extension can reliably read current settings and respond to changes in real-time.\n\nUsers interact with this module through VS Code's settings interface to control core behaviors like enabling/disabling the extension, automatic analysis on file save, and inline hint visibility. They can configure which AI service to use (OpenAI or Claude) along with corresponding API keys and custom endpoints. The module also manages output formatting options (Cursor, ChatGPT, Generic, or Compact) to match different workflow preferences.\n\nAdditional configuration options allow users to fine-tune the extension's behavior by setting minimum severity levels for problem display (Error, Warning, or Info), adjusting HTTP timeouts for AI requests, limiting maximum file sizes for analysis, and toggling debug logging. The module's notification system ensures that when users change any setting, all dependent components immediately receive updates and can adjust their behavior accordingly, providing a seamless and responsive configuration experience.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all configuration settings for the Shadow Watch extension, providing type-safe access to user preferences and notifying components when settings change.",
          "userVisibleActions": [
            "Enable or disable the Shadow Watch extension entirely",
            "Toggle automatic analysis when saving files",
            "Show or hide inline hint decorations in the editor",
            "Configure which LLM provider to use (OpenAI or Claude)",
            "Set API keys for AI services",
            "Choose output format for AI reports (Cursor, ChatGPT, Generic, or Compact)",
            "Adjust minimum severity level for displaying problems (Error, Warning, or Info)",
            "Set custom endpoints for AI services",
            "Configure HTTP timeout for AI requests",
            "Set maximum file size for analysis",
            "Enable or disable debug logging",
            "Show or hide decorations in the status bar"
          ],
          "developerVisibleActions": [
            "Access all Shadow Watch configuration values through type-safe getters",
            "Register callbacks to listen for configuration changes",
            "Validate configuration values and receive error feedback",
            "Retrieve configuration for specific workspace folders",
            "Update configuration values programmatically",
            "Get notified automatically when user changes settings in VSCode preferences",
            "Access validated API keys, endpoints, and service settings"
          ],
          "keyFunctions": [
            {
              "name": "Constructor",
              "desc": "Initializes the configuration manager and sets up automatic watching for configuration changes",
              "inputs": "None",
              "outputs": "ConfigurationManager instance"
            },
            {
              "name": "onConfigurationChange",
              "desc": "Registers a callback function to be invoked whenever Shadow Watch configuration changes",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Removes a previously registered configuration change callback",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "enabled",
              "desc": "Returns whether the Shadow Watch extension is enabled",
              "inputs": "None (getter)",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave",
              "desc": "Returns whether automatic analysis on file save is enabled",
              "inputs": "None (getter)",
              "outputs": "boolean"
            },
            {
              "name": "showInlineHints",
              "desc": "Returns whether inline hint decorations should be displayed",
              "inputs": "None (getter)",
              "outputs": "boolean"
            },
            {
              "name": "llmProvider",
              "desc": "Returns the configured LLM provider (OpenAI or Claude)",
              "inputs": "None (getter)",
              "outputs": "LLMProvider type"
            },
            {
              "name": "llmFormat",
              "desc": "Returns the configured output format for LLM reports",
              "inputs": "None (getter)",
              "outputs": "LLMFormat type"
            },
            {
              "name": "severityThreshold",
              "desc": "Returns the minimum severity level for displaying problems",
              "inputs": "None (getter)",
              "outputs": "SeverityThreshold type"
            },
            {
              "name": "validate",
              "desc": "Validates the current configuration and returns any errors found",
              "inputs": "None",
              "outputs": "ConfigValidationResult with validation status and error messages"
            },
            {
              "name": "getConfigForResource",
              "desc": "Retrieves configuration specific to a workspace folder or file",
              "inputs": "vscode.Uri resource",
              "outputs": "workspace-specific configuration"
            },
            {
              "name": "updateConfig",
              "desc": "Updates a configuration value programmatically",
              "inputs": "key, value, configuration target",
              "outputs": "Promise that resolves when update completes"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety, preventing direct access to raw configuration values, and enabling reactive updates when users change their preferences. It solves the problem of scattered configuration access throughout the codebase and provides validation to ensure settings are correct before use.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all configuration settings for the Shadow Watch extension, providing type-safe access to user preferences and notifying components when settings change.\",\n  \"userVisibleActions\": [\n    \"Enable or disable the Shadow Watch extension entirely\",\n    \"Toggle automatic analysis when saving files\",\n    \"Show or hide inline hint decorations in the editor\",\n    \"Configure which LLM provider to use (OpenAI or Claude)\",\n    \"Set API keys for AI services\",\n    \"Choose output format for AI reports (Cursor, ChatGPT, Generic, or Compact)\",\n    \"Adjust minimum severity level for displaying problems (Error, Warning, or Info)\",\n    \"Set custom endpoints for AI services\",\n    \"Configure HTTP timeout for AI requests\",\n    \"Set maximum file size for analysis\",\n    \"Enable or disable debug logging\",\n    \"Show or hide decorations in the status bar\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access all Shadow Watch configuration values through type-safe getters\",\n    \"Register callbacks to listen for configuration changes\",\n    \"Validate configuration values and receive error feedback\",\n    \"Retrieve configuration for specific workspace folders\",\n    \"Update configuration values programmatically\",\n    \"Get notified automatically when user changes settings in VSCode preferences\",\n    \"Access validated API keys, endpoints, and service settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"Constructor\",\n      \"desc\": \"Initializes the configuration manager and sets up automatic watching for configuration changes\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be invoked whenever Shadow Watch configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Removes a previously registered configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is enabled\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis on file save is enabled\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Returns whether inline hint decorations should be displayed\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider\",\n      \"desc\": \"Returns the configured LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"LLMProvider type\"\n    },\n    {\n      \"name\": \"llmFormat\",\n      \"desc\": \"Returns the configured output format for LLM reports\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"LLMFormat type\"\n    },\n    {\n      \"name\": \"severityThreshold\",\n      \"desc\": \"Returns the minimum severity level for displaying problems\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"SeverityThreshold type\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Validates the current configuration and returns any errors found\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ConfigValidationResult with validation status and error messages\"\n    },\n    {\n      \"name\": \"getConfigForResource\",\n      \"desc\": \"Retrieves configuration specific to a workspace folder or file\",\n      \"inputs\": \"vscode.Uri resource\",\n      \"outputs\": \"workspace-specific configuration\"\n    },\n    {\n      \"name\": \"updateConfig\",\n      \"desc\": \"Updates a configuration value programmatically\",\n      \"inputs\": \"key, value, configuration target\",\n      \"outputs\": \"Promise that resolves when update completes\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety, preventing direct access to raw configuration values, and enabling reactive updates when users change their preferences. It solves the problem of scattered configuration access throughout the codebase and provides validation to ensure settings are correct before use.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Automatically preserves code analysis results for future reference",
        "Creates timestamped snapshots of analysis data in the workspace",
        "Converts technical analysis results into LLM-friendly context format",
        "Maintains a persistent documentation directory within the workspace",
        "Enables retrieval of historical analysis data across sessions"
      ],
      "summary": "The context module provides automatic preservation and formatting of code analysis results. When code is analyzed, this module captures the results and saves them to a dedicated .shadow/docs directory within the workspace, creating timestamped snapshots that can be referenced later.\n\nThis module acts as a bridge between the analysis engine and persistent storage, transforming raw analysis data into a structured format optimized for use with Large Language Models. Each analysis session generates a new snapshot, allowing users to track changes over time and maintain a history of their codebase understanding.\n\nUsers benefit from this module passively - as they analyze their code, the context module automatically handles the storage and formatting of results without requiring manual intervention. The preserved analysis data remains available across VSCode sessions, enabling faster subsequent analyses and providing a foundation for AI-assisted development features.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis results into a format suitable for LLM context and saves them to persistent storage for future use.",
          "userVisibleActions": [
            "Analysis results are automatically saved to the workspace for future reference",
            "Analysis data is preserved in a .shadow/docs directory within the workspace",
            "Timestamped analysis snapshots are created each time code is analyzed"
          ],
          "developerVisibleActions": [
            "Developer triggers code analysis, and results are automatically converted to LLM-compatible format",
            "Analysis context is prepared for sending to language models with all necessary code structure information",
            "Analysis results are persisted to .shadow/docs/code-analysis.json file with metadata",
            "Workspace folders are checked before saving analysis data",
            "Directory structure (.shadow/docs) is created automatically if it doesn't exist"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms raw code analysis data into the specific format required by LLM services",
              "inputs": "CodeAnalysis object containing files, imports, entry points, and metrics",
              "outputs": "AnalysisContext object formatted for LLM consumption with file paths, lines, functions, imports, and statistics"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to disk with timestamp metadata for future retrieval",
              "inputs": "CodeAnalysis object to be saved",
              "outputs": "void - creates code-analysis.json file in .shadow/docs directory"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between code analysis output and LLM input requirements, while also ensuring analysis results are preserved for later use. It solves the problem of formatting code structure data for AI consumption and maintaining a history of code analysis snapshots.",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a format suitable for LLM context and saves them to persistent storage for future use.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to the workspace for future reference\",\n    \"Analysis data is preserved in a .shadow/docs directory within the workspace\",\n    \"Timestamped analysis snapshots are created each time code is analyzed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers code analysis, and results are automatically converted to LLM-compatible format\",\n    \"Analysis context is prepared for sending to language models with all necessary code structure information\",\n    \"Analysis results are persisted to .shadow/docs/code-analysis.json file with metadata\",\n    \"Workspace folders are checked before saving analysis data\",\n    \"Directory structure (.shadow/docs) is created automatically if it doesn't exist\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms raw code analysis data into the specific format required by LLM services\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and metrics\",\n      \"outputs\": \"AnalysisContext object formatted for LLM consumption with file paths, lines, functions, imports, and statistics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk with timestamp metadata for future retrieval\",\n      \"inputs\": \"CodeAnalysis object to be saved\",\n      \"outputs\": \"void - creates code-analysis.json file in .shadow/docs directory\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis output and LLM input requirements, while also ensuring analysis results are preserved for later use. It solves the problem of formatting code structure data for AI consumption and maintaining a history of code analysis snapshots.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Initialize and configure the VS Code extension environment with all necessary components and services",
        "Register and manage all extension commands for code analysis, insights, navigation, and settings",
        "Set up interactive tree views for navigating products, analyses, insights, static analysis results, and unit tests",
        "Provide status bar integration showing real-time analysis progress and LLM provider information",
        "Enable automatic code analysis and view updates when files change in the workspace",
        "Manage clipboard operations for copying analysis results, insights, and menu structures",
        "Configure diagnostics panel integration for displaying code issues and warnings",
        "Support switching between different LLM providers during runtime"
      ],
      "summary": "The bootstrap module serves as the initialization and configuration hub for the VS Code extension, responsible for setting up all user-facing components when the extension activates. It orchestrates the registration of commands, creation of tree views, and initialization of services that power the extension's code analysis capabilities.\n\nUsers interact with this module primarily through the extension's activation process, which automatically configures sidebar views for navigating products, viewing analysis results, exploring insights, examining static analysis findings, and managing unit tests. The module establishes a comprehensive command palette with commands for analyzing workspaces or individual files, copying analysis data to the clipboard, clearing cached data, accessing settings, viewing reports, and switching LLM providers.\n\nThe module enables a seamless workflow where file changes trigger automatic re-analysis, results populate in organized tree views, and users can access detailed information through navigation commands. Status bar integration provides at-a-glance feedback on analysis progress and current LLM provider status, while the diagnostics panel surfaces code issues and warnings in real-time.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers all VS Code commands for the extension and maps them to their handler functions",
          "userVisibleActions": [
            "Analyze entire workspace for code insights",
            "Analyze currently open file",
            "Copy all insights to clipboard",
            "Copy insights for specific file to clipboard",
            "Copy individual insight to clipboard",
            "Clear cached analysis data",
            "Clear all extension data",
            "Open extension settings",
            "View latest analysis report",
            "View latest unit test report",
            "Switch between LLM providers",
            "Copy menu structure to clipboard",
            "View current LLM provider status",
            "Navigate to specific product items",
            "Navigate to analysis items",
            "View detailed information about product items",
            "View detailed information about insights",
            "View detailed information about unit tests"
          ],
          "developerVisibleActions": [
            "Command handlers are centralized in one registry for easy maintenance",
            "Commands are registered with VS Code's command palette and UI elements",
            "Command registration is separated from main extension logic for modularity",
            "All command handlers receive necessary components and dependencies",
            "Commands integrate with tree views, diagnostics, cache, and LLM services"
          ],
          "keyFunctions": [
            {
              "name": "register",
              "desc": "Registers all extension commands with VS Code",
              "inputs": "context (ExtensionContext), components (ExtensionComponents)",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Triggers analysis of entire workspace",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeCurrentFile",
              "desc": "Triggers analysis of currently open file",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyAllInsights",
              "desc": "Copies all generated insights to clipboard",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyFileInsights",
              "desc": "Copies insights for specific file to clipboard",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyInsight",
              "desc": "Copies single insight item to clipboard",
              "inputs": "item (any)",
              "outputs": "Promise<void>"
            },
            {
              "name": "clearCache",
              "desc": "Clears cached analysis results",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "clearAllData",
              "desc": "Clears all extension data including cache and settings",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "showSettings",
              "desc": "Opens extension settings panel",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "openLatestReport",
              "desc": "Opens most recent analysis report",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "openLatestUnitTestReport",
              "desc": "Opens most recent unit test report",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "switchProvider",
              "desc": "Switches between different LLM providers",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyMenuStructure",
              "desc": "Copies menu structure to clipboard",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "showProviderStatus",
              "desc": "Displays current LLM provider status and configuration",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to specific product item in codebase",
              "inputs": "item (ProductNavItem)",
              "outputs": "Promise<void>"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to specific analysis result",
              "inputs": "item (AnalysisItem)",
              "outputs": "Promise<void>"
            },
            {
              "name": "showProductItemDetails",
              "desc": "Shows detailed view of product item",
              "inputs": "item (ProductNavItem)",
              "outputs": "Promise<void>"
            },
            {
              "name": "showInsightItemDetails",
              "desc": "Shows detailed view of insight",
              "inputs": "item (any)",
              "outputs": "Promise<void>"
            },
            {
              "name": "showUnitTestItemDetails",
              "desc": "Shows detailed view of unit test item",
              "inputs": "item (any)",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "This file centralizes command registration to separate concerns and make the extension maintainable. It solves the problem of command sprawl by providing a single registry that maps VS Code command IDs to their implementations, making it easy to add, modify, or remove commands without touching the main extension activation logic.",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension and maps them to their handler functions\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to specific product items\",\n    \"Navigate to analysis items\",\n    \"View detailed information about product items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Command handlers are centralized in one registry for easy maintenance\",\n    \"Commands are registered with VS Code's command palette and UI elements\",\n    \"Command registration is separated from main extension logic for modularity\",\n    \"All command handlers receive necessary components and dependencies\",\n    \"Commands integrate with tree views, diagnostics, cache, and LLM services\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all extension commands with VS Code\",\n      \"inputs\": \"context (ExtensionContext), components (ExtensionComponents)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers analysis of entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Triggers analysis of currently open file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyAllInsights\",\n      \"desc\": \"Copies all generated insights to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyFileInsights\",\n      \"desc\": \"Copies insights for specific file to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyInsight\",\n      \"desc\": \"Copies single insight item to clipboard\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears cached analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearAllData\",\n      \"desc\": \"Clears all extension data including cache and settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showSettings\",\n      \"desc\": \"Opens extension settings panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"openLatestReport\",\n      \"desc\": \"Opens most recent analysis report\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"openLatestUnitTestReport\",\n      \"desc\": \"Opens most recent unit test report\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"switchProvider\",\n      \"desc\": \"Switches between different LLM providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyMenuStructure\",\n      \"desc\": \"Copies menu structure to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProviderStatus\",\n      \"desc\": \"Displays current LLM provider status and configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to specific product item in codebase\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to specific analysis result\",\n      \"inputs\": \"item (AnalysisItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProductItemDetails\",\n      \"desc\": \"Shows detailed view of product item\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showInsightItemDetails\",\n      \"desc\": \"Shows detailed view of insight\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showUnitTestItemDetails\",\n      \"desc\": \"Shows detailed view of unit test item\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file centralizes command registration to separate concerns and make the extension maintainable. It solves the problem of command sprawl by providing a single registry that maps VS Code command IDs to their implementations, making it easy to add, modify, or remove commands without touching the main extension activation logic.\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Bootstraps and initializes all extension components when the VS Code extension is activated, setting up views, commands, and services.",
          "userVisibleActions": [
            "Extension activates and displays status bar item showing analysis status",
            "Product Navigator tree view becomes available in the sidebar",
            "Analysis Viewer tree view displays code analysis results",
            "Insights Viewer tree view shows generated insights",
            "Static Analysis Viewer tree view presents static analysis findings",
            "Unit Tests Navigator tree view lists unit tests",
            "Reports tree view displays generated reports",
            "Diagnostics panel shows code issues and warnings",
            "File changes trigger automatic re-analysis and view updates"
          ],
          "developerVisibleActions": [
            "Creates and registers all extension components during activation",
            "Initializes configuration manager for extension settings",
            "Sets up file watcher service to monitor code changes",
            "Registers tree data providers for all sidebar views",
            "Initializes error handler for centralized error management",
            "Creates analysis cache for performance optimization",
            "Establishes LLM state manager for AI integration tracking",
            "Wires up diagnostics provider to display code issues",
            "Registers status bar item for displaying extension state",
            "Returns ExtensionComponents interface containing all initialized services"
          ],
          "keyFunctions": [
            {
              "name": "bootstrap",
              "desc": "Initializes all extension components and returns them as a structured interface",
              "inputs": "vscode.ExtensionContext",
              "outputs": "ExtensionComponents interface containing all initialized services"
            },
            {
              "name": "ExtensionComponents (interface)",
              "desc": "Defines the structure of all extension components including analyzers, viewers, providers, and services",
              "inputs": "N/A (type definition)",
              "outputs": "Type definition for component collection"
            }
          ],
          "dependencies": [
            "vscode",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "FileWatcher",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "llmIntegration",
            "ProductNavigatorProvider",
            "AnalysisViewerProvider",
            "InsightsViewerProvider",
            "StaticAnalysisViewerProvider",
            "UnitTestsNavigatorProvider",
            "configurationManager",
            "ErrorHandler",
            "FileWatcherService",
            "ReportsViewer",
            "ReportsTreeProvider",
            "llmStateManager"
          ],
          "intent": "Centralizes extension initialization logic to cleanly separate activation concerns from command registration and component lifecycle management, ensuring all services are properly instantiated and wired together before the extension becomes active.",
          "rawContent": "```json\n{\n  \"purpose\": \"Bootstraps and initializes all extension components when the VS Code extension is activated, setting up views, commands, and services.\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis status\",\n    \"Product Navigator tree view becomes available in the sidebar\",\n    \"Analysis Viewer tree view displays code analysis results\",\n    \"Insights Viewer tree view shows generated insights\",\n    \"Static Analysis Viewer tree view presents static analysis findings\",\n    \"Unit Tests Navigator tree view lists unit tests\",\n    \"Reports tree view displays generated reports\",\n    \"Diagnostics panel shows code issues and warnings\",\n    \"File changes trigger automatic re-analysis and view updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Creates and registers all extension components during activation\",\n    \"Initializes configuration manager for extension settings\",\n    \"Sets up file watcher service to monitor code changes\",\n    \"Registers tree data providers for all sidebar views\",\n    \"Initializes error handler for centralized error management\",\n    \"Creates analysis cache for performance optimization\",\n    \"Establishes LLM state manager for AI integration tracking\",\n    \"Wires up diagnostics provider to display code issues\",\n    \"Registers status bar item for displaying extension state\",\n    \"Returns ExtensionComponents interface containing all initialized services\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Initializes all extension components and returns them as a structured interface\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents interface containing all initialized services\"\n    },\n    {\n      \"name\": \"ExtensionComponents (interface)\",\n      \"desc\": \"Defines the structure of all extension components including analyzers, viewers, providers, and services\",\n      \"inputs\": \"N/A (type definition)\",\n      \"outputs\": \"Type definition for component collection\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"Centralizes extension initialization logic to cleanly separate activation concerns from command registration and component lifecycle management, ensuring all services are properly instantiated and wired together before the extension becomes active.\"\n}\n```"
        }
      ],
      "commands": [
        {
          "command": "analyzeWorkspace",
          "description": "Analyze the entire workspace to generate comprehensive code insights and analysis results"
        },
        {
          "command": "analyzeCurrentFile",
          "description": "Analyze the currently open file for code insights and quality metrics"
        },
        {
          "command": "copyAllInsights",
          "description": "Copy all generated insights to the system clipboard"
        },
        {
          "command": "copyInsightsForFile",
          "description": "Copy insights for a specific file to the system clipboard"
        },
        {
          "command": "copyInsight",
          "description": "Copy an individual insight to the system clipboard"
        },
        {
          "command": "clearCache",
          "description": "Clear all cached analysis data to force fresh analysis"
        },
        {
          "command": "clearAllData",
          "description": "Clear all extension data including cache, settings, and stored results"
        },
        {
          "command": "openSettings",
          "description": "Open the extension settings panel for configuration"
        },
        {
          "command": "viewLatestReport",
          "description": "Display the most recent analysis report"
        },
        {
          "command": "viewUnitTestReport",
          "description": "Display the latest unit test analysis report"
        },
        {
          "command": "switchProvider",
          "description": "Switch between available LLM providers for code analysis"
        },
        {
          "command": "copyMenuStructure",
          "description": "Copy the extension's menu structure to the clipboard"
        },
        {
          "command": "showProviderStatus",
          "description": "Display information about the current LLM provider configuration"
        },
        {
          "command": "navigateToProductItem",
          "description": "Navigate to a specific product item in the codebase"
        },
        {
          "command": "navigateToAnalysisItem",
          "description": "Navigate to a specific analysis result item"
        },
        {
          "command": "viewProductItemDetails",
          "description": "View detailed information about a selected product item"
        },
        {
          "command": "viewInsightDetails",
          "description": "View detailed information about a specific insight"
        },
        {
          "command": "viewUnitTestDetails",
          "description": "View detailed information about a unit test"
        }
      ]
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Format product documentation into structured Markdown reports",
        "Organize documentation by user perspective (GUI, CLI, API)",
        "Display key insights and themes from codebase analysis",
        "Generate timestamped documentation with creation metadata",
        "Present file analysis results in readable report format",
        "Structure developer-facing technical information",
        "Format domain insights including patterns and system understanding"
      ],
      "summary": "The formatters module provides capabilities for transforming raw product documentation and codebase analysis into human-readable Markdown format. It serves as the presentation layer that takes structured data about a product's features, architecture, and insights and converts it into well-organized documentation that users can read and understand.\n\nUsers interact with this module's output when viewing generated documentation. The formatter creates comprehensive reports that include an overview section, detailed feature breakdowns organized by user perspective (GUI, CLI, API), key insights about the codebase, and technical considerations for developers. Each generated document includes a timestamp showing when it was created, helping users track documentation versions.\n\nThe module supports multiple documentation workflows: formatting complete product documentation with all perspectives and insights, generating focused reports on specific aspects like file analysis, and presenting domain-level understanding including architectural patterns and system themes. All output is structured as Markdown, making it easy to read in documentation viewers, code editors, or convert to other formats.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and insights into readable Markdown format for display to users",
          "userVisibleActions": [
            "View formatted product documentation with overview, features, and user perspectives",
            "See generated documentation with timestamp showing when it was created",
            "Read documentation organized by sections: GUI, CLI, and API perspectives",
            "View key insights about the codebase in structured format",
            "See developer-facing information like architecture and technical considerations",
            "Read file analysis results formatted as Markdown reports",
            "View domain insights including themes, patterns, and system understanding"
          ],
          "developerVisibleActions": [
            "Call formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown strings",
            "Call formatInsightsAsMarkdown() to convert LLM insights into readable Markdown documentation",
            "Call formatFileAnalysisAsMarkdown() to generate Markdown reports for individual file analysis",
            "Call formatDomainInsightsAsMarkdown() to format domain-level insights into documentation",
            "Receive Markdown-formatted strings that can be saved to files or displayed in UI",
            "Generate timestamped documentation showing both local and UTC time",
            "Create structured documentation with hierarchical sections and bullet points"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation object into formatted Markdown string with sections for overview, features, user perspectives, technical details, and architecture",
              "inputs": "EnhancedProductDocumentation object",
              "outputs": "Markdown string with formatted documentation"
            },
            {
              "name": "formatInsightsAsMarkdown",
              "desc": "Converts LLM-generated insights into formatted Markdown documentation with sections for product understanding, user perspective, and developer information",
              "inputs": "LLMInsights object",
              "outputs": "Markdown string with formatted insights"
            },
            {
              "name": "formatFileAnalysisAsMarkdown",
              "desc": "Formats individual file analysis results into Markdown report showing file role, purpose, behavior, and key functions",
              "inputs": "File analysis object with metadata and extracted information",
              "outputs": "Markdown string with file analysis report"
            },
            {
              "name": "formatDomainInsightsAsMarkdown",
              "desc": "Formats domain-level insights into Markdown documentation showing themes, patterns, system understanding, and technical considerations",
              "inputs": "Domain insights object",
              "outputs": "Markdown string with domain insights documentation"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "This file exists to separate documentation formatting concerns from LLM integration logic. It provides a clean way to convert structured documentation objects into human-readable Markdown format, making the documentation generation pipeline more maintainable and testable by isolating formatting logic from data generation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and insights into readable Markdown format for display to users\",\n  \"userVisibleActions\": [\n    \"View formatted product documentation with overview, features, and user perspectives\",\n    \"See generated documentation with timestamp showing when it was created\",\n    \"Read documentation organized by sections: GUI, CLI, and API perspectives\",\n    \"View key insights about the codebase in structured format\",\n    \"See developer-facing information like architecture and technical considerations\",\n    \"Read file analysis results formatted as Markdown reports\",\n    \"View domain insights including themes, patterns, and system understanding\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown strings\",\n    \"Call formatInsightsAsMarkdown() to convert LLM insights into readable Markdown documentation\",\n    \"Call formatFileAnalysisAsMarkdown() to generate Markdown reports for individual file analysis\",\n    \"Call formatDomainInsightsAsMarkdown() to format domain-level insights into documentation\",\n    \"Receive Markdown-formatted strings that can be saved to files or displayed in UI\",\n    \"Generate timestamped documentation showing both local and UTC time\",\n    \"Create structured documentation with hierarchical sections and bullet points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown string with sections for overview, features, user perspectives, technical details, and architecture\",\n      \"inputs\": \"EnhancedProductDocumentation object\",\n      \"outputs\": \"Markdown string with formatted documentation\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into formatted Markdown documentation with sections for product understanding, user perspective, and developer information\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"Markdown string with formatted insights\"\n    },\n    {\n      \"name\": \"formatFileAnalysisAsMarkdown\",\n      \"desc\": \"Formats individual file analysis results into Markdown report showing file role, purpose, behavior, and key functions\",\n      \"inputs\": \"File analysis object with metadata and extracted information\",\n      \"outputs\": \"Markdown string with file analysis report\"\n    },\n    {\n      \"name\": \"formatDomainInsightsAsMarkdown\",\n      \"desc\": \"Formats domain-level insights into Markdown documentation showing themes, patterns, system understanding, and technical considerations\",\n      \"inputs\": \"Domain insights object\",\n      \"outputs\": \"Markdown string with domain insights documentation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting concerns from LLM integration logic. It provides a clean way to convert structured documentation objects into human-readable Markdown format, making the documentation generation pipeline more maintainable and testable by isolating formatting logic from data generation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate to specific files, functions, and API endpoints in the codebase",
        "Display detailed information about code items in interactive webview panels",
        "Show function signatures with parameters and return types",
        "View API endpoint details including HTTP methods and paths",
        "Display file contents with dependencies and relationships",
        "Jump to precise line numbers within files",
        "Present code analysis results and metrics",
        "Handle navigation errors with informative error messages"
      ],
      "summary": "The handlers module provides navigation and information display capabilities for exploring codebases within VS Code. It enables users to quickly jump to any code location - whether a file, function definition, or API endpoint - and view comprehensive details about code items in dedicated webview panels.\n\nThis module supports developer workflows by making code exploration intuitive and efficient. Users can navigate from high-level API endpoints down to specific function implementations, view function signatures with complete parameter information, and examine file dependencies. The module displays analysis results and code metrics alongside the actual code, helping developers understand both structure and quality.\n\nWhen navigation operations fail - such as attempting to access non-existent files or invalid line numbers - the module provides clear error messages to guide users. All navigation actions integrate seamlessly with VS Code's editor, opening files at the correct locations and presenting supplementary information in webview panels that don't disrupt the main editing workflow.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation to code locations (files, functions, endpoints) and displays detailed information about code items in the VS Code editor.",
          "userVisibleActions": [
            "Navigate to a specific file in the workspace",
            "Navigate to a function definition within a file",
            "Navigate to an API endpoint implementation",
            "View detailed information about a code item in a webview panel",
            "See function signatures, parameters, and return types",
            "View endpoints with their HTTP methods and paths",
            "See file contents and dependencies",
            "Jump to specific line numbers in files",
            "View analysis results and code metrics",
            "See error messages when navigation fails"
          ],
          "developerVisibleActions": [
            "Provide ProductNavItem objects to navigate to code locations",
            "Provide AnalysisItem objects to display code analysis details",
            "Trigger navigation by calling handler methods with item data",
            "Handle navigation to files with absolute or relative paths",
            "Display webview panels with formatted code information",
            "Navigate to functions by name within files",
            "Navigate to endpoints by path and method",
            "Handle entry point navigation with function details",
            "Receive error messages when files cannot be opened",
            "Work with workspace-relative or absolute file paths"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to a product navigation item (file, function, or endpoint)",
              "inputs": "ProductNavItem (contains type and data with file/function/endpoint information)",
              "outputs": "Promise<void> - completes when navigation is done"
            },
            {
              "name": "showProductItemDetails",
              "desc": "Displays detailed information about a product item in a webview panel",
              "inputs": "ProductNavItem (contains item data to display)",
              "outputs": "void - opens webview with formatted details"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to an analysis item location in the code",
              "inputs": "AnalysisItem (contains file path and optional line number)",
              "outputs": "Promise<void> - completes when editor opens"
            },
            {
              "name": "showAnalysisItemDetails",
              "desc": "Displays detailed analysis information in a webview panel",
              "inputs": "AnalysisItem (contains analysis data and metrics)",
              "outputs": "void - shows webview with analysis details"
            },
            {
              "name": "navigateToEntryPoint",
              "desc": "Navigates to an entry point function in the codebase",
              "inputs": "EntryPoint (contains file path and function name)",
              "outputs": "Promise<void> - opens file and jumps to function"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "ProductNavItem from productNavigator",
            "AnalysisItem from analysisViewer",
            "EntryPoint from analyzer"
          ],
          "intent": "This file exists to centralize all navigation logic for the extension, separating concerns of moving around the codebase and displaying code details from the main extension logic. It solves the problem of providing consistent navigation and detail views across different types of code items (files, functions, endpoints, analysis results) while handling workspace path resolution and error cases.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to code locations (files, functions, endpoints) and displays detailed information about code items in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the workspace\",\n    \"Navigate to a function definition within a file\",\n    \"Navigate to an API endpoint implementation\",\n    \"View detailed information about a code item in a webview panel\",\n    \"See function signatures, parameters, and return types\",\n    \"View endpoints with their HTTP methods and paths\",\n    \"See file contents and dependencies\",\n    \"Jump to specific line numbers in files\",\n    \"View analysis results and code metrics\",\n    \"See error messages when navigation fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provide ProductNavItem objects to navigate to code locations\",\n    \"Provide AnalysisItem objects to display code analysis details\",\n    \"Trigger navigation by calling handler methods with item data\",\n    \"Handle navigation to files with absolute or relative paths\",\n    \"Display webview panels with formatted code information\",\n    \"Navigate to functions by name within files\",\n    \"Navigate to endpoints by path and method\",\n    \"Handle entry point navigation with function details\",\n    \"Receive error messages when files cannot be opened\",\n    \"Work with workspace-relative or absolute file paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, or endpoint)\",\n      \"inputs\": \"ProductNavItem (contains type and data with file/function/endpoint information)\",\n      \"outputs\": \"Promise<void> - completes when navigation is done\"\n    },\n    {\n      \"name\": \"showProductItemDetails\",\n      \"desc\": \"Displays detailed information about a product item in a webview panel\",\n      \"inputs\": \"ProductNavItem (contains item data to display)\",\n      \"outputs\": \"void - opens webview with formatted details\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item location in the code\",\n      \"inputs\": \"AnalysisItem (contains file path and optional line number)\",\n      \"outputs\": \"Promise<void> - completes when editor opens\"\n    },\n    {\n      \"name\": \"showAnalysisItemDetails\",\n      \"desc\": \"Displays detailed analysis information in a webview panel\",\n      \"inputs\": \"AnalysisItem (contains analysis data and metrics)\",\n      \"outputs\": \"void - shows webview with analysis details\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point function in the codebase\",\n      \"inputs\": \"EntryPoint (contains file path and function name)\",\n      \"outputs\": \"Promise<void> - opens file and jumps to function\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic for the extension, separating concerns of moving around the codebase and displaying code details from the main extension logic. It solves the problem of providing consistent navigation and detail views across different types of code items (files, functions, endpoints, analysis results) while handling workspace path resolution and error cases.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Generates specialized prompts for LLM-based code analysis across multiple analysis types",
        "Creates structured prompts for architecture analysis and documentation generation",
        "Produces prompts for intelligent code refactoring with detailed migration plans",
        "Builds prompts for automated test plan creation and test code generation",
        "Constructs prompts for multi-level documentation (file, module, and product levels)",
        "Generates prompts that guide LLMs to analyze product purpose and value propositions",
        "Creates prompts with function-level analysis for code extraction and reorganization",
        "Produces prompts that include dependency relationship analysis for refactoring impact assessment"
      ],
      "summary": "This module serves as the prompt engineering layer for LLM-based code analysis and generation workflows. It provides centralized prompt construction services that transform analysis requirements into structured, detailed instructions for language models. The module handles multiple analysis scenarios including architecture documentation, product summaries, code refactoring recommendations, and test generation.\n\nUsers interact with this module indirectly through various code analysis and generation features. When requesting codebase analysis, the module constructs prompts that guide LLMs to produce architecture overviews, identify patterns, and document system structure. For refactoring scenarios, it builds detailed prompts that include function-by-function analysis, dependency graphs, step-by-step migration plans, and before/after code examples. The module also supports test-driven workflows by generating prompts that analyze source code and create comprehensive test plans with actual test implementations.\n\nThe prompt building workflow operates at multiple abstraction levels: file-level for detailed code analysis, module-level for component summaries, and product-level for comprehensive documentation. Each prompt type is carefully structured to include relevant context, specific instructions, and output formatting requirements that ensure consistent, high-quality LLM responses. This centralized approach to prompt management ensures consistency across all AI-assisted code analysis and generation features while maintaining the flexibility to handle diverse analysis scenarios.",
      "files": [
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Centralized prompt construction service that builds specialized prompts for different types of LLM-based code analysis tasks",
          "userVisibleActions": [
            "Generates architecture analysis of the codebase",
            "Produces product documentation summaries",
            "Analyzes product purpose and value proposition",
            "Creates detailed file-level code analysis",
            "Generates module-level summaries from multiple files",
            "Produces comprehensive product-level documentation",
            "Creates test plans for source code files",
            "Generates actual test code from test plans"
          ],
          "developerVisibleActions": [
            "Developer calls buildArchitecturePrompt to get an LLM prompt for analyzing system architecture",
            "Developer calls buildProductDocsPrompt to generate prompts for extracting product documentation",
            "Developer calls buildProductPurposePrompt to create prompts for analyzing product purpose",
            "Developer calls buildFileAnalysisPrompt to generate prompts for analyzing individual files",
            "Developer calls buildModuleRollupPrompt to create prompts that summarize multiple files into module documentation",
            "Developer calls buildProductLevelPrompt to generate prompts for overall product analysis",
            "Developer calls buildPerFileTestPlanPrompt to create test planning prompts for specific files",
            "Developer calls buildTestCodeGenerationPrompt to generate actual test code from test plans",
            "Prompts are constructed with specific context, code analysis data, and documentation",
            "Each prompt builder method accepts relevant context and returns a formatted string ready for LLM consumption"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Constructs a prompt for analyzing codebase architecture",
              "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Constructs a prompt for extracting product documentation",
              "inputs": "context (AnalysisContext)",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Constructs a prompt for analyzing product purpose and value",
              "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Constructs a prompt for analyzing a single source file",
              "inputs": "file (FileInfo), content (string), role (string)",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Constructs a prompt for summarizing multiple files into a module",
              "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Constructs a prompt for overall product-level analysis",
              "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Constructs a prompt for creating test plans for a specific file",
              "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Constructs a prompt for generating actual test code from a test plan",
              "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "../../llmService",
            "../../analyzer",
            "../../fileDocumentation",
            "../../fileAccessHelper"
          ],
          "intent": "Eliminates prompt construction duplication across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent prompt formatting and structure for various analysis tasks including architecture analysis, documentation generation, and test creation",
          "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction service that builds specialized prompts for different types of LLM-based code analysis tasks\",\n  \"userVisibleActions\": [\n    \"Generates architecture analysis of the codebase\",\n    \"Produces product documentation summaries\",\n    \"Analyzes product purpose and value proposition\",\n    \"Creates detailed file-level code analysis\",\n    \"Generates module-level summaries from multiple files\",\n    \"Produces comprehensive product-level documentation\",\n    \"Creates test plans for source code files\",\n    \"Generates actual test code from test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildArchitecturePrompt to get an LLM prompt for analyzing system architecture\",\n    \"Developer calls buildProductDocsPrompt to generate prompts for extracting product documentation\",\n    \"Developer calls buildProductPurposePrompt to create prompts for analyzing product purpose\",\n    \"Developer calls buildFileAnalysisPrompt to generate prompts for analyzing individual files\",\n    \"Developer calls buildModuleRollupPrompt to create prompts that summarize multiple files into module documentation\",\n    \"Developer calls buildProductLevelPrompt to generate prompts for overall product analysis\",\n    \"Developer calls buildPerFileTestPlanPrompt to create test planning prompts for specific files\",\n    \"Developer calls buildTestCodeGenerationPrompt to generate actual test code from test plans\",\n    \"Prompts are constructed with specific context, code analysis data, and documentation\",\n    \"Each prompt builder method accepts relevant context and returns a formatted string ready for LLM consumption\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing codebase architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Constructs a prompt for extracting product documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing product purpose and value\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Constructs a prompt for analyzing a single source file\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs a prompt for summarizing multiple files into a module\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Constructs a prompt for overall product-level analysis\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Constructs a prompt for creating test plans for a specific file\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Constructs a prompt for generating actual test code from a test plan\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"Eliminates prompt construction duplication across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent prompt formatting and structure for various analysis tasks including architecture analysis, documentation generation, and test creation\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Builds structured prompts for LLM-based code refactoring that include detailed analysis, extraction plans, and prescriptive instructions.",
          "userVisibleActions": [
            "Receives detailed refactoring recommendations with step-by-step migration plans",
            "Gets code examples showing before/after states for proposed refactorings",
            "Sees function-by-function analysis explaining why code should be extracted or reorganized",
            "Views dependency relationships between functions to understand extraction impact"
          ],
          "developerVisibleActions": [
            "Generates comprehensive refactoring prompts by combining code analysis, product documentation, and architecture insights",
            "Creates structured extraction plans that identify functions to move and their dependencies",
            "Produces prompts that request specific refactoring formats including migration steps and code examples",
            "Builds function analysis sections showing responsibilities, dependencies, and dependents for each function",
            "Formats prompts to guide LLMs in providing prescriptive refactoring instructions rather than general advice"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Constructs a comprehensive refactoring prompt by combining analysis context, code analysis, product documentation, architecture insights, and function analyses",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array",
              "outputs": "Formatted string prompt for LLM consumption"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Creates the foundational prompt structure including context, code analysis, and documentation",
              "inputs": "AnalysisContext, CodeAnalysis, optional product docs, optional architecture insights",
              "outputs": "Base prompt string"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Formats function-level analysis data into prompt text showing signatures, dependencies, and responsibilities",
              "inputs": "Array of FunctionAnalysis objects",
              "outputs": "Formatted function analysis section string"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Generates prompt section specifying what format and details the refactoring recommendations should include",
              "inputs": "None",
              "outputs": "Extraction requirements section string"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
            "../../llmService (AnalysisContext, LLMInsights)",
            "../../fileDocumentation (EnhancedProductDocumentation)"
          ],
          "intent": "This file exists to transform raw code analysis data into structured, detailed prompts that guide LLMs to produce actionable refactoring recommendations with specific extraction plans, migration steps, and code examples rather than vague suggestions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Builds structured prompts for LLM-based code refactoring that include detailed analysis, extraction plans, and prescriptive instructions.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with step-by-step migration plans\",\n    \"Gets code examples showing before/after states for proposed refactorings\",\n    \"Sees function-by-function analysis explaining why code should be extracted or reorganized\",\n    \"Views dependency relationships between functions to understand extraction impact\"\n  ],\n  \"developerVisibleActions\": [\n    \"Generates comprehensive refactoring prompts by combining code analysis, product documentation, and architecture insights\",\n    \"Creates structured extraction plans that identify functions to move and their dependencies\",\n    \"Produces prompts that request specific refactoring formats including migration steps and code examples\",\n    \"Builds function analysis sections showing responsibilities, dependencies, and dependents for each function\",\n    \"Formats prompts to guide LLMs in providing prescriptive refactoring instructions rather than general advice\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Constructs a comprehensive refactoring prompt by combining analysis context, code analysis, product documentation, architecture insights, and function analyses\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array\",\n      \"outputs\": \"Formatted string prompt for LLM consumption\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundational prompt structure including context, code analysis, and documentation\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional product docs, optional architecture insights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Formats function-level analysis data into prompt text showing signatures, dependencies, and responsibilities\",\n      \"inputs\": \"Array of FunctionAnalysis objects\",\n      \"outputs\": \"Formatted function analysis section string\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates prompt section specifying what format and details the refactoring recommendations should include\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Extraction requirements section string\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into structured, detailed prompts that guide LLMs to produce actionable refactoring recommendations with specific extraction plans, migration steps, and code examples rather than vague suggestions.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides prompt builders that generate structured instructions for LLMs to analyze codebases and create test plans.",
          "userVisibleActions": [
            "No direct user-facing actions - this file generates prompts for AI-driven test generation"
          ],
          "developerVisibleActions": [
            "Developer can generate a test setup recommendation prompt by providing workspace root, file list, and optional package.json content",
            "Developer can generate a test planning prompt by providing analysis context, functions list, and optional product/architecture documentation",
            "Developer receives structured JSON-formatted prompts that instruct LLMs on how to analyze code and recommend test configurations",
            "Developer gets prompts that request specific test setup information including framework, dependencies, config files, and mock requirements",
            "Developer gets prompts that request prioritized test plans based on function complexity, coverage, and importance"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Creates a prompt that asks an LLM to analyze a codebase and recommend optimal test setup configuration",
              "inputs": "workspaceRoot (string), fileList (array of file paths), optional packageJsonContent (string)",
              "outputs": "Formatted string prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Creates a prompt that asks an LLM to analyze functions and create a prioritized test plan",
              "inputs": "context (AnalysisContext), functions (array of function objects), optional productDocs, optional architectureInsights",
              "outputs": "Formatted string prompt with codebase statistics and function list requesting prioritized test strategy"
            }
          ],
          "dependencies": [
            "../../analyzer",
            "../services/testing/types/testPlanTypes"
          ],
          "intent": "This file exists to bridge the gap between code analysis and AI-driven test generation by creating standardized, structured prompts that guide LLMs to generate comprehensive test configurations and plans. It solves the problem of consistently requesting the right information from LLMs in a format that can be programmatically processed.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt builders that generate structured instructions for LLMs to analyze codebases and create test plans.\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this file generates prompts for AI-driven test generation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can generate a test setup recommendation prompt by providing workspace root, file list, and optional package.json content\",\n    \"Developer can generate a test planning prompt by providing analysis context, functions list, and optional product/architecture documentation\",\n    \"Developer receives structured JSON-formatted prompts that instruct LLMs on how to analyze code and recommend test configurations\",\n    \"Developer gets prompts that request specific test setup information including framework, dependencies, config files, and mock requirements\",\n    \"Developer gets prompts that request prioritized test plans based on function complexity, coverage, and importance\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt that asks an LLM to analyze a codebase and recommend optimal test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array of file paths), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted string prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt that asks an LLM to analyze functions and create a prioritized test plan\",\n      \"inputs\": \"context (AnalysisContext), functions (array of function objects), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted string prompt with codebase statistics and function list requesting prioritized test strategy\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis and AI-driven test generation by creating standardized, structured prompts that guide LLMs to generate comprehensive test configurations and plans. It solves the problem of consistently requesting the right information from LLMs in a format that can be programmatically processed.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatic file system monitoring and change detection across the workspace",
        "Iterative code analysis using LLM with multi-round information gathering",
        "Automatic test framework detection and configuration validation",
        "Real-time response to file creation, modification, and deletion events",
        "Progressive analysis with automatic file content and search result retrieval",
        "Test dependency and setup requirement identification"
      ],
      "summary": "The services module provides core automation and monitoring capabilities that power the extension's intelligent features. It includes a file watching service that continuously monitors the workspace for file system changes, enabling real-time responses to file creation, modification, deletion, and save events based on configurable file patterns. This allows the extension to stay synchronized with workspace changes without manual intervention.\n\nThe module features an incremental analysis service that orchestrates multi-round LLM conversations for deep code analysis. This service automatically gathers information across multiple iterations, retrieving file contents and executing searches based on previous results, continuing until analysis criteria are met or iteration limits are reached. This enables comprehensive understanding of complex codebases through progressive refinement.\n\nAdditionally, the module includes a test configuration service that automatically detects which testing framework is in use (Jest, Mocha, Vitest, or Pytest) and validates the test environment setup. It identifies missing dependencies, reports configuration status, and provides actionable setup requirements, ensuring generated tests can run successfully without manual configuration troubleshooting.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides a centralized service for monitoring file system changes and document saves in the workspace, consolidating file watching functionality across the extension.",
          "userVisibleActions": [
            "Automatically detects when files are created in the workspace",
            "Automatically detects when files are modified or saved",
            "Automatically detects when files are deleted from the workspace",
            "Responds to file changes based on specific file patterns (e.g., *.md, *.json)",
            "Triggers updates when documents are saved in the editor"
          ],
          "developerVisibleActions": [
            "Register handlers to respond to file creation events",
            "Register handlers to respond to file modification events",
            "Register handlers to respond to file deletion events",
            "Register handlers to respond to document save events",
            "Filter file changes using ignore patterns (e.g., exclude node_modules)",
            "Watch multiple file patterns simultaneously with different handlers",
            "Dispose of watchers to stop monitoring files",
            "Configure which types of changes to monitor (create, change, delete)",
            "Receive structured file change events with URI and change type"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Monitors file system changes matching a specific pattern and triggers callbacks",
              "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)",
              "outputs": "Disposable object to stop watching"
            },
            {
              "name": "onDocumentSave",
              "desc": "Registers a callback to be triggered whenever a document is saved in the editor",
              "inputs": "handler (callback function receiving TextDocument)",
              "outputs": "Disposable object to unregister the handler"
            },
            {
              "name": "stopWatching",
              "desc": "Stops monitoring a specific file pattern and removes associated handlers",
              "inputs": "id (string)",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all active watchers and handlers when service is no longer needed",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getPatternKey",
              "desc": "Generates a unique key for a file pattern to prevent duplicate watchers",
              "inputs": "pattern (string or RelativePattern)",
              "outputs": "string key"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to eliminate duplication of file watching code across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) by providing a single, reusable service that manages file system monitoring. It solves the problem of multiple components independently creating watchers, which leads to code duplication, inconsistent behavior, and resource waste. By centralizing this functionality, components can easily respond to file changes without managing watcher lifecycles themselves.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes and document saves in the workspace, consolidating file watching functionality across the extension.\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created in the workspace\",\n    \"Automatically detects when files are modified or saved\",\n    \"Automatically detects when files are deleted from the workspace\",\n    \"Responds to file changes based on specific file patterns (e.g., *.md, *.json)\",\n    \"Triggers updates when documents are saved in the editor\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register handlers to respond to file creation events\",\n    \"Register handlers to respond to file modification events\",\n    \"Register handlers to respond to file deletion events\",\n    \"Register handlers to respond to document save events\",\n    \"Filter file changes using ignore patterns (e.g., exclude node_modules)\",\n    \"Watch multiple file patterns simultaneously with different handlers\",\n    \"Dispose of watchers to stop monitoring files\",\n    \"Configure which types of changes to monitor (create, change, delete)\",\n    \"Receive structured file change events with URI and change type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Monitors file system changes matching a specific pattern and triggers callbacks\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)\",\n      \"outputs\": \"Disposable object to stop watching\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a callback to be triggered whenever a document is saved in the editor\",\n      \"inputs\": \"handler (callback function receiving TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"stopWatching\",\n      \"desc\": \"Stops monitoring a specific file pattern and removes associated handlers\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all active watchers and handlers when service is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to prevent duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication of file watching code across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) by providing a single, reusable service that manages file system monitoring. It solves the problem of multiple components independently creating watchers, which leads to code duplication, inconsistent behavior, and resource waste. By centralizing this functionality, components can easily respond to file changes without managing watcher lifecycles themselves.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative LLM analysis by processing file and grep requests across multiple conversation rounds until analysis is complete.",
          "userVisibleActions": [
            "Analysis proceeds in multiple rounds, with each round gathering more information based on previous results",
            "File contents and search results are retrieved automatically during analysis",
            "Progress through iterations is tracked and communicated",
            "Analysis stops when completion criteria are met or maximum iterations reached"
          ],
          "developerVisibleActions": [
            "Service processes LLM requests for file reads and grep searches iteratively",
            "Callbacks notify when iterations start and complete",
            "Returns structured results including iteration count, requests made, and whether to continue",
            "Limits requests to 5 per iteration to prevent excessive processing",
            "Formats file and search results into conversation messages",
            "Provides async iterator pattern for testable iteration control"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes file read and grep search requests from LLM, returning formatted results",
              "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation array)",
              "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
            },
            {
              "name": "IterationResult",
              "desc": "Structure representing outcome of a single analysis iteration",
              "inputs": "N/A (interface)",
              "outputs": "Contains result, iteration number, max iterations, requests made, and continuation flag"
            },
            {
              "name": "IterationCallbacks",
              "desc": "Optional callbacks to monitor iteration lifecycle",
              "inputs": "N/A (interface)",
              "outputs": "Callbacks for iteration start and completion events"
            }
          ],
          "dependencies": [
            "fileAccessHelper",
            "LLMRequest"
          ],
          "intent": "Eliminates code duplication by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM requests additional files or searches to complete its analysis, making the pattern testable and reusable across different analysis scenarios.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file and grep requests across multiple conversation rounds until analysis is complete.\",\n  \"userVisibleActions\": [\n    \"Analysis proceeds in multiple rounds, with each round gathering more information based on previous results\",\n    \"File contents and search results are retrieved automatically during analysis\",\n    \"Progress through iterations is tracked and communicated\",\n    \"Analysis stops when completion criteria are met or maximum iterations reached\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service processes LLM requests for file reads and grep searches iteratively\",\n    \"Callbacks notify when iterations start and complete\",\n    \"Returns structured results including iteration count, requests made, and whether to continue\",\n    \"Limits requests to 5 per iteration to prevent excessive processing\",\n    \"Formats file and search results into conversation messages\",\n    \"Provides async iterator pattern for testable iteration control\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes file read and grep search requests from LLM, returning formatted results\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation array)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"IterationResult\",\n      \"desc\": \"Structure representing outcome of a single analysis iteration\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Contains result, iteration number, max iterations, requests made, and continuation flag\"\n    },\n    {\n      \"name\": \"IterationCallbacks\",\n      \"desc\": \"Optional callbacks to monitor iteration lifecycle\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Callbacks for iteration start and completion events\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest\"\n  ],\n  \"intent\": \"Eliminates code duplication by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM requests additional files or searches to complete its analysis, making the pattern testable and reusable across different analysis scenarios.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects test framework configuration in the workspace and determines if setup is required for generated tests to work",
          "userVisibleActions": [
            "Automatically detects which test framework is being used in the project (Jest, Mocha, Vitest, or Pytest)",
            "Reports whether test configuration is properly set up and ready to use",
            "Identifies missing test dependencies that need to be installed",
            "Provides list of setup actions required to make tests work",
            "Detects if TypeScript support for testing is configured"
          ],
          "developerVisibleActions": [
            "Reads package.json to detect test scripts and installed dependencies",
            "Scans for test framework configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini, etc.)",
            "Checks if TypeScript test dependencies are installed when TypeScript files exist",
            "Returns structured status report about test framework and configuration state",
            "Identifies specific missing dependencies needed for the detected framework",
            "Generates list of required setup actions to complete test configuration"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Analyzes workspace to detect test framework and configuration status",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestConfigStatus object with framework type, configuration status, missing dependencies, and required setup actions"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "SWLogger"
          ],
          "intent": "Eliminates manual test configuration by automatically detecting the test framework in use and identifying any missing setup, ensuring generated tests will work without user intervention or configuration errors",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration in the workspace and determines if setup is required for generated tests to work\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used in the project (Jest, Mocha, Vitest, or Pytest)\",\n    \"Reports whether test configuration is properly set up and ready to use\",\n    \"Identifies missing test dependencies that need to be installed\",\n    \"Provides list of setup actions required to make tests work\",\n    \"Detects if TypeScript support for testing is configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Reads package.json to detect test scripts and installed dependencies\",\n    \"Scans for test framework configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini, etc.)\",\n    \"Checks if TypeScript test dependencies are installed when TypeScript files exist\",\n    \"Returns structured status report about test framework and configuration state\",\n    \"Identifies specific missing dependencies needed for the detected framework\",\n    \"Generates list of required setup actions to complete test configuration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration status, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration by automatically detecting the test framework in use and identifying any missing setup, ensuring generated tests will work without user intervention or configuration errors\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automatically analyze codebases to identify testable functions and create prioritized test plans based on complexity and risk",
        "Detect existing test environments and generate setup plans for multiple programming languages (TypeScript, JavaScript, Python, Java, C++) and frameworks (Jest, Mocha, pytest, JUnit, Google Test)",
        "Generate unit tests for code functions using AI in small batches with real-time progress tracking",
        "Execute test suites and capture detailed results including pass/fail status, error messages, and execution statistics",
        "Automatically validate and fix failing tests through AI-powered retry attempts",
        "Provide comprehensive test reports showing overall test health and coverage"
      ],
      "summary": "This module provides an end-to-end AI-powered testing workflow that helps developers create, execute, and maintain unit tests for their codebase. It begins by analyzing the code to understand which functions are testable and creates a prioritized test plan based on complexity, dependencies, and risk factors. The module then detects the current test environment configuration and can generate setup instructions if the testing infrastructure is incomplete.\n\nOnce the environment is ready, the module generates unit tests for selected functions using AI assistance, processing them in small batches while providing real-time progress updates. After test generation, it automatically executes the test suites using the appropriate testing framework (Jest, Mocha, pytest, JUnit, or Google Test) and captures detailed results including pass/fail counts, error messages, stack traces, and execution timing.\n\nWhen tests fail, the module leverages AI to automatically analyze and fix the failures through multiple retry attempts, significantly reducing manual debugging effort. Throughout the entire workflow, users receive progress notifications, detailed statistics, and comprehensive test reports that help them understand their codebase's test coverage and health. This automated approach transforms testing from a manual, time-consuming task into a streamlined, AI-assisted process.",
      "files": [
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates unit tests for code functions using an LLM in small batches with progress tracking and execution validation.",
          "userVisibleActions": [
            "Progress updates showing which function is being tested and completion percentage",
            "Test generation results indicating success or failure for each function",
            "Notifications when test files are created or updated",
            "Error messages if test generation fails for specific functions"
          ],
          "developerVisibleActions": [
            "Developer triggers test generation for selected functions",
            "System reads source code and extracts function signatures",
            "LLM generates test code based on function context and existing mocks",
            "Generated tests are validated by executing them",
            "Test files are written to the test directory structure",
            "Progress callback provides real-time status updates during batch processing",
            "Results map shows success/failure status for each function tested"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for multiple functions in a batch with progress tracking",
              "inputs": "functions array, workspace root path, LLM service, optional progress callback",
              "outputs": "Map of function names to test generation results"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Retrieves the source code for a specific function from its file",
              "inputs": "TestableFunction object, workspace root path",
              "outputs": "Source code string for the function"
            },
            {
              "name": "generateTestForFunction",
              "desc": "Creates a test for a single function using LLM and validates it",
              "inputs": "Function details, source code, LLM service, workspace root, test framework type, existing mocks",
              "outputs": "TestGenerationResult with test code and execution status"
            },
            {
              "name": "buildGenerationPrompt",
              "desc": "Constructs the LLM prompt with function context and mock information",
              "inputs": "Function object, source code, test framework name, existing mocks",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestableFunction",
            "TestGenerationState",
            "TestGenerationResult",
            "buildGenerationPrompt",
            "TestExecutionService",
            "SWLogger"
          ],
          "intent": "Automates test generation by leveraging AI to write unit tests incrementally for code functions, reducing manual test writing effort while ensuring generated tests are valid through automatic execution and validation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions using an LLM in small batches with progress tracking and execution validation.\",\n  \"userVisibleActions\": [\n    \"Progress updates showing which function is being tested and completion percentage\",\n    \"Test generation results indicating success or failure for each function\",\n    \"Notifications when test files are created or updated\",\n    \"Error messages if test generation fails for specific functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for selected functions\",\n    \"System reads source code and extracts function signatures\",\n    \"LLM generates test code based on function context and existing mocks\",\n    \"Generated tests are validated by executing them\",\n    \"Test files are written to the test directory structure\",\n    \"Progress callback provides real-time status updates during batch processing\",\n    \"Results map shows success/failure status for each function tested\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service, optional progress callback\",\n      \"outputs\": \"Map of function names to test generation results\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Retrieves the source code for a specific function from its file\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    },\n    {\n      \"name\": \"generateTestForFunction\",\n      \"desc\": \"Creates a test for a single function using LLM and validates it\",\n      \"inputs\": \"Function details, source code, LLM service, workspace root, test framework type, existing mocks\",\n      \"outputs\": \"TestGenerationResult with test code and execution status\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Constructs the LLM prompt with function context and mock information\",\n      \"inputs\": \"Function object, source code, test framework name, existing mocks\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Automates test generation by leveraging AI to write unit tests incrementally for code functions, reducing manual test writing effort while ensuring generated tests are valid through automatic execution and validation.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code functions and creates a prioritized test plan using LLM guidance based on complexity, dependencies, and product context.",
          "userVisibleActions": [
            "Receives analysis of which functions in their codebase are testable and which are not",
            "Gets a prioritized test plan showing which functions should be tested first based on complexity and risk",
            "Views function groups organized by testing priority",
            "Sees statistics about total functions vs testable functions in their codebase"
          ],
          "developerVisibleActions": [
            "Calls analyzeFunctions() to extract function metadata from code analysis results",
            "Calls createTestPlan() to generate an LLM-based test strategy with prioritized function groups",
            "Calls saveTestPlan() to persist the generated test plan to disk for later use",
            "Reviews log messages showing test planning progress and statistics",
            "Uses the resulting TestPlan object containing function groups, testability status, and testing priorities"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts and normalizes function metadata from code analysis results",
              "inputs": "codeAnalysis object containing function information",
              "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
            },
            {
              "name": "createTestPlan",
              "desc": "Generates a prioritized test plan by sending function data to LLM with product and architecture context",
              "inputs": "AnalysisContext, functions array, llmService, optional productDocs and architectureInsights",
              "outputs": "TestPlan object with function groups, testability counts, and testing priorities"
            },
            {
              "name": "saveTestPlan",
              "desc": "Persists the generated test plan to a JSON file on disk",
              "inputs": "TestPlan object and file path where to save",
              "outputs": "File written to disk (void return)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "testPlanTypes",
            "testPrompts",
            "AnalysisContext",
            "SWLogger"
          ],
          "intent": "This service exists to bridge code analysis results with test generation by intelligently prioritizing which functions should be tested first. It solves the problem of determining testing priorities in large codebases by using LLM reasoning to consider complexity, dependencies, and business context rather than testing everything indiscriminately.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code functions and creates a prioritized test plan using LLM guidance based on complexity, dependencies, and product context.\",\n  \"userVisibleActions\": [\n    \"Receives analysis of which functions in their codebase are testable and which are not\",\n    \"Gets a prioritized test plan showing which functions should be tested first based on complexity and risk\",\n    \"Views function groups organized by testing priority\",\n    \"Sees statistics about total functions vs testable functions in their codebase\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis results\",\n    \"Calls createTestPlan() to generate an LLM-based test strategy with prioritized function groups\",\n    \"Calls saveTestPlan() to persist the generated test plan to disk for later use\",\n    \"Reviews log messages showing test planning progress and statistics\",\n    \"Uses the resulting TestPlan object containing function groups, testability status, and testing priorities\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function metadata from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing function information\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan by sending function data to LLM with product and architecture context\",\n      \"inputs\": \"AnalysisContext, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups, testability counts, and testing priorities\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to a JSON file on disk\",\n      \"inputs\": \"TestPlan object and file path where to save\",\n      \"outputs\": \"File written to disk (void return)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"testPlanTypes\",\n    \"testPrompts\",\n    \"AnalysisContext\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to bridge code analysis results with test generation by intelligently prioritizing which functions should be tested first. It solves the problem of determining testing priorities in large codebases by using LLM reasoning to consider complexity, dependencies, and business context rather than testing everything indiscriminately.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Detects test environment configuration and generates AI-powered test setup plans for different programming languages and testing frameworks.",
          "userVisibleActions": [
            "Automatically detects the programming language used in the workspace (TypeScript, JavaScript, Python, Java, C++)",
            "Identifies existing testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)",
            "Discovers test directories and configuration files",
            "Generates a test setup plan with recommended dependencies and configuration",
            "Provides step-by-step setup instructions for missing test infrastructure",
            "Reports whether the test environment is ready or needs setup"
          ],
          "developerVisibleActions": [
            "Call detectTestEnvironment() to scan workspace and identify language, framework, and existing test configuration",
            "Use generateTestSetupPlan() to create an AI-generated setup plan based on detected environment",
            "Execute executeSetupPlan() to automatically install dependencies and create configuration files",
            "Receive TestEnvironment object with details about detected language, framework, and file paths",
            "Get TestSetupPlan with missing dependencies, configuration templates, and setup steps",
            "Obtain SetupExecutionResult indicating success/failure and any errors encountered"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Scans workspace to detect programming language, testing framework, and existing test infrastructure",
              "inputs": "workspaceRoot (string path)",
              "outputs": "TestEnvironment object with language, framework, paths, and status"
            },
            {
              "name": "generateTestSetupPlan",
              "desc": "Uses LLM to generate a comprehensive test setup plan based on detected environment",
              "inputs": "TestEnvironment object, optional LLM provider",
              "outputs": "TestSetupPlan with dependencies, configuration, and setup steps"
            },
            {
              "name": "executeSetupPlan",
              "desc": "Executes the generated setup plan by installing dependencies and creating configuration files",
              "inputs": "TestSetupPlan object, workspaceRoot path",
              "outputs": "SetupExecutionResult with success status and execution details"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively retrieves all files in a directory for language detection",
              "inputs": "directory path (string)",
              "outputs": "Array of file paths"
            },
            {
              "name": "detectTestingFramework",
              "desc": "Identifies which testing framework is in use based on dependencies and config files",
              "inputs": "packageJsonPath (string)",
              "outputs": "Framework name string (jest, mocha, pytest, junit, etc.)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "./types/testSetupTypes",
            "../../prompts/testPrompts",
            "../../../logger"
          ],
          "intent": "Automates the detection and setup of test environments across multiple programming languages and testing frameworks, reducing manual configuration burden by using LLM to generate intelligent, context-aware setup plans tailored to the detected project structure.",
          "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates AI-powered test setup plans for different programming languages and testing frameworks.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language used in the workspace (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Identifies existing testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)\",\n    \"Discovers test directories and configuration files\",\n    \"Generates a test setup plan with recommended dependencies and configuration\",\n    \"Provides step-by-step setup instructions for missing test infrastructure\",\n    \"Reports whether the test environment is ready or needs setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call detectTestEnvironment() to scan workspace and identify language, framework, and existing test configuration\",\n    \"Use generateTestSetupPlan() to create an AI-generated setup plan based on detected environment\",\n    \"Execute executeSetupPlan() to automatically install dependencies and create configuration files\",\n    \"Receive TestEnvironment object with details about detected language, framework, and file paths\",\n    \"Get TestSetupPlan with missing dependencies, configuration templates, and setup steps\",\n    \"Obtain SetupExecutionResult indicating success/failure and any errors encountered\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Scans workspace to detect programming language, testing framework, and existing test infrastructure\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"TestEnvironment object with language, framework, paths, and status\"\n    },\n    {\n      \"name\": \"generateTestSetupPlan\",\n      \"desc\": \"Uses LLM to generate a comprehensive test setup plan based on detected environment\",\n      \"inputs\": \"TestEnvironment object, optional LLM provider\",\n      \"outputs\": \"TestSetupPlan with dependencies, configuration, and setup steps\"\n    },\n    {\n      \"name\": \"executeSetupPlan\",\n      \"desc\": \"Executes the generated setup plan by installing dependencies and creating configuration files\",\n      \"inputs\": \"TestSetupPlan object, workspaceRoot path\",\n      \"outputs\": \"SetupExecutionResult with success status and execution details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively retrieves all files in a directory for language detection\",\n      \"inputs\": \"directory path (string)\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"detectTestingFramework\",\n      \"desc\": \"Identifies which testing framework is in use based on dependencies and config files\",\n      \"inputs\": \"packageJsonPath (string)\",\n      \"outputs\": \"Framework name string (jest, mocha, pytest, junit, etc.)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"Automates the detection and setup of test environments across multiple programming languages and testing frameworks, reducing manual configuration burden by using LLM to generate intelligent, context-aware setup plans tailored to the detected project structure.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates tests by running them and automatically fixing failures using LLM assistance",
          "userVisibleActions": [
            "Tests are automatically executed in the workspace",
            "Test results show pass/fail status with counts",
            "Failing tests are automatically fixed through multiple retry attempts",
            "Progress updates appear in logs showing test execution status",
            "Test reports are generated showing overall test health"
          ],
          "developerVisibleActions": [
            "Call runTests() to execute Jest tests in workspace and get execution results",
            "Call fixFailingTest() to automatically repair a failing test using LLM suggestions",
            "Receive TestExecutionResult objects containing passed/failed/error counts",
            "Access test reports and summaries showing test suite health metrics",
            "Configure maximum fix attempts to control auto-repair retry limit",
            "Get detailed failure information including error messages and stack traces"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or a specific test file and returns execution results with pass/fail counts",
              "inputs": "workspaceRoot: string, testFile?: string (optional specific test file)",
              "outputs": "Promise<TestExecutionResult[]> with test outcomes and statistics"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to automatically fix a failing test by using LLM to generate corrections",
              "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)",
              "outputs": "Promise<{ success: boolean; attempts: number; finalError?: string }> indicating fix outcome"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "TestExecutionResult",
            "TestReport",
            "TestReportSummary",
            "buildFixPrompt",
            "SWLogger"
          ],
          "intent": "This service exists to automate test validation and repair in the development workflow. It solves the problem of manually fixing failing tests by using LLM intelligence to analyze test failures and automatically generate fixes, reducing developer time spent on test maintenance and improving test suite reliability.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them and automatically fixing failures using LLM assistance\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed in the workspace\",\n    \"Test results show pass/fail status with counts\",\n    \"Failing tests are automatically fixed through multiple retry attempts\",\n    \"Progress updates appear in logs showing test execution status\",\n    \"Test reports are generated showing overall test health\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runTests() to execute Jest tests in workspace and get execution results\",\n    \"Call fixFailingTest() to automatically repair a failing test using LLM suggestions\",\n    \"Receive TestExecutionResult objects containing passed/failed/error counts\",\n    \"Access test reports and summaries showing test suite health metrics\",\n    \"Configure maximum fix attempts to control auto-repair retry limit\",\n    \"Get detailed failure information including error messages and stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns execution results with pass/fail counts\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string (optional specific test file)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> with test outcomes and statistics\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test by using LLM to generate corrections\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)\",\n      \"outputs\": \"Promise<{ success: boolean; attempts: number; finalError?: string }> indicating fix outcome\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to automate test validation and repair in the development workflow. It solves the problem of manually fixing failing tests by using LLM intelligence to analyze test failures and automatically generate fixes, reducing developer time spent on test maintenance and improving test suite reliability.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes test suites (Jest/Mocha) and captures their results, errors, and execution statistics",
          "userVisibleActions": [
            "Tests run and complete with pass/fail status",
            "Test execution progress is displayed",
            "Test failures show error messages and stack traces",
            "Test duration and timing information is shown",
            "Overall test summary shows passed/failed/error counts"
          ],
          "developerVisibleActions": [
            "Call runJest() or runMocha() to execute tests for specific files or entire test suite",
            "Receive structured test results with pass/fail counts and error details",
            "Get detailed error information including test names, messages, and stack traces",
            "Access test execution duration and performance metrics",
            "Handle test execution errors and timeouts gracefully"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Executes Jest test runner for a specific file or all tests",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> containing test outcomes, counts, and errors"
            },
            {
              "name": "runMocha",
              "desc": "Executes Mocha test runner for a specific file or all tests",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> containing test outcomes, counts, and errors"
            },
            {
              "name": "parseJestOutput",
              "desc": "Parses JSON output from Jest test runner into structured results",
              "inputs": "stdout (string), stderr (string)",
              "outputs": "TestExecutionResult[] with parsed test outcomes and error details"
            },
            {
              "name": "parseMochaOutput",
              "desc": "Parses JSON output from Mocha test runner into structured results",
              "inputs": "stdout (string), stderr (string)",
              "outputs": "TestExecutionResult[] with parsed test outcomes and error details"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "Provides a unified interface for running different test frameworks (Jest and Mocha) in the workspace, capturing their output, and converting it into a consistent format that can be displayed to users and processed by other parts of the application. Solves the problem of executing tests programmatically and handling their results reliably with proper error handling and timeout management.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest/Mocha) and captures their results, errors, and execution statistics\",\n  \"userVisibleActions\": [\n    \"Tests run and complete with pass/fail status\",\n    \"Test execution progress is displayed\",\n    \"Test failures show error messages and stack traces\",\n    \"Test duration and timing information is shown\",\n    \"Overall test summary shows passed/failed/error counts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runJest() or runMocha() to execute tests for specific files or entire test suite\",\n    \"Receive structured test results with pass/fail counts and error details\",\n    \"Get detailed error information including test names, messages, and stack traces\",\n    \"Access test execution duration and performance metrics\",\n    \"Handle test execution errors and timeouts gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest test runner for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes, counts, and errors\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha test runner for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes, counts, and errors\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses JSON output from Jest test runner into structured results\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test outcomes and error details\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses JSON output from Mocha test runner into structured results\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test outcomes and error details\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for running different test frameworks (Jest and Mocha) in the workspace, capturing their output, and converting it into a consistent format that can be displayed to users and processed by other parts of the application. Solves the problem of executing tests programmatically and handling their results reliably with proper error handling and timeout management.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Track test generation progress through multiple phases (setup, planning, generation, validation, complete)",
        "Monitor individual function test status and completion",
        "View test execution results with pass/fail statistics and error details",
        "Access test quality recommendations and improvement suggestions",
        "Review test setup configurations including frameworks, dependencies, and required files",
        "Monitor test environment status and identify missing dependencies",
        "View generated mock statements with explanations for test scenarios",
        "Track test generation failures with error messages and retry attempts"
      ],
      "summary": "This module provides comprehensive type definitions for the testing workflow system, enabling users to understand and track the entire test lifecycle from setup through execution. It structures all the data types needed to represent test planning, generation, validation, and execution phases, giving users visibility into each step of the automated testing process.\n\nUsers can monitor test generation as it progresses through distinct phases, seeing which functions are being tested, how many have completed, and any failures that occur along the way. The module supports detailed test execution reporting, including pass rates, error diagnostics with stack traces, and actionable recommendations for improving test quality. For test setup, users receive clear information about required test frameworks, dependencies to install, configuration files to create, and the overall status of their test environment, ensuring they have everything needed before test generation begins.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for the test planning and generation service, structuring how test plans, functions, and generation states are represented.",
          "userVisibleActions": [
            "Users can see test generation progress through different phases (setup, planning, generation, validation, complete)",
            "Users can view which functions are being tested and their completion status",
            "Users can see failures during test generation with error messages and attempt counts",
            "Users can track how many functions have been generated and validated out of the total"
          ],
          "developerVisibleActions": [
            "Developers create test plans with grouped functions organized by priority",
            "Developers specify which functions are testable and their complexity levels",
            "Developers track dependencies and mocking requirements for each function",
            "Developers monitor test generation state across different phases",
            "Developers access function metadata including file location, line numbers, parameters, and return types",
            "Developers handle test failures with retry logic based on attempt counts"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a strongly-typed contract for the test planning service, ensuring consistency when organizing functions into test groups, tracking test generation progress through multiple phases, and managing failures during automated test creation. Enables type-safe handling of function metadata needed for intelligent test generation decisions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for the test planning and generation service, structuring how test plans, functions, and generation states are represented.\",\n  \"userVisibleActions\": [\n    \"Users can see test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"Users can view which functions are being tested and their completion status\",\n    \"Users can see failures during test generation with error messages and attempt counts\",\n    \"Users can track how many functions have been generated and validated out of the total\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers create test plans with grouped functions organized by priority\",\n    \"Developers specify which functions are testable and their complexity levels\",\n    \"Developers track dependencies and mocking requirements for each function\",\n    \"Developers monitor test generation state across different phases\",\n    \"Developers access function metadata including file location, line numbers, parameters, and return types\",\n    \"Developers handle test failures with retry logic based on attempt counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for the test planning service, ensuring consistency when organizing functions into test groups, tracking test generation progress through multiple phases, and managing failures during automated test creation. Enables type-safe handling of function metadata needed for intelligent test generation decisions.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces for test generation, validation, execution results, and test reporting data structures.",
          "userVisibleActions": [
            "View test execution results showing passed/failed/error counts",
            "See test reports with pass rates and summary statistics",
            "Review error details for failed tests including error messages and stack traces",
            "Access recommendations for improving test quality",
            "View mock statements with explanations for generated tests"
          ],
          "developerVisibleActions": [
            "Import type definitions for test generation results including test file paths, imports, mocks, and test code",
            "Use TestValidationResult to handle test validation outcomes with fixed code and explanations",
            "Access TestExecutionResult to retrieve test run statistics and duration metrics",
            "Generate structured test reports with TestReport interface containing summaries and recommendations",
            "Handle test errors using TestErrorDetail with test names, messages, and stack traces",
            "Structure mock statements with MockStatement interface for generated test mocks"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to provide a consistent, type-safe contract for test-related operations throughout the application. It solves the problem of standardizing data structures for test generation workflows, validation processes, execution results, and reporting, ensuring all components that handle testing features work with the same data format.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test generation, validation, execution results, and test reporting data structures.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed/failed/error counts\",\n    \"See test reports with pass rates and summary statistics\",\n    \"Review error details for failed tests including error messages and stack traces\",\n    \"Access recommendations for improving test quality\",\n    \"View mock statements with explanations for generated tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import type definitions for test generation results including test file paths, imports, mocks, and test code\",\n    \"Use TestValidationResult to handle test validation outcomes with fixed code and explanations\",\n    \"Access TestExecutionResult to retrieve test run statistics and duration metrics\",\n    \"Generate structured test reports with TestReport interface containing summaries and recommendations\",\n    \"Handle test errors using TestErrorDetail with test names, messages, and stack traces\",\n    \"Structure mock statements with MockStatement interface for generated test mocks\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a consistent, type-safe contract for test-related operations throughout the application. It solves the problem of standardizing data structures for test generation workflows, validation processes, execution results, and reporting, ensuring all components that handle testing features work with the same data format.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test setup service operations, including test configuration, dependencies, and execution results.",
          "userVisibleActions": [
            "User receives information about test setup plans including framework and dependencies",
            "User sees which configuration files will be created during test setup",
            "User is informed about test environment status and missing dependencies",
            "User receives feedback on setup execution success with created files and installed dependencies",
            "User is notified of any errors that occurred during test setup"
          ],
          "developerVisibleActions": [
            "Developer uses TestSetupPlan to structure test framework configuration data",
            "Developer accesses TestEnvironment to check existing test infrastructure",
            "Developer receives SetupExecutionResult to understand what was created and installed",
            "Developer identifies mock requirements needed for testing",
            "Developer tracks dependency installation status through structured result types"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides type safety and structure for test setup operations by defining interfaces for test plans, environment detection, dependency management, and execution results, ensuring consistent data handling throughout the test setup service.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup service operations, including test configuration, dependencies, and execution results.\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including framework and dependencies\",\n    \"User sees which configuration files will be created during test setup\",\n    \"User is informed about test environment status and missing dependencies\",\n    \"User receives feedback on setup execution success with created files and installed dependencies\",\n    \"User is notified of any errors that occurred during test setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan to structure test framework configuration data\",\n    \"Developer accesses TestEnvironment to check existing test infrastructure\",\n    \"Developer receives SetupExecutionResult to understand what was created and installed\",\n    \"Developer identifies mock requirements needed for testing\",\n    \"Developer tracks dependency installation status through structured result types\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for test setup operations by defining interfaces for test plans, environment detection, dependency management, and execution results, ensuring consistent data handling throughout the test setup service.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Efficiently processes multiple files in parallel across the codebase",
        "Automatically caches file contents to reduce redundant file system reads",
        "Intelligently filters out common non-source directories (node_modules, .git, dist, build, etc.)",
        "Detects file changes automatically and invalidates cached content",
        "Manages memory through automatic cache cleanup",
        "Handles processing errors gracefully without stopping the entire operation"
      ],
      "summary": "The fileSystem module provides high-performance file processing infrastructure that handles reading, filtering, and caching operations across the codebase. It serves as the foundation for any feature that needs to analyze or process multiple files efficiently.\n\nWhen you work with files, this module automatically skips irrelevant directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea to focus only on source files. It processes files in parallel for maximum speed while caching frequently accessed files to avoid redundant reads. The cache automatically detects when files change and refreshes its content, ensuring you always work with up-to-date data.\n\nThis module is used internally by other features that need to scan, analyze, or process files across your project. It ensures these operations complete quickly even in large codebases, while keeping memory usage under control through intelligent cache management and cleanup.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Optimizes file system operations by caching file contents to reduce redundant reads across multiple components.",
          "userVisibleActions": [
            "Files load faster when accessed multiple times within a short period",
            "Changes to files are automatically detected and reflected immediately",
            "Memory usage is kept under control through automatic cache cleanup"
          ],
          "developerVisibleActions": [
            "Retrieve file content through cache with automatic fallback to disk reads",
            "Cache automatically invalidates when files change on disk",
            "Access cache statistics to monitor performance (hits, misses, evictions)",
            "Configure cache size limits and time-to-live (TTL) settings",
            "Cache entries are automatically evicted using LRU policy when size limit is reached",
            "File changes are detected via file system watcher for automatic invalidation"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache or reads from disk if not cached or stale",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "isStale",
              "desc": "Determines if a cached file has exceeded its time-to-live threshold",
              "inputs": "cached: CachedFile",
              "outputs": "boolean - true if expired"
            },
            {
              "name": "getFileHash",
              "desc": "Computes hash of file to detect content changes",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file hash"
            },
            {
              "name": "evictIfNeeded",
              "desc": "Removes least recently used cache entries when size limit is exceeded",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "setupWatcher",
              "desc": "Configures file system watcher to automatically invalidate cache on file changes",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "invalidate",
              "desc": "Removes specific file from cache when it changes",
              "inputs": "filePath: string",
              "outputs": "void"
            },
            {
              "name": "clear",
              "desc": "Removes all entries from cache",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getStats",
              "desc": "Returns cache performance metrics",
              "inputs": "none",
              "outputs": "CacheStats - hits, misses, evictions, size"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "This file exists to improve extension performance by preventing redundant file system reads. It solves the problem of multiple components requesting the same file content repeatedly, which would slow down operations. The cache intelligently manages memory by evicting old entries and automatically detects file changes to ensure data stays fresh.",
          "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant reads across multiple components.\",\n  \"userVisibleActions\": [\n    \"Files load faster when accessed multiple times within a short period\",\n    \"Changes to files are automatically detected and reflected immediately\",\n    \"Memory usage is kept under control through automatic cache cleanup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file content through cache with automatic fallback to disk reads\",\n    \"Cache automatically invalidates when files change on disk\",\n    \"Access cache statistics to monitor performance (hits, misses, evictions)\",\n    \"Configure cache size limits and time-to-live (TTL) settings\",\n    \"Cache entries are automatically evicted using LRU policy when size limit is reached\",\n    \"File changes are detected via file system watcher for automatic invalidation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache or reads from disk if not cached or stale\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Determines if a cached file has exceeded its time-to-live threshold\",\n      \"inputs\": \"cached: CachedFile\",\n      \"outputs\": \"boolean - true if expired\"\n    },\n    {\n      \"name\": \"getFileHash\",\n      \"desc\": \"Computes hash of file to detect content changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file hash\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used cache entries when size limit is exceeded\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Configures file system watcher to automatically invalidate cache on file changes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes specific file from cache when it changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all entries from cache\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats - hits, misses, evictions, size\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by preventing redundant file system reads. It solves the problem of multiple components requesting the same file content repeatedly, which would slow down operations. The cache intelligently manages memory by evicting old entries and automatically detects file changes to ensure data stays fresh.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel across the codebase",
          "userVisibleActions": [
            "Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing",
            "Files are processed in parallel for faster completion",
            "Error handling ensures processing continues even if individual files fail"
          ],
          "developerVisibleActions": [
            "Developer creates a FileProcessor instance to handle bulk file operations",
            "Developer provides a list of file paths and a processing function",
            "Developer receives processed results for all files that passed filtering",
            "Developer can customize which files to process by providing a custom IFileFilter implementation",
            "Developer can customize how files are read by providing a custom IFileReader implementation",
            "Developer provides error context for better error tracking and debugging",
            "Developer uses DefaultFileFilter to automatically exclude common non-source directories",
            "Developer uses DefaultFileReader for standard UTF-8 file reading"
          ],
          "keyFunctions": [
            {
              "name": "shouldProcess",
              "desc": "Determines if a file should be processed based on its path",
              "inputs": "filePath: string",
              "outputs": "boolean indicating if file should be processed"
            },
            {
              "name": "readFile",
              "desc": "Reads a file's content as UTF-8 text",
              "inputs": "filePath: string",
              "outputs": "Promise<string> containing file content"
            },
            {
              "name": "processFiles",
              "desc": "Filters, reads, and processes multiple files in parallel using a provided processing function",
              "inputs": "files: string[], processor: function, optional context: ErrorContext",
              "outputs": "Promise<T[]> containing array of processed results"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "../../utils/errorHandler"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, reusable implementation that handles filtering unwanted files, reading file contents, and processing multiple files in parallel with proper error handling",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel across the codebase\",\n  \"userVisibleActions\": [\n    \"Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing\",\n    \"Files are processed in parallel for faster completion\",\n    \"Error handling ensures processing continues even if individual files fail\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates a FileProcessor instance to handle bulk file operations\",\n    \"Developer provides a list of file paths and a processing function\",\n    \"Developer receives processed results for all files that passed filtering\",\n    \"Developer can customize which files to process by providing a custom IFileFilter implementation\",\n    \"Developer can customize how files are read by providing a custom IFileReader implementation\",\n    \"Developer provides error context for better error tracking and debugging\",\n    \"Developer uses DefaultFileFilter to automatically exclude common non-source directories\",\n    \"Developer uses DefaultFileReader for standard UTF-8 file reading\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file's content as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> containing file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Filters, reads, and processes multiple files in parallel using a provided processing function\",\n      \"inputs\": \"files: string[], processor: function, optional context: ErrorContext\",\n      \"outputs\": \"Promise<T[]> containing array of processed results\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, reusable implementation that handles filtering unwanted files, reading file contents, and processing multiple files in parallel with proper error handling\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Persistent storage of code analysis results in organized, timestamped directory structures",
        "Automatic generation and saving of product documentation for analyzed codebases",
        "Storage of architecture insights and patterns discovered during analysis",
        "Creation of code summaries with statistics and metadata",
        "Maintenance of a 'latest' reference for easy access to most recent analysis",
        "Structured organization of analysis runs with complete metadata and timing information"
      ],
      "summary": "The persistence module provides comprehensive storage capabilities for code analysis results. It manages a structured file system under .shadow/docs where each analysis run is stored in a timestamped directory, ensuring full history and traceability of all analyses performed.\n\nUsers benefit from automatic organization of analysis outputs including product documentation, architecture insights, and code summaries. Each analysis run captures complete metadata such as execution timing, file counts, and statistics. The module maintains a 'latest' symbolic link that always points to the most recent analysis, enabling quick access to current results without needing to navigate timestamped directories.\n\nThe module handles the entire lifecycle of analysis result persistence, from initial directory creation through final metadata recording. All documentation artifacts are automatically saved with appropriate naming conventions and directory structures, making it easy to review past analyses, track changes over time, and access the most current understanding of a codebase.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages the storage and retrieval of analysis results including product documentation, architecture insights, and code summaries in a timestamped directory structure.",
          "userVisibleActions": [
            "Analysis results are saved to timestamped directories under .shadow/docs",
            "Product documentation files are created for analyzed code",
            "Architecture insights are stored in dedicated run directories",
            "Summary files are generated and saved after analysis",
            "Run metadata including timing and statistics is recorded",
            "Latest analysis results are accessible in a 'latest' directory link"
          ],
          "developerVisibleActions": [
            "Initialize product documentation runs with unique timestamped identifiers",
            "Initialize architecture insights runs with separate tracking",
            "Save individual product documentation entries with formatted content",
            "Store architecture insights with LLM-generated analysis",
            "Generate and save summary markdown files after analysis completion",
            "Track run progress with metadata files (timing, file counts, token usage)",
            "Access current run directories for active analysis sessions",
            "Reset run contexts when starting new analysis operations"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Starts a new product documentation analysis run",
              "inputs": "workspaceRoot: string",
              "outputs": "string (run directory path)"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Starts a new architecture insights analysis run",
              "inputs": "workspaceRoot: string",
              "outputs": "string (run directory path)"
            },
            {
              "name": "saveProductDocumentation",
              "desc": "Saves formatted product documentation for a specific file",
              "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
              "outputs": "Promise<string> (saved file path)"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Saves LLM-generated architecture insights to storage",
              "inputs": "insights: LLMInsights, workspaceRoot: string",
              "outputs": "Promise<string> (saved file path)"
            },
            {
              "name": "saveSummary",
              "desc": "Generates and saves a summary markdown file for the analysis run",
              "inputs": "summaryContent: string, workspaceRoot: string",
              "outputs": "Promise<string> (summary file path)"
            },
            {
              "name": "saveRunMetadata",
              "desc": "Saves metadata about the analysis run including timing and statistics",
              "inputs": "metadata: object, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "getCurrentProductDocsRunDir",
              "desc": "Gets the current product docs run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "getCurrentArchitectureInsightsRunDir",
              "desc": "Gets the current architecture insights run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "resetProductDocsRun",
              "desc": "Clears the current product docs run context",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "resetArchitectureInsightsRun",
              "desc": "Clears the current architecture insights run context",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "fileDocumentation (EnhancedProductDocumentation)",
            "llmService (LLMInsights)",
            "domain/formatters/documentationFormatter",
            "storage/incrementalStorage"
          ],
          "intent": "This file exists to separate persistence concerns from LLM integration logic, providing a dedicated repository layer for storing and organizing analysis results in a structured, timestamped manner that allows tracking multiple analysis runs and their outputs.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages the storage and retrieval of analysis results including product documentation, architecture insights, and code summaries in a timestamped directory structure.\",\n  \"userVisibleActions\": [\n    \"Analysis results are saved to timestamped directories under .shadow/docs\",\n    \"Product documentation files are created for analyzed code\",\n    \"Architecture insights are stored in dedicated run directories\",\n    \"Summary files are generated and saved after analysis\",\n    \"Run metadata including timing and statistics is recorded\",\n    \"Latest analysis results are accessible in a 'latest' directory link\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs with unique timestamped identifiers\",\n    \"Initialize architecture insights runs with separate tracking\",\n    \"Save individual product documentation entries with formatted content\",\n    \"Store architecture insights with LLM-generated analysis\",\n    \"Generate and save summary markdown files after analysis completion\",\n    \"Track run progress with metadata files (timing, file counts, token usage)\",\n    \"Access current run directories for active analysis sessions\",\n    \"Reset run contexts when starting new analysis operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Starts a new product documentation analysis run\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (run directory path)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Starts a new architecture insights analysis run\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (run directory path)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves formatted product documentation for a specific file\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (saved file path)\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves LLM-generated architecture insights to storage\",\n      \"inputs\": \"insights: LLMInsights, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (saved file path)\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Generates and saves a summary markdown file for the analysis run\",\n      \"inputs\": \"summaryContent: string, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (summary file path)\"\n    },\n    {\n      \"name\": \"saveRunMetadata\",\n      \"desc\": \"Saves metadata about the analysis run including timing and statistics\",\n      \"inputs\": \"metadata: object, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Gets the current product docs run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Gets the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product docs run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"This file exists to separate persistence concerns from LLM integration logic, providing a dedicated repository layer for storing and organizing analysis results in a structured, timestamped manner that allows tracking multiple analysis runs and their outputs.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display progress notifications to users during long-running operations",
        "Update progress messages dynamically as operations progress through different stages",
        "Provide cancellable operations with a cancel button in the notification",
        "Show progress indicators in the notification area or other specified locations",
        "Handle user cancellation requests and propagate them to the underlying operation"
      ],
      "summary": "This infrastructure module provides a standardized progress notification service for VS Code extensions. It enables developers to communicate the status of long-running operations to users through consistent, professional progress notifications that appear in the VS Code interface.\n\nThe module supports displaying titled progress notifications with updatable status messages, allowing users to track operations as they move through different stages. When operations are cancellable, users can click a cancel button in the notification to stop the operation mid-execution. The service manages the complete lifecycle of progress notifications, from initial display through updates to completion or cancellation.\n\nThis creates a unified user experience across all extension operations that require time to complete, such as file processing, API calls, or code generation tasks. Users receive clear visual feedback about what's happening and maintain control over long-running processes through the cancellation capability.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations in VS Code",
          "userVisibleActions": [
            "Progress notification appears with a title and status message during operations",
            "Progress message updates as operation progresses through different stages",
            "Cancel button appears in notification (when cancellable) allowing user to stop the operation",
            "Progress indicator shows in notification area or other specified location"
          ],
          "developerVisibleActions": [
            "Developer calls withProgress() to wrap any async operation with progress reporting",
            "Developer provides a title for the progress notification",
            "Developer receives a reporter object to update progress messages during execution",
            "Developer can specify if operation is cancellable and where progress should display",
            "Developer can check cancellation token to stop operation if user cancels",
            "Developer can pass simple string title or full options object for flexibility"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying progress notification to user",
              "inputs": "options (title, cancellable flag, display location), task function that receives progress reporter",
              "outputs": "Returns the result of the executed task"
            },
            {
              "name": "report",
              "desc": "Updates the progress message shown to user",
              "inputs": "message string, optional increment number",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "Reduces boilerplate code and ensures consistent progress reporting UX across the extension by wrapping VS Code's native progress API with a simpler, standardized interface",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations in VS Code\",\n  \"userVisibleActions\": [\n    \"Progress notification appears with a title and status message during operations\",\n    \"Progress message updates as operation progresses through different stages\",\n    \"Cancel button appears in notification (when cancellable) allowing user to stop the operation\",\n    \"Progress indicator shows in notification area or other specified location\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls withProgress() to wrap any async operation with progress reporting\",\n    \"Developer provides a title for the progress notification\",\n    \"Developer receives a reporter object to update progress messages during execution\",\n    \"Developer can specify if operation is cancellable and where progress should display\",\n    \"Developer can check cancellation token to stop operation if user cancels\",\n    \"Developer can pass simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying progress notification to user\",\n      \"inputs\": \"options (title, cancellable flag, display location), task function that receives progress reporter\",\n      \"outputs\": \"Returns the result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress message shown to user\",\n      \"inputs\": \"message string, optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Reduces boilerplate code and ensures consistent progress reporting UX across the extension by wrapping VS Code's native progress API with a simpler, standardized interface\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest testing framework for TypeScript testing in a VSCode extension project",
      "userVisibleActions": [
        "Users do not directly interact with this file - it supports the extension's testing infrastructure"
      ],
      "developerVisibleActions": [
        "Developers run tests using Jest with TypeScript support enabled",
        "Developers can execute tests from files matching patterns like *.test.ts or *.spec.ts",
        "Developers receive test coverage reports in text, lcov, and HTML formats",
        "Developers can run tests in the Node.js environment with a 10-second timeout",
        "Developers see test results from both src/ and UnitTests/ directories",
        "Developers get code coverage data for TypeScript files in the src/ directory"
      ],
      "keyFunctions": [
        {
          "name": "preset",
          "desc": "Configures Jest to use ts-jest preset for TypeScript testing",
          "inputs": "None",
          "outputs": "ts-jest configuration"
        },
        {
          "name": "testMatch",
          "desc": "Defines file patterns for test discovery",
          "inputs": "None",
          "outputs": "Array of glob patterns matching test files"
        },
        {
          "name": "transform",
          "desc": "Transpiles TypeScript files using ts-jest with specific compiler options",
          "inputs": "TypeScript files",
          "outputs": "Compiled JavaScript for testing"
        },
        {
          "name": "collectCoverageFrom",
          "desc": "Specifies which files to include/exclude from coverage reports",
          "inputs": "None",
          "outputs": "Array of file patterns for coverage collection"
        },
        {
          "name": "moduleNameMapper",
          "desc": "Mocks the vscode module for testing purposes",
          "inputs": "None",
          "outputs": "Mock implementation path"
        }
      ],
      "dependencies": [
        "ts-jest",
        "jest"
      ],
      "intent": "This file exists to provide Jest testing configuration that enables TypeScript testing in a Node.js environment with proper VSCode module mocking, code coverage reporting, and TypeScript compilation settings. It solves the problem of setting up a reliable testing infrastructure for a TypeScript-based VSCode extension.",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript testing in a VSCode extension project\",\n  \"userVisibleActions\": [\n    \"Users do not directly interact with this file - it supports the extension's testing infrastructure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers run tests using Jest with TypeScript support enabled\",\n    \"Developers can execute tests from files matching patterns like *.test.ts or *.spec.ts\",\n    \"Developers receive test coverage reports in text, lcov, and HTML formats\",\n    \"Developers can run tests in the Node.js environment with a 10-second timeout\",\n    \"Developers see test results from both src/ and UnitTests/ directories\",\n    \"Developers get code coverage data for TypeScript files in the src/ directory\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"preset\",\n      \"desc\": \"Configures Jest to use ts-jest preset for TypeScript testing\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ts-jest configuration\"\n    },\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Defines file patterns for test discovery\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Array of glob patterns matching test files\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Transpiles TypeScript files using ts-jest with specific compiler options\",\n      \"inputs\": \"TypeScript files\",\n      \"outputs\": \"Compiled JavaScript for testing\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which files to include/exclude from coverage reports\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Array of file patterns for coverage collection\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Mocks the vscode module for testing purposes\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Mock implementation path\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\"\n  ],\n  \"intent\": \"This file exists to provide Jest testing configuration that enables TypeScript testing in a Node.js environment with proper VSCode module mocking, code coverage reporting, and TypeScript compilation settings. It solves the problem of setting up a reliable testing infrastructure for a TypeScript-based VSCode extension.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
      "userVisibleActions": [
        "User's AI requests are automatically throttled to prevent exceeding API limits",
        "User experiences prevented errors when too many AI requests are made too quickly",
        "User's requests are blocked when rate limits are reached within a time window"
      ],
      "developerVisibleActions": [
        "Developer checks if an AI request can be made before calling the API",
        "Developer records each successful AI request to update rate limit tracking",
        "Developer configures custom rate limits for different LLM providers (OpenAI, Claude)",
        "Developer receives boolean feedback on whether a request is allowed",
        "Developer sees default limits: OpenAI (60 req/min), Claude (50 req/min)"
      ],
      "keyFunctions": [
        {
          "name": "canMakeRequest",
          "desc": "Checks if a new request is allowed based on recent request history and configured limits",
          "inputs": "provider: LLMProvider ('openai' or 'claude')",
          "outputs": "boolean - true if request can proceed, false if rate limit reached"
        },
        {
          "name": "recordRequest",
          "desc": "Records a timestamp for a completed request to track usage against rate limits",
          "inputs": "provider: LLMProvider ('openai' or 'claude')",
          "outputs": "void - updates internal request history"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limit configuration for a specific LLM provider",
          "inputs": "provider: LLMProvider, config: RateLimitConfig (maxRequests, windowMs)",
          "outputs": "void - updates provider configuration"
        }
      ],
      "dependencies": [],
      "intent": "Protects the application from exceeding LLM API rate limits by implementing a sliding window rate limiter that tracks request timestamps per provider and enforces configured quotas, preventing API errors and service interruptions",
      "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\n  \"userVisibleActions\": [\n    \"User's AI requests are automatically throttled to prevent exceeding API limits\",\n    \"User experiences prevented errors when too many AI requests are made too quickly\",\n    \"User's requests are blocked when rate limits are reached within a time window\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer checks if an AI request can be made before calling the API\",\n    \"Developer records each successful AI request to update rate limit tracking\",\n    \"Developer configures custom rate limits for different LLM providers (OpenAI, Claude)\",\n    \"Developer receives boolean feedback on whether a request is allowed\",\n    \"Developer sees default limits: OpenAI (60 req/min), Claude (50 req/min)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on recent request history and configured limits\",\n      \"inputs\": \"provider: LLMProvider ('openai' or 'claude')\",\n      \"outputs\": \"boolean - true if request can proceed, false if rate limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a timestamp for a completed request to track usage against rate limits\",\n      \"inputs\": \"provider: LLMProvider ('openai' or 'claude')\",\n      \"outputs\": \"void - updates internal request history\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider: LLMProvider, config: RateLimitConfig (maxRequests, windowMs)\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Protects the application from exceeding LLM API rate limits by implementing a sliding window rate limiter that tracks request timestamps per provider and enforces configured quotas, preventing API errors and service interruptions\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Parses and extracts structured data from LLM text responses into standardized documentation formats",
      "userVisibleActions": [
        "Receives natural language analysis from AI and converts it into organized documentation",
        "Displays parsed file summaries showing what each code file does",
        "Shows module-level documentation describing groups of related files",
        "Presents product-level documentation explaining overall system purpose",
        "Provides fallback text parsing when AI responses aren't in expected JSON format"
      ],
      "developerVisibleActions": [
        "Call parseFileSummary() to convert LLM text into FileSummary objects",
        "Call parseModuleSummary() to extract module-level documentation",
        "Call parseProductDocumentation() to get high-level product analysis",
        "Call parseLLMInsights() to extract AI-generated insights about code",
        "Call parseProductPurpose() to understand overall product goals",
        "Get structured data with fallback text extraction when JSON parsing fails",
        "Extract sections from text using pattern matching for 'purpose', 'userVisibleActions', 'dependencies', etc.",
        "Extract list items from markdown-style bullet points in LLM responses",
        "Handle parsing errors gracefully with default values"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into a structured FileSummary object",
          "inputs": "content (LLM response text), filePath (file being analyzed), role (file's role in system)",
          "outputs": "FileSummary object with purpose, actions, functions, dependencies, and intent"
        },
        {
          "name": "parseModuleSummary",
          "desc": "Extracts module-level documentation from LLM response",
          "inputs": "content (LLM response text), moduleName (name of module being analyzed)",
          "outputs": "ModuleSummary object describing the module's purpose and components"
        },
        {
          "name": "parseProductDocumentation",
          "desc": "Parses high-level product documentation from LLM response",
          "inputs": "content (LLM response text)",
          "outputs": "EnhancedProductDocumentation object with product overview and architecture"
        },
        {
          "name": "parseLLMInsights",
          "desc": "Extracts AI-generated insights about code quality and patterns",
          "inputs": "content (LLM response text)",
          "outputs": "LLMInsights object with analysis findings"
        },
        {
          "name": "parseProductPurpose",
          "desc": "Extracts the overall purpose and goals of the product from LLM analysis",
          "inputs": "content (LLM response text), context (analysis context)",
          "outputs": "ProductPurposeAnalysis object describing what the product does"
        },
        {
          "name": "extractSection",
          "desc": "Finds and extracts a specific section from text response",
          "inputs": "content (text to search), sectionName (section identifier)",
          "outputs": "Extracted section text or empty string"
        },
        {
          "name": "extractListSection",
          "desc": "Extracts bullet-point lists from text responses",
          "inputs": "content (text to search), sectionName (list identifier)",
          "outputs": "Array of list items"
        }
      ],
      "dependencies": [
        "../fileDocumentation",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between unstructured AI responses and structured documentation data. LLMs return natural language text, but the application needs consistent, typed data structures. This parser handles the messy reality of parsing AI output - trying JSON first, falling back to text extraction, and ensuring the application always gets valid documentation objects even when AI responses are malformed.",
      "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into standardized documentation formats\",\n  \"userVisibleActions\": [\n    \"Receives natural language analysis from AI and converts it into organized documentation\",\n    \"Displays parsed file summaries showing what each code file does\",\n    \"Shows module-level documentation describing groups of related files\",\n    \"Presents product-level documentation explaining overall system purpose\",\n    \"Provides fallback text parsing when AI responses aren't in expected JSON format\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM text into FileSummary objects\",\n    \"Call parseModuleSummary() to extract module-level documentation\",\n    \"Call parseProductDocumentation() to get high-level product analysis\",\n    \"Call parseLLMInsights() to extract AI-generated insights about code\",\n    \"Call parseProductPurpose() to understand overall product goals\",\n    \"Get structured data with fallback text extraction when JSON parsing fails\",\n    \"Extract sections from text using pattern matching for 'purpose', 'userVisibleActions', 'dependencies', etc.\",\n    \"Extract list items from markdown-style bullet points in LLM responses\",\n    \"Handle parsing errors gracefully with default values\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a structured FileSummary object\",\n      \"inputs\": \"content (LLM response text), filePath (file being analyzed), role (file's role in system)\",\n      \"outputs\": \"FileSummary object with purpose, actions, functions, dependencies, and intent\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level documentation from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName (name of module being analyzed)\",\n      \"outputs\": \"ModuleSummary object describing the module's purpose and components\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Parses high-level product documentation from LLM response\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"EnhancedProductDocumentation object with product overview and architecture\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts AI-generated insights about code quality and patterns\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"LLMInsights object with analysis findings\"\n    },\n    {\n      \"name\": \"parseProductPurpose\",\n      \"desc\": \"Extracts the overall purpose and goals of the product from LLM analysis\",\n      \"inputs\": \"content (LLM response text), context (analysis context)\",\n      \"outputs\": \"ProductPurposeAnalysis object describing what the product does\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Finds and extracts a specific section from text response\",\n      \"inputs\": \"content (text to search), sectionName (section identifier)\",\n      \"outputs\": \"Extracted section text or empty string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts bullet-point lists from text responses\",\n      \"inputs\": \"content (text to search), sectionName (list identifier)\",\n      \"outputs\": \"Array of list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured AI responses and structured documentation data. LLMs return natural language text, but the application needs consistent, typed data structures. This parser handles the messy reality of parsing AI output - trying JSON first, falling back to text extraction, and ensuring the application always gets valid documentation objects even when AI responses are malformed.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles automatic retries of LLM API requests when they fail due to temporary errors like rate limits or network issues",
      "userVisibleActions": [
        "When an AI request fails temporarily, the system automatically retries it without user intervention",
        "Requests that fail due to rate limits or network issues are automatically retried with increasing delays between attempts",
        "Failed requests are retried up to a maximum number of times before finally failing",
        "Users experience seamless AI interactions even when temporary API issues occur"
      ],
      "developerVisibleActions": [
        "Configure maximum retry attempts, delay timings, and backoff multipliers for API requests",
        "Specify which error types should trigger automatic retries (rate limits, timeouts, network errors)",
        "Receive callbacks on each retry attempt with attempt number and error details",
        "Get retry metadata including total number of attempts made for successful requests",
        "Classify errors as retryable or non-retryable based on error messages and codes",
        "Apply exponential backoff delays between retry attempts to avoid overwhelming services",
        "Non-retryable errors (like authentication failures) are immediately thrown without retry"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an async operation with automatic retry logic and exponential backoff",
          "inputs": "operation function to execute, retry options (maxRetries, delays, retryable errors, callback)",
          "outputs": "Promise resolving to operation result with attempt count metadata"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines if an error should trigger a retry attempt based on error type and message",
          "inputs": "error object, list of retryable error patterns",
          "outputs": "boolean indicating if the error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Provides resilience for LLM API requests by automatically retrying temporary failures like rate limits, timeouts, and network errors with exponential backoff, ensuring a more reliable AI experience without requiring user or developer intervention for transient issues",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of LLM API requests when they fail due to temporary errors like rate limits or network issues\",\n  \"userVisibleActions\": [\n    \"When an AI request fails temporarily, the system automatically retries it without user intervention\",\n    \"Requests that fail due to rate limits or network issues are automatically retried with increasing delays between attempts\",\n    \"Failed requests are retried up to a maximum number of times before finally failing\",\n    \"Users experience seamless AI interactions even when temporary API issues occur\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum retry attempts, delay timings, and backoff multipliers for API requests\",\n    \"Specify which error types should trigger automatic retries (rate limits, timeouts, network errors)\",\n    \"Receive callbacks on each retry attempt with attempt number and error details\",\n    \"Get retry metadata including total number of attempts made for successful requests\",\n    \"Classify errors as retryable or non-retryable based on error messages and codes\",\n    \"Apply exponential backoff delays between retry attempts to avoid overwhelming services\",\n    \"Non-retryable errors (like authentication failures) are immediately thrown without retry\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation function to execute, retry options (maxRetries, delays, retryable errors, callback)\",\n      \"outputs\": \"Promise resolving to operation result with attempt count metadata\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry attempt based on error type and message\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating if the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API requests by automatically retrying temporary failures like rate limits, timeouts, and network errors with exponential backoff, ensuring a more reliable AI experience without requiring user or developer intervention for transient issues\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system",
      "userVisibleActions": [
        "Receives AI-generated text responses from different language model providers",
        "Gets structured JSON data from AI providers for automated processing",
        "System checks if an AI provider is available before attempting to use it"
      ],
      "developerVisibleActions": [
        "Implement this interface to add support for new LLM providers",
        "Send text prompts to AI providers and receive formatted responses",
        "Request structured JSON output from AI models with optional schema validation",
        "Configure provider-specific settings like model, temperature, and token limits",
        "Handle system prompts, conversation history, and response formatting",
        "Request file searches or grep operations from AI providers as follow-up actions"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if the provider has valid credentials and is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating if provider is configured"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt to the AI provider and receives a text response",
          "inputs": "LLMRequestOptions with messages, model settings, temperature, and token limits",
          "outputs": "LLMResponse with generated text content and metadata"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt expecting structured JSON output with optional follow-up requests",
          "inputs": "LLMRequestOptions and optional schema for validation",
          "outputs": "StructuredOutputResponse with parsed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the provider's identifying name",
          "inputs": "none",
          "outputs": "string name of the provider"
        }
      ],
      "dependencies": [],
      "intent": "This interface exists to abstract away differences between AI provider APIs (OpenAI, Anthropic Claude, custom endpoints) so the application can work with multiple LLM services interchangeably. It standardizes how the system communicates with different AI providers, enabling provider switching without code changes and supporting both conversational and structured data extraction use cases.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses from different language model providers\",\n    \"Gets structured JSON data from AI providers for automated processing\",\n    \"System checks if an AI provider is available before attempting to use it\"\n  ],\n  \"developerVisibleActions\": [\n    \"Implement this interface to add support for new LLM providers\",\n    \"Send text prompts to AI providers and receive formatted responses\",\n    \"Request structured JSON output from AI models with optional schema validation\",\n    \"Configure provider-specific settings like model, temperature, and token limits\",\n    \"Handle system prompts, conversation history, and response formatting\",\n    \"Request file searches or grep operations from AI providers as follow-up actions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has valid credentials and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the AI provider and receives a text response\",\n      \"inputs\": \"LLMRequestOptions with messages, model settings, temperature, and token limits\",\n      \"outputs\": \"LLMResponse with generated text content and metadata\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt expecting structured JSON output with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional schema for validation\",\n      \"outputs\": \"StructuredOutputResponse with parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider's identifying name\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string name of the provider\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between AI provider APIs (OpenAI, Anthropic Claude, custom endpoints) so the application can work with multiple LLM services interchangeably. It standardizes how the system communicates with different AI providers, enabling provider switching without code changes and supporting both conversational and structured data extraction use cases.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides an interface to Anthropic's Claude AI model for generating text responses and structured JSON outputs within the extension",
      "userVisibleActions": [
        "Sends prompts to Claude AI and receives text responses",
        "Generates structured JSON outputs from Claude based on schemas",
        "Uses Claude models (like claude-sonnet-4-5) for AI-powered features",
        "Experiences AI responses with up to 8192 tokens of output",
        "May see errors if Claude API key is not configured"
      ],
      "developerVisibleActions": [
        "Configure Claude API key through extension settings to enable the provider",
        "Send text prompts with system prompts and conversation history to Claude",
        "Request structured JSON outputs by providing schemas and instructions",
        "Handle automatic JSON extraction from Claude responses",
        "Receive error messages when API key is missing or invalid",
        "Use consistent provider interface compatible with other LLM providers"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is configured and client is ready",
          "inputs": "none",
          "outputs": "boolean indicating if provider is ready to use"
        },
        {
          "name": "getName",
          "desc": "Returns the identifier name for this provider",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a text prompt to Claude and returns the response",
          "inputs": "LLMRequestOptions (messages, model, system prompt, max tokens)",
          "outputs": "LLMResponse with generated text and token counts"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Requests structured JSON output from Claude based on a schema",
          "inputs": "LLMRequestOptions with schema and output instructions",
          "outputs": "StructuredOutputResponse with parsed JSON object"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Anthropic client with API key from configuration",
          "inputs": "none (reads from config manager)",
          "outputs": "void (initializes client or sets to null)"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "ILLMProvider",
        "configurationManager",
        "jsonExtractor"
      ],
      "intent": "This file exists to integrate Anthropic's Claude AI models into the extension, providing an implementation of the LLM provider interface that handles Claude-specific message formatting, API communication, and JSON response parsing while maintaining compatibility with the extension's provider abstraction layer.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides an interface to Anthropic's Claude AI model for generating text responses and structured JSON outputs within the extension\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives text responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Uses Claude models (like claude-sonnet-4-5) for AI-powered features\",\n    \"Experiences AI responses with up to 8192 tokens of output\",\n    \"May see errors if Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through extension settings to enable the provider\",\n    \"Send text prompts with system prompts and conversation history to Claude\",\n    \"Request structured JSON outputs by providing schemas and instructions\",\n    \"Handle automatic JSON extraction from Claude responses\",\n    \"Receive error messages when API key is missing or invalid\",\n    \"Use consistent provider interface compatible with other LLM providers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and client is ready\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name for this provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text prompt to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions (messages, model, system prompt, max tokens)\",\n      \"outputs\": \"LLMResponse with generated text and token counts\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests structured JSON output from Claude based on a schema\",\n      \"inputs\": \"LLMRequestOptions with schema and output instructions\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON object\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"void (initializes client or sets to null)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to integrate Anthropic's Claude AI models into the extension, providing an implementation of the LLM provider interface that handles Claude-specific message formatting, API communication, and JSON response parsing while maintaining compatibility with the extension's provider abstraction layer.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application",
      "userVisibleActions": [
        "Receives AI-generated text responses to user prompts",
        "Gets structured JSON responses when requesting formatted data",
        "Experiences AI conversation with system prompts guiding behavior",
        "Receives streaming responses for real-time AI text generation"
      ],
      "developerVisibleActions": [
        "Configure OpenAI API key through configuration manager",
        "Send chat completion requests with custom models and prompts",
        "Request structured JSON outputs from AI responses",
        "Stream AI responses in real-time chunks",
        "Check if OpenAI provider is properly configured before use",
        "Handle API errors and timeout scenarios (5 minute timeout)",
        "Extract JSON from AI responses that may contain markdown formatting"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if OpenAI API key is set and client is ready",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "none",
          "outputs": "string 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a chat completion request to OpenAI and returns the response",
          "inputs": "LLMRequestOptions (model, messages, system prompt, response format)",
          "outputs": "LLMResponse with content and finish reason"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Requests a JSON-formatted response and extracts structured data",
          "inputs": "LLMRequestOptions with JSON response format",
          "outputs": "StructuredOutputResponse with parsed JSON data"
        },
        {
          "name": "streamRequest",
          "desc": "Streams AI responses in real-time chunks as they are generated",
          "inputs": "LLMRequestOptions and callback function for each chunk",
          "outputs": "complete response content after streaming finishes"
        }
      ],
      "dependencies": [
        "openai",
        "ILLMProvider",
        "configurationManager",
        "jsonExtractor"
      ],
      "intent": "This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with OpenAI's language models (like GPT-4) for generating AI responses in the application\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses to user prompts\",\n    \"Gets structured JSON responses when requesting formatted data\",\n    \"Experiences AI conversation with system prompts guiding behavior\",\n    \"Receives streaming responses for real-time AI text generation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager\",\n    \"Send chat completion requests with custom models and prompts\",\n    \"Request structured JSON outputs from AI responses\",\n    \"Stream AI responses in real-time chunks\",\n    \"Check if OpenAI provider is properly configured before use\",\n    \"Handle API errors and timeout scenarios (5 minute timeout)\",\n    \"Extract JSON from AI responses that may contain markdown formatting\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI API key is set and client is ready\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, system prompt, response format)\",\n      \"outputs\": \"LLMResponse with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Requests a JSON-formatted response and extracts structured data\",\n      \"inputs\": \"LLMRequestOptions with JSON response format\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams AI responses in real-time chunks as they are generated\",\n      \"inputs\": \"LLMRequestOptions and callback function for each chunk\",\n      \"outputs\": \"complete response content after streaming finishes\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI API interactions behind a common provider interface, allowing the application to use OpenAI's language models for chat completions, structured outputs, and streaming responses while managing API keys and configuration centrally.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Creates and manages AI provider instances (OpenAI or Claude) based on configuration, ensuring only one instance of each provider exists at a time.",
      "userVisibleActions": [
        "Automatically switches between OpenAI and Claude AI providers based on user configuration",
        "Validates that the selected AI provider has valid credentials before use",
        "Shows only configured AI providers as available options"
      ],
      "developerVisibleActions": [
        "Provides a single factory to access any AI provider without managing instances directly",
        "Ensures singleton pattern for each provider type to avoid duplicate connections",
        "Exposes methods to check provider configuration status before attempting AI operations",
        "Returns list of all properly configured providers for UI display"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns the provider instance for a specific AI service (openai or claude)",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the currently active AI provider based on user configuration",
          "inputs": "none",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks if a specific AI provider has valid configuration and credentials",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "boolean (true if configured)"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns list of all AI providers that are properly configured and ready to use",
          "inputs": "none",
          "outputs": "array of provider names ['openai', 'claude']"
        }
      ],
      "dependencies": [
        "ILLMProvider",
        "OpenAIProvider",
        "AnthropicProvider",
        "configurationManager"
      ],
      "intent": "Centralizes AI provider creation and lifecycle management, ensuring developers don't need to manually instantiate or track provider instances, and providing a single point to query provider availability and configuration status.",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI provider instances (OpenAI or Claude) based on configuration, ensuring only one instance of each provider exists at a time.\",\n  \"userVisibleActions\": [\n    \"Automatically switches between OpenAI and Claude AI providers based on user configuration\",\n    \"Validates that the selected AI provider has valid credentials before use\",\n    \"Shows only configured AI providers as available options\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a single factory to access any AI provider without managing instances directly\",\n    \"Ensures singleton pattern for each provider type to avoid duplicate connections\",\n    \"Exposes methods to check provider configuration status before attempting AI operations\",\n    \"Returns list of all properly configured providers for UI display\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the provider instance for a specific AI service (openai or claude)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the currently active AI provider based on user configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific AI provider has valid configuration and credentials\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean (true if configured)\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all AI providers that are properly configured and ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"array of provider names ['openai', 'claude']\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and lifecycle management, ensuring developers don't need to manually instantiate or track provider instances, and providing a single point to query provider availability and configuration status.\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed function metadata, control flow branches, dependencies, and behavioral patterns from source code files.",
      "userVisibleActions": [
        "Receives detailed analysis of code functions including their complexity, dependencies, and behavior patterns",
        "Gets insights into how functions modify state and interact with external dependencies",
        "Views control flow analysis showing different execution paths and branches in code",
        "Sees behavioral hints about what functions do (e.g., validation, transformation, API calls)"
      ],
      "developerVisibleActions": [
        "Calls analyzeFileMetadata() to analyze an entire file and get metadata for all functions",
        "Receives structured FunctionMetadata objects containing branches, dependencies, state mutations, and behavioral hints",
        "Gets TypeScript/JavaScript AST-based analysis for deeper insights compared to regex-based analysis",
        "Accesses branch information showing conditional logic paths and complexity metrics",
        "Retrieves dependency information showing external module usage and side effects",
        "Obtains state mutation tracking showing what variables and properties are modified",
        "Receives behavioral hints categorizing function purposes (validators, transformers, API handlers, etc.)"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes all functions in a file and returns detailed metadata for each",
          "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
          "outputs": "Map<string, FunctionMetadata> containing analysis results for each function"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis on TypeScript/JavaScript functions for detailed insights",
          "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
          "outputs": "FunctionMetadata with branches, dependencies, mutations, and behavioral hints"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Fallback analysis method using pattern matching for non-TypeScript languages",
          "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
          "outputs": "FunctionMetadata with basic analysis from regex patterns"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the source code content for a specific function by line numbers",
          "inputs": "content (string), startLine (number), endLine (number)",
          "outputs": "String containing the function's source code"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)"
      ],
      "intent": "This file exists to provide advanced code intelligence beyond basic parsing. It solves the problem of understanding code behavior at a semantic level by analyzing control flow, tracking state changes, identifying dependencies, and categorizing function purposes. This enables smarter test generation, documentation creation, and code understanding tools.",
      "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed function metadata, control flow branches, dependencies, and behavioral patterns from source code files.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including their complexity, dependencies, and behavior patterns\",\n    \"Gets insights into how functions modify state and interact with external dependencies\",\n    \"Views control flow analysis showing different execution paths and branches in code\",\n    \"Sees behavioral hints about what functions do (e.g., validation, transformation, API calls)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFileMetadata() to analyze an entire file and get metadata for all functions\",\n    \"Receives structured FunctionMetadata objects containing branches, dependencies, state mutations, and behavioral hints\",\n    \"Gets TypeScript/JavaScript AST-based analysis for deeper insights compared to regex-based analysis\",\n    \"Accesses branch information showing conditional logic paths and complexity metrics\",\n    \"Retrieves dependency information showing external module usage and side effects\",\n    \"Obtains state mutation tracking showing what variables and properties are modified\",\n    \"Receives behavioral hints categorizing function purposes (validators, transformers, API handlers, etc.)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes all functions in a file and returns detailed metadata for each\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing analysis results for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions for detailed insights\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata with branches, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Fallback analysis method using pattern matching for non-TypeScript languages\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata with basic analysis from regex patterns\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content for a specific function by line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)\"\n  ],\n  \"intent\": \"This file exists to provide advanced code intelligence beyond basic parsing. It solves the problem of understanding code behavior at a semantic level by analyzing control flow, tracking state changes, identifying dependencies, and categorizing function purposes. This enables smarter test generation, documentation creation, and code understanding tools.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Extracts detailed function information from large code files to support automated refactoring analysis and reporting.",
      "userVisibleActions": [
        "Receives analysis reports showing which functions in large files need refactoring",
        "Gets function signatures, dependencies, and responsibilities listed in refactoring suggestions",
        "Views which functions depend on or are depended upon by target functions"
      ],
      "developerVisibleActions": [
        "Calls analyzeFunctions() to scan large files and extract function metadata for refactoring reports",
        "Processes function signatures, dependencies, and call relationships from TypeScript source files",
        "Integrates with existing CodeAnalysis infrastructure to build comprehensive function analysis",
        "Filters files by size threshold to focus refactoring efforts on large files",
        "Receives FunctionAnalysis objects containing function details, dependencies, and responsibilities"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in files exceeding a size threshold and returns detailed function information",
          "inputs": "CodeAnalysis object, optional size threshold in lines (default 500)",
          "outputs": "Array of FunctionAnalysis objects containing function details"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs deep analysis on a single function to extract its signature, dependencies, and relationships",
          "inputs": "File path, FunctionInfo object, CodeAnalysis context",
          "outputs": "FunctionAnalysis object or null if analysis fails"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves relative file paths to absolute paths for file access",
          "inputs": "File path string, CodeAnalysis context",
          "outputs": "Resolved absolute file path"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to support automated code refactoring by extracting detailed function-level information from large files, enabling the system to understand function boundaries, dependencies, and responsibilities to generate meaningful refactoring recommendations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Extracts detailed function information from large code files to support automated refactoring analysis and reporting.\",\n  \"userVisibleActions\": [\n    \"Receives analysis reports showing which functions in large files need refactoring\",\n    \"Gets function signatures, dependencies, and responsibilities listed in refactoring suggestions\",\n    \"Views which functions depend on or are depended upon by target functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to scan large files and extract function metadata for refactoring reports\",\n    \"Processes function signatures, dependencies, and call relationships from TypeScript source files\",\n    \"Integrates with existing CodeAnalysis infrastructure to build comprehensive function analysis\",\n    \"Filters files by size threshold to focus refactoring efforts on large files\",\n    \"Receives FunctionAnalysis objects containing function details, dependencies, and responsibilities\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files exceeding a size threshold and returns detailed function information\",\n      \"inputs\": \"CodeAnalysis object, optional size threshold in lines (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing function details\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs deep analysis on a single function to extract its signature, dependencies, and relationships\",\n      \"inputs\": \"File path, FunctionInfo object, CodeAnalysis context\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file access\",\n      \"inputs\": \"File path string, CodeAnalysis context\",\n      \"outputs\": \"Resolved absolute file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to support automated code refactoring by extracting detailed function-level information from large files, enabling the system to understand function boundaries, dependencies, and responsibilities to generate meaningful refactoring recommendations.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view interface in VSCode's sidebar to browse and navigate code analysis results organized by files, functions, dependencies, and entry points.",
      "userVisibleActions": [
        "View a tree structure showing code analysis results in the sidebar",
        "See summary statistics (total files, functions, dependencies, entry points)",
        "Browse files organized by directory structure",
        "Expand files to see their functions, imports, and exports",
        "View function details including parameters and complexity metrics",
        "See detected entry points in the codebase",
        "Click on items to jump to specific code locations in the editor",
        "View complexity warnings and dependency information",
        "See file roles (config, test, component, etc.) with icons",
        "Navigate through nested directory structures",
        "View 'No analysis available' message when no analysis has been run"
      ],
      "developerVisibleActions": [
        "Tree view populates with code analysis data after running workspace analysis",
        "Analysis results are displayed in a hierarchical tree structure",
        "Files are grouped by directory with appropriate icons and counts",
        "Functions show their signatures, line counts, and complexity scores",
        "Entry points are listed with their types (HTTP, CLI, event handlers, etc.)",
        "Dependencies show import/export relationships between files",
        "Items are clickable and navigate to corresponding code locations",
        "Tree automatically refreshes when new analysis data is provided",
        "Complex functions (complexity > 10) are flagged with warning icons"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the tree view with new analysis results",
          "inputs": "CodeAnalysis object or null",
          "outputs": "void (triggers tree refresh)"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the tree item representation for display",
          "inputs": "AnalysisItem element",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node or root items if no element provided",
          "inputs": "optional AnalysisItem element",
          "outputs": "Promise<AnalysisItem[]>"
        },
        {
          "name": "getRootItems",
          "desc": "Creates the top-level tree items (statistics, files, functions, dependencies, entry points)",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Creates tree items showing analysis statistics counts",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getFilesItems",
          "desc": "Creates tree items for files and directories organized hierarchically",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getFileDetails",
          "desc": "Creates tree items showing details of a specific file (functions, imports, exports)",
          "inputs": "AnalysisItem representing a file",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getFunctionsItems",
          "desc": "Creates tree items listing all functions across the codebase",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getDependenciesItems",
          "desc": "Creates tree items showing file dependency relationships",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "getEntryPointsItems",
          "desc": "Creates tree items for detected application entry points",
          "inputs": "none",
          "outputs": "AnalysisItem[] array"
        },
        {
          "name": "createFileLocation",
          "desc": "Creates a vscode.Location object for navigating to specific code positions",
          "inputs": "file path, optional line/column numbers",
          "outputs": "vscode.Location object"
        }
      ],
      "dependencies": [
        "vscode",
        "CodeAnalysis (from ./analyzer)",
        "FileInfo (from ./analyzer)",
        "FunctionInfo (from ./analyzer)",
        "EntryPoint (from ./analyzer)",
        "path"
      ],
      "intent": "This file exists to provide a visual, navigable tree interface for developers to explore code analysis results, making it easy to understand codebase structure, identify entry points, review function complexity, and navigate to specific code locations directly from the analysis view.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface in VSCode's sidebar to browse and navigate code analysis results organized by files, functions, dependencies, and entry points.\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code analysis results in the sidebar\",\n    \"See summary statistics (total files, functions, dependencies, entry points)\",\n    \"Browse files organized by directory structure\",\n    \"Expand files to see their functions, imports, and exports\",\n    \"View function details including parameters and complexity metrics\",\n    \"See detected entry points in the codebase\",\n    \"Click on items to jump to specific code locations in the editor\",\n    \"View complexity warnings and dependency information\",\n    \"See file roles (config, test, component, etc.) with icons\",\n    \"Navigate through nested directory structures\",\n    \"View 'No analysis available' message when no analysis has been run\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view populates with code analysis data after running workspace analysis\",\n    \"Analysis results are displayed in a hierarchical tree structure\",\n    \"Files are grouped by directory with appropriate icons and counts\",\n    \"Functions show their signatures, line counts, and complexity scores\",\n    \"Entry points are listed with their types (HTTP, CLI, event handlers, etc.)\",\n    \"Dependencies show import/export relationships between files\",\n    \"Items are clickable and navigate to corresponding code locations\",\n    \"Tree automatically refreshes when new analysis data is provided\",\n    \"Complex functions (complexity > 10) are flagged with warning icons\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void (triggers tree refresh)\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"optional AnalysisItem element\",\n      \"outputs\": \"Promise<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Creates the top-level tree items (statistics, files, functions, dependencies, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing analysis statistics counts\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Creates tree items for files and directories organized hierarchically\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Creates tree items showing details of a specific file (functions, imports, exports)\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getFunctionsItems\",\n      \"desc\": \"Creates tree items listing all functions across the codebase\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getDependenciesItems\",\n      \"desc\": \"Creates tree items showing file dependency relationships\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"getEntryPointsItems\",\n      \"desc\": \"Creates tree items for detected application entry points\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[] array\"\n    },\n    {\n      \"name\": \"createFileLocation\",\n      \"desc\": \"Creates a vscode.Location object for navigating to specific code positions\",\n      \"inputs\": \"file path, optional line/column numbers\",\n      \"outputs\": \"vscode.Location object\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalysis (from ./analyzer)\",\n    \"FileInfo (from ./analyzer)\",\n    \"FunctionInfo (from ./analyzer)\",\n    \"EntryPoint (from ./analyzer)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide a visual, navigable tree interface for developers to explore code analysis results, making it easy to understand codebase structure, identify entry points, review function complexity, and navigate to specific code locations directly from the analysis view.\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code files to extract structure, dependencies, functions, and relationships for codebase understanding and visualization",
      "userVisibleActions": [
        "View total file count, line count, and function count statistics",
        "See list of large files that may need refactoring",
        "View all functions with their metadata and locations",
        "See import relationships between files",
        "Identify orphaned files not imported by others",
        "Find entry points (files not importing others)",
        "Detect duplicate code blocks across the codebase",
        "View risk levels (high/medium/low) for functions",
        "See test coverage mapping for source files and functions",
        "Identify uncovered functions without tests"
      ],
      "developerVisibleActions": [
        "Call analyzer to scan directory and extract code structure",
        "Get structured data about functions including parameters, return types, visibility",
        "Access function dependencies (database, HTTP, filesystem, etc.)",
        "Retrieve branch information (if/else, loops, try/catch)",
        "Track state mutations (assignments, modifications, deletions)",
        "Query import/export relationships between files",
        "Use caching system to speed up repeated analysis",
        "Map test files to source files they test",
        "Filter analysis results by file type or pattern",
        "Export analysis results in structured format"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main data structure containing complete analysis results",
          "inputs": "N/A (interface)",
          "outputs": "Object with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping, etc."
        },
        {
          "name": "FunctionMetadata",
          "desc": "Detailed metadata about a single function",
          "inputs": "N/A (interface)",
          "outputs": "Object with symbolName, parameters, returnType, visibility, branches, dependencies, riskLevel, docstring"
        },
        {
          "name": "BranchInfo",
          "desc": "Information about conditional branches and control flow",
          "inputs": "N/A (interface)",
          "outputs": "Object with type (if/loop/try/etc), condition description, lineNumber"
        },
        {
          "name": "DependencyInfo",
          "desc": "Tracks external and internal dependencies",
          "inputs": "N/A (interface)",
          "outputs": "Object with dependency name, type (db/http/filesystem/etc), isInternal flag"
        },
        {
          "name": "StateMutationInfo",
          "desc": "Tracks where and how state is modified",
          "inputs": "N/A (interface)",
          "outputs": "Object with target name, mutationType (assign/modify/delete/read), lineNumber"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source files and functions to their test files",
          "inputs": "N/A (interface)",
          "outputs": "Object with sourceFileToTests map, functionToTests map, uncoveredFunctions list"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache (AnalysisCache)"
      ],
      "intent": "This file defines the core data structures and interfaces for code analysis results. It exists to provide a standardized way to represent codebase structure, function metadata, dependencies, test coverage, and code quality metrics. Developers use these interfaces to understand code relationships, identify technical debt, assess risk, and improve test coverage.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code files to extract structure, dependencies, functions, and relationships for codebase understanding and visualization\",\n  \"userVisibleActions\": [\n    \"View total file count, line count, and function count statistics\",\n    \"See list of large files that may need refactoring\",\n    \"View all functions with their metadata and locations\",\n    \"See import relationships between files\",\n    \"Identify orphaned files not imported by others\",\n    \"Find entry points (files not importing others)\",\n    \"Detect duplicate code blocks across the codebase\",\n    \"View risk levels (high/medium/low) for functions\",\n    \"See test coverage mapping for source files and functions\",\n    \"Identify uncovered functions without tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzer to scan directory and extract code structure\",\n    \"Get structured data about functions including parameters, return types, visibility\",\n    \"Access function dependencies (database, HTTP, filesystem, etc.)\",\n    \"Retrieve branch information (if/else, loops, try/catch)\",\n    \"Track state mutations (assignments, modifications, deletions)\",\n    \"Query import/export relationships between files\",\n    \"Use caching system to speed up repeated analysis\",\n    \"Map test files to source files they test\",\n    \"Filter analysis results by file type or pattern\",\n    \"Export analysis results in structured format\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main data structure containing complete analysis results\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping, etc.\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with symbolName, parameters, returnType, visibility, branches, dependencies, riskLevel, docstring\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Information about conditional branches and control flow\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with type (if/loop/try/etc), condition description, lineNumber\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Tracks external and internal dependencies\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with dependency name, type (db/http/filesystem/etc), isInternal flag\"\n    },\n    {\n      \"name\": \"StateMutationInfo\",\n      \"desc\": \"Tracks where and how state is modified\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with target name, mutationType (assign/modify/delete/read), lineNumber\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their test files\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Object with sourceFileToTests map, functionToTests map, uncoveredFunctions list\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file defines the core data structures and interfaces for code analysis results. It exists to provide a standardized way to represent codebase structure, function metadata, dependencies, test coverage, and code quality metrics. Developers use these interfaces to understand code relationships, identify technical debt, assess risk, and improve test coverage.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration after 24 hours",
      "userVisibleActions": [
        "Analysis results are loaded instantly when reopening a previously analyzed workspace",
        "Analysis results become stale and are automatically refreshed after 24 hours",
        "Cache storage is automatically created in the workspace on first use",
        "Old analysis data can be cleared to free up disk space"
      ],
      "developerVisibleActions": [
        "Store code analysis results to disk for future retrieval",
        "Retrieve previously cached analysis results for a workspace",
        "Clear all cached analysis data across workspaces",
        "Invalidate outdated cache entries automatically after 24 hours",
        "Generate unique cache keys for different workspace paths"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes the cache manager with a storage location",
          "inputs": "storagePath (string) - base directory for cache storage",
          "outputs": "AnalysisCache instance"
        },
        {
          "name": "getCacheKey",
          "desc": "Converts a workspace path into a safe filename for cache storage",
          "inputs": "workspaceRoot (string) - workspace directory path",
          "outputs": "string - base64-encoded safe filename"
        },
        {
          "name": "get",
          "desc": "Retrieves cached analysis results if they exist and are not expired",
          "inputs": "workspaceRoot (string) - workspace directory path",
          "outputs": "Promise<CodeAnalysis | null> - cached analysis or null if expired/missing"
        },
        {
          "name": "set",
          "desc": "Saves analysis results to cache with current timestamp",
          "inputs": "workspaceRoot (string), data (CodeAnalysis) - workspace path and analysis to cache",
          "outputs": "Promise<void>"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis files from storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "This file exists to speed up the extension by avoiding repeated analysis of unchanged codebases. It solves the performance problem of re-analyzing large projects every time VS Code is opened by persisting analysis results to disk with a time-based expiration strategy.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration after 24 hours\",\n  \"userVisibleActions\": [\n    \"Analysis results are loaded instantly when reopening a previously analyzed workspace\",\n    \"Analysis results become stale and are automatically refreshed after 24 hours\",\n    \"Cache storage is automatically created in the workspace on first use\",\n    \"Old analysis data can be cleared to free up disk space\"\n  ],\n  \"developerVisibleActions\": [\n    \"Store code analysis results to disk for future retrieval\",\n    \"Retrieve previously cached analysis results for a workspace\",\n    \"Clear all cached analysis data across workspaces\",\n    \"Invalidate outdated cache entries automatically after 24 hours\",\n    \"Generate unique cache keys for different workspace paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the cache manager with a storage location\",\n      \"inputs\": \"storagePath (string) - base directory for cache storage\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Converts a workspace path into a safe filename for cache storage\",\n      \"inputs\": \"workspaceRoot (string) - workspace directory path\",\n      \"outputs\": \"string - base64-encoded safe filename\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results if they exist and are not expired\",\n      \"inputs\": \"workspaceRoot (string) - workspace directory path\",\n      \"outputs\": \"Promise<CodeAnalysis | null> - cached analysis or null if expired/missing\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot (string), data (CodeAnalysis) - workspace path and analysis to cache\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to speed up the extension by avoiding repeated analysis of unchanged codebases. It solves the performance problem of re-analyzing large projects every time VS Code is opened by persisting analysis results to disk with a time-based expiration strategy.\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all configuration settings for the Shadow Watch extension, providing type-safe access to user preferences and notifying components when settings change.",
      "userVisibleActions": [
        "Enable or disable the Shadow Watch extension entirely",
        "Toggle automatic analysis when saving files",
        "Show or hide inline hint decorations in the editor",
        "Configure which LLM provider to use (OpenAI or Claude)",
        "Set API keys for AI services",
        "Choose output format for AI reports (Cursor, ChatGPT, Generic, or Compact)",
        "Adjust minimum severity level for displaying problems (Error, Warning, or Info)",
        "Set custom endpoints for AI services",
        "Configure HTTP timeout for AI requests",
        "Set maximum file size for analysis",
        "Enable or disable debug logging",
        "Show or hide decorations in the status bar"
      ],
      "developerVisibleActions": [
        "Access all Shadow Watch configuration values through type-safe getters",
        "Register callbacks to listen for configuration changes",
        "Validate configuration values and receive error feedback",
        "Retrieve configuration for specific workspace folders",
        "Update configuration values programmatically",
        "Get notified automatically when user changes settings in VSCode preferences",
        "Access validated API keys, endpoints, and service settings"
      ],
      "keyFunctions": [
        {
          "name": "Constructor",
          "desc": "Initializes the configuration manager and sets up automatic watching for configuration changes",
          "inputs": "None",
          "outputs": "ConfigurationManager instance"
        },
        {
          "name": "onConfigurationChange",
          "desc": "Registers a callback function to be invoked whenever Shadow Watch configuration changes",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Removes a previously registered configuration change callback",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "enabled",
          "desc": "Returns whether the Shadow Watch extension is enabled",
          "inputs": "None (getter)",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave",
          "desc": "Returns whether automatic analysis on file save is enabled",
          "inputs": "None (getter)",
          "outputs": "boolean"
        },
        {
          "name": "showInlineHints",
          "desc": "Returns whether inline hint decorations should be displayed",
          "inputs": "None (getter)",
          "outputs": "boolean"
        },
        {
          "name": "llmProvider",
          "desc": "Returns the configured LLM provider (OpenAI or Claude)",
          "inputs": "None (getter)",
          "outputs": "LLMProvider type"
        },
        {
          "name": "llmFormat",
          "desc": "Returns the configured output format for LLM reports",
          "inputs": "None (getter)",
          "outputs": "LLMFormat type"
        },
        {
          "name": "severityThreshold",
          "desc": "Returns the minimum severity level for displaying problems",
          "inputs": "None (getter)",
          "outputs": "SeverityThreshold type"
        },
        {
          "name": "validate",
          "desc": "Validates the current configuration and returns any errors found",
          "inputs": "None",
          "outputs": "ConfigValidationResult with validation status and error messages"
        },
        {
          "name": "getConfigForResource",
          "desc": "Retrieves configuration specific to a workspace folder or file",
          "inputs": "vscode.Uri resource",
          "outputs": "workspace-specific configuration"
        },
        {
          "name": "updateConfig",
          "desc": "Updates a configuration value programmatically",
          "inputs": "key, value, configuration target",
          "outputs": "Promise that resolves when update completes"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety, preventing direct access to raw configuration values, and enabling reactive updates when users change their preferences. It solves the problem of scattered configuration access throughout the codebase and provides validation to ensure settings are correct before use.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all configuration settings for the Shadow Watch extension, providing type-safe access to user preferences and notifying components when settings change.\",\n  \"userVisibleActions\": [\n    \"Enable or disable the Shadow Watch extension entirely\",\n    \"Toggle automatic analysis when saving files\",\n    \"Show or hide inline hint decorations in the editor\",\n    \"Configure which LLM provider to use (OpenAI or Claude)\",\n    \"Set API keys for AI services\",\n    \"Choose output format for AI reports (Cursor, ChatGPT, Generic, or Compact)\",\n    \"Adjust minimum severity level for displaying problems (Error, Warning, or Info)\",\n    \"Set custom endpoints for AI services\",\n    \"Configure HTTP timeout for AI requests\",\n    \"Set maximum file size for analysis\",\n    \"Enable or disable debug logging\",\n    \"Show or hide decorations in the status bar\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access all Shadow Watch configuration values through type-safe getters\",\n    \"Register callbacks to listen for configuration changes\",\n    \"Validate configuration values and receive error feedback\",\n    \"Retrieve configuration for specific workspace folders\",\n    \"Update configuration values programmatically\",\n    \"Get notified automatically when user changes settings in VSCode preferences\",\n    \"Access validated API keys, endpoints, and service settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"Constructor\",\n      \"desc\": \"Initializes the configuration manager and sets up automatic watching for configuration changes\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be invoked whenever Shadow Watch configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Removes a previously registered configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is enabled\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis on file save is enabled\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Returns whether inline hint decorations should be displayed\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider\",\n      \"desc\": \"Returns the configured LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"LLMProvider type\"\n    },\n    {\n      \"name\": \"llmFormat\",\n      \"desc\": \"Returns the configured output format for LLM reports\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"LLMFormat type\"\n    },\n    {\n      \"name\": \"severityThreshold\",\n      \"desc\": \"Returns the minimum severity level for displaying problems\",\n      \"inputs\": \"None (getter)\",\n      \"outputs\": \"SeverityThreshold type\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Validates the current configuration and returns any errors found\",\n      \"inputs\": \"None\",\n      \"outputs\": \"ConfigValidationResult with validation status and error messages\"\n    },\n    {\n      \"name\": \"getConfigForResource\",\n      \"desc\": \"Retrieves configuration specific to a workspace folder or file\",\n      \"inputs\": \"vscode.Uri resource\",\n      \"outputs\": \"workspace-specific configuration\"\n    },\n    {\n      \"name\": \"updateConfig\",\n      \"desc\": \"Updates a configuration value programmatically\",\n      \"inputs\": \"key, value, configuration target\",\n      \"outputs\": \"Promise that resolves when update completes\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety, preventing direct access to raw configuration values, and enabling reactive updates when users change their preferences. It solves the problem of scattered configuration access throughout the codebase and provides validation to ensure settings are correct before use.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis results into a format suitable for LLM context and saves them to persistent storage for future use.",
      "userVisibleActions": [
        "Analysis results are automatically saved to the workspace for future reference",
        "Analysis data is preserved in a .shadow/docs directory within the workspace",
        "Timestamped analysis snapshots are created each time code is analyzed"
      ],
      "developerVisibleActions": [
        "Developer triggers code analysis, and results are automatically converted to LLM-compatible format",
        "Analysis context is prepared for sending to language models with all necessary code structure information",
        "Analysis results are persisted to .shadow/docs/code-analysis.json file with metadata",
        "Workspace folders are checked before saving analysis data",
        "Directory structure (.shadow/docs) is created automatically if it doesn't exist"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms raw code analysis data into the specific format required by LLM services",
          "inputs": "CodeAnalysis object containing files, imports, entry points, and metrics",
          "outputs": "AnalysisContext object formatted for LLM consumption with file paths, lines, functions, imports, and statistics"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to disk with timestamp metadata for future retrieval",
          "inputs": "CodeAnalysis object to be saved",
          "outputs": "void - creates code-analysis.json file in .shadow/docs directory"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between code analysis output and LLM input requirements, while also ensuring analysis results are preserved for later use. It solves the problem of formatting code structure data for AI consumption and maintaining a history of code analysis snapshots.",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a format suitable for LLM context and saves them to persistent storage for future use.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to the workspace for future reference\",\n    \"Analysis data is preserved in a .shadow/docs directory within the workspace\",\n    \"Timestamped analysis snapshots are created each time code is analyzed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers code analysis, and results are automatically converted to LLM-compatible format\",\n    \"Analysis context is prepared for sending to language models with all necessary code structure information\",\n    \"Analysis results are persisted to .shadow/docs/code-analysis.json file with metadata\",\n    \"Workspace folders are checked before saving analysis data\",\n    \"Directory structure (.shadow/docs) is created automatically if it doesn't exist\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms raw code analysis data into the specific format required by LLM services\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and metrics\",\n      \"outputs\": \"AnalysisContext object formatted for LLM consumption with file paths, lines, functions, imports, and statistics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk with timestamp metadata for future retrieval\",\n      \"inputs\": \"CodeAnalysis object to be saved\",\n      \"outputs\": \"void - creates code-analysis.json file in .shadow/docs directory\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis output and LLM input requirements, while also ensuring analysis results are preserved for later use. It solves the problem of formatting code structure data for AI consumption and maintaining a history of code analysis snapshots.\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Manages the display of code insights as inline diagnostics (squiggly underlines and problems panel entries) in the VS Code editor.",
      "userVisibleActions": [
        "See squiggly underlines in code where insights are detected",
        "View insights in the Problems panel with severity indicators (error, warning, info)",
        "Click on problems to navigate to the corresponding code location",
        "See 'Shadow Watch' as the source of diagnostic messages",
        "View insight descriptions as diagnostic messages",
        "Have diagnostics automatically cleared when insights are updated"
      ],
      "developerVisibleActions": [
        "Provide insights to be displayed as diagnostics in the editor",
        "Update diagnostics for all files or a specific file",
        "Clear all diagnostics from the Problems panel",
        "Dispose of the diagnostics collection when extension deactivates",
        "Diagnostics are automatically grouped by file",
        "Each insight is converted to a VS Code diagnostic with appropriate severity"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Updates diagnostics for all files based on provided insights",
          "inputs": "Array of Insight objects",
          "outputs": "Void - displays diagnostics in editor and Problems panel"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostics for a specific file",
          "inputs": "File URI and array of Insight objects for that file",
          "outputs": "Void - displays diagnostics for the specified file"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostics from the editor and Problems panel",
          "inputs": "None",
          "outputs": "Void"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts an insight into a VS Code diagnostic with severity, message, and location",
          "inputs": "Insight object",
          "outputs": "VS Code Diagnostic object"
        },
        {
          "name": "dispose",
          "desc": "Cleans up the diagnostics collection when no longer needed",
          "inputs": "None",
          "outputs": "Void"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "This file exists to bridge the gap between Shadow Watch's insight generation system and VS Code's native diagnostics UI. It translates insights into the standard VS Code problems/diagnostics format so users can see issues directly in their code with familiar VS Code UI patterns (squiggles, Problems panel). It solves the problem of how to visually communicate detected insights to users in an intuitive, IDE-native way.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages the display of code insights as inline diagnostics (squiggly underlines and problems panel entries) in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"See squiggly underlines in code where insights are detected\",\n    \"View insights in the Problems panel with severity indicators (error, warning, info)\",\n    \"Click on problems to navigate to the corresponding code location\",\n    \"See 'Shadow Watch' as the source of diagnostic messages\",\n    \"View insight descriptions as diagnostic messages\",\n    \"Have diagnostics automatically cleared when insights are updated\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provide insights to be displayed as diagnostics in the editor\",\n    \"Update diagnostics for all files or a specific file\",\n    \"Clear all diagnostics from the Problems panel\",\n    \"Dispose of the diagnostics collection when extension deactivates\",\n    \"Diagnostics are automatically grouped by file\",\n    \"Each insight is converted to a VS Code diagnostic with appropriate severity\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates diagnostics for all files based on provided insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"Void - displays diagnostics in editor and Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file\",\n      \"inputs\": \"File URI and array of Insight objects for that file\",\n      \"outputs\": \"Void - displays diagnostics for the specified file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the editor and Problems panel\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic with severity, message, and location\",\n      \"inputs\": \"Insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up the diagnostics collection when no longer needed\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between Shadow Watch's insight generation system and VS Code's native diagnostics UI. It translates insights into the standard VS Code problems/diagnostics format so users can see issues directly in their code with familiar VS Code UI patterns (squiggles, Problems panel). It solves the problem of how to visually communicate detected insights to users in an intuitive, IDE-native way.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers all VS Code commands for the extension and maps them to their handler functions",
      "userVisibleActions": [
        "Analyze entire workspace for code insights",
        "Analyze currently open file",
        "Copy all insights to clipboard",
        "Copy insights for specific file to clipboard",
        "Copy individual insight to clipboard",
        "Clear cached analysis data",
        "Clear all extension data",
        "Open extension settings",
        "View latest analysis report",
        "View latest unit test report",
        "Switch between LLM providers",
        "Copy menu structure to clipboard",
        "View current LLM provider status",
        "Navigate to specific product items",
        "Navigate to analysis items",
        "View detailed information about product items",
        "View detailed information about insights",
        "View detailed information about unit tests"
      ],
      "developerVisibleActions": [
        "Command handlers are centralized in one registry for easy maintenance",
        "Commands are registered with VS Code's command palette and UI elements",
        "Command registration is separated from main extension logic for modularity",
        "All command handlers receive necessary components and dependencies",
        "Commands integrate with tree views, diagnostics, cache, and LLM services"
      ],
      "keyFunctions": [
        {
          "name": "register",
          "desc": "Registers all extension commands with VS Code",
          "inputs": "context (ExtensionContext), components (ExtensionComponents)",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Triggers analysis of entire workspace",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeCurrentFile",
          "desc": "Triggers analysis of currently open file",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyAllInsights",
          "desc": "Copies all generated insights to clipboard",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyFileInsights",
          "desc": "Copies insights for specific file to clipboard",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyInsight",
          "desc": "Copies single insight item to clipboard",
          "inputs": "item (any)",
          "outputs": "Promise<void>"
        },
        {
          "name": "clearCache",
          "desc": "Clears cached analysis results",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "clearAllData",
          "desc": "Clears all extension data including cache and settings",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "showSettings",
          "desc": "Opens extension settings panel",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "openLatestReport",
          "desc": "Opens most recent analysis report",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "openLatestUnitTestReport",
          "desc": "Opens most recent unit test report",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "switchProvider",
          "desc": "Switches between different LLM providers",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyMenuStructure",
          "desc": "Copies menu structure to clipboard",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "showProviderStatus",
          "desc": "Displays current LLM provider status and configuration",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to specific product item in codebase",
          "inputs": "item (ProductNavItem)",
          "outputs": "Promise<void>"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to specific analysis result",
          "inputs": "item (AnalysisItem)",
          "outputs": "Promise<void>"
        },
        {
          "name": "showProductItemDetails",
          "desc": "Shows detailed view of product item",
          "inputs": "item (ProductNavItem)",
          "outputs": "Promise<void>"
        },
        {
          "name": "showInsightItemDetails",
          "desc": "Shows detailed view of insight",
          "inputs": "item (any)",
          "outputs": "Promise<void>"
        },
        {
          "name": "showUnitTestItemDetails",
          "desc": "Shows detailed view of unit test item",
          "inputs": "item (any)",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "This file centralizes command registration to separate concerns and make the extension maintainable. It solves the problem of command sprawl by providing a single registry that maps VS Code command IDs to their implementations, making it easy to add, modify, or remove commands without touching the main extension activation logic.",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension and maps them to their handler functions\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to specific product items\",\n    \"Navigate to analysis items\",\n    \"View detailed information about product items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Command handlers are centralized in one registry for easy maintenance\",\n    \"Commands are registered with VS Code's command palette and UI elements\",\n    \"Command registration is separated from main extension logic for modularity\",\n    \"All command handlers receive necessary components and dependencies\",\n    \"Commands integrate with tree views, diagnostics, cache, and LLM services\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all extension commands with VS Code\",\n      \"inputs\": \"context (ExtensionContext), components (ExtensionComponents)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers analysis of entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Triggers analysis of currently open file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyAllInsights\",\n      \"desc\": \"Copies all generated insights to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyFileInsights\",\n      \"desc\": \"Copies insights for specific file to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyInsight\",\n      \"desc\": \"Copies single insight item to clipboard\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears cached analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearAllData\",\n      \"desc\": \"Clears all extension data including cache and settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showSettings\",\n      \"desc\": \"Opens extension settings panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"openLatestReport\",\n      \"desc\": \"Opens most recent analysis report\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"openLatestUnitTestReport\",\n      \"desc\": \"Opens most recent unit test report\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"switchProvider\",\n      \"desc\": \"Switches between different LLM providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyMenuStructure\",\n      \"desc\": \"Copies menu structure to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProviderStatus\",\n      \"desc\": \"Displays current LLM provider status and configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to specific product item in codebase\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to specific analysis result\",\n      \"inputs\": \"item (AnalysisItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProductItemDetails\",\n      \"desc\": \"Shows detailed view of product item\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showInsightItemDetails\",\n      \"desc\": \"Shows detailed view of insight\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showUnitTestItemDetails\",\n      \"desc\": \"Shows detailed view of unit test item\",\n      \"inputs\": \"item (any)\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file centralizes command registration to separate concerns and make the extension maintainable. It solves the problem of command sprawl by providing a single registry that maps VS Code command IDs to their implementations, making it easy to add, modify, or remove commands without touching the main extension activation logic.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Bootstraps and initializes all extension components when the VS Code extension is activated, setting up views, commands, and services.",
      "userVisibleActions": [
        "Extension activates and displays status bar item showing analysis status",
        "Product Navigator tree view becomes available in the sidebar",
        "Analysis Viewer tree view displays code analysis results",
        "Insights Viewer tree view shows generated insights",
        "Static Analysis Viewer tree view presents static analysis findings",
        "Unit Tests Navigator tree view lists unit tests",
        "Reports tree view displays generated reports",
        "Diagnostics panel shows code issues and warnings",
        "File changes trigger automatic re-analysis and view updates"
      ],
      "developerVisibleActions": [
        "Creates and registers all extension components during activation",
        "Initializes configuration manager for extension settings",
        "Sets up file watcher service to monitor code changes",
        "Registers tree data providers for all sidebar views",
        "Initializes error handler for centralized error management",
        "Creates analysis cache for performance optimization",
        "Establishes LLM state manager for AI integration tracking",
        "Wires up diagnostics provider to display code issues",
        "Registers status bar item for displaying extension state",
        "Returns ExtensionComponents interface containing all initialized services"
      ],
      "keyFunctions": [
        {
          "name": "bootstrap",
          "desc": "Initializes all extension components and returns them as a structured interface",
          "inputs": "vscode.ExtensionContext",
          "outputs": "ExtensionComponents interface containing all initialized services"
        },
        {
          "name": "ExtensionComponents (interface)",
          "desc": "Defines the structure of all extension components including analyzers, viewers, providers, and services",
          "inputs": "N/A (type definition)",
          "outputs": "Type definition for component collection"
        }
      ],
      "dependencies": [
        "vscode",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "FileWatcher",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "llmIntegration",
        "ProductNavigatorProvider",
        "AnalysisViewerProvider",
        "InsightsViewerProvider",
        "StaticAnalysisViewerProvider",
        "UnitTestsNavigatorProvider",
        "configurationManager",
        "ErrorHandler",
        "FileWatcherService",
        "ReportsViewer",
        "ReportsTreeProvider",
        "llmStateManager"
      ],
      "intent": "Centralizes extension initialization logic to cleanly separate activation concerns from command registration and component lifecycle management, ensuring all services are properly instantiated and wired together before the extension becomes active.",
      "rawContent": "```json\n{\n  \"purpose\": \"Bootstraps and initializes all extension components when the VS Code extension is activated, setting up views, commands, and services.\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis status\",\n    \"Product Navigator tree view becomes available in the sidebar\",\n    \"Analysis Viewer tree view displays code analysis results\",\n    \"Insights Viewer tree view shows generated insights\",\n    \"Static Analysis Viewer tree view presents static analysis findings\",\n    \"Unit Tests Navigator tree view lists unit tests\",\n    \"Reports tree view displays generated reports\",\n    \"Diagnostics panel shows code issues and warnings\",\n    \"File changes trigger automatic re-analysis and view updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Creates and registers all extension components during activation\",\n    \"Initializes configuration manager for extension settings\",\n    \"Sets up file watcher service to monitor code changes\",\n    \"Registers tree data providers for all sidebar views\",\n    \"Initializes error handler for centralized error management\",\n    \"Creates analysis cache for performance optimization\",\n    \"Establishes LLM state manager for AI integration tracking\",\n    \"Wires up diagnostics provider to display code issues\",\n    \"Registers status bar item for displaying extension state\",\n    \"Returns ExtensionComponents interface containing all initialized services\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Initializes all extension components and returns them as a structured interface\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents interface containing all initialized services\"\n    },\n    {\n      \"name\": \"ExtensionComponents (interface)\",\n      \"desc\": \"Defines the structure of all extension components including analyzers, viewers, providers, and services\",\n      \"inputs\": \"N/A (type definition)\",\n      \"outputs\": \"Type definition for component collection\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"Centralizes extension initialization logic to cleanly separate activation concerns from command registration and component lifecycle management, ensuring all services are properly instantiated and wired together before the extension becomes active.\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and insights into readable Markdown format for display to users",
      "userVisibleActions": [
        "View formatted product documentation with overview, features, and user perspectives",
        "See generated documentation with timestamp showing when it was created",
        "Read documentation organized by sections: GUI, CLI, and API perspectives",
        "View key insights about the codebase in structured format",
        "See developer-facing information like architecture and technical considerations",
        "Read file analysis results formatted as Markdown reports",
        "View domain insights including themes, patterns, and system understanding"
      ],
      "developerVisibleActions": [
        "Call formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown strings",
        "Call formatInsightsAsMarkdown() to convert LLM insights into readable Markdown documentation",
        "Call formatFileAnalysisAsMarkdown() to generate Markdown reports for individual file analysis",
        "Call formatDomainInsightsAsMarkdown() to format domain-level insights into documentation",
        "Receive Markdown-formatted strings that can be saved to files or displayed in UI",
        "Generate timestamped documentation showing both local and UTC time",
        "Create structured documentation with hierarchical sections and bullet points"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation object into formatted Markdown string with sections for overview, features, user perspectives, technical details, and architecture",
          "inputs": "EnhancedProductDocumentation object",
          "outputs": "Markdown string with formatted documentation"
        },
        {
          "name": "formatInsightsAsMarkdown",
          "desc": "Converts LLM-generated insights into formatted Markdown documentation with sections for product understanding, user perspective, and developer information",
          "inputs": "LLMInsights object",
          "outputs": "Markdown string with formatted insights"
        },
        {
          "name": "formatFileAnalysisAsMarkdown",
          "desc": "Formats individual file analysis results into Markdown report showing file role, purpose, behavior, and key functions",
          "inputs": "File analysis object with metadata and extracted information",
          "outputs": "Markdown string with file analysis report"
        },
        {
          "name": "formatDomainInsightsAsMarkdown",
          "desc": "Formats domain-level insights into Markdown documentation showing themes, patterns, system understanding, and technical considerations",
          "inputs": "Domain insights object",
          "outputs": "Markdown string with domain insights documentation"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "This file exists to separate documentation formatting concerns from LLM integration logic. It provides a clean way to convert structured documentation objects into human-readable Markdown format, making the documentation generation pipeline more maintainable and testable by isolating formatting logic from data generation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and insights into readable Markdown format for display to users\",\n  \"userVisibleActions\": [\n    \"View formatted product documentation with overview, features, and user perspectives\",\n    \"See generated documentation with timestamp showing when it was created\",\n    \"Read documentation organized by sections: GUI, CLI, and API perspectives\",\n    \"View key insights about the codebase in structured format\",\n    \"See developer-facing information like architecture and technical considerations\",\n    \"Read file analysis results formatted as Markdown reports\",\n    \"View domain insights including themes, patterns, and system understanding\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown strings\",\n    \"Call formatInsightsAsMarkdown() to convert LLM insights into readable Markdown documentation\",\n    \"Call formatFileAnalysisAsMarkdown() to generate Markdown reports for individual file analysis\",\n    \"Call formatDomainInsightsAsMarkdown() to format domain-level insights into documentation\",\n    \"Receive Markdown-formatted strings that can be saved to files or displayed in UI\",\n    \"Generate timestamped documentation showing both local and UTC time\",\n    \"Create structured documentation with hierarchical sections and bullet points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown string with sections for overview, features, user perspectives, technical details, and architecture\",\n      \"inputs\": \"EnhancedProductDocumentation object\",\n      \"outputs\": \"Markdown string with formatted documentation\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into formatted Markdown documentation with sections for product understanding, user perspective, and developer information\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"Markdown string with formatted insights\"\n    },\n    {\n      \"name\": \"formatFileAnalysisAsMarkdown\",\n      \"desc\": \"Formats individual file analysis results into Markdown report showing file role, purpose, behavior, and key functions\",\n      \"inputs\": \"File analysis object with metadata and extracted information\",\n      \"outputs\": \"Markdown string with file analysis report\"\n    },\n    {\n      \"name\": \"formatDomainInsightsAsMarkdown\",\n      \"desc\": \"Formats domain-level insights into Markdown documentation showing themes, patterns, system understanding, and technical considerations\",\n      \"inputs\": \"Domain insights object\",\n      \"outputs\": \"Markdown string with domain insights documentation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting concerns from LLM integration logic. It provides a clean way to convert structured documentation objects into human-readable Markdown format, making the documentation generation pipeline more maintainable and testable by isolating formatting logic from data generation.\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation to code locations (files, functions, endpoints) and displays detailed information about code items in the VS Code editor.",
      "userVisibleActions": [
        "Navigate to a specific file in the workspace",
        "Navigate to a function definition within a file",
        "Navigate to an API endpoint implementation",
        "View detailed information about a code item in a webview panel",
        "See function signatures, parameters, and return types",
        "View endpoints with their HTTP methods and paths",
        "See file contents and dependencies",
        "Jump to specific line numbers in files",
        "View analysis results and code metrics",
        "See error messages when navigation fails"
      ],
      "developerVisibleActions": [
        "Provide ProductNavItem objects to navigate to code locations",
        "Provide AnalysisItem objects to display code analysis details",
        "Trigger navigation by calling handler methods with item data",
        "Handle navigation to files with absolute or relative paths",
        "Display webview panels with formatted code information",
        "Navigate to functions by name within files",
        "Navigate to endpoints by path and method",
        "Handle entry point navigation with function details",
        "Receive error messages when files cannot be opened",
        "Work with workspace-relative or absolute file paths"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to a product navigation item (file, function, or endpoint)",
          "inputs": "ProductNavItem (contains type and data with file/function/endpoint information)",
          "outputs": "Promise<void> - completes when navigation is done"
        },
        {
          "name": "showProductItemDetails",
          "desc": "Displays detailed information about a product item in a webview panel",
          "inputs": "ProductNavItem (contains item data to display)",
          "outputs": "void - opens webview with formatted details"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to an analysis item location in the code",
          "inputs": "AnalysisItem (contains file path and optional line number)",
          "outputs": "Promise<void> - completes when editor opens"
        },
        {
          "name": "showAnalysisItemDetails",
          "desc": "Displays detailed analysis information in a webview panel",
          "inputs": "AnalysisItem (contains analysis data and metrics)",
          "outputs": "void - shows webview with analysis details"
        },
        {
          "name": "navigateToEntryPoint",
          "desc": "Navigates to an entry point function in the codebase",
          "inputs": "EntryPoint (contains file path and function name)",
          "outputs": "Promise<void> - opens file and jumps to function"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "ProductNavItem from productNavigator",
        "AnalysisItem from analysisViewer",
        "EntryPoint from analyzer"
      ],
      "intent": "This file exists to centralize all navigation logic for the extension, separating concerns of moving around the codebase and displaying code details from the main extension logic. It solves the problem of providing consistent navigation and detail views across different types of code items (files, functions, endpoints, analysis results) while handling workspace path resolution and error cases.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to code locations (files, functions, endpoints) and displays detailed information about code items in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the workspace\",\n    \"Navigate to a function definition within a file\",\n    \"Navigate to an API endpoint implementation\",\n    \"View detailed information about a code item in a webview panel\",\n    \"See function signatures, parameters, and return types\",\n    \"View endpoints with their HTTP methods and paths\",\n    \"See file contents and dependencies\",\n    \"Jump to specific line numbers in files\",\n    \"View analysis results and code metrics\",\n    \"See error messages when navigation fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provide ProductNavItem objects to navigate to code locations\",\n    \"Provide AnalysisItem objects to display code analysis details\",\n    \"Trigger navigation by calling handler methods with item data\",\n    \"Handle navigation to files with absolute or relative paths\",\n    \"Display webview panels with formatted code information\",\n    \"Navigate to functions by name within files\",\n    \"Navigate to endpoints by path and method\",\n    \"Handle entry point navigation with function details\",\n    \"Receive error messages when files cannot be opened\",\n    \"Work with workspace-relative or absolute file paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, or endpoint)\",\n      \"inputs\": \"ProductNavItem (contains type and data with file/function/endpoint information)\",\n      \"outputs\": \"Promise<void> - completes when navigation is done\"\n    },\n    {\n      \"name\": \"showProductItemDetails\",\n      \"desc\": \"Displays detailed information about a product item in a webview panel\",\n      \"inputs\": \"ProductNavItem (contains item data to display)\",\n      \"outputs\": \"void - opens webview with formatted details\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item location in the code\",\n      \"inputs\": \"AnalysisItem (contains file path and optional line number)\",\n      \"outputs\": \"Promise<void> - completes when editor opens\"\n    },\n    {\n      \"name\": \"showAnalysisItemDetails\",\n      \"desc\": \"Displays detailed analysis information in a webview panel\",\n      \"inputs\": \"AnalysisItem (contains analysis data and metrics)\",\n      \"outputs\": \"void - shows webview with analysis details\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point function in the codebase\",\n      \"inputs\": \"EntryPoint (contains file path and function name)\",\n      \"outputs\": \"Promise<void> - opens file and jumps to function\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic for the extension, separating concerns of moving around the codebase and displaying code details from the main extension logic. It solves the problem of providing consistent navigation and detail views across different types of code items (files, functions, endpoints, analysis results) while handling workspace path resolution and error cases.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralized prompt construction service that builds specialized prompts for different types of LLM-based code analysis tasks",
      "userVisibleActions": [
        "Generates architecture analysis of the codebase",
        "Produces product documentation summaries",
        "Analyzes product purpose and value proposition",
        "Creates detailed file-level code analysis",
        "Generates module-level summaries from multiple files",
        "Produces comprehensive product-level documentation",
        "Creates test plans for source code files",
        "Generates actual test code from test plans"
      ],
      "developerVisibleActions": [
        "Developer calls buildArchitecturePrompt to get an LLM prompt for analyzing system architecture",
        "Developer calls buildProductDocsPrompt to generate prompts for extracting product documentation",
        "Developer calls buildProductPurposePrompt to create prompts for analyzing product purpose",
        "Developer calls buildFileAnalysisPrompt to generate prompts for analyzing individual files",
        "Developer calls buildModuleRollupPrompt to create prompts that summarize multiple files into module documentation",
        "Developer calls buildProductLevelPrompt to generate prompts for overall product analysis",
        "Developer calls buildPerFileTestPlanPrompt to create test planning prompts for specific files",
        "Developer calls buildTestCodeGenerationPrompt to generate actual test code from test plans",
        "Prompts are constructed with specific context, code analysis data, and documentation",
        "Each prompt builder method accepts relevant context and returns a formatted string ready for LLM consumption"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Constructs a prompt for analyzing codebase architecture",
          "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Constructs a prompt for extracting product documentation",
          "inputs": "context (AnalysisContext)",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Constructs a prompt for analyzing product purpose and value",
          "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Constructs a prompt for analyzing a single source file",
          "inputs": "file (FileInfo), content (string), role (string)",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Constructs a prompt for summarizing multiple files into a module",
          "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Constructs a prompt for overall product-level analysis",
          "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Constructs a prompt for creating test plans for a specific file",
          "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Constructs a prompt for generating actual test code from a test plan",
          "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "../../llmService",
        "../../analyzer",
        "../../fileDocumentation",
        "../../fileAccessHelper"
      ],
      "intent": "Eliminates prompt construction duplication across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent prompt formatting and structure for various analysis tasks including architecture analysis, documentation generation, and test creation",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction service that builds specialized prompts for different types of LLM-based code analysis tasks\",\n  \"userVisibleActions\": [\n    \"Generates architecture analysis of the codebase\",\n    \"Produces product documentation summaries\",\n    \"Analyzes product purpose and value proposition\",\n    \"Creates detailed file-level code analysis\",\n    \"Generates module-level summaries from multiple files\",\n    \"Produces comprehensive product-level documentation\",\n    \"Creates test plans for source code files\",\n    \"Generates actual test code from test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildArchitecturePrompt to get an LLM prompt for analyzing system architecture\",\n    \"Developer calls buildProductDocsPrompt to generate prompts for extracting product documentation\",\n    \"Developer calls buildProductPurposePrompt to create prompts for analyzing product purpose\",\n    \"Developer calls buildFileAnalysisPrompt to generate prompts for analyzing individual files\",\n    \"Developer calls buildModuleRollupPrompt to create prompts that summarize multiple files into module documentation\",\n    \"Developer calls buildProductLevelPrompt to generate prompts for overall product analysis\",\n    \"Developer calls buildPerFileTestPlanPrompt to create test planning prompts for specific files\",\n    \"Developer calls buildTestCodeGenerationPrompt to generate actual test code from test plans\",\n    \"Prompts are constructed with specific context, code analysis data, and documentation\",\n    \"Each prompt builder method accepts relevant context and returns a formatted string ready for LLM consumption\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing codebase architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Constructs a prompt for extracting product documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing product purpose and value\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Constructs a prompt for analyzing a single source file\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs a prompt for summarizing multiple files into a module\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Constructs a prompt for overall product-level analysis\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Constructs a prompt for creating test plans for a specific file\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Constructs a prompt for generating actual test code from a test plan\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"Eliminates prompt construction duplication across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent prompt formatting and structure for various analysis tasks including architecture analysis, documentation generation, and test creation\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Builds structured prompts for LLM-based code refactoring that include detailed analysis, extraction plans, and prescriptive instructions.",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations with step-by-step migration plans",
        "Gets code examples showing before/after states for proposed refactorings",
        "Sees function-by-function analysis explaining why code should be extracted or reorganized",
        "Views dependency relationships between functions to understand extraction impact"
      ],
      "developerVisibleActions": [
        "Generates comprehensive refactoring prompts by combining code analysis, product documentation, and architecture insights",
        "Creates structured extraction plans that identify functions to move and their dependencies",
        "Produces prompts that request specific refactoring formats including migration steps and code examples",
        "Builds function analysis sections showing responsibilities, dependencies, and dependents for each function",
        "Formats prompts to guide LLMs in providing prescriptive refactoring instructions rather than general advice"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Constructs a comprehensive refactoring prompt by combining analysis context, code analysis, product documentation, architecture insights, and function analyses",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array",
          "outputs": "Formatted string prompt for LLM consumption"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Creates the foundational prompt structure including context, code analysis, and documentation",
          "inputs": "AnalysisContext, CodeAnalysis, optional product docs, optional architecture insights",
          "outputs": "Base prompt string"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Formats function-level analysis data into prompt text showing signatures, dependencies, and responsibilities",
          "inputs": "Array of FunctionAnalysis objects",
          "outputs": "Formatted function analysis section string"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Generates prompt section specifying what format and details the refactoring recommendations should include",
          "inputs": "None",
          "outputs": "Extraction requirements section string"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to transform raw code analysis data into structured, detailed prompts that guide LLMs to produce actionable refactoring recommendations with specific extraction plans, migration steps, and code examples rather than vague suggestions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds structured prompts for LLM-based code refactoring that include detailed analysis, extraction plans, and prescriptive instructions.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with step-by-step migration plans\",\n    \"Gets code examples showing before/after states for proposed refactorings\",\n    \"Sees function-by-function analysis explaining why code should be extracted or reorganized\",\n    \"Views dependency relationships between functions to understand extraction impact\"\n  ],\n  \"developerVisibleActions\": [\n    \"Generates comprehensive refactoring prompts by combining code analysis, product documentation, and architecture insights\",\n    \"Creates structured extraction plans that identify functions to move and their dependencies\",\n    \"Produces prompts that request specific refactoring formats including migration steps and code examples\",\n    \"Builds function analysis sections showing responsibilities, dependencies, and dependents for each function\",\n    \"Formats prompts to guide LLMs in providing prescriptive refactoring instructions rather than general advice\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Constructs a comprehensive refactoring prompt by combining analysis context, code analysis, product documentation, architecture insights, and function analyses\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array\",\n      \"outputs\": \"Formatted string prompt for LLM consumption\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundational prompt structure including context, code analysis, and documentation\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional product docs, optional architecture insights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Formats function-level analysis data into prompt text showing signatures, dependencies, and responsibilities\",\n      \"inputs\": \"Array of FunctionAnalysis objects\",\n      \"outputs\": \"Formatted function analysis section string\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates prompt section specifying what format and details the refactoring recommendations should include\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Extraction requirements section string\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into structured, detailed prompts that guide LLMs to produce actionable refactoring recommendations with specific extraction plans, migration steps, and code examples rather than vague suggestions.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt builders that generate structured instructions for LLMs to analyze codebases and create test plans.",
      "userVisibleActions": [
        "No direct user-facing actions - this file generates prompts for AI-driven test generation"
      ],
      "developerVisibleActions": [
        "Developer can generate a test setup recommendation prompt by providing workspace root, file list, and optional package.json content",
        "Developer can generate a test planning prompt by providing analysis context, functions list, and optional product/architecture documentation",
        "Developer receives structured JSON-formatted prompts that instruct LLMs on how to analyze code and recommend test configurations",
        "Developer gets prompts that request specific test setup information including framework, dependencies, config files, and mock requirements",
        "Developer gets prompts that request prioritized test plans based on function complexity, coverage, and importance"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates a prompt that asks an LLM to analyze a codebase and recommend optimal test setup configuration",
          "inputs": "workspaceRoot (string), fileList (array of file paths), optional packageJsonContent (string)",
          "outputs": "Formatted string prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates a prompt that asks an LLM to analyze functions and create a prioritized test plan",
          "inputs": "context (AnalysisContext), functions (array of function objects), optional productDocs, optional architectureInsights",
          "outputs": "Formatted string prompt with codebase statistics and function list requesting prioritized test strategy"
        }
      ],
      "dependencies": [
        "../../analyzer",
        "../services/testing/types/testPlanTypes"
      ],
      "intent": "This file exists to bridge the gap between code analysis and AI-driven test generation by creating standardized, structured prompts that guide LLMs to generate comprehensive test configurations and plans. It solves the problem of consistently requesting the right information from LLMs in a format that can be programmatically processed.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt builders that generate structured instructions for LLMs to analyze codebases and create test plans.\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this file generates prompts for AI-driven test generation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can generate a test setup recommendation prompt by providing workspace root, file list, and optional package.json content\",\n    \"Developer can generate a test planning prompt by providing analysis context, functions list, and optional product/architecture documentation\",\n    \"Developer receives structured JSON-formatted prompts that instruct LLMs on how to analyze code and recommend test configurations\",\n    \"Developer gets prompts that request specific test setup information including framework, dependencies, config files, and mock requirements\",\n    \"Developer gets prompts that request prioritized test plans based on function complexity, coverage, and importance\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt that asks an LLM to analyze a codebase and recommend optimal test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array of file paths), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted string prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt that asks an LLM to analyze functions and create a prioritized test plan\",\n      \"inputs\": \"context (AnalysisContext), functions (array of function objects), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted string prompt with codebase statistics and function list requesting prioritized test strategy\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis and AI-driven test generation by creating standardized, structured prompts that guide LLMs to generate comprehensive test configurations and plans. It solves the problem of consistently requesting the right information from LLMs in a format that can be programmatically processed.\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides a centralized service for monitoring file system changes and document saves in the workspace, consolidating file watching functionality across the extension.",
      "userVisibleActions": [
        "Automatically detects when files are created in the workspace",
        "Automatically detects when files are modified or saved",
        "Automatically detects when files are deleted from the workspace",
        "Responds to file changes based on specific file patterns (e.g., *.md, *.json)",
        "Triggers updates when documents are saved in the editor"
      ],
      "developerVisibleActions": [
        "Register handlers to respond to file creation events",
        "Register handlers to respond to file modification events",
        "Register handlers to respond to file deletion events",
        "Register handlers to respond to document save events",
        "Filter file changes using ignore patterns (e.g., exclude node_modules)",
        "Watch multiple file patterns simultaneously with different handlers",
        "Dispose of watchers to stop monitoring files",
        "Configure which types of changes to monitor (create, change, delete)",
        "Receive structured file change events with URI and change type"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Monitors file system changes matching a specific pattern and triggers callbacks",
          "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)",
          "outputs": "Disposable object to stop watching"
        },
        {
          "name": "onDocumentSave",
          "desc": "Registers a callback to be triggered whenever a document is saved in the editor",
          "inputs": "handler (callback function receiving TextDocument)",
          "outputs": "Disposable object to unregister the handler"
        },
        {
          "name": "stopWatching",
          "desc": "Stops monitoring a specific file pattern and removes associated handlers",
          "inputs": "id (string)",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all active watchers and handlers when service is no longer needed",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getPatternKey",
          "desc": "Generates a unique key for a file pattern to prevent duplicate watchers",
          "inputs": "pattern (string or RelativePattern)",
          "outputs": "string key"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to eliminate duplication of file watching code across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) by providing a single, reusable service that manages file system monitoring. It solves the problem of multiple components independently creating watchers, which leads to code duplication, inconsistent behavior, and resource waste. By centralizing this functionality, components can easily respond to file changes without managing watcher lifecycles themselves.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes and document saves in the workspace, consolidating file watching functionality across the extension.\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created in the workspace\",\n    \"Automatically detects when files are modified or saved\",\n    \"Automatically detects when files are deleted from the workspace\",\n    \"Responds to file changes based on specific file patterns (e.g., *.md, *.json)\",\n    \"Triggers updates when documents are saved in the editor\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register handlers to respond to file creation events\",\n    \"Register handlers to respond to file modification events\",\n    \"Register handlers to respond to file deletion events\",\n    \"Register handlers to respond to document save events\",\n    \"Filter file changes using ignore patterns (e.g., exclude node_modules)\",\n    \"Watch multiple file patterns simultaneously with different handlers\",\n    \"Dispose of watchers to stop monitoring files\",\n    \"Configure which types of changes to monitor (create, change, delete)\",\n    \"Receive structured file change events with URI and change type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Monitors file system changes matching a specific pattern and triggers callbacks\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)\",\n      \"outputs\": \"Disposable object to stop watching\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a callback to be triggered whenever a document is saved in the editor\",\n      \"inputs\": \"handler (callback function receiving TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"stopWatching\",\n      \"desc\": \"Stops monitoring a specific file pattern and removes associated handlers\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all active watchers and handlers when service is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to prevent duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication of file watching code across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) by providing a single, reusable service that manages file system monitoring. It solves the problem of multiple components independently creating watchers, which leads to code duplication, inconsistent behavior, and resource waste. By centralizing this functionality, components can easily respond to file changes without managing watcher lifecycles themselves.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative LLM analysis by processing file and grep requests across multiple conversation rounds until analysis is complete.",
      "userVisibleActions": [
        "Analysis proceeds in multiple rounds, with each round gathering more information based on previous results",
        "File contents and search results are retrieved automatically during analysis",
        "Progress through iterations is tracked and communicated",
        "Analysis stops when completion criteria are met or maximum iterations reached"
      ],
      "developerVisibleActions": [
        "Service processes LLM requests for file reads and grep searches iteratively",
        "Callbacks notify when iterations start and complete",
        "Returns structured results including iteration count, requests made, and whether to continue",
        "Limits requests to 5 per iteration to prevent excessive processing",
        "Formats file and search results into conversation messages",
        "Provides async iterator pattern for testable iteration control"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes file read and grep search requests from LLM, returning formatted results",
          "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation array)",
          "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
        },
        {
          "name": "IterationResult",
          "desc": "Structure representing outcome of a single analysis iteration",
          "inputs": "N/A (interface)",
          "outputs": "Contains result, iteration number, max iterations, requests made, and continuation flag"
        },
        {
          "name": "IterationCallbacks",
          "desc": "Optional callbacks to monitor iteration lifecycle",
          "inputs": "N/A (interface)",
          "outputs": "Callbacks for iteration start and completion events"
        }
      ],
      "dependencies": [
        "fileAccessHelper",
        "LLMRequest"
      ],
      "intent": "Eliminates code duplication by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM requests additional files or searches to complete its analysis, making the pattern testable and reusable across different analysis scenarios.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file and grep requests across multiple conversation rounds until analysis is complete.\",\n  \"userVisibleActions\": [\n    \"Analysis proceeds in multiple rounds, with each round gathering more information based on previous results\",\n    \"File contents and search results are retrieved automatically during analysis\",\n    \"Progress through iterations is tracked and communicated\",\n    \"Analysis stops when completion criteria are met or maximum iterations reached\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service processes LLM requests for file reads and grep searches iteratively\",\n    \"Callbacks notify when iterations start and complete\",\n    \"Returns structured results including iteration count, requests made, and whether to continue\",\n    \"Limits requests to 5 per iteration to prevent excessive processing\",\n    \"Formats file and search results into conversation messages\",\n    \"Provides async iterator pattern for testable iteration control\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes file read and grep search requests from LLM, returning formatted results\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation array)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"IterationResult\",\n      \"desc\": \"Structure representing outcome of a single analysis iteration\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Contains result, iteration number, max iterations, requests made, and continuation flag\"\n    },\n    {\n      \"name\": \"IterationCallbacks\",\n      \"desc\": \"Optional callbacks to monitor iteration lifecycle\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Callbacks for iteration start and completion events\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest\"\n  ],\n  \"intent\": \"Eliminates code duplication by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM requests additional files or searches to complete its analysis, making the pattern testable and reusable across different analysis scenarios.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects test framework configuration in the workspace and determines if setup is required for generated tests to work",
      "userVisibleActions": [
        "Automatically detects which test framework is being used in the project (Jest, Mocha, Vitest, or Pytest)",
        "Reports whether test configuration is properly set up and ready to use",
        "Identifies missing test dependencies that need to be installed",
        "Provides list of setup actions required to make tests work",
        "Detects if TypeScript support for testing is configured"
      ],
      "developerVisibleActions": [
        "Reads package.json to detect test scripts and installed dependencies",
        "Scans for test framework configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini, etc.)",
        "Checks if TypeScript test dependencies are installed when TypeScript files exist",
        "Returns structured status report about test framework and configuration state",
        "Identifies specific missing dependencies needed for the detected framework",
        "Generates list of required setup actions to complete test configuration"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Analyzes workspace to detect test framework and configuration status",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestConfigStatus object with framework type, configuration status, missing dependencies, and required setup actions"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "SWLogger"
      ],
      "intent": "Eliminates manual test configuration by automatically detecting the test framework in use and identifying any missing setup, ensuring generated tests will work without user intervention or configuration errors",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration in the workspace and determines if setup is required for generated tests to work\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used in the project (Jest, Mocha, Vitest, or Pytest)\",\n    \"Reports whether test configuration is properly set up and ready to use\",\n    \"Identifies missing test dependencies that need to be installed\",\n    \"Provides list of setup actions required to make tests work\",\n    \"Detects if TypeScript support for testing is configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Reads package.json to detect test scripts and installed dependencies\",\n    \"Scans for test framework configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini, etc.)\",\n    \"Checks if TypeScript test dependencies are installed when TypeScript files exist\",\n    \"Returns structured status report about test framework and configuration state\",\n    \"Identifies specific missing dependencies needed for the detected framework\",\n    \"Generates list of required setup actions to complete test configuration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration status, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration by automatically detecting the test framework in use and identifying any missing setup, ensuring generated tests will work without user intervention or configuration errors\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates unit tests for code functions using an LLM in small batches with progress tracking and execution validation.",
      "userVisibleActions": [
        "Progress updates showing which function is being tested and completion percentage",
        "Test generation results indicating success or failure for each function",
        "Notifications when test files are created or updated",
        "Error messages if test generation fails for specific functions"
      ],
      "developerVisibleActions": [
        "Developer triggers test generation for selected functions",
        "System reads source code and extracts function signatures",
        "LLM generates test code based on function context and existing mocks",
        "Generated tests are validated by executing them",
        "Test files are written to the test directory structure",
        "Progress callback provides real-time status updates during batch processing",
        "Results map shows success/failure status for each function tested"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for multiple functions in a batch with progress tracking",
          "inputs": "functions array, workspace root path, LLM service, optional progress callback",
          "outputs": "Map of function names to test generation results"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Retrieves the source code for a specific function from its file",
          "inputs": "TestableFunction object, workspace root path",
          "outputs": "Source code string for the function"
        },
        {
          "name": "generateTestForFunction",
          "desc": "Creates a test for a single function using LLM and validates it",
          "inputs": "Function details, source code, LLM service, workspace root, test framework type, existing mocks",
          "outputs": "TestGenerationResult with test code and execution status"
        },
        {
          "name": "buildGenerationPrompt",
          "desc": "Constructs the LLM prompt with function context and mock information",
          "inputs": "Function object, source code, test framework name, existing mocks",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestableFunction",
        "TestGenerationState",
        "TestGenerationResult",
        "buildGenerationPrompt",
        "TestExecutionService",
        "SWLogger"
      ],
      "intent": "Automates test generation by leveraging AI to write unit tests incrementally for code functions, reducing manual test writing effort while ensuring generated tests are valid through automatic execution and validation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions using an LLM in small batches with progress tracking and execution validation.\",\n  \"userVisibleActions\": [\n    \"Progress updates showing which function is being tested and completion percentage\",\n    \"Test generation results indicating success or failure for each function\",\n    \"Notifications when test files are created or updated\",\n    \"Error messages if test generation fails for specific functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for selected functions\",\n    \"System reads source code and extracts function signatures\",\n    \"LLM generates test code based on function context and existing mocks\",\n    \"Generated tests are validated by executing them\",\n    \"Test files are written to the test directory structure\",\n    \"Progress callback provides real-time status updates during batch processing\",\n    \"Results map shows success/failure status for each function tested\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service, optional progress callback\",\n      \"outputs\": \"Map of function names to test generation results\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Retrieves the source code for a specific function from its file\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    },\n    {\n      \"name\": \"generateTestForFunction\",\n      \"desc\": \"Creates a test for a single function using LLM and validates it\",\n      \"inputs\": \"Function details, source code, LLM service, workspace root, test framework type, existing mocks\",\n      \"outputs\": \"TestGenerationResult with test code and execution status\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Constructs the LLM prompt with function context and mock information\",\n      \"inputs\": \"Function object, source code, test framework name, existing mocks\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Automates test generation by leveraging AI to write unit tests incrementally for code functions, reducing manual test writing effort while ensuring generated tests are valid through automatic execution and validation.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code functions and creates a prioritized test plan using LLM guidance based on complexity, dependencies, and product context.",
      "userVisibleActions": [
        "Receives analysis of which functions in their codebase are testable and which are not",
        "Gets a prioritized test plan showing which functions should be tested first based on complexity and risk",
        "Views function groups organized by testing priority",
        "Sees statistics about total functions vs testable functions in their codebase"
      ],
      "developerVisibleActions": [
        "Calls analyzeFunctions() to extract function metadata from code analysis results",
        "Calls createTestPlan() to generate an LLM-based test strategy with prioritized function groups",
        "Calls saveTestPlan() to persist the generated test plan to disk for later use",
        "Reviews log messages showing test planning progress and statistics",
        "Uses the resulting TestPlan object containing function groups, testability status, and testing priorities"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts and normalizes function metadata from code analysis results",
          "inputs": "codeAnalysis object containing function information",
          "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
        },
        {
          "name": "createTestPlan",
          "desc": "Generates a prioritized test plan by sending function data to LLM with product and architecture context",
          "inputs": "AnalysisContext, functions array, llmService, optional productDocs and architectureInsights",
          "outputs": "TestPlan object with function groups, testability counts, and testing priorities"
        },
        {
          "name": "saveTestPlan",
          "desc": "Persists the generated test plan to a JSON file on disk",
          "inputs": "TestPlan object and file path where to save",
          "outputs": "File written to disk (void return)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "testPlanTypes",
        "testPrompts",
        "AnalysisContext",
        "SWLogger"
      ],
      "intent": "This service exists to bridge code analysis results with test generation by intelligently prioritizing which functions should be tested first. It solves the problem of determining testing priorities in large codebases by using LLM reasoning to consider complexity, dependencies, and business context rather than testing everything indiscriminately.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code functions and creates a prioritized test plan using LLM guidance based on complexity, dependencies, and product context.\",\n  \"userVisibleActions\": [\n    \"Receives analysis of which functions in their codebase are testable and which are not\",\n    \"Gets a prioritized test plan showing which functions should be tested first based on complexity and risk\",\n    \"Views function groups organized by testing priority\",\n    \"Sees statistics about total functions vs testable functions in their codebase\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis results\",\n    \"Calls createTestPlan() to generate an LLM-based test strategy with prioritized function groups\",\n    \"Calls saveTestPlan() to persist the generated test plan to disk for later use\",\n    \"Reviews log messages showing test planning progress and statistics\",\n    \"Uses the resulting TestPlan object containing function groups, testability status, and testing priorities\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function metadata from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing function information\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan by sending function data to LLM with product and architecture context\",\n      \"inputs\": \"AnalysisContext, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups, testability counts, and testing priorities\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to a JSON file on disk\",\n      \"inputs\": \"TestPlan object and file path where to save\",\n      \"outputs\": \"File written to disk (void return)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"testPlanTypes\",\n    \"testPrompts\",\n    \"AnalysisContext\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to bridge code analysis results with test generation by intelligently prioritizing which functions should be tested first. It solves the problem of determining testing priorities in large codebases by using LLM reasoning to consider complexity, dependencies, and business context rather than testing everything indiscriminately.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Detects test environment configuration and generates AI-powered test setup plans for different programming languages and testing frameworks.",
      "userVisibleActions": [
        "Automatically detects the programming language used in the workspace (TypeScript, JavaScript, Python, Java, C++)",
        "Identifies existing testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)",
        "Discovers test directories and configuration files",
        "Generates a test setup plan with recommended dependencies and configuration",
        "Provides step-by-step setup instructions for missing test infrastructure",
        "Reports whether the test environment is ready or needs setup"
      ],
      "developerVisibleActions": [
        "Call detectTestEnvironment() to scan workspace and identify language, framework, and existing test configuration",
        "Use generateTestSetupPlan() to create an AI-generated setup plan based on detected environment",
        "Execute executeSetupPlan() to automatically install dependencies and create configuration files",
        "Receive TestEnvironment object with details about detected language, framework, and file paths",
        "Get TestSetupPlan with missing dependencies, configuration templates, and setup steps",
        "Obtain SetupExecutionResult indicating success/failure and any errors encountered"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Scans workspace to detect programming language, testing framework, and existing test infrastructure",
          "inputs": "workspaceRoot (string path)",
          "outputs": "TestEnvironment object with language, framework, paths, and status"
        },
        {
          "name": "generateTestSetupPlan",
          "desc": "Uses LLM to generate a comprehensive test setup plan based on detected environment",
          "inputs": "TestEnvironment object, optional LLM provider",
          "outputs": "TestSetupPlan with dependencies, configuration, and setup steps"
        },
        {
          "name": "executeSetupPlan",
          "desc": "Executes the generated setup plan by installing dependencies and creating configuration files",
          "inputs": "TestSetupPlan object, workspaceRoot path",
          "outputs": "SetupExecutionResult with success status and execution details"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively retrieves all files in a directory for language detection",
          "inputs": "directory path (string)",
          "outputs": "Array of file paths"
        },
        {
          "name": "detectTestingFramework",
          "desc": "Identifies which testing framework is in use based on dependencies and config files",
          "inputs": "packageJsonPath (string)",
          "outputs": "Framework name string (jest, mocha, pytest, junit, etc.)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "./types/testSetupTypes",
        "../../prompts/testPrompts",
        "../../../logger"
      ],
      "intent": "Automates the detection and setup of test environments across multiple programming languages and testing frameworks, reducing manual configuration burden by using LLM to generate intelligent, context-aware setup plans tailored to the detected project structure.",
      "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates AI-powered test setup plans for different programming languages and testing frameworks.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language used in the workspace (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Identifies existing testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)\",\n    \"Discovers test directories and configuration files\",\n    \"Generates a test setup plan with recommended dependencies and configuration\",\n    \"Provides step-by-step setup instructions for missing test infrastructure\",\n    \"Reports whether the test environment is ready or needs setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call detectTestEnvironment() to scan workspace and identify language, framework, and existing test configuration\",\n    \"Use generateTestSetupPlan() to create an AI-generated setup plan based on detected environment\",\n    \"Execute executeSetupPlan() to automatically install dependencies and create configuration files\",\n    \"Receive TestEnvironment object with details about detected language, framework, and file paths\",\n    \"Get TestSetupPlan with missing dependencies, configuration templates, and setup steps\",\n    \"Obtain SetupExecutionResult indicating success/failure and any errors encountered\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Scans workspace to detect programming language, testing framework, and existing test infrastructure\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"TestEnvironment object with language, framework, paths, and status\"\n    },\n    {\n      \"name\": \"generateTestSetupPlan\",\n      \"desc\": \"Uses LLM to generate a comprehensive test setup plan based on detected environment\",\n      \"inputs\": \"TestEnvironment object, optional LLM provider\",\n      \"outputs\": \"TestSetupPlan with dependencies, configuration, and setup steps\"\n    },\n    {\n      \"name\": \"executeSetupPlan\",\n      \"desc\": \"Executes the generated setup plan by installing dependencies and creating configuration files\",\n      \"inputs\": \"TestSetupPlan object, workspaceRoot path\",\n      \"outputs\": \"SetupExecutionResult with success status and execution details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively retrieves all files in a directory for language detection\",\n      \"inputs\": \"directory path (string)\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"detectTestingFramework\",\n      \"desc\": \"Identifies which testing framework is in use based on dependencies and config files\",\n      \"inputs\": \"packageJsonPath (string)\",\n      \"outputs\": \"Framework name string (jest, mocha, pytest, junit, etc.)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"Automates the detection and setup of test environments across multiple programming languages and testing frameworks, reducing manual configuration burden by using LLM to generate intelligent, context-aware setup plans tailored to the detected project structure.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates tests by running them and automatically fixing failures using LLM assistance",
      "userVisibleActions": [
        "Tests are automatically executed in the workspace",
        "Test results show pass/fail status with counts",
        "Failing tests are automatically fixed through multiple retry attempts",
        "Progress updates appear in logs showing test execution status",
        "Test reports are generated showing overall test health"
      ],
      "developerVisibleActions": [
        "Call runTests() to execute Jest tests in workspace and get execution results",
        "Call fixFailingTest() to automatically repair a failing test using LLM suggestions",
        "Receive TestExecutionResult objects containing passed/failed/error counts",
        "Access test reports and summaries showing test suite health metrics",
        "Configure maximum fix attempts to control auto-repair retry limit",
        "Get detailed failure information including error messages and stack traces"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or a specific test file and returns execution results with pass/fail counts",
          "inputs": "workspaceRoot: string, testFile?: string (optional specific test file)",
          "outputs": "Promise<TestExecutionResult[]> with test outcomes and statistics"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to automatically fix a failing test by using LLM to generate corrections",
          "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)",
          "outputs": "Promise<{ success: boolean; attempts: number; finalError?: string }> indicating fix outcome"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "TestExecutionResult",
        "TestReport",
        "TestReportSummary",
        "buildFixPrompt",
        "SWLogger"
      ],
      "intent": "This service exists to automate test validation and repair in the development workflow. It solves the problem of manually fixing failing tests by using LLM intelligence to analyze test failures and automatically generate fixes, reducing developer time spent on test maintenance and improving test suite reliability.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them and automatically fixing failures using LLM assistance\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed in the workspace\",\n    \"Test results show pass/fail status with counts\",\n    \"Failing tests are automatically fixed through multiple retry attempts\",\n    \"Progress updates appear in logs showing test execution status\",\n    \"Test reports are generated showing overall test health\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runTests() to execute Jest tests in workspace and get execution results\",\n    \"Call fixFailingTest() to automatically repair a failing test using LLM suggestions\",\n    \"Receive TestExecutionResult objects containing passed/failed/error counts\",\n    \"Access test reports and summaries showing test suite health metrics\",\n    \"Configure maximum fix attempts to control auto-repair retry limit\",\n    \"Get detailed failure information including error messages and stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns execution results with pass/fail counts\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string (optional specific test file)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> with test outcomes and statistics\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test by using LLM to generate corrections\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)\",\n      \"outputs\": \"Promise<{ success: boolean; attempts: number; finalError?: string }> indicating fix outcome\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to automate test validation and repair in the development workflow. It solves the problem of manually fixing failing tests by using LLM intelligence to analyze test failures and automatically generate fixes, reducing developer time spent on test maintenance and improving test suite reliability.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes test suites (Jest/Mocha) and captures their results, errors, and execution statistics",
      "userVisibleActions": [
        "Tests run and complete with pass/fail status",
        "Test execution progress is displayed",
        "Test failures show error messages and stack traces",
        "Test duration and timing information is shown",
        "Overall test summary shows passed/failed/error counts"
      ],
      "developerVisibleActions": [
        "Call runJest() or runMocha() to execute tests for specific files or entire test suite",
        "Receive structured test results with pass/fail counts and error details",
        "Get detailed error information including test names, messages, and stack traces",
        "Access test execution duration and performance metrics",
        "Handle test execution errors and timeouts gracefully"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Executes Jest test runner for a specific file or all tests",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> containing test outcomes, counts, and errors"
        },
        {
          "name": "runMocha",
          "desc": "Executes Mocha test runner for a specific file or all tests",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> containing test outcomes, counts, and errors"
        },
        {
          "name": "parseJestOutput",
          "desc": "Parses JSON output from Jest test runner into structured results",
          "inputs": "stdout (string), stderr (string)",
          "outputs": "TestExecutionResult[] with parsed test outcomes and error details"
        },
        {
          "name": "parseMochaOutput",
          "desc": "Parses JSON output from Mocha test runner into structured results",
          "inputs": "stdout (string), stderr (string)",
          "outputs": "TestExecutionResult[] with parsed test outcomes and error details"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "Provides a unified interface for running different test frameworks (Jest and Mocha) in the workspace, capturing their output, and converting it into a consistent format that can be displayed to users and processed by other parts of the application. Solves the problem of executing tests programmatically and handling their results reliably with proper error handling and timeout management.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest/Mocha) and captures their results, errors, and execution statistics\",\n  \"userVisibleActions\": [\n    \"Tests run and complete with pass/fail status\",\n    \"Test execution progress is displayed\",\n    \"Test failures show error messages and stack traces\",\n    \"Test duration and timing information is shown\",\n    \"Overall test summary shows passed/failed/error counts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runJest() or runMocha() to execute tests for specific files or entire test suite\",\n    \"Receive structured test results with pass/fail counts and error details\",\n    \"Get detailed error information including test names, messages, and stack traces\",\n    \"Access test execution duration and performance metrics\",\n    \"Handle test execution errors and timeouts gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest test runner for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes, counts, and errors\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha test runner for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes, counts, and errors\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses JSON output from Jest test runner into structured results\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test outcomes and error details\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses JSON output from Mocha test runner into structured results\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test outcomes and error details\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for running different test frameworks (Jest and Mocha) in the workspace, capturing their output, and converting it into a consistent format that can be displayed to users and processed by other parts of the application. Solves the problem of executing tests programmatically and handling their results reliably with proper error handling and timeout management.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for the test planning and generation service, structuring how test plans, functions, and generation states are represented.",
      "userVisibleActions": [
        "Users can see test generation progress through different phases (setup, planning, generation, validation, complete)",
        "Users can view which functions are being tested and their completion status",
        "Users can see failures during test generation with error messages and attempt counts",
        "Users can track how many functions have been generated and validated out of the total"
      ],
      "developerVisibleActions": [
        "Developers create test plans with grouped functions organized by priority",
        "Developers specify which functions are testable and their complexity levels",
        "Developers track dependencies and mocking requirements for each function",
        "Developers monitor test generation state across different phases",
        "Developers access function metadata including file location, line numbers, parameters, and return types",
        "Developers handle test failures with retry logic based on attempt counts"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a strongly-typed contract for the test planning service, ensuring consistency when organizing functions into test groups, tracking test generation progress through multiple phases, and managing failures during automated test creation. Enables type-safe handling of function metadata needed for intelligent test generation decisions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for the test planning and generation service, structuring how test plans, functions, and generation states are represented.\",\n  \"userVisibleActions\": [\n    \"Users can see test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"Users can view which functions are being tested and their completion status\",\n    \"Users can see failures during test generation with error messages and attempt counts\",\n    \"Users can track how many functions have been generated and validated out of the total\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers create test plans with grouped functions organized by priority\",\n    \"Developers specify which functions are testable and their complexity levels\",\n    \"Developers track dependencies and mocking requirements for each function\",\n    \"Developers monitor test generation state across different phases\",\n    \"Developers access function metadata including file location, line numbers, parameters, and return types\",\n    \"Developers handle test failures with retry logic based on attempt counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for the test planning service, ensuring consistency when organizing functions into test groups, tracking test generation progress through multiple phases, and managing failures during automated test creation. Enables type-safe handling of function metadata needed for intelligent test generation decisions.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces for test generation, validation, execution results, and test reporting data structures.",
      "userVisibleActions": [
        "View test execution results showing passed/failed/error counts",
        "See test reports with pass rates and summary statistics",
        "Review error details for failed tests including error messages and stack traces",
        "Access recommendations for improving test quality",
        "View mock statements with explanations for generated tests"
      ],
      "developerVisibleActions": [
        "Import type definitions for test generation results including test file paths, imports, mocks, and test code",
        "Use TestValidationResult to handle test validation outcomes with fixed code and explanations",
        "Access TestExecutionResult to retrieve test run statistics and duration metrics",
        "Generate structured test reports with TestReport interface containing summaries and recommendations",
        "Handle test errors using TestErrorDetail with test names, messages, and stack traces",
        "Structure mock statements with MockStatement interface for generated test mocks"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to provide a consistent, type-safe contract for test-related operations throughout the application. It solves the problem of standardizing data structures for test generation workflows, validation processes, execution results, and reporting, ensuring all components that handle testing features work with the same data format.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test generation, validation, execution results, and test reporting data structures.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed/failed/error counts\",\n    \"See test reports with pass rates and summary statistics\",\n    \"Review error details for failed tests including error messages and stack traces\",\n    \"Access recommendations for improving test quality\",\n    \"View mock statements with explanations for generated tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import type definitions for test generation results including test file paths, imports, mocks, and test code\",\n    \"Use TestValidationResult to handle test validation outcomes with fixed code and explanations\",\n    \"Access TestExecutionResult to retrieve test run statistics and duration metrics\",\n    \"Generate structured test reports with TestReport interface containing summaries and recommendations\",\n    \"Handle test errors using TestErrorDetail with test names, messages, and stack traces\",\n    \"Structure mock statements with MockStatement interface for generated test mocks\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a consistent, type-safe contract for test-related operations throughout the application. It solves the problem of standardizing data structures for test generation workflows, validation processes, execution results, and reporting, ensuring all components that handle testing features work with the same data format.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test setup service operations, including test configuration, dependencies, and execution results.",
      "userVisibleActions": [
        "User receives information about test setup plans including framework and dependencies",
        "User sees which configuration files will be created during test setup",
        "User is informed about test environment status and missing dependencies",
        "User receives feedback on setup execution success with created files and installed dependencies",
        "User is notified of any errors that occurred during test setup"
      ],
      "developerVisibleActions": [
        "Developer uses TestSetupPlan to structure test framework configuration data",
        "Developer accesses TestEnvironment to check existing test infrastructure",
        "Developer receives SetupExecutionResult to understand what was created and installed",
        "Developer identifies mock requirements needed for testing",
        "Developer tracks dependency installation status through structured result types"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides type safety and structure for test setup operations by defining interfaces for test plans, environment detection, dependency management, and execution results, ensuring consistent data handling throughout the test setup service.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup service operations, including test configuration, dependencies, and execution results.\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including framework and dependencies\",\n    \"User sees which configuration files will be created during test setup\",\n    \"User is informed about test environment status and missing dependencies\",\n    \"User receives feedback on setup execution success with created files and installed dependencies\",\n    \"User is notified of any errors that occurred during test setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan to structure test framework configuration data\",\n    \"Developer accesses TestEnvironment to check existing test infrastructure\",\n    \"Developer receives SetupExecutionResult to understand what was created and installed\",\n    \"Developer identifies mock requirements needed for testing\",\n    \"Developer tracks dependency installation status through structured result types\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for test setup operations by defining interfaces for test plans, environment detection, dependency management, and execution results, ensuring consistent data handling throughout the test setup service.\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "Activates and orchestrates the VS Code extension for code analysis, providing commands, views, and integrations for analyzing codebases and generating insights.",
      "userVisibleActions": [
        "Trigger full codebase analysis through command palette or status bar",
        "Analyze currently open file for structure and insights",
        "View analyzed code insights in tree view sidebar",
        "Format analysis output for LLM consumption",
        "Navigate to specific code elements (functions, classes, entry points) from analysis views",
        "Export analysis results to markdown or JSON files",
        "View code analysis diagnostics and warnings in Problems panel",
        "Clear analysis cache to force fresh analysis",
        "View product navigation tree showing project structure",
        "View static analysis results in dedicated panel",
        "View unit tests organization in test navigator",
        "See analysis progress in status bar with clickable indicator"
      ],
      "developerVisibleActions": [
        "Extension initializes on VS Code startup and registers all commands and providers",
        "File watcher monitors workspace for changes and triggers automatic re-analysis",
        "Analysis results are cached to improve performance on subsequent requests",
        "Multiple webview providers display different aspects of analysis (insights, static analysis, unit tests)",
        "Command handlers process user actions and coordinate between analyzer, generators, and UI components",
        "Diagnostics provider updates Problems panel with code issues found during analysis",
        "Status bar item shows current analysis state and provides quick access to analysis commands",
        "Extension uses bootstrapper pattern to initialize components in correct dependency order",
        "Configuration manager provides centralized access to extension settings",
        "Error handler catches and displays user-friendly error messages for analysis failures"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Entry point that initializes the extension, sets up all providers, registers commands, and starts file watching",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "void (registers disposables in context)"
        },
        {
          "name": "deactivate",
          "desc": "Cleanup function called when extension is disabled or VS Code closes",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Analyzes entire workspace codebase and updates all views with results",
          "inputs": "none (uses workspace folders)",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeCurrentFile",
          "desc": "Analyzes the currently active editor file and displays results",
          "inputs": "none (uses active text editor)",
          "outputs": "Promise<void>"
        },
        {
          "name": "formatForLLM",
          "desc": "Formats analysis output in LLM-friendly format and displays in editor",
          "inputs": "none (uses cached analysis)",
          "outputs": "Promise<void>"
        },
        {
          "name": "exportAnalysis",
          "desc": "Exports current analysis results to file (markdown or JSON format)",
          "inputs": "format: 'markdown' | 'json'",
          "outputs": "Promise<void>"
        },
        {
          "name": "clearCache",
          "desc": "Clears analysis cache and forces fresh analysis on next request",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "navigateToElement",
          "desc": "Opens file and jumps to specific code element location from analysis view",
          "inputs": "item: TreeItem | AnalysisItem | InsightItem | StaticAnalysisItem",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./productNavigator",
        "./analysisViewer",
        "./insightsViewer",
        "./staticAnalysisViewer",
        "./unitTestsNavigator",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler"
      ],
      "intent": "This file exists as the main entry point and orchestrator for the VS Code extension. It solves the problem of coordinating multiple subsystems (analysis, UI, caching, file watching) into a cohesive user experience, registering all commands and views that users interact with, and managing the lifecycle of extension components from activation to deactivation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Activates and orchestrates the VS Code extension for code analysis, providing commands, views, and integrations for analyzing codebases and generating insights.\",\n  \"userVisibleActions\": [\n    \"Trigger full codebase analysis through command palette or status bar\",\n    \"Analyze currently open file for structure and insights\",\n    \"View analyzed code insights in tree view sidebar\",\n    \"Format analysis output for LLM consumption\",\n    \"Navigate to specific code elements (functions, classes, entry points) from analysis views\",\n    \"Export analysis results to markdown or JSON files\",\n    \"View code analysis diagnostics and warnings in Problems panel\",\n    \"Clear analysis cache to force fresh analysis\",\n    \"View product navigation tree showing project structure\",\n    \"View static analysis results in dedicated panel\",\n    \"View unit tests organization in test navigator\",\n    \"See analysis progress in status bar with clickable indicator\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension initializes on VS Code startup and registers all commands and providers\",\n    \"File watcher monitors workspace for changes and triggers automatic re-analysis\",\n    \"Analysis results are cached to improve performance on subsequent requests\",\n    \"Multiple webview providers display different aspects of analysis (insights, static analysis, unit tests)\",\n    \"Command handlers process user actions and coordinate between analyzer, generators, and UI components\",\n    \"Diagnostics provider updates Problems panel with code issues found during analysis\",\n    \"Status bar item shows current analysis state and provides quick access to analysis commands\",\n    \"Extension uses bootstrapper pattern to initialize components in correct dependency order\",\n    \"Configuration manager provides centralized access to extension settings\",\n    \"Error handler catches and displays user-friendly error messages for analysis failures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Entry point that initializes the extension, sets up all providers, registers commands, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void (registers disposables in context)\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleanup function called when extension is disabled or VS Code closes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes entire workspace codebase and updates all views with results\",\n      \"inputs\": \"none (uses workspace folders)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Analyzes the currently active editor file and displays results\",\n      \"inputs\": \"none (uses active text editor)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatForLLM\",\n      \"desc\": \"Formats analysis output in LLM-friendly format and displays in editor\",\n      \"inputs\": \"none (uses cached analysis)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportAnalysis\",\n      \"desc\": \"Exports current analysis results to file (markdown or JSON format)\",\n      \"inputs\": \"format: 'markdown' | 'json'\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears analysis cache and forces fresh analysis on next request\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"navigateToElement\",\n      \"desc\": \"Opens file and jumps to specific code element location from analysis view\",\n      \"inputs\": \"item: TreeItem | AnalysisItem | InsightItem | StaticAnalysisItem\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./staticAnalysisViewer\",\n    \"./unitTestsNavigator\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file exists as the main entry point and orchestrator for the VS Code extension. It solves the problem of coordinating multiple subsystems (analysis, UI, caching, file watching) into a cohesive user experience, registering all commands and views that users interact with, and managing the lifecycle of extension components from activation to deactivation.\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and grep search functionality to enable iterative LLM analysis of code workspaces",
      "userVisibleActions": [
        "Search for code patterns across project files using grep",
        "View file contents on demand during analysis",
        "See search results with line numbers and context",
        "Get organized file listings by folder structure"
      ],
      "developerVisibleActions": [
        "Request specific files by path to read their contents",
        "Search for text patterns across the codebase with optional file filtering",
        "Limit search results to prevent overwhelming output",
        "Receive structured responses with file paths, line numbers, and content",
        "Get file listings organized by directory with metadata (lines, language)",
        "Process batch requests for multiple files or searches",
        "Handle workspace-relative file paths automatically"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Returns organized directory structure of files",
          "inputs": "Array of file objects with path, lines, and language",
          "outputs": "Formatted string showing files grouped by folder"
        },
        {
          "name": "processRequests",
          "desc": "Handles batch file reading and grep search requests",
          "inputs": "Array of FileRequest or GrepRequest objects",
          "outputs": "Array of FileResponse or GrepResponse objects"
        },
        {
          "name": "readFile",
          "desc": "Reads a single file and returns its content with metadata",
          "inputs": "File path string",
          "outputs": "FileResponse with content, line count, and exists flag"
        },
        {
          "name": "grepFiles",
          "desc": "Searches files for text patterns with optional filtering",
          "inputs": "Search pattern, file pattern (glob), max results limit",
          "outputs": "GrepResponse with matches, line numbers, and context"
        },
        {
          "name": "getFileContent",
          "desc": "Retrieves raw file content",
          "inputs": "File path",
          "outputs": "String content or error"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to give LLMs the ability to explore codebases iteratively - instead of loading all files at once, the LLM can request specific files or search for patterns as needed during analysis, making the process more efficient and token-conscious",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative LLM analysis of code workspaces\",\n  \"userVisibleActions\": [\n    \"Search for code patterns across project files using grep\",\n    \"View file contents on demand during analysis\",\n    \"See search results with line numbers and context\",\n    \"Get organized file listings by folder structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path to read their contents\",\n    \"Search for text patterns across the codebase with optional file filtering\",\n    \"Limit search results to prevent overwhelming output\",\n    \"Receive structured responses with file paths, line numbers, and content\",\n    \"Get file listings organized by directory with metadata (lines, language)\",\n    \"Process batch requests for multiple files or searches\",\n    \"Handle workspace-relative file paths automatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Returns organized directory structure of files\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files grouped by folder\"\n    },\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Handles batch file reading and grep search requests\",\n      \"inputs\": \"Array of FileRequest or GrepRequest objects\",\n      \"outputs\": \"Array of FileResponse or GrepResponse objects\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a single file and returns its content with metadata\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"FileResponse with content, line count, and exists flag\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches files for text patterns with optional filtering\",\n      \"inputs\": \"Search pattern, file pattern (glob), max results limit\",\n      \"outputs\": \"GrepResponse with matches, line numbers, and context\"\n    },\n    {\n      \"name\": \"getFileContent\",\n      \"desc\": \"Retrieves raw file content\",\n      \"inputs\": \"File path\",\n      \"outputs\": \"String content or error\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to give LLMs the ability to explore codebases iteratively - instead of loading all files at once, the LLM can request specific files or search for patterns as needed during analysis, making the process more efficient and token-conscious\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines the structured data models and type definitions for organizing code documentation at file, module, and product levels.",
      "userVisibleActions": [
        "User can view file-level summaries showing what each code file does",
        "User can see module-level rollups grouping related files by functionality",
        "User can browse product-level documentation with architecture diagrams",
        "User can access API endpoints, CLI commands, and worker job flows",
        "User can view dependency graphs showing how components relate"
      ],
      "developerVisibleActions": [
        "Developer defines file summaries with role, purpose, and key functions",
        "Developer organizes files into modules (API, CLI, workers, core, GUI)",
        "Developer documents user-facing actions separately from internal behavior",
        "Developer creates structured metadata for endpoints, commands, and workers",
        "Developer generates product documentation with overview and architecture",
        "Developer tracks dependencies between files and components",
        "Developer stores raw LLM responses alongside structured data"
      ],
      "keyFunctions": [
        {
          "name": "FileSummary",
          "desc": "Represents a single file's documentation including role, purpose, actions, and dependencies",
          "inputs": "file path, role, purpose, actions, functions, dependencies, intent",
          "outputs": "Structured file documentation object"
        },
        {
          "name": "ModuleSummary",
          "desc": "Aggregates multiple files into a module with capabilities, endpoints, commands, or workers",
          "inputs": "module path, type, capabilities, files array, optional endpoints/commands/workers",
          "outputs": "Module-level documentation object"
        },
        {
          "name": "EnhancedProductDocumentation",
          "desc": "Top-level product documentation with overview, user perspectives, architecture, and workflow integration",
          "inputs": "overview, capabilities, user perspectives (GUI/CLI/API/CI-CD), architecture, diagrams, metadata",
          "outputs": "Complete product documentation structure"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "This file exists to establish a hierarchical documentation structure that transforms raw code analysis into user-friendly documentation at three levels: individual files, functional modules, and complete product overview. It separates user-visible behavior from developer-facing implementation details, enabling stakeholders at different levels to understand the codebase from their perspective.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the structured data models and type definitions for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"User can view file-level summaries showing what each code file does\",\n    \"User can see module-level rollups grouping related files by functionality\",\n    \"User can browse product-level documentation with architecture diagrams\",\n    \"User can access API endpoints, CLI commands, and worker job flows\",\n    \"User can view dependency graphs showing how components relate\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file summaries with role, purpose, and key functions\",\n    \"Developer organizes files into modules (API, CLI, workers, core, GUI)\",\n    \"Developer documents user-facing actions separately from internal behavior\",\n    \"Developer creates structured metadata for endpoints, commands, and workers\",\n    \"Developer generates product documentation with overview and architecture\",\n    \"Developer tracks dependencies between files and components\",\n    \"Developer stores raw LLM responses alongside structured data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"FileSummary\",\n      \"desc\": \"Represents a single file's documentation including role, purpose, actions, and dependencies\",\n      \"inputs\": \"file path, role, purpose, actions, functions, dependencies, intent\",\n      \"outputs\": \"Structured file documentation object\"\n    },\n    {\n      \"name\": \"ModuleSummary\",\n      \"desc\": \"Aggregates multiple files into a module with capabilities, endpoints, commands, or workers\",\n      \"inputs\": \"module path, type, capabilities, files array, optional endpoints/commands/workers\",\n      \"outputs\": \"Module-level documentation object\"\n    },\n    {\n      \"name\": \"EnhancedProductDocumentation\",\n      \"desc\": \"Top-level product documentation with overview, user perspectives, architecture, and workflow integration\",\n      \"inputs\": \"overview, capabilities, user perspectives (GUI/CLI/API/CI-CD), architecture, diagrams, metadata\",\n      \"outputs\": \"Complete product documentation structure\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a hierarchical documentation structure that transforms raw code analysis into user-friendly documentation at three levels: individual files, functional modules, and complete product overview. It separates user-visible behavior from developer-facing implementation details, enabling stakeholders at different levels to understand the codebase from their perspective.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file changes in the workspace and triggers automatic code analysis when files are saved",
      "userVisibleActions": [
        "Automatically analyzes code when files are saved in the editor",
        "Shows analysis progress indicator during file analysis",
        "Updates diagnostics and insights view after file changes",
        "Respects user's 'analyze on save' configuration setting"
      ],
      "developerVisibleActions": [
        "Starts/stops file watching based on configuration settings",
        "Debounces analysis requests to prevent multiple simultaneous analyses",
        "Handles document save events and triggers analysis pipeline",
        "Manages analysis state to prevent concurrent analyses",
        "Cleans up resources when stopping the watcher"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins watching for file save events if analyze-on-save is enabled",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops watching for file changes and cleans up resources",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save events and triggers debounced analysis",
          "inputs": "document (TextDocument)",
          "outputs": "Promise<void>"
        },
        {
          "name": "shouldAnalyzeFile",
          "desc": "Determines if a file should be analyzed based on file type and configuration",
          "inputs": "document (TextDocument)",
          "outputs": "boolean"
        },
        {
          "name": "triggerAnalysis",
          "desc": "Executes the full analysis pipeline for a document",
          "inputs": "document (TextDocument)",
          "outputs": "Promise<void>"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all resources and event listeners",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "ConfigurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of having to manually trigger analysis by automatically detecting file changes and running the analysis pipeline, while preventing duplicate analyses through debouncing and state management.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and triggers automatic code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when files are saved in the editor\",\n    \"Shows analysis progress indicator during file analysis\",\n    \"Updates diagnostics and insights view after file changes\",\n    \"Respects user's 'analyze on save' configuration setting\"\n  ],\n  \"developerVisibleActions\": [\n    \"Starts/stops file watching based on configuration settings\",\n    \"Debounces analysis requests to prevent multiple simultaneous analyses\",\n    \"Handles document save events and triggers analysis pipeline\",\n    \"Manages analysis state to prevent concurrent analyses\",\n    \"Cleans up resources when stopping the watcher\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events if analyze-on-save is enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file changes and cleans up resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and triggers debounced analysis\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"shouldAnalyzeFile\",\n      \"desc\": \"Determines if a file should be analyzed based on file type and configuration\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline for a document\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all resources and event listeners\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of having to manually trigger analysis by automatically detecting file changes and running the analysis pipeline, while preventing duplicate analyses through debouncing and state management.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Optimizes file system operations by caching file contents to reduce redundant reads across multiple components.",
      "userVisibleActions": [
        "Files load faster when accessed multiple times within a short period",
        "Changes to files are automatically detected and reflected immediately",
        "Memory usage is kept under control through automatic cache cleanup"
      ],
      "developerVisibleActions": [
        "Retrieve file content through cache with automatic fallback to disk reads",
        "Cache automatically invalidates when files change on disk",
        "Access cache statistics to monitor performance (hits, misses, evictions)",
        "Configure cache size limits and time-to-live (TTL) settings",
        "Cache entries are automatically evicted using LRU policy when size limit is reached",
        "File changes are detected via file system watcher for automatic invalidation"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache or reads from disk if not cached or stale",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "isStale",
          "desc": "Determines if a cached file has exceeded its time-to-live threshold",
          "inputs": "cached: CachedFile",
          "outputs": "boolean - true if expired"
        },
        {
          "name": "getFileHash",
          "desc": "Computes hash of file to detect content changes",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file hash"
        },
        {
          "name": "evictIfNeeded",
          "desc": "Removes least recently used cache entries when size limit is exceeded",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "setupWatcher",
          "desc": "Configures file system watcher to automatically invalidate cache on file changes",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "invalidate",
          "desc": "Removes specific file from cache when it changes",
          "inputs": "filePath: string",
          "outputs": "void"
        },
        {
          "name": "clear",
          "desc": "Removes all entries from cache",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getStats",
          "desc": "Returns cache performance metrics",
          "inputs": "none",
          "outputs": "CacheStats - hits, misses, evictions, size"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "This file exists to improve extension performance by preventing redundant file system reads. It solves the problem of multiple components requesting the same file content repeatedly, which would slow down operations. The cache intelligently manages memory by evicting old entries and automatically detects file changes to ensure data stays fresh.",
      "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant reads across multiple components.\",\n  \"userVisibleActions\": [\n    \"Files load faster when accessed multiple times within a short period\",\n    \"Changes to files are automatically detected and reflected immediately\",\n    \"Memory usage is kept under control through automatic cache cleanup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file content through cache with automatic fallback to disk reads\",\n    \"Cache automatically invalidates when files change on disk\",\n    \"Access cache statistics to monitor performance (hits, misses, evictions)\",\n    \"Configure cache size limits and time-to-live (TTL) settings\",\n    \"Cache entries are automatically evicted using LRU policy when size limit is reached\",\n    \"File changes are detected via file system watcher for automatic invalidation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache or reads from disk if not cached or stale\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Determines if a cached file has exceeded its time-to-live threshold\",\n      \"inputs\": \"cached: CachedFile\",\n      \"outputs\": \"boolean - true if expired\"\n    },\n    {\n      \"name\": \"getFileHash\",\n      \"desc\": \"Computes hash of file to detect content changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file hash\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used cache entries when size limit is exceeded\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Configures file system watcher to automatically invalidate cache on file changes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes specific file from cache when it changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all entries from cache\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats - hits, misses, evictions, size\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by preventing redundant file system reads. It solves the problem of multiple components requesting the same file content repeatedly, which would slow down operations. The cache intelligently manages memory by evicting old entries and automatically detects file changes to ensure data stays fresh.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel across the codebase",
      "userVisibleActions": [
        "Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing",
        "Files are processed in parallel for faster completion",
        "Error handling ensures processing continues even if individual files fail"
      ],
      "developerVisibleActions": [
        "Developer creates a FileProcessor instance to handle bulk file operations",
        "Developer provides a list of file paths and a processing function",
        "Developer receives processed results for all files that passed filtering",
        "Developer can customize which files to process by providing a custom IFileFilter implementation",
        "Developer can customize how files are read by providing a custom IFileReader implementation",
        "Developer provides error context for better error tracking and debugging",
        "Developer uses DefaultFileFilter to automatically exclude common non-source directories",
        "Developer uses DefaultFileReader for standard UTF-8 file reading"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines if a file should be processed based on its path",
          "inputs": "filePath: string",
          "outputs": "boolean indicating if file should be processed"
        },
        {
          "name": "readFile",
          "desc": "Reads a file's content as UTF-8 text",
          "inputs": "filePath: string",
          "outputs": "Promise<string> containing file content"
        },
        {
          "name": "processFiles",
          "desc": "Filters, reads, and processes multiple files in parallel using a provided processing function",
          "inputs": "files: string[], processor: function, optional context: ErrorContext",
          "outputs": "Promise<T[]> containing array of processed results"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../utils/errorHandler"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, reusable implementation that handles filtering unwanted files, reading file contents, and processing multiple files in parallel with proper error handling",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel across the codebase\",\n  \"userVisibleActions\": [\n    \"Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing\",\n    \"Files are processed in parallel for faster completion\",\n    \"Error handling ensures processing continues even if individual files fail\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates a FileProcessor instance to handle bulk file operations\",\n    \"Developer provides a list of file paths and a processing function\",\n    \"Developer receives processed results for all files that passed filtering\",\n    \"Developer can customize which files to process by providing a custom IFileFilter implementation\",\n    \"Developer can customize how files are read by providing a custom IFileReader implementation\",\n    \"Developer provides error context for better error tracking and debugging\",\n    \"Developer uses DefaultFileFilter to automatically exclude common non-source directories\",\n    \"Developer uses DefaultFileReader for standard UTF-8 file reading\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file's content as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> containing file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Filters, reads, and processes multiple files in parallel using a provided processing function\",\n      \"inputs\": \"files: string[], processor: function, optional context: ErrorContext\",\n      \"outputs\": \"Promise<T[]> containing array of processed results\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, reusable implementation that handles filtering unwanted files, reading file contents, and processing multiple files in parallel with proper error handling\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages the storage and retrieval of analysis results including product documentation, architecture insights, and code summaries in a timestamped directory structure.",
      "userVisibleActions": [
        "Analysis results are saved to timestamped directories under .shadow/docs",
        "Product documentation files are created for analyzed code",
        "Architecture insights are stored in dedicated run directories",
        "Summary files are generated and saved after analysis",
        "Run metadata including timing and statistics is recorded",
        "Latest analysis results are accessible in a 'latest' directory link"
      ],
      "developerVisibleActions": [
        "Initialize product documentation runs with unique timestamped identifiers",
        "Initialize architecture insights runs with separate tracking",
        "Save individual product documentation entries with formatted content",
        "Store architecture insights with LLM-generated analysis",
        "Generate and save summary markdown files after analysis completion",
        "Track run progress with metadata files (timing, file counts, token usage)",
        "Access current run directories for active analysis sessions",
        "Reset run contexts when starting new analysis operations"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Starts a new product documentation analysis run",
          "inputs": "workspaceRoot: string",
          "outputs": "string (run directory path)"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Starts a new architecture insights analysis run",
          "inputs": "workspaceRoot: string",
          "outputs": "string (run directory path)"
        },
        {
          "name": "saveProductDocumentation",
          "desc": "Saves formatted product documentation for a specific file",
          "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
          "outputs": "Promise<string> (saved file path)"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Saves LLM-generated architecture insights to storage",
          "inputs": "insights: LLMInsights, workspaceRoot: string",
          "outputs": "Promise<string> (saved file path)"
        },
        {
          "name": "saveSummary",
          "desc": "Generates and saves a summary markdown file for the analysis run",
          "inputs": "summaryContent: string, workspaceRoot: string",
          "outputs": "Promise<string> (summary file path)"
        },
        {
          "name": "saveRunMetadata",
          "desc": "Saves metadata about the analysis run including timing and statistics",
          "inputs": "metadata: object, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "getCurrentProductDocsRunDir",
          "desc": "Gets the current product docs run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "getCurrentArchitectureInsightsRunDir",
          "desc": "Gets the current architecture insights run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "resetProductDocsRun",
          "desc": "Clears the current product docs run context",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "resetArchitectureInsightsRun",
          "desc": "Clears the current architecture insights run context",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "fileDocumentation (EnhancedProductDocumentation)",
        "llmService (LLMInsights)",
        "domain/formatters/documentationFormatter",
        "storage/incrementalStorage"
      ],
      "intent": "This file exists to separate persistence concerns from LLM integration logic, providing a dedicated repository layer for storing and organizing analysis results in a structured, timestamped manner that allows tracking multiple analysis runs and their outputs.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages the storage and retrieval of analysis results including product documentation, architecture insights, and code summaries in a timestamped directory structure.\",\n  \"userVisibleActions\": [\n    \"Analysis results are saved to timestamped directories under .shadow/docs\",\n    \"Product documentation files are created for analyzed code\",\n    \"Architecture insights are stored in dedicated run directories\",\n    \"Summary files are generated and saved after analysis\",\n    \"Run metadata including timing and statistics is recorded\",\n    \"Latest analysis results are accessible in a 'latest' directory link\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs with unique timestamped identifiers\",\n    \"Initialize architecture insights runs with separate tracking\",\n    \"Save individual product documentation entries with formatted content\",\n    \"Store architecture insights with LLM-generated analysis\",\n    \"Generate and save summary markdown files after analysis completion\",\n    \"Track run progress with metadata files (timing, file counts, token usage)\",\n    \"Access current run directories for active analysis sessions\",\n    \"Reset run contexts when starting new analysis operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Starts a new product documentation analysis run\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (run directory path)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Starts a new architecture insights analysis run\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (run directory path)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves formatted product documentation for a specific file\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (saved file path)\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves LLM-generated architecture insights to storage\",\n      \"inputs\": \"insights: LLMInsights, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (saved file path)\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Generates and saves a summary markdown file for the analysis run\",\n      \"inputs\": \"summaryContent: string, workspaceRoot: string\",\n      \"outputs\": \"Promise<string> (summary file path)\"\n    },\n    {\n      \"name\": \"saveRunMetadata\",\n      \"desc\": \"Saves metadata about the analysis run including timing and statistics\",\n      \"inputs\": \"metadata: object, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Gets the current product docs run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Gets the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product docs run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"This file exists to separate persistence concerns from LLM integration logic, providing a dedicated repository layer for storing and organizing analysis results in a structured, timestamped manner that allows tracking multiple analysis runs and their outputs.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations in VS Code",
      "userVisibleActions": [
        "Progress notification appears with a title and status message during operations",
        "Progress message updates as operation progresses through different stages",
        "Cancel button appears in notification (when cancellable) allowing user to stop the operation",
        "Progress indicator shows in notification area or other specified location"
      ],
      "developerVisibleActions": [
        "Developer calls withProgress() to wrap any async operation with progress reporting",
        "Developer provides a title for the progress notification",
        "Developer receives a reporter object to update progress messages during execution",
        "Developer can specify if operation is cancellable and where progress should display",
        "Developer can check cancellation token to stop operation if user cancels",
        "Developer can pass simple string title or full options object for flexibility"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying progress notification to user",
          "inputs": "options (title, cancellable flag, display location), task function that receives progress reporter",
          "outputs": "Returns the result of the executed task"
        },
        {
          "name": "report",
          "desc": "Updates the progress message shown to user",
          "inputs": "message string, optional increment number",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "Reduces boilerplate code and ensures consistent progress reporting UX across the extension by wrapping VS Code's native progress API with a simpler, standardized interface",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations in VS Code\",\n  \"userVisibleActions\": [\n    \"Progress notification appears with a title and status message during operations\",\n    \"Progress message updates as operation progresses through different stages\",\n    \"Cancel button appears in notification (when cancellable) allowing user to stop the operation\",\n    \"Progress indicator shows in notification area or other specified location\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls withProgress() to wrap any async operation with progress reporting\",\n    \"Developer provides a title for the progress notification\",\n    \"Developer receives a reporter object to update progress messages during execution\",\n    \"Developer can specify if operation is cancellable and where progress should display\",\n    \"Developer can check cancellation token to stop operation if user cancels\",\n    \"Developer can pass simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying progress notification to user\",\n      \"inputs\": \"options (title, cancellable flag, display location), task function that receives progress reporter\",\n      \"outputs\": \"Returns the result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress message shown to user\",\n      \"inputs\": \"message string, optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Reduces boilerplate code and ensures consistent progress reporting UX across the extension by wrapping VS Code's native progress API with a simpler, standardized interface\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Generates code quality insights and recommendations by analyzing code files for issues like large files, orphaned code, circular dependencies, and complexity problems.",
      "userVisibleActions": [
        "Displays warnings when files exceed 500 lines of code",
        "Shows alerts for orphaned files that aren't imported anywhere",
        "Highlights missing entry points in the project",
        "Reports potential circular dependency issues",
        "Identifies 'god objects' (files with too many exports or responsibilities)",
        "Flags potential dead code that may not be used",
        "Provides file organization recommendations",
        "Reports overly complex functions that need refactoring",
        "Shows code snippets with specific issues",
        "Displays severity levels (error, warning, info) for each insight",
        "Provides actionable suggestions for fixing each issue"
      ],
      "developerVisibleActions": [
        "Call generateInsights() with code analysis to get all insights for a project",
        "Call generateInsightsForFile() to get insights for a specific file path",
        "Receive structured Insight objects containing id, title, description, severity, category, file location, line number, suggestion, and optional code snippet",
        "Use insights to improve code quality through automated analysis",
        "Filter insights by severity (error, warning, info) or category",
        "Integrate insight generation into code review or CI/CD workflows"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Analyzes entire codebase and returns all quality insights",
          "inputs": "CodeAnalysis object containing file and function information",
          "outputs": "Array of Insight objects with detected issues and recommendations"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Analyzes a specific file and returns insights only for that file",
          "inputs": "CodeAnalysis object and file path string",
          "outputs": "Array of Insight objects specific to the requested file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Detects files exceeding recommended line count",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for large files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Finds files that aren't imported or used anywhere",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for orphaned files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Verifies project has proper entry points",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Detects potential circular import dependencies",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for circular dependencies"
        },
        {
          "name": "checkGodObjects",
          "desc": "Identifies files with too many responsibilities or exports",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for god objects"
        },
        {
          "name": "checkDeadCode",
          "desc": "Finds code that may not be actively used",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for potential dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Evaluates project structure and organization",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for organization issues"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Analyzes function complexity and size",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for overly complex functions"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to provide automated code quality analysis and actionable recommendations to developers. It solves the problem of manually identifying code smells, architectural issues, and maintainability concerns by automatically scanning code and generating structured insights with severity levels, categories, and improvement suggestions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates code quality insights and recommendations by analyzing code files for issues like large files, orphaned code, circular dependencies, and complexity problems.\",\n  \"userVisibleActions\": [\n    \"Displays warnings when files exceed 500 lines of code\",\n    \"Shows alerts for orphaned files that aren't imported anywhere\",\n    \"Highlights missing entry points in the project\",\n    \"Reports potential circular dependency issues\",\n    \"Identifies 'god objects' (files with too many exports or responsibilities)\",\n    \"Flags potential dead code that may not be used\",\n    \"Provides file organization recommendations\",\n    \"Reports overly complex functions that need refactoring\",\n    \"Shows code snippets with specific issues\",\n    \"Displays severity levels (error, warning, info) for each insight\",\n    \"Provides actionable suggestions for fixing each issue\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateInsights() with code analysis to get all insights for a project\",\n    \"Call generateInsightsForFile() to get insights for a specific file path\",\n    \"Receive structured Insight objects containing id, title, description, severity, category, file location, line number, suggestion, and optional code snippet\",\n    \"Use insights to improve code quality through automated analysis\",\n    \"Filter insights by severity (error, warning, info) or category\",\n    \"Integrate insight generation into code review or CI/CD workflows\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all quality insights\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with detected issues and recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights only for that file\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Detects files exceeding recommended line count\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for large files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that aren't imported or used anywhere\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for orphaned files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies project has proper entry points\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular import dependencies\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with too many responsibilities or exports\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds code that may not be actively used\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potential dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and organization\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organization issues\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity and size\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for overly complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to provide automated code quality analysis and actionable recommendations to developers. It solves the problem of manually identifying code smells, architectural issues, and maintainability concerns by automatically scanning code and generating structured insights with severity levels, categories, and improvement suggestions.\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in the VS Code sidebar that displays code insights, documentation status, analysis results, and generated reports with interactive actions.",
      "userVisibleActions": [
        "View a tree of code analysis insights organized by severity (critical, high, medium, low)",
        "See status indicators for product documentation generation (idle, generating, complete)",
        "See status indicators for insights generation and unit test generation",
        "Click on insights to navigate to the relevant code location",
        "Refresh the insights tree to update displayed information",
        "Generate product documentation from the tree view",
        "Generate architecture documentation from the tree view",
        "Generate unit tests from the tree view",
        "Open generated report files (workspace, product, architecture, unit test, static analysis)",
        "View timestamp information showing when reports were generated",
        "Copy insight text to clipboard",
        "Expand/collapse insight categories and details",
        "See a 'No insights available' message when no analysis has been performed",
        "View detailed insight information including file path, line number, and recommendations"
      ],
      "developerVisibleActions": [
        "Tree view updates automatically when insights are generated or refreshed",
        "Status changes are reflected in real-time (generating, complete, idle)",
        "Reports are saved to workspace storage and persist across sessions",
        "Tree items show contextual actions based on their type (generate, open, refresh)",
        "LLM-generated insights are displayed alongside traditional code insights",
        "Timestamps are persisted and restored when VS Code restarts",
        "Tree structure adapts based on available data (insights, reports, documentation)",
        "Context values enable conditional command visibility in the tree"
      ],
      "keyFunctions": [
        {
          "name": "setInsights",
          "desc": "Updates the tree view with new code insights",
          "inputs": "Array of Insight objects",
          "outputs": "Triggers tree refresh"
        },
        {
          "name": "setLLMInsights",
          "desc": "Updates the tree view with LLM-generated insights and documentation status",
          "inputs": "LLMInsights object containing status and generated content",
          "outputs": "Triggers tree refresh and saves timestamps"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts a tree item into a VS Code tree item for display",
          "inputs": "TreeItem object",
          "outputs": "vscode.TreeItem with display properties"
        },
        {
          "name": "getChildren",
          "desc": "Provides the hierarchical structure of tree items",
          "inputs": "Optional parent TreeItem",
          "outputs": "Array of child TreeItem objects"
        },
        {
          "name": "setReportPath",
          "desc": "Saves the path to a generated report file",
          "inputs": "Report file path and type (workspace, product, architecture, unit test)",
          "outputs": "Updates tree display with report availability"
        },
        {
          "name": "refresh",
          "desc": "Forces the tree view to reload and display updated data",
          "inputs": "Optional TreeItem to refresh specific branch",
          "outputs": "Tree view refresh event"
        },
        {
          "name": "setStaticAnalysisViewer",
          "desc": "Associates the static analysis viewer with the tree view",
          "inputs": "Static analysis viewer instance",
          "outputs": "Enables static analysis report display"
        },
        {
          "name": "loadPersistedState",
          "desc": "Restores saved report paths and timestamps from previous sessions",
          "inputs": "Reads from extension context storage",
          "outputs": "Restores tree state with persisted data"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator",
        "./llmFormatter",
        "./llmService"
      ],
      "intent": "This file exists to provide a visual, interactive sidebar panel in VS Code where users can view code analysis results, track documentation generation progress, access generated reports, and trigger various code analysis and documentation actions without leaving the editor.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in the VS Code sidebar that displays code insights, documentation status, analysis results, and generated reports with interactive actions.\",\n  \"userVisibleActions\": [\n    \"View a tree of code analysis insights organized by severity (critical, high, medium, low)\",\n    \"See status indicators for product documentation generation (idle, generating, complete)\",\n    \"See status indicators for insights generation and unit test generation\",\n    \"Click on insights to navigate to the relevant code location\",\n    \"Refresh the insights tree to update displayed information\",\n    \"Generate product documentation from the tree view\",\n    \"Generate architecture documentation from the tree view\",\n    \"Generate unit tests from the tree view\",\n    \"Open generated report files (workspace, product, architecture, unit test, static analysis)\",\n    \"View timestamp information showing when reports were generated\",\n    \"Copy insight text to clipboard\",\n    \"Expand/collapse insight categories and details\",\n    \"See a 'No insights available' message when no analysis has been performed\",\n    \"View detailed insight information including file path, line number, and recommendations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when insights are generated or refreshed\",\n    \"Status changes are reflected in real-time (generating, complete, idle)\",\n    \"Reports are saved to workspace storage and persist across sessions\",\n    \"Tree items show contextual actions based on their type (generate, open, refresh)\",\n    \"LLM-generated insights are displayed alongside traditional code insights\",\n    \"Timestamps are persisted and restored when VS Code restarts\",\n    \"Tree structure adapts based on available data (insights, reports, documentation)\",\n    \"Context values enable conditional command visibility in the tree\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the tree view with new code insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"Triggers tree refresh\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the tree view with LLM-generated insights and documentation status\",\n      \"inputs\": \"LLMInsights object containing status and generated content\",\n      \"outputs\": \"Triggers tree refresh and saves timestamps\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts a tree item into a VS Code tree item for display\",\n      \"inputs\": \"TreeItem object\",\n      \"outputs\": \"vscode.TreeItem with display properties\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Provides the hierarchical structure of tree items\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of child TreeItem objects\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Saves the path to a generated report file\",\n      \"inputs\": \"Report file path and type (workspace, product, architecture, unit test)\",\n      \"outputs\": \"Updates tree display with report availability\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces the tree view to reload and display updated data\",\n      \"inputs\": \"Optional TreeItem to refresh specific branch\",\n      \"outputs\": \"Tree view refresh event\"\n    },\n    {\n      \"name\": \"setStaticAnalysisViewer\",\n      \"desc\": \"Associates the static analysis viewer with the tree view\",\n      \"inputs\": \"Static analysis viewer instance\",\n      \"outputs\": \"Enables static analysis report display\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved report paths and timestamps from previous sessions\",\n      \"inputs\": \"Reads from extension context storage\",\n      \"outputs\": \"Restores tree state with persisted data\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive sidebar panel in VS Code where users can view code analysis results, track documentation generation progress, access generated reports, and trigger various code analysis and documentation actions without leaving the editor.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, including purpose, relationships, and file organization.",
      "userVisibleActions": [
        "View architecture insights in a tree view panel showing project purpose, file relationships, and directory structure",
        "Click on files in the insights tree to open them in the editor",
        "See color-coded file roles (Model, View, Controller, Service, etc.) with icons",
        "Browse files grouped by their architectural purpose",
        "Refresh the insights view to reload analysis results",
        "See file summaries and purposes when hovering or selecting items",
        "View metadata like LOC (lines of code) and programming language for each file",
        "Access insights even when files are missing from the workspace",
        "See real-time updates when insights.json or project-purpose.md files change"
      ],
      "developerVisibleActions": [
        "Tree view automatically refreshes when .shadow/docs/insights.json is modified",
        "Tree view updates when .shadow/project-purpose.md changes",
        "Files are organized by their architectural role (GUI, Model, Service, Controller, etc.)",
        "Clicking a file item navigates to that file in the editor",
        "Insights data is loaded from the .shadow/docs directory",
        "File watcher service monitors changes to insights and purpose files",
        "Tree provider implements VS Code TreeDataProvider interface for rendering",
        "Handles missing files gracefully by showing them in the tree with appropriate styling"
      ],
      "keyFunctions": [
        {
          "name": "refresh",
          "desc": "Reloads insights data from the file system and updates the tree view",
          "inputs": "insightsData (optional LLMInsights object)",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts an InsightItem into a VS Code TreeItem for display in the tree view",
          "inputs": "element (InsightItem)",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node (categories, files, or metadata)",
          "inputs": "element (optional InsightItem)",
          "outputs": "Promise<InsightItem[]>"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Creates file system watchers to monitor changes to insights.json and project-purpose.md",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getRoleIcon",
          "desc": "Returns the appropriate icon name for a file based on its architectural role",
          "inputs": "role (string)",
          "outputs": "string (icon name)"
        },
        {
          "name": "getRoleColor",
          "desc": "Returns a color code for displaying files based on their role category",
          "inputs": "role (string)",
          "outputs": "string (color code)"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file watchers and other resources when the provider is destroyed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs",
        "./llmService (LLMInsights type)",
        "./domain/services/fileWatcherService"
      ],
      "intent": "This file exists to visualize AI-generated architecture insights in VS Code's sidebar, helping developers understand their codebase structure by showing how files relate to each other, what roles they play, and what purpose they serve. It solves the problem of navigating and understanding large codebases by providing an architectural overview that auto-updates as the analysis changes.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, including purpose, relationships, and file organization.\",\n  \"userVisibleActions\": [\n    \"View architecture insights in a tree view panel showing project purpose, file relationships, and directory structure\",\n    \"Click on files in the insights tree to open them in the editor\",\n    \"See color-coded file roles (Model, View, Controller, Service, etc.) with icons\",\n    \"Browse files grouped by their architectural purpose\",\n    \"Refresh the insights view to reload analysis results\",\n    \"See file summaries and purposes when hovering or selecting items\",\n    \"View metadata like LOC (lines of code) and programming language for each file\",\n    \"Access insights even when files are missing from the workspace\",\n    \"See real-time updates when insights.json or project-purpose.md files change\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when .shadow/docs/insights.json is modified\",\n    \"Tree view updates when .shadow/project-purpose.md changes\",\n    \"Files are organized by their architectural role (GUI, Model, Service, Controller, etc.)\",\n    \"Clicking a file item navigates to that file in the editor\",\n    \"Insights data is loaded from the .shadow/docs directory\",\n    \"File watcher service monitors changes to insights and purpose files\",\n    \"Tree provider implements VS Code TreeDataProvider interface for rendering\",\n    \"Handles missing files gracefully by showing them in the tree with appropriate styling\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights data from the file system and updates the tree view\",\n      \"inputs\": \"insightsData (optional LLMInsights object)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem for display in the tree view\",\n      \"inputs\": \"element (InsightItem)\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node (categories, files, or metadata)\",\n      \"inputs\": \"element (optional InsightItem)\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers to monitor changes to insights.json and project-purpose.md\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getRoleIcon\",\n      \"desc\": \"Returns the appropriate icon name for a file based on its architectural role\",\n      \"inputs\": \"role (string)\",\n      \"outputs\": \"string (icon name)\"\n    },\n    {\n      \"name\": \"getRoleColor\",\n      \"desc\": \"Returns a color code for displaying files based on their role category\",\n      \"inputs\": \"role (string)\",\n      \"outputs\": \"string (color code)\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and other resources when the provider is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"./llmService (LLMInsights type)\",\n    \"./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to visualize AI-generated architecture insights in VS Code's sidebar, helping developers understand their codebase structure by showing how files relate to each other, what roles they play, and what purpose they serve. It solves the problem of navigating and understanding large codebases by providing an architectural overview that auto-updates as the analysis changes.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different output styles optimized for various LLM tools and display contexts.",
      "userVisibleActions": [
        "View architecture issues organized by severity (Critical, Warnings, Informational)",
        "See formatted output optimized for Cursor AI assistant",
        "See formatted output optimized for ChatGPT",
        "View compact format for quick scanning of issues",
        "Read generic formatted output compatible with any LLM",
        "See emoji indicators (, , ) for issue severity levels",
        "View actionable guidance on what help is needed from the LLM"
      ],
      "developerVisibleActions": [
        "Choose output format (cursor, chatgpt, compact, generic) when formatting insights",
        "Pass array of Insight objects to be formatted",
        "Receive formatted markdown string ready for display or LLM consumption",
        "Get insights automatically grouped by severity level",
        "Get structured output with clear sections for issue categories",
        "Get prompts embedded in output to guide LLM responses"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Routes insights to appropriate formatter based on specified format type",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "Formatted string in requested style"
        },
        {
          "name": "formatForCursor",
          "desc": "Creates Cursor AI-optimized output with severity grouping and action requests",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string with sections for errors, warnings, info, and guidance prompts"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Creates ChatGPT-optimized output formatted as a conversation starter",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string formatted as a help request to ChatGPT"
        },
        {
          "name": "formatCompact",
          "desc": "Creates condensed output showing only essential information",
          "inputs": "insights: Insight[]",
          "outputs": "Compact markdown string with minimal formatting"
        },
        {
          "name": "formatGeneric",
          "desc": "Creates standard output compatible with any LLM or display context",
          "inputs": "insights: Insight[]",
          "outputs": "Generic markdown string with basic structure"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats individual insight with file location, issue details, and suggestions",
          "inputs": "insight: Insight",
          "outputs": "Formatted markdown section for single insight"
        }
      ],
      "dependencies": [
        "./insightGenerator"
      ],
      "intent": "Transforms technical code analysis insights into human-readable, LLM-friendly formats that prompt effective assistance from AI coding tools. Solves the problem of presenting architecture issues in a way that maximizes helpful responses from different AI assistants by tailoring the output format and embedded prompts to each tool's strengths.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output styles optimized for various LLM tools and display contexts.\",\n  \"userVisibleActions\": [\n    \"View architecture issues organized by severity (Critical, Warnings, Informational)\",\n    \"See formatted output optimized for Cursor AI assistant\",\n    \"See formatted output optimized for ChatGPT\",\n    \"View compact format for quick scanning of issues\",\n    \"Read generic formatted output compatible with any LLM\",\n    \"See emoji indicators (, , ) for issue severity levels\",\n    \"View actionable guidance on what help is needed from the LLM\"\n  ],\n  \"developerVisibleActions\": [\n    \"Choose output format (cursor, chatgpt, compact, generic) when formatting insights\",\n    \"Pass array of Insight objects to be formatted\",\n    \"Receive formatted markdown string ready for display or LLM consumption\",\n    \"Get insights automatically grouped by severity level\",\n    \"Get structured output with clear sections for issue categories\",\n    \"Get prompts embedded in output to guide LLM responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Routes insights to appropriate formatter based on specified format type\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string in requested style\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized output with severity grouping and action requests\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with sections for errors, warnings, info, and guidance prompts\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT-optimized output formatted as a conversation starter\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string formatted as a help request to ChatGPT\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates condensed output showing only essential information\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with minimal formatting\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard output compatible with any LLM or display context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown string with basic structure\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file location, issue details, and suggestions\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown section for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Transforms technical code analysis insights into human-readable, LLM-friendly formats that prompt effective assistance from AI coding tools. Solves the problem of presenting architecture issues in a way that maximizes helpful responses from different AI assistants by tailoring the output format and embedded prompts to each tool's strengths.\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Manages LLM-powered code analysis features, including initializing services, generating documentation, analyzing code, and handling user interactions with AI-generated insights.",
      "userVisibleActions": [
        "Generate documentation for code files and products",
        "View AI-generated insights about code structure and behavior",
        "Navigate through analyzed code via tree views",
        "See analysis progress and status messages in output channel",
        "Access generated documentation in webview panels",
        "View code analysis results including entry points and components",
        "Receive notifications when analysis completes or fails",
        "See API configuration status and warnings"
      ],
      "developerVisibleActions": [
        "Initialize LLM service on extension startup",
        "Trigger code analysis for workspace files",
        "Generate product documentation from analysis results",
        "Request AI insights for specific code contexts",
        "Refresh tree views when analysis data changes",
        "Save and load analysis results from cache",
        "Handle API key configuration and validation",
        "Manage analysis state across sessions",
        "Convert code analysis to LLM context format",
        "Display documentation in formatted webview",
        "Register commands for documentation and analysis actions",
        "Handle errors and display user-friendly messages",
        "Coordinate between analysis services and UI providers"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Sets up LLM service and loads saved analysis data on startup",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "generateDocumentation",
          "desc": "Creates AI-generated documentation for code files or entire products",
          "inputs": "file paths, analysis context",
          "outputs": "EnhancedProductDocumentation"
        },
        {
          "name": "analyzeCode",
          "desc": "Performs deep code analysis using LLM to extract structure and behavior",
          "inputs": "workspace paths, file list",
          "outputs": "CodeAnalysis with entry points and insights"
        },
        {
          "name": "requestInsights",
          "desc": "Gets AI-generated insights about code patterns and architecture",
          "inputs": "AnalysisContext",
          "outputs": "LLMInsights"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists analysis results to cache for future sessions",
          "inputs": "CodeAnalysis object",
          "outputs": "void"
        },
        {
          "name": "loadSavedCodeAnalysis",
          "desc": "Retrieves previously saved analysis from cache",
          "inputs": "workspace identifier",
          "outputs": "CodeAnalysis or null"
        },
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms code analysis into format suitable for LLM processing",
          "inputs": "CodeAnalysis",
          "outputs": "AnalysisContext"
        },
        {
          "name": "showDocumentation",
          "desc": "Displays generated documentation in webview panel",
          "inputs": "documentation object",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "llmService",
        "insightsTreeView",
        "fileDocumentation",
        "analyzer",
        "productNavigator",
        "analysisViewer",
        "insightsViewer",
        "unitTestsNavigator",
        "logger",
        "llmStateManager",
        "analysisContextBuilder",
        "documentationFormatter",
        "analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between VS Code extension UI and LLM analysis capabilities, coordinating all AI-powered features like documentation generation, code insights, and intelligent navigation. It solves the problem of managing complex interactions between user actions, background analysis, state persistence, and AI service calls in a unified way.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages LLM-powered code analysis features, including initializing services, generating documentation, analyzing code, and handling user interactions with AI-generated insights.\",\n  \"userVisibleActions\": [\n    \"Generate documentation for code files and products\",\n    \"View AI-generated insights about code structure and behavior\",\n    \"Navigate through analyzed code via tree views\",\n    \"See analysis progress and status messages in output channel\",\n    \"Access generated documentation in webview panels\",\n    \"View code analysis results including entry points and components\",\n    \"Receive notifications when analysis completes or fails\",\n    \"See API configuration status and warnings\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service on extension startup\",\n    \"Trigger code analysis for workspace files\",\n    \"Generate product documentation from analysis results\",\n    \"Request AI insights for specific code contexts\",\n    \"Refresh tree views when analysis data changes\",\n    \"Save and load analysis results from cache\",\n    \"Handle API key configuration and validation\",\n    \"Manage analysis state across sessions\",\n    \"Convert code analysis to LLM context format\",\n    \"Display documentation in formatted webview\",\n    \"Register commands for documentation and analysis actions\",\n    \"Handle errors and display user-friendly messages\",\n    \"Coordinate between analysis services and UI providers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up LLM service and loads saved analysis data on startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates AI-generated documentation for code files or entire products\",\n      \"inputs\": \"file paths, analysis context\",\n      \"outputs\": \"EnhancedProductDocumentation\"\n    },\n    {\n      \"name\": \"analyzeCode\",\n      \"desc\": \"Performs deep code analysis using LLM to extract structure and behavior\",\n      \"inputs\": \"workspace paths, file list\",\n      \"outputs\": \"CodeAnalysis with entry points and insights\"\n    },\n    {\n      \"name\": \"requestInsights\",\n      \"desc\": \"Gets AI-generated insights about code patterns and architecture\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"LLMInsights\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to cache for future sessions\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis from cache\",\n      \"inputs\": \"workspace identifier\",\n      \"outputs\": \"CodeAnalysis or null\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis into format suitable for LLM processing\",\n      \"inputs\": \"CodeAnalysis\",\n      \"outputs\": \"AnalysisContext\"\n    },\n    {\n      \"name\": \"showDocumentation\",\n      \"desc\": \"Displays generated documentation in webview panel\",\n      \"inputs\": \"documentation object\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"llmStateManager\",\n    \"analysisContextBuilder\",\n    \"documentationFormatter\",\n    \"analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between VS Code extension UI and LLM analysis capabilities, coordinating all AI-powered features like documentation generation, code insights, and intelligent navigation. It solves the problem of managing complex interactions between user actions, background analysis, state persistence, and AI service calls in a unified way.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure and validate LLM responses to ensure consistent, parseable output formats for code analysis tasks.",
      "userVisibleActions": [
        "Receives structured analysis of product purpose and architecture rationale",
        "Gets organized lists of design decisions and user goals from code analysis",
        "Views categorized code issues with titles, descriptions, and relevant files",
        "Sees risk assessments with severity levels and impact descriptions",
        "Receives actionable recommendations with priorities and effort estimates",
        "Gets structured summaries of codebase analysis results"
      ],
      "developerVisibleActions": [
        "Provides JSON schemas to LLM API calls to guarantee response structure",
        "Ensures LLM responses conform to expected formats without manual parsing",
        "Defines validation rules for product purpose analysis output",
        "Specifies required fields and data types for issue detection",
        "Enforces consistent format for risk assessments and recommendations",
        "Validates that all LLM responses include mandatory properties"
      ],
      "keyFunctions": [
        {
          "name": "productPurposeAnalysisSchema",
          "desc": "Schema for analyzing product purpose, architecture rationale, and design decisions",
          "inputs": "None (exported constant schema object)",
          "outputs": "JSON schema with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
        },
        {
          "name": "issueItemSchema",
          "desc": "Schema for individual code issues with title, description, and relevant files/functions",
          "inputs": "None (nested schema definition)",
          "outputs": "JSON schema with title, description, relevantFiles, relevantFunctions properties"
        }
      ],
      "dependencies": [],
      "intent": "Ensures Claude AI responses for code analysis are consistently structured and machine-parseable, eliminating the need for fragile text parsing and guaranteeing that all required information fields are present in every response.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate LLM responses to ensure consistent, parseable output formats for code analysis tasks.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and architecture rationale\",\n    \"Gets organized lists of design decisions and user goals from code analysis\",\n    \"Views categorized code issues with titles, descriptions, and relevant files\",\n    \"Sees risk assessments with severity levels and impact descriptions\",\n    \"Receives actionable recommendations with priorities and effort estimates\",\n    \"Gets structured summaries of codebase analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides JSON schemas to LLM API calls to guarantee response structure\",\n    \"Ensures LLM responses conform to expected formats without manual parsing\",\n    \"Defines validation rules for product purpose analysis output\",\n    \"Specifies required fields and data types for issue detection\",\n    \"Enforces consistent format for risk assessments and recommendations\",\n    \"Validates that all LLM responses include mandatory properties\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose, architecture rationale, and design decisions\",\n      \"inputs\": \"None (exported constant schema object)\",\n      \"outputs\": \"JSON schema with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema for individual code issues with title, description, and relevant files/functions\",\n      \"inputs\": \"None (nested schema definition)\",\n      \"outputs\": \"JSON schema with title, description, relevantFiles, relevantFunctions properties\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Ensures Claude AI responses for code analysis are consistently structured and machine-parseable, eliminating the need for fragile text parsing and guaranteeing that all required information fields are present in every response.\"\n}\n```"
    },
    {
      "file": "src/llmService.ts",
      "role": "Core Logic",
      "purpose": "Provides LLM-powered AI analysis services to generate intelligent insights, documentation, and code analysis by interfacing with OpenAI/Claude APIs.",
      "userVisibleActions": [
        "Generate intelligent insights about codebase purpose and architecture",
        "Create comprehensive product documentation from code analysis",
        "Analyze code quality and provide improvement suggestions",
        "Generate unit test plans for functions",
        "Get AI-powered refactoring suggestions for complex functions",
        "Receive explanations of what the product does and why it was built",
        "View AI-generated module summaries and relationships",
        "See incremental analysis results as codebase changes",
        "Get file-level and function-level documentation generated by AI"
      ],
      "developerVisibleActions": [
        "Call LLM service to analyze codebase structure and purpose",
        "Request AI-generated documentation for entire product",
        "Trigger AI analysis of code quality and architecture",
        "Generate test plans using AI understanding of functions",
        "Request refactoring suggestions for complex code",
        "Use incremental analysis to only analyze changed files",
        "Configure LLM provider (OpenAI, Claude, or local models)",
        "Set custom system prompts for AI analysis",
        "Control token budgets and rate limiting for API calls",
        "Handle retries and errors from LLM API responses",
        "Parse structured AI responses into usable data structures",
        "Access file summaries and module groupings from AI analysis"
      ],
      "keyFunctions": [
        {
          "name": "analyzePurpose",
          "desc": "Analyzes the codebase to determine product purpose, architecture rationale, and key features using AI",
          "inputs": "AnalysisContext with file structure, imports, and entry points",
          "outputs": "ProductPurposeAnalysis with product purpose, architecture, and design patterns"
        },
        {
          "name": "generateEnhancedDocumentation",
          "desc": "Generates comprehensive product documentation including purpose, features, architecture, and user scenarios using AI",
          "inputs": "CodeAnalysis and AnalysisContext",
          "outputs": "EnhancedProductDocumentation with full product overview and technical details"
        },
        {
          "name": "generateLLMInsights",
          "desc": "Generates intelligent insights about code quality, patterns, and improvement suggestions using AI",
          "inputs": "CodeAnalysis with code metrics and structure",
          "outputs": "LLM insights with code quality assessment and recommendations"
        },
        {
          "name": "generateUnitTestPlan",
          "desc": "Creates a comprehensive unit test plan for a specific function using AI analysis",
          "inputs": "Function metadata, file content, and function name",
          "outputs": "Unit test plan with test cases, setup, assertions, and edge cases"
        },
        {
          "name": "generateRefactoringSuggestions",
          "desc": "Provides AI-powered refactoring suggestions for complex or problematic functions",
          "inputs": "Function code, metrics (complexity, length, nesting), and surrounding context",
          "outputs": "Refactoring suggestions with specific improvements and code examples"
        },
        {
          "name": "analyzeIncrementally",
          "desc": "Performs incremental AI analysis only on files that have changed since last analysis",
          "inputs": "Changed file URIs and analysis context",
          "outputs": "Updated insights and documentation for changed files only"
        },
        {
          "name": "callLLM",
          "desc": "Makes API calls to configured LLM provider with rate limiting, retries, and error handling",
          "inputs": "System prompt, user prompt, optional schema for structured output",
          "outputs": "Parsed LLM response with requested analysis or documentation"
        },
        {
          "name": "generateFileSummary",
          "desc": "Creates AI-generated summary of a single file's purpose, functionality, and role",
          "inputs": "File path, content, and role in codebase",
          "outputs": "FileSummary with description, key functions, and relationships"
        },
        {
          "name": "generateModuleSummary",
          "desc": "Creates AI-generated summary of a module's purpose and file organization",
          "inputs": "Module name, list of files, and module type",
          "outputs": "ModuleSummary with module purpose and file descriptions"
        }
      ],
      "dependencies": [
        "vscode",
        "./fileDocumentation",
        "./analyzer",
        "./analysis/enhancedAnalyzer",
        "./llmSchemas",
        "./fileAccessHelper",
        "./logger",
        "./config/configurationManager",
        "./ai/providers/providerFactory",
        "./ai/llmResponseParser",
        "./ai/llmRateLimiter",
        "./ai/llmRetryHandler",
        "./domain/prompts/promptBuilder",
        "./domain/services/incrementalAnalysisService",
        "./domain/prompts/refactoringPromptBuilder",
        "./analysis/functionAnalyzer"
      ],
      "intent": "This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by using LLMs to generate human-readable documentation, identify architectural patterns, suggest improvements, and create test plans. It abstracts away the complexity of calling different LLM providers (OpenAI, Claude, local models) and handles rate limiting, retries, and response parsing so developers can get AI insights without managing API details.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides LLM-powered AI analysis services to generate intelligent insights, documentation, and code analysis by interfacing with OpenAI/Claude APIs.\",\n  \"userVisibleActions\": [\n    \"Generate intelligent insights about codebase purpose and architecture\",\n    \"Create comprehensive product documentation from code analysis\",\n    \"Analyze code quality and provide improvement suggestions\",\n    \"Generate unit test plans for functions\",\n    \"Get AI-powered refactoring suggestions for complex functions\",\n    \"Receive explanations of what the product does and why it was built\",\n    \"View AI-generated module summaries and relationships\",\n    \"See incremental analysis results as codebase changes\",\n    \"Get file-level and function-level documentation generated by AI\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call LLM service to analyze codebase structure and purpose\",\n    \"Request AI-generated documentation for entire product\",\n    \"Trigger AI analysis of code quality and architecture\",\n    \"Generate test plans using AI understanding of functions\",\n    \"Request refactoring suggestions for complex code\",\n    \"Use incremental analysis to only analyze changed files\",\n    \"Configure LLM provider (OpenAI, Claude, or local models)\",\n    \"Set custom system prompts for AI analysis\",\n    \"Control token budgets and rate limiting for API calls\",\n    \"Handle retries and errors from LLM API responses\",\n    \"Parse structured AI responses into usable data structures\",\n    \"Access file summaries and module groupings from AI analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzePurpose\",\n      \"desc\": \"Analyzes the codebase to determine product purpose, architecture rationale, and key features using AI\",\n      \"inputs\": \"AnalysisContext with file structure, imports, and entry points\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture, and design patterns\"\n    },\n    {\n      \"name\": \"generateEnhancedDocumentation\",\n      \"desc\": \"Generates comprehensive product documentation including purpose, features, architecture, and user scenarios using AI\",\n      \"inputs\": \"CodeAnalysis and AnalysisContext\",\n      \"outputs\": \"EnhancedProductDocumentation with full product overview and technical details\"\n    },\n    {\n      \"name\": \"generateLLMInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and improvement suggestions using AI\",\n      \"inputs\": \"CodeAnalysis with code metrics and structure\",\n      \"outputs\": \"LLM insights with code quality assessment and recommendations\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a comprehensive unit test plan for a specific function using AI analysis\",\n      \"inputs\": \"Function metadata, file content, and function name\",\n      \"outputs\": \"Unit test plan with test cases, setup, assertions, and edge cases\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Provides AI-powered refactoring suggestions for complex or problematic functions\",\n      \"inputs\": \"Function code, metrics (complexity, length, nesting), and surrounding context\",\n      \"outputs\": \"Refactoring suggestions with specific improvements and code examples\"\n    },\n    {\n      \"name\": \"analyzeIncrementally\",\n      \"desc\": \"Performs incremental AI analysis only on files that have changed since last analysis\",\n      \"inputs\": \"Changed file URIs and analysis context\",\n      \"outputs\": \"Updated insights and documentation for changed files only\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Makes API calls to configured LLM provider with rate limiting, retries, and error handling\",\n      \"inputs\": \"System prompt, user prompt, optional schema for structured output\",\n      \"outputs\": \"Parsed LLM response with requested analysis or documentation\"\n    },\n    {\n      \"name\": \"generateFileSummary\",\n      \"desc\": \"Creates AI-generated summary of a single file's purpose, functionality, and role\",\n      \"inputs\": \"File path, content, and role in codebase\",\n      \"outputs\": \"FileSummary with description, key functions, and relationships\"\n    },\n    {\n      \"name\": \"generateModuleSummary\",\n      \"desc\": \"Creates AI-generated summary of a module's purpose and file organization\",\n      \"inputs\": \"Module name, list of files, and module type\",\n      \"outputs\": \"ModuleSummary with module purpose and file descriptions\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by using LLMs to generate human-readable documentation, identify architectural patterns, suggest improvements, and create test plans. It abstracts away the complexity of calling different LLM providers (OpenAI, Claude, local models) and handles rate limiting, retries, and response parsing so developers can get AI insights without managing API details.\"\n}\n```"
    },
    {
      "file": "src/logger.ts",
      "role": "Core Logic",
      "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
      "userVisibleActions": [
        "Log files are automatically created in .shadow/logs/shadow-watch.log in the workspace root",
        "All logged events are timestamped with ISO format timestamps",
        "Log sections are visually separated with header lines for easier reading"
      ],
      "developerVisibleActions": [
        "Developers can log messages that appear in .shadow/logs/shadow-watch.log",
        "Developers can create section headers in the log file to organize different parts of execution",
        "Logging fails silently if the workspace is not available or errors occur",
        "The .shadow/logs directory is automatically created if it doesn't exist"
      ],
      "keyFunctions": [
        {
          "name": "log",
          "desc": "Writes a timestamped message to the log file",
          "inputs": "message (string) - the text to log",
          "outputs": "void - writes to file system"
        },
        {
          "name": "section",
          "desc": "Creates a formatted section header in the log file with surrounding equals signs",
          "inputs": "title (string) - the section header text",
          "outputs": "void - writes to file system"
        },
        {
          "name": "getLogPath",
          "desc": "Determines the file path where logs should be written",
          "inputs": "none",
          "outputs": "string | null - path to log file or null if no workspace"
        },
        {
          "name": "ensureDir",
          "desc": "Creates a directory if it doesn't already exist",
          "inputs": "dir (string) - directory path to create",
          "outputs": "void - modifies file system"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "vscode"
      ],
      "intent": "This file exists to provide a centralized, file-based logging system for the extension, allowing developers to track extension behavior and debug issues by writing timestamped logs to a consistent location in the workspace",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are automatically created in .shadow/logs/shadow-watch.log in the workspace root\",\n    \"All logged events are timestamped with ISO format timestamps\",\n    \"Log sections are visually separated with header lines for easier reading\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can log messages that appear in .shadow/logs/shadow-watch.log\",\n    \"Developers can create section headers in the log file to organize different parts of execution\",\n    \"Logging fails silently if the workspace is not available or errors occur\",\n    \"The .shadow/logs directory is automatically created if it doesn't exist\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the log file\",\n      \"inputs\": \"message (string) - the text to log\",\n      \"outputs\": \"void - writes to file system\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a formatted section header in the log file with surrounding equals signs\",\n      \"inputs\": \"title (string) - the section header text\",\n      \"outputs\": \"void - writes to file system\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - path to log file or null if no workspace\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory if it doesn't already exist\",\n      \"inputs\": \"dir (string) - directory path to create\",\n      \"outputs\": \"void - modifies file system\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, file-based logging system for the extension, allowing developers to track extension behavior and debug issues by writing timestamped logs to a consistent location in the workspace\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is a VS Code extension that provides AI-powered code intelligence and automated testing capabilities for software development teams. The extension analyzes your codebase to generate comprehensive documentation, identify code quality issues, and create unit tests automatically. Users interact with the extension through multiple sidebar panels, command palette actions, and inline diagnostics that appear directly in the editor as you work.\\n\\nThe extension connects to AI language models (OpenAI GPT-4 or Anthropic Claude) to understand your code at multiple levels - from individual functions to entire product architecture. It automatically generates documentation describing what your application does, how components relate to each other, and what problems your code solves. The extension watches your files for changes and can automatically re-analyze your code as you save, keeping documentation and insights up to date.\\n\\nShadow Watch transforms time-consuming manual tasks into automated workflows. Instead of manually writing documentation, reviewing code for quality issues, or creating unit tests from scratch, users can generate these artifacts with a few clicks. The extension presents all analysis results in organized tree views, exports documentation in multiple formats optimized for different AI assistants, and provides detailed reports that help teams understand and improve their codebase.\",\"whatItDoes\":[\"Generates comprehensive product documentation automatically by analyzing your entire codebase\",\"Creates detailed architecture insights describing system components and their relationships\",\"Identifies code quality issues like large files, orphaned code, circular dependencies, and complexity problems\",\"Generates unit tests automatically for your functions with AI-powered test planning\",\"Executes test suites and automatically fixes failing tests using AI assistance\",\"Provides interactive tree views for navigating code structure, dependencies, and entry points\",\"Displays inline diagnostics showing code issues directly in the editor with squiggly underlines\",\"Exports analysis results in multiple formats (Markdown, JSON) optimized for Cursor, ChatGPT, and other AI tools\",\"Watches files for changes and automatically re-analyzes code when you save\",\"Searches codebases using grep patterns to find specific code elements\",\"Caches analysis results for 24 hours to provide instant access across sessions\",\"Detects test framework configuration and generates setup instructions if needed\",\"Creates prioritized test plans based on function complexity, dependencies, and risk\",\"Generates tests in small batches with real-time progress tracking\",\"Validates generated tests by running them and captures detailed results\"],\"userPerspective\":{\"gui\":[\"Browse code structure through interactive tree views showing products, analyses, insights, and test results\",\"View AI-generated architecture insights in a dedicated sidebar panel\",\"Navigate from high-level components down to specific functions with single clicks\",\"See code quality issues highlighted with inline squiggly underlines in the editor\",\"Monitor analysis progress through status bar indicators showing current operations\",\"View comprehensive reports in webview panels displaying formatted documentation\",\"Access detailed information about functions, API endpoints, and dependencies in popup panels\",\"Track test generation progress with real-time updates showing completed and failed tests\",\"Review test execution results with pass/fail counts and error details\",\"Copy analysis results, insights, and documentation to clipboard for sharing\"],\"cli\":[\"Execute workspace analysis through VS Code command palette\",\"Trigger file-specific analysis for currently open files\",\"Generate product documentation on demand\",\"Clear cached analysis data to force fresh analysis\",\"Switch between OpenAI and Claude AI providers\",\"Configure extension settings through VS Code preferences\",\"Export analysis results in different formats\",\"Access test generation and validation workflows\"],\"api\":[\"Integrates with OpenAI GPT-4 API for AI-powered code analysis\",\"Connects to Anthropic Claude API as alternative AI provider\",\"Handles API rate limiting automatically to prevent quota violations\",\"Retries failed API requests with intelligent backoff strategies\",\"Supports streaming responses for real-time AI text generation\",\"Validates API credentials and provider availability before use\"],\"cicd\":[\"Generates test suites that integrate with existing test frameworks (Jest, Mocha, Vitest, Pytest, JUnit, Google Test)\",\"Detects test environment configuration automatically\",\"Creates setup instructions for missing test dependencies\",\"Executes tests and captures results for CI/CD pipeline integration\",\"Exports analysis results in standardized formats for automated workflows\",\"Validates generated tests to ensure they run successfully\"]},\"workflowIntegration\":[\"Code review workflow: Analyze files to identify quality issues before committing changes\",\"Documentation workflow: Generate comprehensive product and architecture documentation automatically\",\"Testing workflow: Create test plans, generate unit tests, execute tests, and fix failures in one automated flow\",\"Refactoring workflow: Analyze function dependencies and complexity to plan safe code reorganization\",\"Onboarding workflow: Generate architecture insights and documentation to help new team members understand the codebase\",\"AI-assisted development: Export analysis results in formats optimized for Cursor, ChatGPT, and other AI coding assistants\",\"Quality monitoring: Continuously track code quality through automatic re-analysis on file save\",\"Test coverage workflow: Identify untested functions and generate tests to improve coverage\",\"Cross-language testing: Support multiple programming languages and testing frameworks in polyglot projects\"],\"problemsSolved\":[\"Eliminates manual documentation writing by automatically generating comprehensive product and architecture documentation\",\"Reduces time spent understanding unfamiliar codebases through AI-generated insights and navigation tools\",\"Catches code quality issues early by identifying large files, orphaned code, and circular dependencies automatically\",\"Accelerates test creation by generating unit tests with AI assistance instead of writing them manually\",\"Reduces debugging time by automatically fixing failing tests through AI-powered retry attempts\",\"Prevents API quota violations through automatic rate limiting when calling AI services\",\"Maintains up-to-date documentation through automatic re-analysis when code changes\",\"Streamlines code reviews by highlighting quality issues with inline diagnostics\",\"Simplifies test environment setup by detecting configuration and generating setup instructions\",\"Improves test coverage by prioritizing which functions need tests based on complexity and risk\",\"Enables efficient code navigation through interactive tree views showing dependencies and relationships\",\"Reduces context switching by keeping analysis results accessible for 24 hours across sessions\",\"Supports diverse workflows by exporting results in multiple formats for different tools\",\"Handles temporary API failures gracefully through intelligent retry logic\",\"Provides consistent AI interactions across multiple providers (OpenAI, Claude) through unified interface\"],\"architecture\":\"Shadow Watch follows a layered architecture with distinct separation between user interface, domain logic, infrastructure services, and AI integration. The user interface layer consists of multiple VS Code tree view providers and webview panels that present analysis results, insights, and reports. These views receive data from the domain layer and respond to user commands through registered command handlers. The extension bootstrapper initializes all components during activation and establishes the communication pathways between layers.\\n\\nThe domain layer contains the core business logic organized into specialized services. The analysis services parse code files to extract structure, dependencies, and function information. The testing services orchestrate the complete test generation workflow from planning through execution and validation. The prompt builders construct structured instructions for AI models based on analysis requirements. The formatting services transform raw analysis data into human-readable documentation. All domain services coordinate with each other through well-defined interfaces and data structures.\\n\\nThe infrastructure layer provides foundational capabilities that support the domain logic. The file system services handle efficient file reading, caching, and watching operations. The persistence layer manages storage and retrieval of analysis results in a timestamped directory structure. The AI provider layer abstracts interactions with different language models (OpenAI, Claude) behind a common interface. Rate limiting, retry logic, and response parsing ensure reliable AI interactions. The configuration manager centralizes all user preferences and broadcasts changes to interested components. This layered design enables each component to focus on its specific responsibility while maintaining clean boundaries and testability.\",\"titles\":[\"Shadow Watch Extension\",\"Code Analysis\",\"Architecture Insights\",\"Product Documentation\",\"Test Generation Workflow\",\"Test Planning Service\",\"Test Setup Service\",\"Test Execution Service\",\"Test Validation Service\",\"Interactive Tree Views\",\"Analysis Viewer\",\"Insights Viewer\",\"Static Analysis Viewer\",\"Unit Tests Navigator\",\"Product Navigator\",\"Reports Tree Provider\",\"Inline Diagnostics\",\"Command Palette Integration\",\"LLM Service\",\"AI Provider Factory\",\"Rate Limiter\",\"Retry Handler\",\"Response Parser\",\"File Watcher Service\",\"Incremental Analysis Service\",\"Configuration Manager\",\"Documentation Formatter\",\"Navigation Handler\",\"Prompt Builder\",\"Refactoring Prompt Builder\",\"Test Prompts\",\"File Cache\",\"File Processor\",\"Analysis Result Repository\",\"Progress Service\",\"Enhanced Analyzer\",\"Function Analyzer\",\"Insight Generator\",\"File Access Helper\",\"LLM State Manager\",\"Incremental Storage\",\"Reports Viewer\",\"Error Handler\",\"JSON Extractor\"],\"descriptions\":[{\"title\":\"Shadow Watch Extension\",\"description\":\"The main VS Code extension that provides AI-powered code analysis, documentation generation, and automated testing capabilities through multiple integrated views and commands\",\"category\":\"feature\"},{\"title\":\"Code Analysis\",\"description\":\"Analyzes source code files to extract structure, functions, dependencies, entry points, and relationships for comprehensive codebase understanding\",\"category\":\"feature\"},{\"title\":\"Architecture Insights\",\"description\":\"AI-generated insights describing the high-level architecture, component relationships, system themes, and design patterns used in the codebase\",\"category\":\"feature\"},{\"title\":\"Product Documentation\",\"description\":\"Comprehensive documentation automatically generated from code analysis that describes what the application does from a user perspective, including features, workflows, and problems solved\",\"category\":\"feature\"},{\"title\":\"Test Generation Workflow\",\"description\":\"End-to-end automated workflow that analyzes code, creates test plans, generates unit tests with AI assistance, executes tests, and fixes failures automatically\",\"category\":\"workflow\"},{\"title\":\"Interactive Tree Views\",\"description\":\"Sidebar panels that display code structure, analysis results, insights, and test information in an organized, navigable tree format with interactive actions\",\"category\":\"feature\"},{\"title\":\"Inline Diagnostics\",\"description\":\"Code quality issues displayed directly in the editor as squiggly underlines with detailed problem descriptions in the problems panel\",\"category\":\"feature\"},{\"title\":\"Command Palette Integration\",\"description\":\"All extension features accessible through VS Code's command palette for quick access to analysis, documentation, testing, and configuration actions\",\"category\":\"integration\"},{\"title\":\"LLM Service\",\"description\":\"AI-powered analysis service that generates insights, documentation, and code understanding by interfacing with OpenAI GPT-4 or Anthropic Claude language models\",\"category\":\"module\"},{\"title\":\"File Watcher Service\",\"description\":\"Monitors workspace files for changes and automatically triggers re-analysis when files are saved, keeping documentation and insights up to date\",\"category\":\"module\"},{\"title\":\"Configuration Manager\",\"description\":\"Centralized management of all user preferences including AI provider selection, API credentials, analysis triggers, and display options\",\"category\":\"module\"},{\"title\":\"Test Planning Service\",\"description\":\"Analyzes code functions and creates prioritized test plans based on complexity, dependencies, and risk factors using AI guidance\",\"category\":\"module\"},{\"title\":\"Test Setup Service\",\"description\":\"Detects existing test framework configuration and generates setup instructions including required dependencies and configuration files\",\"category\":\"module\"},{\"title\":\"Test Execution Service\",\"description\":\"Runs test suites using the appropriate testing framework and captures detailed results including pass/fail status, errors, and execution timing\",\"category\":\"module\"},{\"title\":\"Test Validation Service\",\"description\":\"Validates generated tests by executing them and automatically fixes failures through AI-powered retry attempts\",\"category\":\"module\"},{\"title\":\"Enhanced Analyzer\",\"description\":\"Deep code analysis engine that parses Abstract Syntax Trees to extract detailed function metadata, control flow, dependencies, and behavioral patterns\",\"category\":\"component\"},{\"title\":\"Function Analyzer\",\"description\":\"Extracts comprehensive function information from large code files to support refactoring analysis including signatures, dependencies, and complexity metrics\",\"category\":\"component\"},{\"title\":\"Insight Generator\",\"description\":\"Identifies code quality issues like large files, orphaned code, circular dependencies, and complexity problems with severity-based categorization\",\"category\":\"component\"},{\"title\":\"Documentation Formatter\",\"description\":\"Transforms raw analysis data into well-structured Markdown documentation organized by user perspective and technical considerations\",\"category\":\"component\"},{\"title\":\"Navigation Handler\",\"description\":\"Enables navigation to specific code locations and displays detailed information about functions, API endpoints, and dependencies in webview panels\",\"category\":\"component\"},{\"title\":\"Prompt Builder\",\"description\":\"Constructs specialized prompts for different types of AI analysis including architecture documentation, refactoring plans, and test generation\",\"category\":\"component\"},{\"title\":\"AI Provider Factory\",\"description\":\"Creates and manages AI language model provider instances ensuring single instance per provider type and supporting OpenAI and Claude\",\"category\":\"component\"},{\"title\":\"Rate Limiter\",\"description\":\"Prevents API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\"category\":\"component\"},{\"title\":\"Retry Handler\",\"description\":\"Handles automatic retries of failed AI requests with intelligent exponential backoff for temporary errors like rate limits or network issues\",\"category\":\"component\"},{\"title\":\"Response Parser\",\"description\":\"Extracts structured data from AI text responses and converts them into standardized documentation formats\",\"category\":\"component\"},{\"title\":\"File Cache\",\"description\":\"Optimizes file operations by caching file contents and automatically invalidating cached data when files change\",\"category\":\"component\"},{\"title\":\"File Processor\",\"description\":\"Provides parallel file processing with automatic filtering of non-source directories like node_modules and build outputs\",\"category\":\"component\"},{\"title\":\"Analysis Result Repository\",\"description\":\"Manages persistent storage of analysis results in timestamped directory structures with automatic maintenance of latest reference links\",\"category\":\"component\"},{\"title\":\"Progress Service\",\"description\":\"Displays standardized progress notifications to users during long-running operations with support for cancellation\",\"category\":\"component\"},{\"title\":\"Analysis Viewer\",\"description\":\"Tree view that displays code structure organized by files, functions, dependencies, and entry points with navigation support\",\"category\":\"feature\"},{\"title\":\"Insights Viewer\",\"description\":\"Tree view showing AI-generated architecture insights including system purpose, component relationships, and organizational patterns\",\"category\":\"feature\"},{\"title\":\"Static Analysis Viewer\",\"description\":\"Tree view presenting code quality issues identified by static analysis with severity indicators and recommendations\",\"category\":\"feature\"},{\"title\":\"Unit Tests Navigator\",\"description\":\"Tree view for browsing and navigating unit tests in the codebase with links to test files and source code\",\"category\":\"feature\"},{\"title\":\"Product Navigator\",\"description\":\"Tree view showing high-level product structure and enabling navigation between documentation and source code\",\"category\":\"feature\"},{\"title\":\"Reports Tree Provider\",\"description\":\"Tree view displaying generated reports including documentation, test results, and analysis summaries\",\"category\":\"feature\"},{\"title\":\"Incremental Analysis Service\",\"description\":\"Orchestrates multi-round AI conversations that progressively gather information through file reads and searches until analysis is complete\",\"category\":\"module\"},{\"title\":\"Test Configuration Service\",\"description\":\"Automatically detects which testing framework is in use and validates that all required dependencies and configuration are present\",\"category\":\"module\"},{\"title\":\"Export Formats\",\"description\":\"Multiple output formats optimized for different AI assistants including Cursor (tree structure), ChatGPT (detailed markdown), Generic (standard format), and Compact (minimal format)\",\"category\":\"feature\"},{\"title\":\"Grep Search\",\"description\":\"Pattern-based code search that finds specific elements across the codebase using regex patterns with configurable file filters\",\"category\":\"feature\"},{\"title\":\"Context Builder\",\"description\":\"Converts analysis results into formats suitable for LLM context and saves them to persistent storage for future use\",\"category\":\"component\"},{\"title\":\"LLM State Manager\",\"description\":\"Manages the state of LLM operations including tracking active requests, handling cancellations, and coordinating multi-step workflows\",\"category\":\"component\"},{\"title\":\"Incremental Storage\",\"description\":\"Provides incremental saving of analysis results allowing partial results to be stored and accessed during long-running analysis operations\",\"category\":\"component\"}],\"relevantFunctions\":[{\"name\":\"analyzeWorkspace\",\"description\":\"Analyzes the entire workspace codebase to generate comprehensive documentation, insights, and structural information\",\"file\":\"src/extension.ts\",\"module\":\"Extension\"},{\"name\":\"analyzeFile\",\"description\":\"Analyzes a single code file to extract its structure, functions, dependencies, and generates file-level documentation\",\"file\":\"src/analyzer.ts\",\"module\":\"Analyzer\"},{\"name\":\"generateProductDocs\",\"description\":\"Creates complete product documentation by analyzing the codebase and using AI to generate user-facing descriptions\",\"file\":\"src/llmIntegration.ts\",\"module\":\"LLM Integration\"},{\"name\":\"generateArchitectureInsights\",\"description\":\"Produces high-level architecture insights describing system components, relationships, and design patterns\",\"file\":\"src/llmIntegration.ts\",\"module\":\"LLM Integration\"},{\"name\":\"generateTests\",\"description\":\"Orchestrates the complete test generation workflow including planning, generation, and validation\",\"file\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"module\":\"Test Generation\"},{\"name\":\"createTestPlan\",\"description\":\"Analyzes code functions and creates a prioritized test plan based on complexity and dependencies\",\"file\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"module\":\"Test Planning\"},{\"name\":\"detectTestSetup\",\"description\":\"Automatically detects test framework configuration and identifies missing dependencies or setup requirements\",\"file\":\"src/domain/services/testing/llmTestSetupService.ts\",\"module\":\"Test Setup\"},{\"name\":\"executeTests\",\"description\":\"Runs test suites using the appropriate testing framework and captures detailed execution results\",\"file\":\"src/domain/services/testing/testExecutionService.ts\",\"module\":\"Test Execution\"},{\"name\":\"validateAndFixTests\",\"description\":\"Validates generated tests by running them and automatically fixes failures using AI assistance\",\"file\":\"src/domain/services/testing/llmTestValidationService.ts\",\"module\":\"Test Validation\"},{\"name\":\"analyzeFunction\",\"description\":\"Performs deep analysis on a function by parsing its AST to extract metadata, dependencies, and behavioral patterns\",\"file\":\"src/analysis/enhancedAnalyzer.ts\",\"module\":\"Enhanced Analyzer\"},{\"name\":\"extractFunctionInfo\",\"description\":\"Extracts detailed function information from large code files to support refactoring analysis\",\"file\":\"src/analysis/functionAnalyzer.ts\",\"module\":\"Function Analyzer\"},{\"name\":\"generateInsights\",\"description\":\"Identifies code quality issues like large files, orphaned code, and complexity problems with severity ratings\",\"file\":\"src/insightGenerator.ts\",\"module\":\"Insight Generator\"},{\"name\":\"navigateToLocation\",\"description\":\"Opens a file at a specific line number in the VS Code editor\",\"file\":\"src/domain/handlers/navigationHandler.ts\",\"module\":\"Navigation Handler\"},{\"name\":\"showItemDetails\",\"description\":\"Displays detailed information about code items (functions, endpoints) in a webview panel\",\"file\":\"src/domain/handlers/navigationHandler.ts\",\"module\":\"Navigation Handler\"},{\"name\":\"buildPrompt\",\"description\":\"Constructs specialized prompts for different types of AI analysis tasks based on analysis requirements\",\"file\":\"src/domain/prompts/promptBuilder.ts\",\"module\":\"Prompt Builder\"},{\"name\":\"buildRefactoringPrompt\",\"description\":\"Creates detailed prompts for AI-powered code refactoring including extraction plans and migration steps\",\"file\":\"src/domain/prompts/refactoringPromptBuilder.ts\",\"module\":\"Refactoring Prompts\"},{\"name\":\"formatDocumentation\",\"description\":\"Transforms raw analysis data into well-structured Markdown documentation\",\"file\":\"src/domain/formatters/documentationFormatter.ts\",\"module\":\"Documentation Formatter\"},{\"name\":\"parseResponse\",\"description\":\"Extracts structured data from AI text responses and converts them into standardized documentation formats\",\"file\":\"src/ai/llmResponseParser.ts\",\"module\":\"Response Parser\"},{\"name\":\"enforceRateLimit\",\"description\":\"Tracks and enforces API rate limits to prevent exceeding provider quotas\",\"file\":\"src/ai/llmRateLimiter.ts\",\"module\":\"Rate Limiter\"},{\"name\":\"retryWithBackoff\",\"description\":\"Automatically retries failed AI requests with exponential backoff for temporary errors\",\"file\":\"src/ai/llmRetryHandler.ts\",\"module\":\"Retry Handler\"},{\"name\":\"getCachedFile\",\"description\":\"Retrieves file contents from cache or reads from disk if not cached\",\"file\":\"src/infrastructure/fileSystem/fileCache.ts\",\"module\":\"File Cache\"},{\"name\":\"processFiles\",\"description\":\"Processes multiple files in parallel with automatic filtering of non-source directories\",\"file\":\"src/infrastructure/fileSystem/fileProcessor.ts\",\"module\":\"File Processor\"},{\"name\":\"saveAnalysisResults\",\"description\":\"Persists analysis results to disk in a timestamped directory structure\",\"file\":\"src/infrastructure/persistence/analysisResultRepository.ts\",\"module\":\"Analysis Repository\"},{\"name\":\"watchFiles\",\"description\":\"Monitors workspace files for changes and triggers callbacks when files are modified or saved\",\"file\":\"src/domain/services/fileWatcherService.ts\",\"module\":\"File Watcher\"},{\"name\":\"performIncrementalAnalysis\",\"description\":\"Conducts multi-round AI analysis by iteratively requesting files and searches based on previous results\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\",\"module\":\"Incremental Analysis\"}],\"relevantDataStructures\":[{\"name\":\"FileDocumentation\",\"description\":\"Represents documentation for a single file including summary, capabilities, functions, and dependencies\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"ModuleDocumentation\",\"description\":\"Represents documentation for a module including overview, capabilities, and contained files\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"ProductDocumentation\",\"description\":\"Comprehensive product-level documentation including overview, features, workflows, architecture, and user perspectives\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"CodeInsight\",\"description\":\"Represents a code quality issue with title, description, severity, category, and affected files\",\"type\":\"interface\",\"file\":\"src/insightGenerator.ts\"},{\"name\":\"AnalysisResult\",\"description\":\"Complete analysis result for a workspace including files, modules, products, insights, and statistics\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"TestPlan\",\"description\":\"Structured test plan containing functions to test, priorities, and generation configuration\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestGenerationProgress\",\"description\":\"Tracks progress of test generation including phase, completed count, and failure information\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestExecutionResult\",\"description\":\"Results from test execution including pass/fail counts, errors, and execution timing\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestSetupConfiguration\",\"description\":\"Configuration for test environment including framework, dependencies, and setup instructions\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testSetupTypes.ts\"},{\"name\":\"FunctionAnalysis\",\"description\":\"Detailed analysis of a function including signature, dependencies, complexity, and behavioral hints\",\"type\":\"interface\",\"file\":\"src/analysis/enhancedAnalyzer.ts\"},{\"name\":\"ArchitectureInsight\",\"description\":\"AI-generated insight about system architecture including purpose, relationships, and design patterns\",\"type\":\"interface\",\"file\":\"src/llmService.ts\"},{\"name\":\"LLMResponse\",\"description\":\"Structured response from AI language model including generated content and metadata\",\"type\":\"interface\",\"file\":\"src/ai/llmResponseParser.ts\"},{\"name\":\"RateLimitConfig\",\"description\":\"Configuration for API rate limiting including requests per minute and time window\",\"type\":\"interface\",\"file\":\"src/ai/llmRateLimiter.ts\"},{\"name\":\"NavigationTarget\",\"description\":\"Represents a code location to navigate to including file path and line number\",\"type\":\"interface\",\"file\":\"src/domain/handlers/navigationHandler.ts\"},{\"name\":\"ExportFormat\",\"description\":\"Enumeration of supported export formats (Cursor, ChatGPT, Generic, Compact)\",\"type\":\"type\",\"file\":\"src/llmFormatter.ts\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main extension activation and command registration\",\"purpose\":\"Initializes all extension components, registers commands, and coordinates analysis workflows\",\"role\":\"Entry point\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"LLM-powered analysis orchestration\",\"purpose\":\"Manages AI-powered documentation generation and code analysis features\",\"role\":\"Core feature\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Code analysis engine\",\"purpose\":\"Analyzes source code files to extract structure, functions, and dependencies\",\"role\":\"Core feature\"},{\"path\":\"src/insightGenerator.ts\",\"description\":\"Code quality analysis\",\"purpose\":\"Identifies code quality issues and generates recommendations\",\"role\":\"Core feature\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Test generation orchestration\",\"purpose\":\"Coordinates the complete test generation workflow from planning to validation\",\"role\":\"Core feature\"},{\"path\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"description\":\"Test planning\",\"purpose\":\"Analyzes code and creates prioritized test plans\",\"role\":\"Core feature\"},{\"path\":\"src/domain/services/testing/testExecutionService.ts\",\"description\":\"Test execution\",\"purpose\":\"Runs test suites and captures detailed execution results\",\"role\":\"Core feature\"},{\"path\":\"src/analysis/enhancedAnalyzer.ts\",\"description\":\"Deep code analysis\",\"purpose\":\"Performs AST-based analysis to extract function metadata and behavioral patterns\",\"role\":\"Core component\"},{\"path\":\"src/ai/providers/providerFactory.ts\",\"description\":\"AI provider management\",\"purpose\":\"Creates and manages AI language model provider instances\",\"role\":\"Infrastructure\"},{\"path\":\"src/domain/prompts/promptBuilder.ts\",\"description\":\"AI prompt construction\",\"purpose\":\"Builds specialized prompts for different types of AI analysis\",\"role\":\"Core component\"},{\"path\":\"src/domain/formatters/documentationFormatter.ts\",\"description\":\"Documentation formatting\",\"purpose\":\"Transforms analysis data into readable Markdown documentation\",\"role\":\"Core component\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Code navigation\",\"purpose\":\"Handles navigation to code locations and displays item details\",\"role\":\"Core feature\"},{\"path\":\"src/config/configurationManager.ts\",\"description\":\"Settings management\",\"purpose\":\"Manages all user preferences and broadcasts configuration changes\",\"role\":\"Infrastructure\"},{\"path\":\"src/infrastructure/persistence/analysisResultRepository.ts\",\"description\":\"Analysis storage\",\"purpose\":\"Persists and retrieves analysis results with timestamped versioning\",\"role\":\"Infrastructure\"},{\"path\":\"src/domain/services/fileWatcherService.ts\",\"description\":\"File monitoring\",\"purpose\":\"Watches workspace files and triggers re-analysis on changes\",\"role\":\"Infrastructure\"},{\"path\":\"src/analysisViewer.ts\",\"description\":\"Code structure tree view\",\"purpose\":\"Displays code structure in an interactive sidebar tree view\",\"role\":\"User interface\"},{\"path\":\"src/insightsViewer.ts\",\"description\":\"Architecture insights tree view\",\"purpose\":\"Displays AI-generated architecture insights in a sidebar panel\",\"role\":\"User interface\"},{\"path\":\"src/insightsTreeView.ts\",\"description\":\"Insights and reports tree view\",\"purpose\":\"Shows code insights, documentation status, and generated reports\",\"role\":\"User interface\"}],\"exampleInput\":{\"description\":\"Example input showing a request to analyze a workspace and generate product documentation. This represents the type of data the extension receives when users trigger analysis through commands.\",\"json\":\"{\\\"command\\\":\\\"shadowwatch.analyzeWorkspace\\\",\\\"workspace\\\":{\\\"rootPath\\\":\\\"/users/developer/projects/myapp\\\",\\\"name\\\":\\\"myapp\\\"},\\\"options\\\":{\\\"generateProductDocs\\\":true,\\\"generateArchitectureInsights\\\":true,\\\"includeTestCoverage\\\":true,\\\"llmProvider\\\":\\\"openai\\\",\\\"exportFormat\\\":\\\"cursor\\\",\\\"minSeverity\\\":\\\"warning\\\"}}\"},\"exampleOutput\":{\"description\":\"Example output showing a complete analysis result with product documentation, architecture insights, and code quality findings. This represents the structured data the extension generates and displays to users.\",\"json\":\"{\\\"product\\\":{\\\"name\\\":\\\"MyApp\\\",\\\"overview\\\":\\\"MyApp is a web application that helps users manage their tasks and projects...\\\",\\\"whatItDoes\\\":[\\\"Create and organize tasks with priorities and due dates\\\",\\\"Track project progress with visual dashboards\\\"],\\\"userPerspective\\\":{\\\"gui\\\":[\\\"Users can drag and drop tasks between project boards\\\",\\\"Visual progress indicators show completion status\\\"],\\\"api\\\":[\\\"REST API allows external systems to create and update tasks\\\",\\\"Webhook notifications alert external services of task changes\\\"]},\\\"architecture\\\":\\\"MyApp follows a three-tier architecture with a React frontend, Node.js backend, and PostgreSQL database...\\\"},\\\"insights\\\":[{\\\"title\\\":\\\"Large API Handler File\\\",\\\"description\\\":\\\"The main API handler file contains 1500 lines and handles multiple concerns\\\",\\\"severity\\\":\\\"warning\\\",\\\"category\\\":\\\"maintainability\\\",\\\"files\\\":[\\\"src/api/handlers.ts\\\"],\\\"recommendation\\\":\\\"Consider splitting into separate handler files per resource type\\\"},{\\\"title\\\":\\\"Circular Dependency Detected\\\",\\\"description\\\":\\\"Task service and project service have circular dependencies\\\",\\\"severity\\\":\\\"error\\\",\\\"category\\\":\\\"architecture\\\",\\\"files\\\":[\\\"src/services/taskService.ts\\\",\\\"src/services/projectService.ts\\\"],\\\"recommendation\\\":\\\"Extract shared logic to a common utilities module\\\"}],\\\"statistics\\\":{\\\"totalFiles\\\":127,\\\"totalLines\\\":45823,\\\"filesAnalyzed\\\":115,\\\"insightsGenerated\\\":12,\\\"analysisTimeMs\\\":8934},\\\"timestamp\\\":\\\"2024-01-15T10:30:45.123Z\\\"}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-20T01:04:05.240Z",
    "generatedAtLocal": "11/19/2025, 5:04:05 PM",
    "runId": "product-docs-2025-11-20T00-47-52-354Z"
  }
}