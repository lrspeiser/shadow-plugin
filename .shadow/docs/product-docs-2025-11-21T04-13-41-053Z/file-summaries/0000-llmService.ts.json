{
  "file": "src/llmService.ts",
  "role": "Core Logic",
  "purpose": "Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.",
  "userVisibleActions": [
    "Receives AI-generated explanations of what the product/codebase does",
    "Gets intelligent insights about code architecture and design patterns",
    "Views AI-generated product documentation with purpose, features, and architecture",
    "Sees automated test plans and suggestions for code improvements",
    "Receives refactoring suggestions for complex functions",
    "Gets incremental analysis updates as code changes"
  ],
  "developerVisibleActions": [
    "Calls AI providers to analyze entire codebases and generate product purpose summaries",
    "Requests AI analysis of code structure, entry points, and module relationships",
    "Generates enhanced product documentation by analyzing file summaries and module structure",
    "Creates unit test plans by analyzing code coverage and function signatures",
    "Obtains refactoring suggestions for specific functions or code sections",
    "Triggers incremental analysis for file changes without re-analyzing entire codebase",
    "Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration",
    "Handles rate limiting and retry logic for LLM API calls automatically",
    "Parses and validates LLM responses using predefined schemas",
    "Accesses detailed function metadata and code analysis results"
  ],
  "keyFunctions": [
    {
      "name": "analyzeProductPurpose",
      "desc": "Analyzes the entire codebase to determine the product's main purpose and architecture",
      "inputs": "CodeAnalysis object containing all analyzed files and their metadata",
      "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules"
    },
    {
      "name": "generateInsights",
      "desc": "Generates AI-powered insights about code quality, patterns, and potential issues",
      "inputs": "CodeAnalysis with file information and analysis context",
      "outputs": "LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions"
    },
    {
      "name": "generateEnhancedProductDocumentation",
      "desc": "Creates comprehensive product documentation by analyzing file summaries and module structure",
      "inputs": "Array of FileSummary and ModuleSummary objects",
      "outputs": "EnhancedProductDocumentation with product overview, architecture, features, and technical details"
    },
    {
      "name": "generateUnitTestPlan",
      "desc": "Analyzes code to create a test plan identifying untested functions and suggesting test cases",
      "inputs": "CodeAnalysis and list of existing test files",
      "outputs": "UnitTestPlan with prioritized list of functions to test and suggested test cases"
    },
    {
      "name": "generateRefactoringSuggestions",
      "desc": "Analyzes a specific function and provides refactoring recommendations",
      "inputs": "Function code, metadata, and surrounding context",
      "outputs": "RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps"
    },
    {
      "name": "performIncrementalAnalysis",
      "desc": "Analyzes changes to specific files without re-analyzing the entire codebase",
      "inputs": "Array of changed file paths and full code analysis",
      "outputs": "Updated analysis focusing only on changed files and their immediate dependencies"
    },
    {
      "name": "callLLM",
      "desc": "Makes authenticated API calls to configured LLM provider with rate limiting and retry logic",
      "inputs": "Prompt string, expected response schema, and optional provider override",
      "outputs": "Parsed and validated response from the LLM matching the specified schema"
    }
  ],
  "dependencies": [
    "vscode",
    "./fileDocumentation",
    "./analyzer",
    "./analysis/enhancedAnalyzer",
    "./llmSchemas",
    "./fileAccessHelper",
    "./logger",
    "./config/configurationManager",
    "./ai/providers/providerFactory",
    "./ai/llmResponseParser",
    "./ai/llmRateLimiter",
    "./ai/llmRetryHandler",
    "./domain/prompts/promptBuilder",
    "./domain/services/incrementalAnalysisService",
    "./domain/prompts/refactoringPromptBuilder",
    "./analysis/functionAnalyzer"
  ],
  "intent": "This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated explanations of what the product/codebase does\",\n    \"Gets intelligent insights about code architecture and design patterns\",\n    \"Views AI-generated product documentation with purpose, features, and architecture\",\n    \"Sees automated test plans and suggestions for code improvements\",\n    \"Receives refactoring suggestions for complex functions\",\n    \"Gets incremental analysis updates as code changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls AI providers to analyze entire codebases and generate product purpose summaries\",\n    \"Requests AI analysis of code structure, entry points, and module relationships\",\n    \"Generates enhanced product documentation by analyzing file summaries and module structure\",\n    \"Creates unit test plans by analyzing code coverage and function signatures\",\n    \"Obtains refactoring suggestions for specific functions or code sections\",\n    \"Triggers incremental analysis for file changes without re-analyzing entire codebase\",\n    \"Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration\",\n    \"Handles rate limiting and retry logic for LLM API calls automatically\",\n    \"Parses and validates LLM responses using predefined schemas\",\n    \"Accesses detailed function metadata and code analysis results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine the product's main purpose and architecture\",\n      \"inputs\": \"CodeAnalysis object containing all analyzed files and their metadata\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules\"\n    },\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates AI-powered insights about code quality, patterns, and potential issues\",\n      \"inputs\": \"CodeAnalysis with file information and analysis context\",\n      \"outputs\": \"LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation by analyzing file summaries and module structure\",\n      \"inputs\": \"Array of FileSummary and ModuleSummary objects\",\n      \"outputs\": \"EnhancedProductDocumentation with product overview, architecture, features, and technical details\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Analyzes code to create a test plan identifying untested functions and suggesting test cases\",\n      \"inputs\": \"CodeAnalysis and list of existing test files\",\n      \"outputs\": \"UnitTestPlan with prioritized list of functions to test and suggested test cases\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Analyzes a specific function and provides refactoring recommendations\",\n      \"inputs\": \"Function code, metadata, and surrounding context\",\n      \"outputs\": \"RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps\"\n    },\n    {\n      \"name\": \"performIncrementalAnalysis\",\n      \"desc\": \"Analyzes changes to specific files without re-analyzing the entire codebase\",\n      \"inputs\": \"Array of changed file paths and full code analysis\",\n      \"outputs\": \"Updated analysis focusing only on changed files and their immediate dependencies\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Makes authenticated API calls to configured LLM provider with rate limiting and retry logic\",\n      \"inputs\": \"Prompt string, expected response schema, and optional provider override\",\n      \"outputs\": \"Parsed and validated response from the LLM matching the specified schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-21T04:24:20.292Z"
  }
}