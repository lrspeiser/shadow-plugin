{
  "overview": "Shadow Watch is a Visual Studio Code extension that provides AI-powered code analysis and automated documentation generation for software development teams. It analyzes your codebase to identify code quality issues, generate comprehensive documentation, and provide intelligent refactoring recommendations. The extension continuously monitors your workspace, automatically detecting problems like high complexity functions, circular dependencies, orphaned code, and missing test coverage, then presents these findings through interactive visualizations and structured reports.\n\nUsers interact with Shadow Watch through VS Code's command palette, sidebar views, and inline editor annotations. The extension integrates with AI providers (OpenAI or Claude) to generate intelligent insights about your codebase architecture, produce product documentation, and create automated tests. All analysis results are presented through multiple interactive views including a problem diagnostics panel, hierarchical tree views for browsing insights, and a product navigator that shows your codebase structure organized by modules and components.\n\nShadow Watch enables development workflows focused on code quality improvement, technical debt management, and knowledge capture. It automatically saves all analysis results with timestamps, allowing teams to track code health over time and maintain comprehensive documentation without manual effort. The extension works continuously in the background, re-analyzing code when files change and keeping all views synchronized with the current codebase state.",
  "whatItDoes": [
    "Automatically analyzes code quality and identifies issues like high complexity, large files, and circular dependencies",
    "Generates comprehensive product documentation and architecture insights using AI language models",
    "Creates interactive visualizations of code problems directly in the VS Code editor and Problems panel",
    "Provides hierarchical navigation of analysis results through multiple sidebar tree views",
    "Automatically generates unit tests for functions with AI-powered test planning and validation",
    "Detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) without manual setup",
    "Exports analysis results in multiple formats optimized for AI assistants like Cursor and ChatGPT",
    "Tracks code coverage and identifies untested functions across your codebase",
    "Monitors file changes and automatically re-analyzes modified code",
    "Generates detailed refactoring recommendations with step-by-step implementation guidance",
    "Creates timestamped documentation archives to track codebase evolution over time",
    "Provides search capabilities for AI agents to explore and understand codebases"
  ],
  "userPerspective": {
    "gui": [
      "Command palette commands for triggering workspace or file-specific analysis",
      "Interactive tree views in the sidebar showing analysis results, insights, and documentation hierarchy",
      "Visual problem indicators in the editor with color-coded severity levels",
      "Hover tooltips displaying detailed information about detected issues",
      "Click-to-navigate functionality from tree views to source code locations",
      "Status bar indicators showing analysis progress and extension state",
      "Real-time progress notifications during long-running operations with cancel buttons",
      "Problems panel integration displaying all detected code issues with jump-to-source links",
      "Webview panels for viewing detailed reports and documentation",
      "Context menus for quick access to analysis and documentation commands"
    ],
    "cli": [
      "VS Code command palette commands like 'Shadow Watch: Analyze Workspace'",
      "Commands for generating insights, clearing cache, and switching AI providers",
      "Export commands for saving analysis results to disk in various formats",
      "Test generation commands for creating automated unit tests",
      "Commands for navigating to specific code elements and viewing details"
    ],
    "api": [
      "Integration with OpenAI API for GPT-based code analysis and documentation generation",
      "Integration with Anthropic Claude API for alternative AI-powered analysis",
      "Extensible provider system allowing integration of additional AI services",
      "File system watching API for detecting workspace changes",
      "Analysis result storage API for persisting documentation and insights"
    ],
    "cicd": [
      "Can be integrated into CI/CD pipelines through VS Code automation",
      "Exports analysis results that can be consumed by automated quality gates",
      "Generates machine-readable JSON reports for integration with other tools",
      "Timestamps all analysis runs for tracking quality metrics over time"
    ]
  },
  "workflowIntegration": [
    "Code review preparation: Generate documentation and identify issues before submitting pull requests",
    "Technical debt management: Identify and prioritize refactoring opportunities based on complexity metrics",
    "Onboarding new team members: Provide AI-generated architecture documentation and codebase overviews",
    "Test coverage improvement: Automatically generate missing tests and validate they execute correctly",
    "Knowledge capture: Maintain up-to-date documentation that evolves with the codebase",
    "Quality monitoring: Track code health metrics across multiple analysis runs",
    "Refactoring planning: Get AI-generated step-by-step guidance for extracting complex functions",
    "Documentation maintenance: Keep product documentation synchronized with code changes"
  ],
  "problemsSolved": [
    "Manual documentation becomes outdated quickly - Shadow Watch automatically generates and updates documentation as code changes",
    "Identifying code quality issues requires expertise - The extension automatically detects complexity, circular dependencies, and other problems",
    "Writing tests is time-consuming - AI-powered test generation creates comprehensive unit tests automatically",
    "Understanding large codebases is difficult - Interactive navigation and AI-generated insights make exploration easier",
    "Tracking code health over time requires manual effort - Timestamped analysis runs create a historical record",
    "Setting up test frameworks is complex - Automatic detection and configuration eliminates manual setup",
    "Refactoring complex code is risky - Detailed step-by-step plans reduce the chance of introducing bugs",
    "Finding relevant code quickly in large projects - Search and navigation tools help locate specific functions and modules"
  ],
  "architecture": "Shadow Watch follows a modular architecture organized around core domains: analysis, documentation generation, testing automation, and user interface presentation. The analysis domain performs deep code inspection using TypeScript/JavaScript AST parsing to extract function metadata, complexity metrics, and dependency relationships. This analysis data flows through a caching layer that stores results to avoid redundant processing, then feeds into insight generators that identify code quality issues and refactoring opportunities.\n\nThe documentation generation domain integrates with AI language model providers through an abstraction layer that supports both OpenAI and Claude. Rate limiting, retry handling, and response parsing components ensure reliable AI interactions. Documentation requests flow through a prompt building system that constructs specialized queries for different tasks (architecture analysis, test generation, refactoring guidance), then results are formatted into structured Markdown and persisted to timestamped storage directories.\n\nThe user interface architecture consists of multiple coordinated views: tree view providers for hierarchical data display, diagnostics providers for inline problem annotations, webview providers for rich content display, and a navigation handler for jumping between code locations. A file watching service monitors workspace changes and triggers appropriate updates across all views, while a progress service provides consistent user feedback during long-running operations. All components communicate through a command registry that maps user actions to appropriate handlers, creating a cohesive user experience across the extension.",
  "titles": [
    "Shadow Watch Extension",
    "Code Analysis Engine",
    "AI Documentation Generator",
    "Test Automation System",
    "Architecture Insights Generator",
    "Product Documentation Generator",
    "Refactoring Recommendation Engine",
    "Code Quality Diagnostics",
    "Interactive Analysis Browser",
    "Insights Tree View",
    "Product Navigator",
    "Unit Test Navigator",
    "Static Analysis Viewer",
    "Reports Tree Provider",
    "File Watcher Service",
    "Incremental Analysis Service",
    "Test Configuration Service",
    "LLM Integration Layer",
    "Rate Limiter",
    "Retry Handler",
    "Response Parser",
    "Provider Factory",
    "Configuration Manager",
    "Navigation Handler",
    "Documentation Formatter",
    "LLM Formatter",
    "Prompt Builder",
    "Test Prompt Builder",
    "Refactoring Prompt Builder",
    "File Cache",
    "File Processor",
    "Analysis Result Repository",
    "Progress Service",
    "Test Generation Service",
    "Test Planning Service",
    "Test Setup Service",
    "Test Validation Service",
    "Test Execution Service",
    "Enhanced Code Analyzer",
    "Function Analyzer",
    "Context Builder",
    "Extension Bootstrapper",
    "Command Registry",
    "Diagnostic Provider",
    "Insight Generator"
  ],
  "descriptions": [
    {
      "title": "Shadow Watch Extension",
      "description": "VS Code extension that provides comprehensive code analysis, AI-powered documentation generation, and automated testing capabilities for software development teams",
      "category": "feature"
    },
    {
      "title": "Code Analysis Engine",
      "description": "Deep code inspection system that parses TypeScript and JavaScript files to extract function metadata, calculate complexity metrics, map dependencies, and identify code quality issues",
      "category": "component"
    },
    {
      "title": "AI Documentation Generator",
      "description": "Integrates with OpenAI and Claude to automatically generate product documentation, architecture insights, and code explanations from analyzed codebases",
      "category": "feature"
    },
    {
      "title": "Test Automation System",
      "description": "Comprehensive testing workflow that automatically plans, generates, executes, and validates unit tests using AI analysis and multi-framework support",
      "category": "feature"
    },
    {
      "title": "Architecture Insights Generator",
      "description": "Produces high-level architecture documentation showing component relationships, data flows, and system organization using AI analysis",
      "category": "feature"
    },
    {
      "title": "Product Documentation Generator",
      "description": "Creates user-facing documentation describing what the application does, how users interact with it, and what problems it solves",
      "category": "feature"
    },
    {
      "title": "Refactoring Recommendation Engine",
      "description": "Analyzes complex functions and generates detailed step-by-step refactoring plans with AI-guided extraction instructions",
      "category": "feature"
    },
    {
      "title": "Code Quality Diagnostics",
      "description": "Visual problem indicators that appear in the editor and Problems panel showing issues like high complexity, large files, circular dependencies, and missing tests",
      "category": "feature"
    },
    {
      "title": "Interactive Analysis Browser",
      "description": "Sidebar tree view that displays complete analysis results organized hierarchically with click-to-navigate functionality",
      "category": "feature"
    },
    {
      "title": "Insights Tree View",
      "description": "Displays AI-generated insights, reports, and documentation in a hierarchical tree structure with real-time status updates",
      "category": "component"
    },
    {
      "title": "Product Navigator",
      "description": "Shows codebase structure organized by modules, components, and entry points with navigation capabilities",
      "category": "feature"
    },
    {
      "title": "Unit Test Navigator",
      "description": "Displays test coverage information and allows navigation to tested and untested functions",
      "category": "feature"
    },
    {
      "title": "Static Analysis Viewer",
      "description": "Shows static analysis results including file-level metrics and quality indicators",
      "category": "component"
    },
    {
      "title": "File Watcher Service",
      "description": "Monitors workspace for file changes and automatically triggers re-analysis when code is modified",
      "category": "component"
    },
    {
      "title": "Incremental Analysis Service",
      "description": "Manages iterative analysis where AI can request additional context through multiple rounds until sufficient information is gathered",
      "category": "component"
    },
    {
      "title": "Test Configuration Service",
      "description": "Automatically detects test frameworks in use and configures them without manual user intervention",
      "category": "component"
    },
    {
      "title": "LLM Integration Layer",
      "description": "Abstraction layer for integrating multiple AI providers with rate limiting, retry handling, and response parsing",
      "category": "component"
    },
    {
      "title": "Rate Limiter",
      "description": "Prevents exceeding API rate limits by throttling requests to AI providers",
      "category": "component"
    },
    {
      "title": "Retry Handler",
      "description": "Automatically retries failed AI requests with exponential backoff for transient errors",
      "category": "component"
    },
    {
      "title": "Response Parser",
      "description": "Extracts structured data from AI text responses into typed objects for file summaries, module summaries, and documentation",
      "category": "component"
    },
    {
      "title": "Configuration Manager",
      "description": "Manages all extension settings with type-safe access and automatic change detection",
      "category": "component"
    },
    {
      "title": "Navigation Handler",
      "description": "Handles jumping to code locations including files, functions, and API endpoints with detailed information display",
      "category": "component"
    },
    {
      "title": "Documentation Formatter",
      "description": "Transforms analysis and product information into well-structured Markdown documents",
      "category": "component"
    },
    {
      "title": "Prompt Builder",
      "description": "Constructs specialized prompts for different AI tasks including analysis, documentation, and test generation",
      "category": "component"
    },
    {
      "title": "File Cache",
      "description": "Caches file contents in memory to reduce disk I/O and improve performance",
      "category": "component"
    },
    {
      "title": "Analysis Result Repository",
      "description": "Manages saving and organizing analysis results to disk in timestamped directories",
      "category": "component"
    },
    {
      "title": "Progress Service",
      "description": "Displays standardized progress notifications during long-running operations with cancellation support",
      "category": "component"
    },
    {
      "title": "Test Generation Service",
      "description": "Generates unit tests for functions incrementally using AI with progress feedback",
      "category": "component"
    },
    {
      "title": "Test Planning Service",
      "description": "Analyzes code and creates prioritized test plans recommending which functions should be tested",
      "category": "component"
    },
    {
      "title": "Test Setup Service",
      "description": "Detects test environment and generates setup plans using AI analysis",
      "category": "component"
    },
    {
      "title": "Test Validation Service",
      "description": "Runs generated tests, captures failures, and automatically fixes failing tests using AI",
      "category": "component"
    },
    {
      "title": "Test Execution Service",
      "description": "Executes test suites across multiple frameworks and captures results",
      "category": "component"
    },
    {
      "title": "Enhanced Code Analyzer",
      "description": "Parses code to extract detailed function metadata including complexity, dependencies, and behavioral hints",
      "category": "component"
    },
    {
      "title": "Context Builder",
      "description": "Converts analysis data into formats suitable for AI consumption",
      "category": "component"
    }
  ],
  "relevantFunctions": [
    {
      "name": "analyzeWorkspace",
      "description": "Performs comprehensive analysis of entire workspace, detecting issues and generating insights",
      "file": "src/extension.ts",
      "module": "Extension"
    },
    {
      "name": "analyzeFile",
      "description": "Analyzes a single file for code quality issues and complexity metrics",
      "file": "src/extension.ts",
      "module": "Extension"
    },
    {
      "name": "generateInsights",
      "description": "Creates AI-powered architecture insights and recommendations from analysis results",
      "file": "src/llmIntegration.ts",
      "module": "LLM Integration"
    },
    {
      "name": "generateProductDocs",
      "description": "Produces product documentation describing application functionality from code analysis",
      "file": "src/llmIntegration.ts",
      "module": "LLM Integration"
    },
    {
      "name": "generateTests",
      "description": "Automatically creates unit tests for functions using AI analysis",
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "module": "Test Generation"
    },
    {
      "name": "planTests",
      "description": "Analyzes code and recommends which functions should be tested with priorities",
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "module": "Test Planning"
    },
    {
      "name": "validateTests",
      "description": "Runs generated tests and automatically fixes failures using AI",
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "module": "Test Validation"
    },
    {
      "name": "detectTestEnvironment",
      "description": "Identifies test framework in use and checks configuration completeness",
      "file": "src/domain/services/testConfigurationService.ts",
      "module": "Test Configuration"
    },
    {
      "name": "analyzeFunction",
      "description": "Extracts detailed metadata from functions including complexity and dependencies",
      "file": "src/analysis/functionAnalyzer.ts",
      "module": "Function Analyzer"
    },
    {
      "name": "generateRefactoringPlan",
      "description": "Creates step-by-step refactoring instructions for complex functions",
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "module": "Refactoring"
    },
    {
      "name": "navigateToLocation",
      "description": "Handles navigation to specific code locations with automatic scrolling",
      "file": "src/domain/handlers/navigationHandler.ts",
      "module": "Navigation"
    },
    {
      "name": "formatDocumentation",
      "description": "Transforms raw analysis into structured Markdown documentation",
      "file": "src/domain/formatters/documentationFormatter.ts",
      "module": "Documentation Formatting"
    },
    {
      "name": "handleRateLimit",
      "description": "Manages API rate limiting to prevent exceeding provider quotas",
      "file": "src/ai/llmRateLimiter.ts",
      "module": "Rate Limiting"
    },
    {
      "name": "retryWithBackoff",
      "description": "Automatically retries failed AI requests with exponential delay",
      "file": "src/ai/llmRetryHandler.ts",
      "module": "Retry Handling"
    },
    {
      "name": "parseResponse",
      "description": "Extracts structured data from AI-generated text responses",
      "file": "src/ai/llmResponseParser.ts",
      "module": "Response Parsing"
    },
    {
      "name": "watchFiles",
      "description": "Monitors workspace for file changes and triggers re-analysis",
      "file": "src/domain/services/fileWatcherService.ts",
      "module": "File Watching"
    },
    {
      "name": "processIncremental",
      "description": "Manages iterative analysis where AI requests additional context",
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "module": "Incremental Analysis"
    },
    {
      "name": "executeTests",
      "description": "Runs test suites and captures execution results",
      "file": "src/domain/services/testing/testExecutionService.ts",
      "module": "Test Execution"
    },
    {
      "name": "generateInsightsFromAnalysis",
      "description": "Identifies code quality issues and generates actionable recommendations",
      "file": "src/insightGenerator.ts",
      "module": "Insight Generation"
    },
    {
      "name": "exportForLLM",
      "description": "Formats analysis results for consumption by AI assistants like Cursor",
      "file": "src/llmFormatter.ts",
      "module": "LLM Formatting"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "AnalysisResult",
      "description": "Complete analysis results for a workspace including file metadata, dependencies, and insights",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FileAnalysis",
      "description": "Analysis data for a single file including functions, complexity, and quality metrics",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FunctionInfo",
      "description": "Metadata about a function including signature, complexity, dependencies, and behavioral hints",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "ProductDocumentation",
      "description": "Structured product documentation including overview, features, user perspective, and architecture",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "ArchitectureInsight",
      "description": "AI-generated insight about codebase architecture, patterns, or structure",
      "type": "interface",
      "file": "src/llmIntegration.ts"
    },
    {
      "name": "TestPlan",
      "description": "Prioritized plan for testing functions with recommendations and test areas",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestResult",
      "description": "Results of test execution including pass/fail counts, errors, and coverage data",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestSetupPlan",
      "description": "Plan for configuring test environment including frameworks, dependencies, and files",
      "type": "interface",
      "file": "src/domain/services/testing/types/testSetupTypes.ts"
    },
    {
      "name": "RefactoringPlan",
      "description": "Step-by-step plan for refactoring complex functions with extraction instructions",
      "type": "interface",
      "file": "src/domain/prompts/refactoringPromptBuilder.ts"
    },
    {
      "name": "Insight",
      "description": "Code quality insight describing an issue, severity, and recommendation",
      "type": "interface",
      "file": "src/insightGenerator.ts"
    },
    {
      "name": "LLMRequest",
      "description": "Request configuration for AI provider including prompt, schema, and timeout",
      "type": "interface",
      "file": "src/ai/providers/ILLMProvider.ts"
    },
    {
      "name": "LLMResponse",
      "description": "Response from AI provider with generated text or structured JSON",
      "type": "interface",
      "file": "src/ai/providers/ILLMProvider.ts"
    },
    {
      "name": "FileRequest",
      "description": "Request for specific file content during incremental analysis",
      "type": "interface",
      "file": "src/domain/services/incrementalAnalysisService.ts"
    },
    {
      "name": "GrepRequest",
      "description": "Request to search codebase for patterns during incremental analysis",
      "type": "interface",
      "file": "src/domain/services/incrementalAnalysisService.ts"
    },
    {
      "name": "DiagnosticInfo",
      "description": "Visual problem indicator with severity, message, and location",
      "type": "interface",
      "file": "src/diagnosticsProvider.ts"
    },
    {
      "name": "NavigationItem",
      "description": "Tree view item representing navigable code element with location and metadata",
      "type": "class",
      "file": "src/productNavigator.ts"
    },
    {
      "name": "AnalysisTreeItem",
      "description": "Tree view item representing analysis result or insight with hierarchy",
      "type": "class",
      "file": "src/analysisViewer.ts"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Main extension entry point that registers all commands and initializes components when VS Code activates the extension",
      "purpose": "Coordinates extension activation, command registration, and component initialization",
      "role": "Entry point and orchestrator"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "Manages all AI-powered features including documentation generation, insights creation, and analysis formatting",
      "purpose": "Integrates AI capabilities into the extension workflow",
      "role": "AI feature coordinator"
    },
    {
      "path": "src/llmService.ts",
      "description": "Core service for making AI requests, handling responses, and managing provider communication",
      "purpose": "Provides reliable AI request/response handling with error management",
      "role": "AI communication layer"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Defines data structures and interfaces for representing code analysis results throughout the system",
      "purpose": "Provides type definitions for analysis data",
      "role": "Type definitions"
    },
    {
      "path": "src/insightGenerator.ts",
      "description": "Analyzes code metrics to identify quality issues and generate actionable recommendations",
      "purpose": "Transforms analysis data into user-facing insights",
      "role": "Insight generation"
    },
    {
      "path": "src/analysisViewer.ts",
      "description": "Implements tree view for browsing complete analysis results in the sidebar",
      "purpose": "Provides hierarchical navigation of analysis data",
      "role": "UI component"
    },
    {
      "path": "src/insightsTreeView.ts",
      "description": "Implements tree view for displaying AI-generated insights and documentation",
      "purpose": "Shows AI-powered analysis results in navigable tree structure",
      "role": "UI component"
    },
    {
      "path": "src/productNavigator.ts",
      "description": "Implements tree view for navigating codebase structure organized by modules and components",
      "purpose": "Provides codebase exploration through hierarchical organization",
      "role": "UI component"
    },
    {
      "path": "src/diagnosticsProvider.ts",
      "description": "Creates and displays visual problem indicators in the editor and Problems panel",
      "purpose": "Shows code quality issues inline in the editor",
      "role": "UI component"
    },
    {
      "path": "src/domain/bootstrap/extensionBootstrapper.ts",
      "description": "Handles complete extension initialization including UI setup and command registration",
      "purpose": "Bootstraps all extension components during activation",
      "role": "Initialization"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Manages navigation to code locations and displays detailed information about code elements",
      "purpose": "Enables jumping to source code from tree views and listings",
      "role": "Navigation handler"
    },
    {
      "path": "src/domain/services/fileWatcherService.ts",
      "description": "Monitors workspace for file changes and triggers appropriate updates",
      "purpose": "Enables automatic re-analysis when code changes",
      "role": "File monitoring"
    },
    {
      "path": "src/domain/services/incrementalAnalysisService.ts",
      "description": "Manages multi-round analysis where AI requests additional context iteratively",
      "purpose": "Enables thorough analysis through iterative information gathering",
      "role": "Analysis orchestration"
    },
    {
      "path": "src/domain/services/testConfigurationService.ts",
      "description": "Automatically detects and configures test frameworks without manual setup",
      "purpose": "Eliminates manual test environment configuration",
      "role": "Test setup automation"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Generates unit tests for functions using AI with progress tracking",
      "purpose": "Automates test creation with AI assistance",
      "role": "Test generation"
    },
    {
      "path": "src/domain/services/testing/llmTestPlanningService.ts",
      "description": "Creates prioritized test plans recommending which functions need testing",
      "purpose": "Guides test coverage improvement with AI recommendations",
      "role": "Test planning"
    },
    {
      "path": "src/domain/services/testing/llmTestValidationService.ts",
      "description": "Validates generated tests and automatically fixes failures using AI",
      "purpose": "Ensures generated tests actually work correctly",
      "role": "Test validation"
    },
    {
      "path": "src/domain/services/testing/testExecutionService.ts",
      "description": "Executes test suites across multiple frameworks and captures results",
      "purpose": "Runs tests and reports execution outcomes",
      "role": "Test execution"
    },
    {
      "path": "src/analysis/enhancedAnalyzer.ts",
      "description": "Performs deep code analysis extracting function metadata, complexity, and dependencies",
      "purpose": "Provides detailed code quality metrics",
      "role": "Code analysis"
    },
    {
      "path": "src/analysis/functionAnalyzer.ts",
      "description": "Analyzes individual functions to extract signatures, dependencies, and refactoring candidates",
      "purpose": "Enables function-level analysis and refactoring guidance",
      "role": "Function analysis"
    },
    {
      "path": "src/domain/prompts/promptBuilder.ts",
      "description": "Constructs specialized AI prompts for different analysis and documentation tasks",
      "purpose": "Creates effective prompts that produce useful AI responses",
      "role": "Prompt engineering"
    },
    {
      "path": "src/domain/prompts/refactoringPromptBuilder.ts",
      "description": "Builds detailed refactoring plans with step-by-step extraction instructions",
      "purpose": "Guides complex refactoring with AI-generated plans",
      "role": "Refactoring guidance"
    },
    {
      "path": "src/domain/prompts/testPrompts.ts",
      "description": "Creates prompts for test generation, planning, and configuration analysis",
      "purpose": "Enables AI-powered test automation",
      "role": "Test prompt engineering"
    },
    {
      "path": "src/domain/formatters/documentationFormatter.ts",
      "description": "Transforms analysis results into well-structured Markdown documentation",
      "purpose": "Produces readable documentation from analysis data",
      "role": "Documentation formatting"
    },
    {
      "path": "src/ai/llmRateLimiter.ts",
      "description": "Manages API rate limiting to prevent exceeding provider quotas",
      "purpose": "Ensures reliable AI operations within rate limits",
      "role": "Rate limiting"
    },
    {
      "path": "src/ai/llmRetryHandler.ts",
      "description": "Automatically retries failed AI requests with intelligent backoff",
      "purpose": "Handles transient failures without user intervention",
      "role": "Retry logic"
    },
    {
      "path": "src/ai/llmResponseParser.ts",
      "description": "Extracts structured data from AI-generated text responses",
      "purpose": "Converts AI output into usable data structures",
      "role": "Response parsing"
    },
    {
      "path": "src/ai/providers/providerFactory.ts",
      "description": "Creates and manages AI provider instances based on configuration",
      "purpose": "Enables flexible AI provider selection",
      "role": "Provider management"
    },
    {
      "path": "src/config/configurationManager.ts",
      "description": "Manages all extension settings with type-safe access and change detection",
      "purpose": "Provides centralized configuration management",
      "role": "Configuration"
    },
    {
      "path": "src/infrastructure/persistence/analysisResultRepository.ts",
      "description": "Saves and organizes analysis results to disk in timestamped directories",
      "purpose": "Maintains historical record of analysis runs",
      "role": "Data persistence"
    },
    {
      "path": "src/infrastructure/progressService.ts",
      "description": "Displays standardized progress notifications during long-running operations",
      "purpose": "Provides consistent user feedback for async operations",
      "role": "Progress reporting"
    },
    {
      "path": "src/infrastructure/fileSystem/fileCache.ts",
      "description": "Caches file contents in memory to reduce redundant disk reads",
      "purpose": "Improves performance through intelligent caching",
      "role": "Performance optimization"
    },
    {
      "path": "src/infrastructure/fileSystem/fileProcessor.ts",
      "description": "Provides reusable framework for parallel file processing with filtering",
      "purpose": "Enables efficient batch file operations",
      "role": "File processing"
    }
  ],
  "exampleInput": {
    "description": "Example analysis configuration and code snippet submitted for analysis",
    "json": "{\"analysisType\":\"workspace\",\"config\":{\"analyzeOnSave\":true,\"aiProvider\":\"openai\",\"severityThreshold\":\"warning\",\"timeout\":300000},\"codeSnippet\":{\"file\":\"src/userService.ts\",\"content\":\"export class UserService {\\n  async getUser(id: string) {\\n    const user = await db.users.findOne(id);\\n    if (!user) throw new Error('Not found');\\n    return user;\\n  }\\n}\",\"language\":\"typescript\"}}"
  },
  "exampleOutput": {
    "description": "Example analysis result showing detected issues, insights, and documentation",
    "json": "{\"analysisId\":\"20240115-143022\",\"timestamp\":\"2024-01-15T14:30:22.000Z\",\"summary\":{\"filesAnalyzed\":147,\"functionsAnalyzed\":892,\"issuesFound\":23,\"testCoverage\":67.5},\"insights\":[{\"type\":\"complexity\",\"severity\":\"warning\",\"file\":\"src/orderProcessor.ts\",\"function\":\"processOrder\",\"message\":\"High complexity detected (15 branches)\",\"recommendation\":\"Consider extracting order validation logic into separate function\",\"line\":45}],\"documentation\":{\"overview\":\"User management system that handles authentication, authorization, and profile management\",\"features\":[\"User registration and login\",\"Role-based access control\",\"Profile editing and preferences\"],\"architecture\":\"Layered architecture with service, repository, and controller layers\"},\"refactoringRecommendations\":[{\"function\":\"processOrder\",\"priority\":\"high\",\"reason\":\"High complexity and multiple responsibilities\",\"steps\":[\"Extract validation logic\",\"Extract payment processing\",\"Extract notification logic\"]}],\"testResults\":{\"totalTests\":156,\"passed\":142,\"failed\":8,\"skipped\":6,\"coverage\":67.5,\"uncoveredFunctions\":[\"handlePaymentFailure\",\"retryOrder\"]}}}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Provides standardized Jest testing environment for TypeScript-based tests",
        "Enables code coverage tracking and reporting across the codebase",
        "Supports module path resolution and TypeScript transformation during test execution",
        "Configures test file discovery patterns and execution environment"
      ],
      "summary": "This module establishes the testing infrastructure for the project by configuring Jest as the testing framework. It enables developers to write and execute TypeScript tests with proper module resolution, transformation, and coverage reporting.\n\nThe configuration supports developers in validating code quality and functionality through automated testing. It defines how test files are discovered, how TypeScript code is transformed for execution, and how coverage metrics are collected and reported. This ensures consistent testing practices across the development workflow.\n\nWhile this is a configuration module with no direct user-facing features, it is essential for the development process, enabling quality assurance through automated testing, continuous integration pipelines, and code coverage analysis.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest testing framework for TypeScript test execution with coverage reporting and module resolution.",
          "userVisibleActions": [
            "No direct user-visible actions - this is a testing configuration file"
          ],
          "developerVisibleActions": [
            "Developer runs test suites located in src and UnitTests directories",
            "Developer views test coverage reports in text, lcov, and HTML formats",
            "Developer writes tests in TypeScript with .spec.ts or .test.ts extensions",
            "Developer sees test results with a 10 second timeout per test",
            "Developer gets code coverage metrics excluding test files, type definitions, and mock files"
          ],
          "keyFunctions": [],
          "dependencies": [
            "ts-jest",
            "jest",
            "typescript"
          ],
          "intent": "This file exists to configure the Jest testing framework for a TypeScript-based VSCode extension project, ensuring tests can be run with proper TypeScript compilation, module resolution (including VSCode API mocking), and coverage reporting to maintain code quality.",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript test execution with coverage reporting and module resolution.\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a testing configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer runs test suites located in src and UnitTests directories\",\n    \"Developer views test coverage reports in text, lcov, and HTML formats\",\n    \"Developer writes tests in TypeScript with .spec.ts or .test.ts extensions\",\n    \"Developer sees test results with a 10 second timeout per test\",\n    \"Developer gets code coverage metrics excluding test files, type definitions, and mock files\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript-based VSCode extension project, ensuring tests can be run with proper TypeScript compilation, module resolution (including VSCode API mocking), and coverage reporting to maintain code quality.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Automatically rate limits AI API requests to stay within OpenAI and Claude provider limits",
        "Intelligently retries failed AI requests with exponential backoff for transient errors",
        "Parses AI-generated responses into structured documentation formats",
        "Provides graceful error handling and fallback mechanisms for AI interactions",
        "Ensures smooth and reliable AI-powered documentation generation without manual intervention"
      ],
      "summary": "This module provides robust infrastructure for reliable AI interactions throughout the documentation generation process. It acts as a resilient middleware layer between the application and LLM providers (OpenAI, Claude), ensuring that AI requests complete successfully even in the face of rate limits, network issues, and temporary service disruptions.\n\nUsers benefit from automatic rate limiting that prevents API quota exhaustion, intelligent retry logic that handles transient failures without manual intervention, and smart response parsing that extracts structured data from AI-generated text. When AI requests fail due to rate limits or timeouts, the system automatically waits and retries with exponential backoff, while non-recoverable errors fail immediately to save time.\n\nThe module enables seamless AI-powered documentation workflows by handling the complexity of API communication, allowing users to generate file summaries, module summaries, and product documentation without worrying about rate limits, parsing errors, or temporary service interruptions. All AI interactions are automatically throttled, retried when appropriate, and parsed into usable structured formats.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Manages rate limiting for LLM API requests to prevent exceeding provider rate limits",
          "userVisibleActions": [
            "User's AI requests are automatically throttled to prevent API rate limit errors",
            "User experiences smooth AI interactions without hitting rate limit errors from OpenAI or Claude",
            "User's rapid successive AI requests are controlled to stay within provider limits"
          ],
          "developerVisibleActions": [
            "Developer can check if an AI request is allowed before making it to avoid rate limit errors",
            "Developer records each AI API request to track usage against rate limits",
            "Developer can configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)",
            "System automatically cleans up old request history outside the time window"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes rate limiter with default limits for OpenAI (60 req/min) and Claude (50 req/min)",
              "inputs": "none",
              "outputs": "RateLimiter instance"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limit configuration for a specific LLM provider",
              "inputs": "provider (openai or claude), config (maxRequests and windowMs)",
              "outputs": "void"
            },
            {
              "name": "canMakeRequest",
              "desc": "Checks if a new request can be made without exceeding the rate limit",
              "inputs": "provider (openai or claude)",
              "outputs": "boolean (true if request allowed, false if rate limited)"
            },
            {
              "name": "recordRequest",
              "desc": "Records timestamp of a completed request for rate limit tracking",
              "inputs": "provider (openai or claude)",
              "outputs": "void"
            }
          ],
          "dependencies": [],
          "intent": "Prevents the application from exceeding LLM provider API rate limits by tracking request frequency per provider, protecting against rate limit errors and potential API access suspension",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages rate limiting for LLM API requests to prevent exceeding provider rate limits\",\n  \"userVisibleActions\": [\n    \"User's AI requests are automatically throttled to prevent API rate limit errors\",\n    \"User experiences smooth AI interactions without hitting rate limit errors from OpenAI or Claude\",\n    \"User's rapid successive AI requests are controlled to stay within provider limits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can check if an AI request is allowed before making it to avoid rate limit errors\",\n    \"Developer records each AI API request to track usage against rate limits\",\n    \"Developer can configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)\",\n    \"System automatically cleans up old request history outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits for OpenAI (60 req/min) and Claude (50 req/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (openai or claude), config (maxRequests and windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request can be made without exceeding the rate limit\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"boolean (true if request allowed, false if rate limited)\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records timestamp of a completed request for rate limit tracking\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Prevents the application from exceeding LLM provider API rate limits by tracking request frequency per provider, protecting against rate limit errors and potential API access suspension\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Parses and extracts structured data from LLM text responses into typed objects for file summaries, module summaries, and product documentation.",
          "userVisibleActions": [
            "Converts AI-generated text responses into structured documentation format",
            "Extracts meaningful information from AI responses even when JSON parsing fails",
            "Provides fallback text extraction when AI responses are not in expected format"
          ],
          "developerVisibleActions": [
            "Call parseFileSummary() to convert LLM text into FileSummary object with file path, role, purpose, actions, and dependencies",
            "Call parseModuleSummary() to convert LLM text into ModuleSummary object with module overview and file relationships",
            "Call parseProductDocumentation() to convert LLM text into EnhancedProductDocumentation with product purpose, features, and user flows",
            "Call parseLLMInsights() to extract analysis insights about product behavior and architecture",
            "Call parseProductPurposeAnalysis() to get structured product purpose information",
            "Automatically handles both JSON-formatted and plain text LLM responses",
            "Receives original LLM response content plus metadata like file paths and roles",
            "Gets structured objects back with typed fields ready for documentation generation"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into FileSummary object with file metadata, purpose, actions, and dependencies",
              "inputs": "content (string), filePath (string), role (string)",
              "outputs": "FileSummary object"
            },
            {
              "name": "parseModuleSummary",
              "desc": "Converts LLM response text into ModuleSummary object with module overview and file relationships",
              "inputs": "content (string)",
              "outputs": "ModuleSummary object"
            },
            {
              "name": "parseProductDocumentation",
              "desc": "Converts LLM response text into EnhancedProductDocumentation with complete product information",
              "inputs": "content (string)",
              "outputs": "EnhancedProductDocumentation object"
            },
            {
              "name": "parseLLMInsights",
              "desc": "Extracts LLM analysis insights about product behavior and architecture from response text",
              "inputs": "content (string)",
              "outputs": "LLMInsights object"
            },
            {
              "name": "parseProductPurposeAnalysis",
              "desc": "Extracts structured product purpose information from LLM response",
              "inputs": "content (string)",
              "outputs": "ProductPurposeAnalysis object"
            },
            {
              "name": "extractSection",
              "desc": "Helper that extracts a specific named section from text content",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Extracted section text as string"
            },
            {
              "name": "extractListSection",
              "desc": "Helper that extracts a list of items from a named section in text",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Array of strings"
            }
          ],
          "dependencies": [
            "../fileDocumentation",
            "../llmService"
          ],
          "intent": "This file exists to reliably transform free-form AI-generated text responses into consistent, typed data structures that the application can use programmatically. It solves the problem of working with unpredictable LLM output formats by providing intelligent parsing with JSON fallback to text extraction, ensuring the application always gets usable structured data regardless of how the AI formats its response.",
          "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into typed objects for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"Converts AI-generated text responses into structured documentation format\",\n    \"Extracts meaningful information from AI responses even when JSON parsing fails\",\n    \"Provides fallback text extraction when AI responses are not in expected format\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM text into FileSummary object with file path, role, purpose, actions, and dependencies\",\n    \"Call parseModuleSummary() to convert LLM text into ModuleSummary object with module overview and file relationships\",\n    \"Call parseProductDocumentation() to convert LLM text into EnhancedProductDocumentation with product purpose, features, and user flows\",\n    \"Call parseLLMInsights() to extract analysis insights about product behavior and architecture\",\n    \"Call parseProductPurposeAnalysis() to get structured product purpose information\",\n    \"Automatically handles both JSON-formatted and plain text LLM responses\",\n    \"Receives original LLM response content plus metadata like file paths and roles\",\n    \"Gets structured objects back with typed fields ready for documentation generation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into FileSummary object with file metadata, purpose, actions, and dependencies\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Converts LLM response text into ModuleSummary object with module overview and file relationships\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Converts LLM response text into EnhancedProductDocumentation with complete product information\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts LLM analysis insights about product behavior and architecture from response text\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductPurposeAnalysis\",\n      \"desc\": \"Extracts structured product purpose information from LLM response\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Helper that extracts a specific named section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted section text as string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Helper that extracts a list of items from a named section in text\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to reliably transform free-form AI-generated text responses into consistent, typed data structures that the application can use programmatically. It solves the problem of working with unpredictable LLM output formats by providing intelligent parsing with JSON fallback to text extraction, ensuring the application always gets usable structured data regardless of how the AI formats its response.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles automatic retries of failed LLM API requests with exponential backoff and intelligent error classification",
          "userVisibleActions": [
            "When LLM API requests fail temporarily, they automatically retry without user intervention",
            "Users experience fewer failures from rate limits, timeouts, and temporary network issues",
            "Failed requests wait progressively longer between retries to avoid overwhelming the API",
            "Non-recoverable errors fail immediately instead of wasting time retrying"
          ],
          "developerVisibleActions": [
            "Wrap any LLM API call with retry logic to handle transient failures automatically",
            "Configure retry behavior (max attempts, delays, backoff multiplier)",
            "Specify which error types should trigger retries vs fail immediately",
            "Receive callbacks on each retry attempt to log or monitor retry behavior",
            "Get final result with total number of attempts made"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an async operation with automatic retry logic and exponential backoff",
              "inputs": "operation function that returns a Promise, optional retry configuration (maxRetries, delays, error types, callback)",
              "outputs": "Promise resolving to operation result along with number of attempts made"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines if an error should trigger a retry or fail immediately",
              "inputs": "error object, list of retryable error patterns",
              "outputs": "boolean indicating whether the error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, timeouts, network issues) through intelligent retry logic, preventing unnecessary failures while avoiding infinite retry loops on permanent errors",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of failed LLM API requests with exponential backoff and intelligent error classification\",\n  \"userVisibleActions\": [\n    \"When LLM API requests fail temporarily, they automatically retry without user intervention\",\n    \"Users experience fewer failures from rate limits, timeouts, and temporary network issues\",\n    \"Failed requests wait progressively longer between retries to avoid overwhelming the API\",\n    \"Non-recoverable errors fail immediately instead of wasting time retrying\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic to handle transient failures automatically\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries vs fail immediately\",\n    \"Receive callbacks on each retry attempt to log or monitor retry behavior\",\n    \"Get final result with total number of attempts made\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation function that returns a Promise, optional retry configuration (maxRetries, delays, error types, callback)\",\n      \"outputs\": \"Promise resolving to operation result along with number of attempts made\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry or fail immediately\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating whether the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, timeouts, network issues) through intelligent retry logic, preventing unnecessary failures while avoiding infinite retry loops on permanent errors\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Provides unified interface for multiple AI language model providers (OpenAI and Anthropic Claude)",
        "Generates text responses from AI models based on user prompts",
        "Produces structured JSON outputs from AI models using defined schemas",
        "Automatically selects and initializes the configured AI provider",
        "Handles provider configuration validation and error reporting",
        "Enforces 5-minute timeout protection for long-running AI requests"
      ],
      "summary": "This module serves as the AI provider abstraction layer, enabling the application to integrate with multiple AI language model services through a unified interface. Users interact with AI capabilities without needing to know which provider (OpenAI or Claude) is being used behind the scenes. The module automatically instantiates the appropriate provider based on system configuration and API key availability.\n\nUsers can generate both free-form text responses and structured JSON outputs from AI models. When requesting AI assistance, prompts are routed through the configured provider, which handles the underlying API communication and response formatting. The module ensures reliable operation by validating provider configuration, managing timeouts, and providing clear error messages when API keys are missing or invalid.\n\nThe provider factory pattern allows seamless switching between AI services, giving system administrators flexibility in choosing their preferred AI backend while maintaining consistent functionality for end users. All AI interactions are protected by a 5-minute timeout to prevent indefinite waiting, and the system gracefully handles scenarios where providers are not properly configured.",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system",
          "userVisibleActions": [
            "User receives text responses from AI models through any configured provider",
            "User receives structured JSON responses from AI models for data parsing",
            "User gets appropriate error handling when AI provider is not configured"
          ],
          "developerVisibleActions": [
            "Developer implements this interface to add support for new AI providers",
            "Developer sends text prompts with optional system instructions and conversation history",
            "Developer requests structured JSON output with optional schema validation",
            "Developer checks if a provider is properly configured before use",
            "Developer controls AI behavior via temperature and token limits",
            "Developer receives file and grep requests from AI responses for code exploration"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if the AI provider has valid credentials and is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt with messages to the AI and gets back a text response",
              "inputs": "LLMRequestOptions with model, messages, system prompt, temperature, max tokens",
              "outputs": "LLMResponse with content string and metadata"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt and gets back parsed JSON data with optional follow-up requests",
              "inputs": "LLMRequestOptions and optional JSON schema for validation",
              "outputs": "StructuredOutputResponse with typed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the identifier name of the provider",
              "inputs": "none",
              "outputs": "string with provider name"
            }
          ],
          "dependencies": [],
          "intent": "This interface exists to provide a unified abstraction layer over different AI language model providers (like OpenAI, Claude, or custom models), allowing the application to switch between providers or use multiple providers without changing the consuming code. It solves the problem of vendor lock-in and enables flexible AI provider selection while maintaining consistent request/response handling across all implementations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system\",\n  \"userVisibleActions\": [\n    \"User receives text responses from AI models through any configured provider\",\n    \"User receives structured JSON responses from AI models for data parsing\",\n    \"User gets appropriate error handling when AI provider is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add support for new AI providers\",\n    \"Developer sends text prompts with optional system instructions and conversation history\",\n    \"Developer requests structured JSON output with optional schema validation\",\n    \"Developer checks if a provider is properly configured before use\",\n    \"Developer controls AI behavior via temperature and token limits\",\n    \"Developer receives file and grep requests from AI responses for code exploration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the AI provider has valid credentials and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt with messages to the AI and gets back a text response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, system prompt, temperature, max tokens\",\n      \"outputs\": \"LLMResponse with content string and metadata\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt and gets back parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema for validation\",\n      \"outputs\": \"StructuredOutputResponse with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name of the provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to provide a unified abstraction layer over different AI language model providers (like OpenAI, Claude, or custom models), allowing the application to switch between providers or use multiple providers without changing the consuming code. It solves the problem of vendor lock-in and enables flexible AI provider selection while maintaining consistent request/response handling across all implementations.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with Anthropic's Claude AI models for text generation and structured output requests",
          "userVisibleActions": [
            "Sends prompts to Claude AI and receives text responses",
            "Generates structured JSON outputs from Claude based on schemas",
            "Receives error messages when Claude API is not configured",
            "Experiences 5-minute timeout for long-running requests"
          ],
          "developerVisibleActions": [
            "Configure Claude API key through configuration manager",
            "Send text generation requests with custom prompts and parameters",
            "Request structured JSON outputs by providing JSON schemas",
            "Receive responses with content and token usage information",
            "Handle provider availability checks before making requests",
            "Access Claude-specific models like claude-sonnet-4-5"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is configured and provider is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a text generation request to Claude with messages and system prompt",
              "inputs": "LLMRequestOptions (messages, model, systemPrompt, maxTokens)",
              "outputs": "LLMResponse with content and token usage"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Requests Claude to generate output matching a specific JSON schema",
              "inputs": "LLMRequestOptions with jsonSchema",
              "outputs": "StructuredOutputResponse with parsed JSON object"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier name",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Anthropic client with API key from configuration",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to enable the application to use Anthropic's Claude AI models as an alternative to OpenAI, providing AI-powered text generation and structured output capabilities with Claude-specific message formatting and API integration",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for text generation and structured output requests\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives text responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Receives error messages when Claude API is not configured\",\n    \"Experiences 5-minute timeout for long-running requests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through configuration manager\",\n    \"Send text generation requests with custom prompts and parameters\",\n    \"Request structured JSON outputs by providing JSON schemas\",\n    \"Receive responses with content and token usage information\",\n    \"Handle provider availability checks before making requests\",\n    \"Access Claude-specific models like claude-sonnet-4-5\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text generation request to Claude with messages and system prompt\",\n      \"inputs\": \"LLMRequestOptions (messages, model, systemPrompt, maxTokens)\",\n      \"outputs\": \"LLMResponse with content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests Claude to generate output matching a specific JSON schema\",\n      \"inputs\": \"LLMRequestOptions with jsonSchema\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON object\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier name\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to enable the application to use Anthropic's Claude AI models as an alternative to OpenAI, providing AI-powered text generation and structured output capabilities with Claude-specific message formatting and API integration\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with OpenAI's API to send chat completion requests and receive AI-generated responses",
          "userVisibleActions": [
            "Receives AI-generated text responses from OpenAI models (like GPT-4)",
            "Gets structured JSON responses when requesting formatted output",
            "Experiences timeout after 5 minutes if AI response takes too long",
            "Sees error messages when OpenAI API key is not configured"
          ],
          "developerVisibleActions": [
            "Configure OpenAI API key through configuration manager to enable the provider",
            "Send chat completion requests with system prompts and conversation messages",
            "Request structured JSON output by specifying response format",
            "Check if provider is configured before making requests",
            "Receive responses with content, finish reason, and token usage information",
            "Handle errors when API key is missing or requests fail"
          ],
          "keyFunctions": [
            {
              "name": "initialize",
              "desc": "Sets up the OpenAI client with API key from configuration",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "isConfigured",
              "desc": "Checks if the provider has a valid API key and is ready to use",
              "inputs": "None",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "None",
              "outputs": "string 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a chat completion request to OpenAI and returns the response",
              "inputs": "LLMRequestOptions (model, messages, system prompt, response format)",
              "outputs": "Promise<LLMResponse> with content, finish reason, and usage"
            },
            {
              "name": "sendRequestStructured",
              "desc": "Sends a request expecting structured JSON output and parses the result",
              "inputs": "LLMRequestOptions with json_object response format",
              "outputs": "Promise<StructuredOutputResponse> with parsed JSON data and raw content"
            }
          ],
          "dependencies": [
            "openai",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to abstract OpenAI's API behind a common provider interface, allowing the application to send AI requests and receive responses while handling configuration, error cases, and both text and structured JSON outputs consistently with other AI providers",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with OpenAI's API to send chat completion requests and receive AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses from OpenAI models (like GPT-4)\",\n    \"Gets structured JSON responses when requesting formatted output\",\n    \"Experiences timeout after 5 minutes if AI response takes too long\",\n    \"Sees error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager to enable the provider\",\n    \"Send chat completion requests with system prompts and conversation messages\",\n    \"Request structured JSON output by specifying response format\",\n    \"Check if provider is configured before making requests\",\n    \"Receive responses with content, finish reason, and token usage information\",\n    \"Handle errors when API key is missing or requests fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has a valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, system prompt, response format)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, and usage\"\n    },\n    {\n      \"name\": \"sendRequestStructured\",\n      \"desc\": \"Sends a request expecting structured JSON output and parses the result\",\n      \"inputs\": \"LLMRequestOptions with json_object response format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data and raw content\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI's API behind a common provider interface, allowing the application to send AI requests and receive responses while handling configuration, error cases, and both text and structured JSON outputs consistently with other AI providers\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Creates and manages AI language model provider instances (OpenAI and Claude) based on configuration",
          "userVisibleActions": [
            "AI responses come from the configured provider (OpenAI or Claude)",
            "System automatically uses the provider specified in settings",
            "AI features only work when at least one provider is properly configured with API keys"
          ],
          "developerVisibleActions": [
            "Request an AI provider instance by name ('openai' or 'claude')",
            "Get the currently configured provider without specifying which one",
            "Check if a specific provider has valid configuration/API keys",
            "Retrieve a list of all properly configured providers available for use",
            "Provider instances are reused (singleton pattern) to avoid recreating connections"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns a provider instance for the specified AI service",
              "inputs": "provider type ('openai' or 'claude')",
              "outputs": "ILLMProvider instance for making AI requests"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the provider instance that matches the user's current configuration setting",
              "inputs": "none (reads from config)",
              "outputs": "ILLMProvider instance of the configured provider"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks whether a specific provider has valid configuration and can be used",
              "inputs": "provider type ('openai' or 'claude')",
              "outputs": "boolean indicating if the provider is ready to use"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns a list of all providers that are properly configured and available",
              "inputs": "none",
              "outputs": "array of provider names that have valid configuration"
            }
          ],
          "dependencies": [
            "ILLMProvider",
            "OpenAIProvider",
            "AnthropicProvider",
            "configurationManager"
          ],
          "intent": "Centralizes AI provider creation and management so the rest of the application doesn't need to know which AI service is being used or handle provider instantiation - it acts as a single point of access for all AI providers and ensures only one instance of each provider exists throughout the application lifecycle",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI language model provider instances (OpenAI and Claude) based on configuration\",\n  \"userVisibleActions\": [\n    \"AI responses come from the configured provider (OpenAI or Claude)\",\n    \"System automatically uses the provider specified in settings\",\n    \"AI features only work when at least one provider is properly configured with API keys\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request an AI provider instance by name ('openai' or 'claude')\",\n    \"Get the currently configured provider without specifying which one\",\n    \"Check if a specific provider has valid configuration/API keys\",\n    \"Retrieve a list of all properly configured providers available for use\",\n    \"Provider instances are reused (singleton pattern) to avoid recreating connections\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a provider instance for the specified AI service\",\n      \"inputs\": \"provider type ('openai' or 'claude')\",\n      \"outputs\": \"ILLMProvider instance for making AI requests\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the provider instance that matches the user's current configuration setting\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"ILLMProvider instance of the configured provider\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks whether a specific provider has valid configuration and can be used\",\n      \"inputs\": \"provider type ('openai' or 'claude')\",\n      \"outputs\": \"boolean indicating if the provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all providers that are properly configured and available\",\n      \"inputs\": \"none\",\n      \"outputs\": \"array of provider names that have valid configuration\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and management so the rest of the application doesn't need to know which AI service is being used or handle provider instantiation - it acts as a single point of access for all AI providers and ensures only one instance of each provider exists throughout the application lifecycle\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Analyze TypeScript and JavaScript code files to extract detailed function metadata",
        "Calculate code complexity metrics including branch complexity and decision points",
        "Map function dependencies and relationships across the codebase",
        "Identify state mutations and side effects in functions",
        "Extract behavioral hints and function responsibilities",
        "Detect functions that may need refactoring based on size and complexity",
        "Track which functions are called by many other parts of the code (dependents)",
        "Parse function signatures and parameter information"
      ],
      "summary": "The analysis module provides comprehensive code analysis capabilities for TypeScript and JavaScript projects. It enables users to gain deep insights into their codebase by examining function-level details, complexity metrics, and inter-function relationships. This module is essential for understanding code quality, identifying refactoring opportunities, and mapping dependencies.\n\nUsers can leverage this module to analyze individual functions or entire files to understand code complexity through branch analysis, track how functions interact through dependency mapping, and identify potential code smells. The module extracts metadata such as function signatures, parameters, return types, and behavioral characteristics like state mutations and side effects.\n\nThe typical workflow involves passing source code files to the analyzers, which parse the Abstract Syntax Tree (AST) to extract function metadata. The enhanced analyzer provides detailed complexity metrics and behavioral insights, while the function analyzer focuses on relationships and refactoring candidates. Together, these tools help developers make informed decisions about code maintenance, refactoring priorities, and architectural improvements.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Provides deep code analysis capabilities by parsing TypeScript/JavaScript files to extract function metadata, including branch complexity, dependencies, state mutations, and behavioral hints",
          "userVisibleActions": [
            "Receives detailed analysis of code functions including complexity metrics",
            "Gets insights into function behavior and side effects",
            "Views branch analysis showing decision points in code",
            "Sees dependency relationships between functions and modules",
            "Obtains state mutation information showing what data changes"
          ],
          "developerVisibleActions": [
            "Call analyzeFileMetadata() to extract comprehensive metadata for all functions in a file",
            "Receive FunctionMetadata objects containing branch analysis, dependency info, state mutations, and behavioral hints",
            "Get AST-based analysis for TypeScript/JavaScript files with full type information",
            "Fallback to regex-based analysis for non-TypeScript languages",
            "Extract function content by line ranges for targeted analysis",
            "Analyze function complexity, conditional branches, and control flow",
            "Identify external dependencies and function calls within code",
            "Detect state mutations and side effects in functions",
            "Map test coverage and relationships to test files"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and mutations",
              "inputs": "filePath: string, content: string, language: string, functions: FunctionInfo[]",
              "outputs": "Promise<Map<string, FunctionMetadata>> - Map of function names to their detailed metadata"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed structural and behavioral information",
              "inputs": "filePath: string, content: string, func: FunctionInfo, functionContent: string",
              "outputs": "Promise<FunctionMetadata> - Comprehensive function metadata"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Provides fallback regex-based analysis for non-TypeScript languages to extract basic function metadata",
              "inputs": "filePath: string, func: FunctionInfo, functionContent: string, language: string",
              "outputs": "FunctionMetadata - Basic function metadata"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the source code content of a function given its start and end line numbers",
              "inputs": "content: string, startLine: number, endLine: number",
              "outputs": "string - The function's source code"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer"
          ],
          "intent": "This file exists to provide advanced code analysis beyond basic function detection. It solves the problem of understanding code behavior, complexity, and relationships by parsing Abstract Syntax Trees (AST) to extract branch conditions, dependencies, state changes, and behavioral patterns. This enables intelligent code documentation, test generation, and impact analysis by understanding not just what functions exist, but how they work and what they affect.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities by parsing TypeScript/JavaScript files to extract function metadata, including branch complexity, dependencies, state mutations, and behavioral hints\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including complexity metrics\",\n    \"Gets insights into function behavior and side effects\",\n    \"Views branch analysis showing decision points in code\",\n    \"Sees dependency relationships between functions and modules\",\n    \"Obtains state mutation information showing what data changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzeFileMetadata() to extract comprehensive metadata for all functions in a file\",\n    \"Receive FunctionMetadata objects containing branch analysis, dependency info, state mutations, and behavioral hints\",\n    \"Get AST-based analysis for TypeScript/JavaScript files with full type information\",\n    \"Fallback to regex-based analysis for non-TypeScript languages\",\n    \"Extract function content by line ranges for targeted analysis\",\n    \"Analyze function complexity, conditional branches, and control flow\",\n    \"Identify external dependencies and function calls within code\",\n    \"Detect state mutations and side effects in functions\",\n    \"Map test coverage and relationships to test files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and mutations\",\n      \"inputs\": \"filePath: string, content: string, language: string, functions: FunctionInfo[]\",\n      \"outputs\": \"Promise<Map<string, FunctionMetadata>> - Map of function names to their detailed metadata\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed structural and behavioral information\",\n      \"inputs\": \"filePath: string, content: string, func: FunctionInfo, functionContent: string\",\n      \"outputs\": \"Promise<FunctionMetadata> - Comprehensive function metadata\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for non-TypeScript languages to extract basic function metadata\",\n      \"inputs\": \"filePath: string, func: FunctionInfo, functionContent: string, language: string\",\n      \"outputs\": \"FunctionMetadata - Basic function metadata\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function given its start and end line numbers\",\n      \"inputs\": \"content: string, startLine: number, endLine: number\",\n      \"outputs\": \"string - The function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced code analysis beyond basic function detection. It solves the problem of understanding code behavior, complexity, and relationships by parsing Abstract Syntax Trees (AST) to extract branch conditions, dependencies, state changes, and behavioral patterns. This enables intelligent code documentation, test generation, and impact analysis by understanding not just what functions exist, but how they work and what they affect.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, dependents, and responsibilities for refactoring reports.",
          "userVisibleActions": [
            "Identifies which functions in large files may need refactoring",
            "Shows function dependencies and relationships across the codebase",
            "Reveals which functions are called by many other parts of the code",
            "Displays function signatures and their responsibilities"
          ],
          "developerVisibleActions": [
            "Filters code analysis to focus on files exceeding a size threshold (default 500 lines)",
            "Extracts function metadata from TypeScript files including name, signature, and location",
            "Maps out which functions depend on other functions (dependencies)",
            "Identifies which functions are called by the analyzed function (dependents)",
            "Generates structured function analysis data for refactoring prompt builders",
            "Handles analysis failures gracefully with warnings for individual functions"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in large files to extract detailed information for refactoring",
              "inputs": "codeAnalysis (full code analysis), largeFileThreshold (minimum lines, default 500)",
              "outputs": "Array of FunctionAnalysis objects with detailed metadata"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs deep analysis on a single function to extract dependencies, dependents, and metadata",
              "inputs": "filePath (file location), func (FunctionInfo), codeAnalysis (context)",
              "outputs": "FunctionAnalysis object or null if analysis fails"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves relative file paths to absolute paths for file system access",
              "inputs": "filePath (relative path), codeAnalysis (for base directory)",
              "outputs": "Absolute file path string"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to provide deep function-level analysis for large files that may need refactoring. It solves the problem of understanding complex function relationships and responsibilities when deciding how to break up large code files. By extracting detailed metadata about each function's dependencies, callers, and purpose, it enables automated generation of refactoring recommendations and reports.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, dependents, and responsibilities for refactoring reports.\",\n  \"userVisibleActions\": [\n    \"Identifies which functions in large files may need refactoring\",\n    \"Shows function dependencies and relationships across the codebase\",\n    \"Reveals which functions are called by many other parts of the code\",\n    \"Displays function signatures and their responsibilities\"\n  ],\n  \"developerVisibleActions\": [\n    \"Filters code analysis to focus on files exceeding a size threshold (default 500 lines)\",\n    \"Extracts function metadata from TypeScript files including name, signature, and location\",\n    \"Maps out which functions depend on other functions (dependencies)\",\n    \"Identifies which functions are called by the analyzed function (dependents)\",\n    \"Generates structured function analysis data for refactoring prompt builders\",\n    \"Handles analysis failures gracefully with warnings for individual functions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in large files to extract detailed information for refactoring\",\n      \"inputs\": \"codeAnalysis (full code analysis), largeFileThreshold (minimum lines, default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects with detailed metadata\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs deep analysis on a single function to extract dependencies, dependents, and metadata\",\n      \"inputs\": \"filePath (file location), func (FunctionInfo), codeAnalysis (context)\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file system access\",\n      \"inputs\": \"filePath (relative path), codeAnalysis (for base directory)\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep function-level analysis for large files that may need refactoring. It solves the problem of understanding complex function relationships and responsibilities when deciding how to break up large code files. By extracting detailed metadata about each function's dependencies, callers, and purpose, it enables automated generation of refactoring recommendations and reports.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "Automated code analysis and quality assessment across entire workspace or individual files",
        "AI-powered architecture insights and documentation generation using LLM providers (OpenAI/Claude)",
        "Real-time code diagnostics and visual problem indicators in editor and Problems panel",
        "Interactive tree views for browsing analysis results, insights, and documentation hierarchy",
        "Automatic file watching and analysis on save with intelligent caching",
        "Code health monitoring including complexity metrics, orphaned files, and duplicate detection",
        "Test coverage tracking and identification of uncovered functions",
        "Multiple export formats (Markdown, JSON) for analysis results and documentation",
        "LLM-optimized formatting for integration with Cursor AI, ChatGPT, and other AI assistants",
        "Intelligent file access and search capabilities for LLM agent exploration"
      ],
      "summary": "This module provides a comprehensive VS Code extension for AI-powered code analysis and documentation. Users can analyze their entire codebase or individual files to understand structure, quality, and architecture. The extension automatically detects code issues like large files, high complexity functions, circular dependencies, orphaned code, and missing test coverage, presenting findings through visual diagnostics, interactive tree views, and structured reports.\n\nThe extension integrates with LLM providers to generate intelligent architecture insights, product documentation, and refactoring suggestions. Users see real-time analysis updates through multiple interactive views including an analysis browser, insights tree, and product navigator. All analysis results can be exported in various formats optimized for different LLM interfaces. The extension features automatic file watching that triggers analysis on save, with intelligent caching to avoid redundant processing.\n\nKey workflows include: (1) Analyzing workspace to get comprehensive code health metrics and insights, (2) Viewing diagnostics as color-coded problems in the editor with hover tooltips, (3) Browsing hierarchical analysis results through sidebar tree views with click-to-navigate functionality, (4) Generating AI-powered documentation and architecture insights with progress tracking, (5) Exporting results in formats optimized for AI assistants like Cursor or ChatGPT, and (6) Navigating codebase through product navigator showing modules, components, and entry points.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree-view interface for browsing and exploring code analysis results in the VSCode sidebar",
          "userVisibleActions": [
            "View a hierarchical tree of code analysis results in the sidebar",
            "Browse analysis statistics (total files, lines of code, functions count)",
            "Explore files organized by directory structure",
            "View individual file details (LOC, complexity, functions)",
            "See all functions across the codebase with their signatures",
            "Browse entry points (main functions, exports) in the code",
            "Click on items to jump to specific locations in source files",
            "See message 'No analysis available' when no analysis has been run",
            "Refresh the tree view to see updated analysis results"
          ],
          "developerVisibleActions": [
            "Instantiate AnalysisViewerProvider to create the tree view",
            "Call setAnalysis() to populate the tree with analysis data",
            "Call refresh() to update the tree view display",
            "Implement vscode.TreeDataProvider interface for VSCode integration",
            "Subscribe to onDidChangeTreeData events for tree updates",
            "Tree items are clickable and navigate to source code locations",
            "Tree displays nested categories: statistics, files, functions, entry points"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the tree view with new code analysis results",
              "inputs": "analysis: CodeAnalysis | null",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a refresh of the entire tree view display",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the tree item representation for display in the view",
              "inputs": "element: AnalysisItem",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node or root items if no element provided",
              "inputs": "element?: AnalysisItem",
              "outputs": "Thenable<AnalysisItem[]>"
            },
            {
              "name": "getRootItems",
              "desc": "Generates top-level categories shown in the tree (statistics, files, functions, entry points)",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Creates tree items showing code metrics like file count, LOC, function count",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFilesItems",
              "desc": "Organizes files into a directory tree structure for browsing",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFileDetails",
              "desc": "Shows detailed information about a specific file (functions, complexity, LOC)",
              "inputs": "element: AnalysisItem",
              "outputs": "AnalysisItem[]"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)"
          ],
          "intent": "This file exists to provide a visual, interactive way for users to explore code analysis results directly within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree-view interface, allowing users to drill down from high-level statistics to specific files and functions, and jump directly to source code locations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree-view interface for browsing and exploring code analysis results in the VSCode sidebar\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"Browse analysis statistics (total files, lines of code, functions count)\",\n    \"Explore files organized by directory structure\",\n    \"View individual file details (LOC, complexity, functions)\",\n    \"See all functions across the codebase with their signatures\",\n    \"Browse entry points (main functions, exports) in the code\",\n    \"Click on items to jump to specific locations in source files\",\n    \"See message 'No analysis available' when no analysis has been run\",\n    \"Refresh the tree view to see updated analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Instantiate AnalysisViewerProvider to create the tree view\",\n    \"Call setAnalysis() to populate the tree with analysis data\",\n    \"Call refresh() to update the tree view display\",\n    \"Implement vscode.TreeDataProvider interface for VSCode integration\",\n    \"Subscribe to onDidChangeTreeData events for tree updates\",\n    \"Tree items are clickable and navigate to source code locations\",\n    \"Tree displays nested categories: statistics, files, functions, entry points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new code analysis results\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the entire tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display in the view\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level categories shown in the tree (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing code metrics like file count, LOC, function count\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes files into a directory tree structure for browsing\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Shows detailed information about a specific file (functions, complexity, LOC)\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive way for users to explore code analysis results directly within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree-view interface, allowing users to drill down from high-level statistics to specific files and functions, and jump directly to source code locations.\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
          "userVisibleActions": [
            "View total file count, line count, and function count in codebase",
            "See list of large files that may need refactoring",
            "Identify orphaned files not imported anywhere",
            "Discover entry points (main files) in the project",
            "Find duplicate code blocks across files",
            "View function complexity and risk levels",
            "See test coverage mapping for source files",
            "Identify uncovered functions without tests"
          ],
          "developerVisibleActions": [
            "Import and use CodeAnalysis interface to structure analysis results",
            "Access file-level metrics (lines, functions, complexity)",
            "Query function metadata including parameters, return types, and visibility",
            "Retrieve branch information (if/else, loops, try/catch)",
            "Track dependencies by type (database, HTTP, filesystem, etc.)",
            "Monitor state mutations (assignments, modifications, deletions)",
            "Map source files to their test files",
            "Identify functions missing test coverage",
            "Access cached analysis results for performance",
            "Determine risk levels for functions based on complexity"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main interface containing complete analysis results for a codebase",
              "inputs": "none (interface/type definition)",
              "outputs": "Structure with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, and optional enhanced metadata"
            },
            {
              "name": "FunctionMetadata",
              "desc": "Detailed information about a single function including signature, complexity, and dependencies",
              "inputs": "none (interface/type definition)",
              "outputs": "Structure with symbolName, parameters, returnType, visibility, branches, dependencies, stateMutations, riskLevel"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source files and functions to their corresponding test files and test cases",
              "inputs": "none (interface/type definition)",
              "outputs": "Structure with sourceFileToTests map, functionToTests map, and uncoveredFunctions list"
            },
            {
              "name": "DependencyInfo",
              "desc": "Describes a single dependency with its type and whether it's internal or external",
              "inputs": "none (interface/type definition)",
              "outputs": "Structure with name, type (db/http/filesystem/etc), isInternal flag, and optional lineNumber"
            },
            {
              "name": "BranchInfo",
              "desc": "Represents a branching point in code (if/else, switch, loop, exception handling)",
              "inputs": "none (interface/type definition)",
              "outputs": "Structure with type, human-readable condition, and lineNumber"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache (AnalysisCache)"
          ],
          "intent": "This file exists to provide a standardized schema for representing code analysis results across the application. It solves the problem of inconsistent data structures by defining clear interfaces for file metrics, function metadata, dependencies, test coverage, and code quality indicators, enabling other components to consume and display analysis data in a type-safe manner.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View total file count, line count, and function count in codebase\",\n    \"See list of large files that may need refactoring\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points (main files) in the project\",\n    \"Find duplicate code blocks across files\",\n    \"View function complexity and risk levels\",\n    \"See test coverage mapping for source files\",\n    \"Identify uncovered functions without tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access file-level metrics (lines, functions, complexity)\",\n    \"Query function metadata including parameters, return types, and visibility\",\n    \"Retrieve branch information (if/else, loops, try/catch)\",\n    \"Track dependencies by type (database, HTTP, filesystem, etc.)\",\n    \"Monitor state mutations (assignments, modifications, deletions)\",\n    \"Map source files to their test files\",\n    \"Identify functions missing test coverage\",\n    \"Access cached analysis results for performance\",\n    \"Determine risk levels for functions based on complexity\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface containing complete analysis results for a codebase\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed information about a single function including signature, complexity, and dependencies\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with symbolName, parameters, returnType, visibility, branches, dependencies, stateMutations, riskLevel\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their corresponding test files and test cases\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with sourceFileToTests map, functionToTests map, and uncoveredFunctions list\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Describes a single dependency with its type and whether it's internal or external\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with name, type (db/http/filesystem/etc), isInternal flag, and optional lineNumber\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Represents a branching point in code (if/else, switch, loop, exception handling)\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with type, human-readable condition, and lineNumber\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for representing code analysis results across the application. It solves the problem of inconsistent data structures by defining clear interfaces for file metrics, function metadata, dependencies, test coverage, and code quality indicators, enabling other components to consume and display analysis data in a type-safe manner.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent storage and retrieval of code analysis results to avoid redundant analysis operations",
          "userVisibleActions": [
            "Analysis results load instantly when reopening a previously analyzed workspace",
            "Analysis cache automatically expires after 24 hours, ensuring fresh results",
            "Cache can be cleared to force fresh analysis of the workspace"
          ],
          "developerVisibleActions": [
            "Cache is automatically stored in a .shadowwatch-cache directory within the storage path",
            "Cache files are created per workspace using base64-encoded workspace path as identifier",
            "Cache read/write errors are logged to console without interrupting operations",
            "Cache validation checks timestamp to determine if cached data is still valid"
          ],
          "keyFunctions": [
            {
              "name": "get",
              "desc": "Retrieves cached analysis results for a workspace if they exist and are less than 24 hours old",
              "inputs": "workspaceRoot (string path)",
              "outputs": "CodeAnalysis object or null if cache is invalid/missing"
            },
            {
              "name": "set",
              "desc": "Stores analysis results in cache with current timestamp for future retrieval",
              "inputs": "workspaceRoot (string path), data (CodeAnalysis object)",
              "outputs": "void (Promise)"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis files from the cache directory",
              "inputs": "none",
              "outputs": "void (Promise)"
            },
            {
              "name": "getCacheKey",
              "desc": "Generates a safe filename identifier from workspace path using base64 encoding",
              "inputs": "workspaceRoot (string path)",
              "outputs": "string (sanitized cache key)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer (CodeAnalysis type)"
          ],
          "intent": "Improves user experience by caching expensive code analysis operations, allowing instant access to previously analyzed workspace data while maintaining freshness through automatic expiration",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results to avoid redundant analysis operations\",\n  \"userVisibleActions\": [\n    \"Analysis results load instantly when reopening a previously analyzed workspace\",\n    \"Analysis cache automatically expires after 24 hours, ensuring fresh results\",\n    \"Cache can be cleared to force fresh analysis of the workspace\"\n  ],\n  \"developerVisibleActions\": [\n    \"Cache is automatically stored in a .shadowwatch-cache directory within the storage path\",\n    \"Cache files are created per workspace using base64-encoded workspace path as identifier\",\n    \"Cache read/write errors are logged to console without interrupting operations\",\n    \"Cache validation checks timestamp to determine if cached data is still valid\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results for a workspace if they exist and are less than 24 hours old\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"CodeAnalysis object or null if cache is invalid/missing\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Stores analysis results in cache with current timestamp for future retrieval\",\n      \"inputs\": \"workspaceRoot (string path), data (CodeAnalysis object)\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier from workspace path using base64 encoding\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"string (sanitized cache key)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis type)\"\n  ],\n  \"intent\": \"Improves user experience by caching expensive code analysis operations, allowing instant access to previously analyzed workspace data while maintaining freshness through automatic expiration\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Displays code insights as visual diagnostic messages (warnings, errors, info) in the VS Code Problems panel and editor gutter",
          "userVisibleActions": [
            "See colored underlines/squiggles in code where insights are detected",
            "View insights listed in the Problems panel (Ctrl+Shift+M)",
            "Hover over underlined code to see insight descriptions",
            "Click on problems to navigate to specific code locations",
            "See insight severity indicated by icon color (error/warning/info)"
          ],
          "developerVisibleActions": [
            "Developer triggers insight generation which updates diagnostics automatically",
            "Diagnostics update in real-time as insights are discovered",
            "Diagnostics are grouped by file for organized viewing",
            "Diagnostics clear when insights are refreshed or extension is reset",
            "Each diagnostic shows source as 'Shadow Watch' and includes insight ID"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Updates all diagnostics across all files based on new insights",
              "inputs": "Array of insights",
              "outputs": "Visual diagnostics in editor and Problems panel"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostics for a single specific file",
              "inputs": "File URI and array of insights for that file",
              "outputs": "Visual diagnostics for that file only"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts an insight into a VS Code diagnostic message with appropriate severity and location",
              "inputs": "Single insight object",
              "outputs": "VS Code Diagnostic object"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostic messages from the editor and Problems panel",
              "inputs": "None",
              "outputs": "Cleared diagnostics UI"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "Bridges the gap between generated code insights and VS Code's native diagnostics system, making insights visible to users through familiar VS Code UI elements (squiggles, Problems panel) rather than requiring custom UI",
          "rawContent": "```json\n{\n  \"purpose\": \"Displays code insights as visual diagnostic messages (warnings, errors, info) in the VS Code Problems panel and editor gutter\",\n  \"userVisibleActions\": [\n    \"See colored underlines/squiggles in code where insights are detected\",\n    \"View insights listed in the Problems panel (Ctrl+Shift+M)\",\n    \"Hover over underlined code to see insight descriptions\",\n    \"Click on problems to navigate to specific code locations\",\n    \"See insight severity indicated by icon color (error/warning/info)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers insight generation which updates diagnostics automatically\",\n    \"Diagnostics update in real-time as insights are discovered\",\n    \"Diagnostics are grouped by file for organized viewing\",\n    \"Diagnostics clear when insights are refreshed or extension is reset\",\n    \"Each diagnostic shows source as 'Shadow Watch' and includes insight ID\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across all files based on new insights\",\n      \"inputs\": \"Array of insights\",\n      \"outputs\": \"Visual diagnostics in editor and Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a single specific file\",\n      \"inputs\": \"File URI and array of insights for that file\",\n      \"outputs\": \"Visual diagnostics for that file only\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic message with appropriate severity and location\",\n      \"inputs\": \"Single insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostic messages from the editor and Problems panel\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Cleared diagnostics UI\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Bridges the gap between generated code insights and VS Code's native diagnostics system, making insights visible to users through familiar VS Code UI elements (squiggles, Problems panel) rather than requiring custom UI\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "Main entry point that initializes and coordinates the VS Code extension, registering all commands, views, and handlers for code analysis and navigation features.",
          "userVisibleActions": [
            "Analyze entire workspace to understand code structure and behavior",
            "Analyze current file to extract insights about active code",
            "View code insights in a tree view sidebar showing entry points and connections",
            "Navigate to specific code locations by clicking on insights",
            "See analysis progress in status bar showing active analysis state",
            "Refresh insights view to update analysis results",
            "Clear analysis cache to force fresh analysis",
            "Export analysis results in different formats (markdown, JSON)",
            "Navigate through product features using a product navigator panel",
            "View code behavior extracted and formatted for LLM consumption",
            "See diagnostic warnings and errors from code analysis"
          ],
          "developerVisibleActions": [
            "Trigger workspace analysis via command palette or on extension activation",
            "Trigger file analysis when opening or switching between files",
            "Access cached analysis results to avoid re-processing unchanged code",
            "Watch for file system changes that invalidate cached analysis",
            "Register commands that appear in VS Code command palette",
            "Initialize analysis cache with configurable storage backend",
            "Handle errors during analysis with graceful fallback and user notifications",
            "Bootstrap extension components in dependency injection container",
            "Configure analysis behavior through VS Code settings",
            "Access configuration manager for reading extension settings"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Initializes the extension, sets up all components, registers commands and views, and starts file watching",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "void"
            },
            {
              "name": "deactivate",
              "desc": "Cleans up resources when extension is deactivated, disposing watchers and providers",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Analyzes all code files in the workspace to extract entry points, insights, and behavior",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeCurrentFile",
              "desc": "Analyzes the currently active file and updates insights for that file",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "navigateToDefinition",
              "desc": "Navigates the editor to a specific code location based on tree item selection",
              "inputs": "item: TreeItem",
              "outputs": "Promise<void>"
            },
            {
              "name": "refreshInsights",
              "desc": "Forces a refresh of the insights tree view with latest analysis data",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "clearCache",
              "desc": "Clears all cached analysis data and forces re-analysis on next request",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "exportInsights",
              "desc": "Exports analysis results to a file in selected format (markdown or JSON)",
              "inputs": "format: string",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler",
            "./productNavigator"
          ],
          "intent": "This file exists to serve as the central coordination point for the VS Code extension, solving the problem of organizing and connecting all analysis, navigation, and visualization features into a cohesive user experience. It ensures proper initialization, command registration, and lifecycle management so users can seamlessly analyze code behavior and navigate through insights without worrying about underlying complexity.",
          "rawContent": "```json\n{\n  \"purpose\": \"Main entry point that initializes and coordinates the VS Code extension, registering all commands, views, and handlers for code analysis and navigation features.\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to understand code structure and behavior\",\n    \"Analyze current file to extract insights about active code\",\n    \"View code insights in a tree view sidebar showing entry points and connections\",\n    \"Navigate to specific code locations by clicking on insights\",\n    \"See analysis progress in status bar showing active analysis state\",\n    \"Refresh insights view to update analysis results\",\n    \"Clear analysis cache to force fresh analysis\",\n    \"Export analysis results in different formats (markdown, JSON)\",\n    \"Navigate through product features using a product navigator panel\",\n    \"View code behavior extracted and formatted for LLM consumption\",\n    \"See diagnostic warnings and errors from code analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger workspace analysis via command palette or on extension activation\",\n    \"Trigger file analysis when opening or switching between files\",\n    \"Access cached analysis results to avoid re-processing unchanged code\",\n    \"Watch for file system changes that invalidate cached analysis\",\n    \"Register commands that appear in VS Code command palette\",\n    \"Initialize analysis cache with configurable storage backend\",\n    \"Handle errors during analysis with graceful fallback and user notifications\",\n    \"Bootstrap extension components in dependency injection container\",\n    \"Configure analysis behavior through VS Code settings\",\n    \"Access configuration manager for reading extension settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, sets up all components, registers commands and views, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when extension is deactivated, disposing watchers and providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes all code files in the workspace to extract entry points, insights, and behavior\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Analyzes the currently active file and updates insights for that file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToDefinition\",\n      \"desc\": \"Navigates the editor to a specific code location based on tree item selection\",\n      \"inputs\": \"item: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Forces a refresh of the insights tree view with latest analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears all cached analysis data and forces re-analysis on next request\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportInsights\",\n      \"desc\": \"Exports analysis results to a file in selected format (markdown or JSON)\",\n      \"inputs\": \"format: string\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file exists to serve as the central coordination point for the VS Code extension, solving the problem of organizing and connecting all analysis, navigation, and visualization features into a cohesive user experience. It ensures proper initialization, command registration, and lifecycle management so users can seamlessly analyze code behavior and navigate through insights without worrying about underlying complexity.\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and grep search functionality to enable LLM agents to iteratively explore and analyze codebases",
          "userVisibleActions": [
            "LLM agent can request to read specific files from the workspace",
            "LLM agent can search across files using grep patterns to find code",
            "Search results show matching lines with surrounding context",
            "File listings show organized folder structure with file metadata",
            "Results are limited to prevent overwhelming responses"
          ],
          "developerVisibleActions": [
            "Developer provides workspace root path to initialize helper",
            "Developer receives structured file content with line counts",
            "Developer gets grep search results with file, line number, and context",
            "Developer can filter searches by file patterns (e.g., '*.ts', 'src/**/*.ts')",
            "Developer can limit maximum number of search results returned",
            "Developer sees organized file listings grouped by folder with depth sorting"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Organizes and formats a list of files grouped by folder with metadata",
              "inputs": "Array of file objects with path, lines, and language",
              "outputs": "Formatted string showing folder-organized file structure"
            },
            {
              "name": "readFile",
              "desc": "Reads a file from the workspace and returns its content with metadata",
              "inputs": "FileRequest with file path and optional reason",
              "outputs": "FileResponse with content, line count, and existence status"
            },
            {
              "name": "grep",
              "desc": "Searches files for pattern matches and returns results with context",
              "inputs": "GrepRequest with pattern, optional file pattern filter, max results, and reason",
              "outputs": "GrepResponse with matches including file, line number, content, and context lines"
            },
            {
              "name": "processLLMRequest",
              "desc": "Routes LLM file or grep requests to appropriate handler",
              "inputs": "LLMRequest (either FileRequest or GrepRequest)",
              "outputs": "Either FileResponse or GrepResponse based on request type"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to enable LLM agents to dynamically explore codebases through file reading and pattern searching, supporting iterative analysis workflows where the agent discovers what files to examine based on previous results rather than receiving all code upfront",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable LLM agents to iteratively explore and analyze codebases\",\n  \"userVisibleActions\": [\n    \"LLM agent can request to read specific files from the workspace\",\n    \"LLM agent can search across files using grep patterns to find code\",\n    \"Search results show matching lines with surrounding context\",\n    \"File listings show organized folder structure with file metadata\",\n    \"Results are limited to prevent overwhelming responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides workspace root path to initialize helper\",\n    \"Developer receives structured file content with line counts\",\n    \"Developer gets grep search results with file, line number, and context\",\n    \"Developer can filter searches by file patterns (e.g., '*.ts', 'src/**/*.ts')\",\n    \"Developer can limit maximum number of search results returned\",\n    \"Developer sees organized file listings grouped by folder with depth sorting\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by folder with metadata\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing folder-organized file structure\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its content with metadata\",\n      \"inputs\": \"FileRequest with file path and optional reason\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grep\",\n      \"desc\": \"Searches files for pattern matches and returns results with context\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern filter, max results, and reason\",\n      \"outputs\": \"GrepResponse with matches including file, line number, content, and context lines\"\n    },\n    {\n      \"name\": \"processLLMRequest\",\n      \"desc\": \"Routes LLM file or grep requests to appropriate handler\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"Either FileResponse or GrepResponse based on request type\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable LLM agents to dynamically explore codebases through file reading and pattern searching, supporting iterative analysis workflows where the agent discovers what files to examine based on previous results rather than receiving all code upfront\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines type interfaces and structures for organizing extracted documentation from code files into hierarchical summaries (file  module  product  full aggregation).",
          "userVisibleActions": [
            "Users see documentation organized by what actions they can take through GUI, CLI, API, or CI/CD interfaces",
            "Users understand what problems the product solves and how it fits into their workflow",
            "Users view structured capabilities grouped by module type (API endpoints, CLI commands, workers)"
          ],
          "developerVisibleActions": [
            "Developers use FileSummary to document individual files with role, purpose, and key functions",
            "Developers use ModuleSummary to group related files and expose endpoints, commands, or worker flows",
            "Developers use EnhancedProductDocumentation to create complete product documentation with overview, architecture diagrams, and user perspectives",
            "Developers structure documentation with userVisibleActions and developerVisibleActions to separate concerns",
            "Developers can include Mermaid diagrams for component and flow visualization",
            "Developers organize features, modules, and components with titles and descriptions"
          ],
          "keyFunctions": [],
          "dependencies": [
            "fs",
            "path",
            "CodeAnalysis from ./analyzer",
            "FileInfo from ./analyzer"
          ],
          "intent": "This file exists to establish a standardized documentation schema that follows a four-level hierarchy (file  module  product  full aggregation), enabling systematic extraction and organization of codebase documentation with clear separation between user-facing and developer-facing information.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines type interfaces and structures for organizing extracted documentation from code files into hierarchical summaries (file  module  product  full aggregation).\",\n  \"userVisibleActions\": [\n    \"Users see documentation organized by what actions they can take through GUI, CLI, API, or CI/CD interfaces\",\n    \"Users understand what problems the product solves and how it fits into their workflow\",\n    \"Users view structured capabilities grouped by module type (API endpoints, CLI commands, workers)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers use FileSummary to document individual files with role, purpose, and key functions\",\n    \"Developers use ModuleSummary to group related files and expose endpoints, commands, or worker flows\",\n    \"Developers use EnhancedProductDocumentation to create complete product documentation with overview, architecture diagrams, and user perspectives\",\n    \"Developers structure documentation with userVisibleActions and developerVisibleActions to separate concerns\",\n    \"Developers can include Mermaid diagrams for component and flow visualization\",\n    \"Developers organize features, modules, and components with titles and descriptions\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"CodeAnalysis from ./analyzer\",\n    \"FileInfo from ./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a standardized documentation schema that follows a four-level hierarchy (file  module  product  full aggregation), enabling systematic extraction and organization of codebase documentation with clear separation between user-facing and developer-facing information.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file changes in the workspace and automatically triggers code analysis when files are saved",
          "userVisibleActions": [
            "Code is automatically analyzed when a file is saved (if 'analyzeOnSave' is enabled in settings)",
            "Analysis results appear in diagnostics/problems panel after file save",
            "Insights tree view updates automatically after file analysis completes",
            "Analysis is throttled to prevent excessive re-analysis (minimum 1 second between analyses)",
            "Analysis skips if configuration is disabled or invalid workspace"
          ],
          "developerVisibleActions": [
            "FileWatcher coordinates automatic analysis workflow when files are saved",
            "Debounces file save events to avoid duplicate analysis runs",
            "Checks configuration settings to determine if analysis should run",
            "Validates workspace folders exist before triggering analysis",
            "Orchestrates analyzer, insight generator, diagnostics provider, and tree view updates",
            "Maintains analysis state to prevent concurrent analysis runs",
            "Handles errors during analysis and reports them appropriately",
            "Can be started/stopped programmatically to enable/disable file watching",
            "Cleans up resources and timers when stopped or disposed"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins watching for file save events to trigger automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops watching file changes and cleans up pending analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save event by scheduling/triggering code analysis with debouncing",
              "inputs": "document (TextDocument)",
              "outputs": "void"
            },
            {
              "name": "triggerAnalysis",
              "desc": "Executes the full analysis workflow: analyzes code, generates insights, updates diagnostics and tree view",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all resources, stops watching, and cancels pending operations",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "ConfigurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic, background code analysis triggered by file saves. It solves the problem of keeping code insights up-to-date without requiring manual user action, while intelligently throttling analysis to avoid performance issues. It acts as the orchestration layer that connects file system events to the analysis pipeline.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Code is automatically analyzed when a file is saved (if 'analyzeOnSave' is enabled in settings)\",\n    \"Analysis results appear in diagnostics/problems panel after file save\",\n    \"Insights tree view updates automatically after file analysis completes\",\n    \"Analysis is throttled to prevent excessive re-analysis (minimum 1 second between analyses)\",\n    \"Analysis skips if configuration is disabled or invalid workspace\"\n  ],\n  \"developerVisibleActions\": [\n    \"FileWatcher coordinates automatic analysis workflow when files are saved\",\n    \"Debounces file save events to avoid duplicate analysis runs\",\n    \"Checks configuration settings to determine if analysis should run\",\n    \"Validates workspace folders exist before triggering analysis\",\n    \"Orchestrates analyzer, insight generator, diagnostics provider, and tree view updates\",\n    \"Maintains analysis state to prevent concurrent analysis runs\",\n    \"Handles errors during analysis and reports them appropriately\",\n    \"Can be started/stopped programmatically to enable/disable file watching\",\n    \"Cleans up resources and timers when stopped or disposed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events to trigger automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching file changes and cleans up pending analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save event by scheduling/triggering code analysis with debouncing\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis workflow: analyzes code, generates insights, updates diagnostics and tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all resources, stops watching, and cancels pending operations\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, background code analysis triggered by file saves. It solves the problem of keeping code insights up-to-date without requiring manual user action, while intelligently throttling analysis to avoid performance issues. It acts as the orchestration layer that connects file system events to the analysis pipeline.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Generates actionable insights and recommendations by analyzing code metrics, identifying issues like large files, orphaned code, circular dependencies, and complexity problems.",
          "userVisibleActions": [
            "Receives insights about large files that exceed recommended line counts",
            "Gets warnings about orphaned files that aren't referenced elsewhere",
            "Sees alerts for missing entry points in the codebase",
            "Views notifications about potential circular dependencies",
            "Receives warnings about god objects (overly complex classes/modules)",
            "Gets alerts about potential dead code that may be unused",
            "Sees recommendations for better file organization",
            "Receives warnings about complex functions that need refactoring"
          ],
          "developerVisibleActions": [
            "Calls generateInsights() to analyze entire codebase and receive all insights",
            "Calls generateInsightsForFile() to get insights for a specific file",
            "Receives structured Insight objects with severity levels (error/warning/info)",
            "Gets actionable suggestions for each identified issue",
            "Sees categorized insights for easier filtering and prioritization",
            "Accesses file path and line number information for navigation to issues",
            "Views code snippets highlighting problematic areas"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Analyzes entire codebase and returns comprehensive list of all identified issues and recommendations",
              "inputs": "CodeAnalysis object containing analyzed code structure",
              "outputs": "Array of Insight objects with issues, warnings, and suggestions"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Generates insights specific to a single file including size, complexity, and organization checks",
              "inputs": "CodeAnalysis object and file path string",
              "outputs": "Array of Insight objects specific to the requested file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Identifies files exceeding recommended line count thresholds",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for oversized files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Finds files that aren't imported or referenced by other files",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for isolated files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Validates presence of required entry points in the project",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Detects potential circular dependency patterns between modules",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for circular dependencies"
            },
            {
              "name": "checkGodObjects",
              "desc": "Identifies overly complex classes or modules with too many responsibilities",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for god objects"
            },
            {
              "name": "checkDeadCode",
              "desc": "Finds potentially unused or unreachable code segments",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Evaluates project structure and file organization patterns",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for organizational improvements"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Analyzes functions for excessive complexity and recommends refactoring",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights for complex functions"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers improve code quality, maintainability, and organization by identifying common problems and anti-patterns with specific suggestions for improvement.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates actionable insights and recommendations by analyzing code metrics, identifying issues like large files, orphaned code, circular dependencies, and complexity problems.\",\n  \"userVisibleActions\": [\n    \"Receives insights about large files that exceed recommended line counts\",\n    \"Gets warnings about orphaned files that aren't referenced elsewhere\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Views notifications about potential circular dependencies\",\n    \"Receives warnings about god objects (overly complex classes/modules)\",\n    \"Gets alerts about potential dead code that may be unused\",\n    \"Sees recommendations for better file organization\",\n    \"Receives warnings about complex functions that need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls generateInsights() to analyze entire codebase and receive all insights\",\n    \"Calls generateInsightsForFile() to get insights for a specific file\",\n    \"Receives structured Insight objects with severity levels (error/warning/info)\",\n    \"Gets actionable suggestions for each identified issue\",\n    \"Sees categorized insights for easier filtering and prioritization\",\n    \"Accesses file path and line number information for navigation to issues\",\n    \"Views code snippets highlighting problematic areas\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns comprehensive list of all identified issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing analyzed code structure\",\n      \"outputs\": \"Array of Insight objects with issues, warnings, and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates insights specific to a single file including size, complexity, and organization checks\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that aren't imported or referenced by other files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry points in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between modules\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies overly complex classes or modules with too many responsibilities\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds potentially unused or unreachable code segments\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file organization patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for organizational improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes functions for excessive complexity and recommends refactoring\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers improve code quality, maintainability, and organization by identifying common problems and anti-patterns with specific suggestions for improvement.\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view UI in VS Code's sidebar that displays code analysis insights, reports, and AI-generated documentation with real-time status updates.",
          "userVisibleActions": [
            "View code insights organized in a hierarchical tree structure in the sidebar",
            "See real-time status indicators (idle, generating, complete) for different analysis types",
            "Click on insights to navigate to specific code locations",
            "Expand/collapse sections to view product docs, architecture analysis, unit tests, and reports",
            "See timestamps showing when each analysis was last generated",
            "View file counts and statistics for different analysis categories",
            "Access generated reports through clickable tree items",
            "See loading spinners and progress indicators during AI analysis generation",
            "View categorized insights with severity indicators and descriptions",
            "Navigate between workspace-level and file-level analysis results"
          ],
          "developerVisibleActions": [
            "Tree view automatically refreshes when new insights are generated",
            "Status updates propagate from LLM services to the UI",
            "Tree structure persists state across VS Code sessions",
            "Icons and tooltips provide visual feedback about analysis status",
            "Tree items become clickable commands when analysis is complete",
            "Background services update tree data without blocking user interaction",
            "Timestamps and file paths are stored and restored on extension reload",
            "Tree view integrates with VS Code's command system for user actions",
            "Static analysis results are displayed alongside AI-generated insights",
            "Report generation status is tracked and displayed independently for each report type"
          ],
          "keyFunctions": [
            {
              "name": "getTreeItem",
              "desc": "Returns a VS Code tree item with appropriate icon, label, and command for display in the sidebar",
              "inputs": "TreeItem element",
              "outputs": "vscode.TreeItem or Thenable<vscode.TreeItem>"
            },
            {
              "name": "getChildren",
              "desc": "Provides the hierarchical structure of insights, reports, and analysis results for the tree view",
              "inputs": "Optional parent TreeItem",
              "outputs": "Array of child TreeItems or Thenable<TreeItem[]>"
            },
            {
              "name": "updateInsights",
              "desc": "Updates the displayed insights and refreshes the tree view UI",
              "inputs": "Array of Insight objects",
              "outputs": "void"
            },
            {
              "name": "setProductDocsStatus",
              "desc": "Updates the status of product documentation generation and refreshes the UI",
              "inputs": "Status string (idle, generating, complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setInsightsStatus",
              "desc": "Updates the status of insights generation and refreshes the UI",
              "inputs": "Status string (idle, generating, complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setUnitTestStatus",
              "desc": "Updates the status of unit test generation and refreshes the UI",
              "inputs": "Status string (idle, generating, complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setAnalysisStatus",
              "desc": "Updates the status of static analysis and refreshes the UI",
              "inputs": "Status string (idle, complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setLLMService",
              "desc": "Connects the tree view to the LLM service for displaying AI-generated insights",
              "inputs": "LLMService instance",
              "outputs": "void"
            },
            {
              "name": "setReportPath",
              "desc": "Sets the file path for a generated report and updates the display with timestamp",
              "inputs": "Report file path string and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Forces a complete refresh of the tree view UI",
              "inputs": "Optional TreeItem to refresh",
              "outputs": "void"
            },
            {
              "name": "loadPersistedState",
              "desc": "Restores saved timestamps and file paths from previous VS Code sessions",
              "inputs": "None",
              "outputs": "Promise<void>"
            },
            {
              "name": "formatTimestamp",
              "desc": "Converts a timestamp into a human-readable relative time string",
              "inputs": "Timestamp number",
              "outputs": "Formatted time string (e.g., '5 minutes ago')"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator",
            "./llmFormatter",
            "./llmService"
          ],
          "intent": "This file exists to provide a visual interface in VS Code's sidebar that organizes and displays all code analysis results, AI-generated documentation, and reports in an easy-to-navigate tree structure. It solves the problem of presenting complex, multi-layered analysis data to users in a way that's accessible, interactive, and provides real-time feedback on generation status. It acts as the main UI bridge between background analysis services and the user's workspace exploration experience.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view UI in VS Code's sidebar that displays code analysis insights, reports, and AI-generated documentation with real-time status updates.\",\n  \"userVisibleActions\": [\n    \"View code insights organized in a hierarchical tree structure in the sidebar\",\n    \"See real-time status indicators (idle, generating, complete) for different analysis types\",\n    \"Click on insights to navigate to specific code locations\",\n    \"Expand/collapse sections to view product docs, architecture analysis, unit tests, and reports\",\n    \"See timestamps showing when each analysis was last generated\",\n    \"View file counts and statistics for different analysis categories\",\n    \"Access generated reports through clickable tree items\",\n    \"See loading spinners and progress indicators during AI analysis generation\",\n    \"View categorized insights with severity indicators and descriptions\",\n    \"Navigate between workspace-level and file-level analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when new insights are generated\",\n    \"Status updates propagate from LLM services to the UI\",\n    \"Tree structure persists state across VS Code sessions\",\n    \"Icons and tooltips provide visual feedback about analysis status\",\n    \"Tree items become clickable commands when analysis is complete\",\n    \"Background services update tree data without blocking user interaction\",\n    \"Timestamps and file paths are stored and restored on extension reload\",\n    \"Tree view integrates with VS Code's command system for user actions\",\n    \"Static analysis results are displayed alongside AI-generated insights\",\n    \"Report generation status is tracked and displayed independently for each report type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns a VS Code tree item with appropriate icon, label, and command for display in the sidebar\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem or Thenable<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Provides the hierarchical structure of insights, reports, and analysis results for the tree view\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of child TreeItems or Thenable<TreeItem[]>\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view UI\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the status of insights generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the status of unit test generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of static analysis and refreshes the UI\",\n      \"inputs\": \"Status string (idle, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Connects the tree view to the LLM service for displaying AI-generated insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and updates the display with timestamp\",\n      \"inputs\": \"Report file path string and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces a complete refresh of the tree view UI\",\n      \"inputs\": \"Optional TreeItem to refresh\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved timestamps and file paths from previous VS Code sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatTimestamp\",\n      \"desc\": \"Converts a timestamp into a human-readable relative time string\",\n      \"inputs\": \"Timestamp number\",\n      \"outputs\": \"Formatted time string (e.g., '5 minutes ago')\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual interface in VS Code's sidebar that organizes and displays all code analysis results, AI-generated documentation, and reports in an easy-to-navigate tree structure. It solves the problem of presenting complex, multi-layered analysis data to users in a way that's accessible, interactive, and provides real-time feedback on generation status. It acts as the main UI bridge between background analysis services and the user's workspace exploration experience.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, with automatic refresh when insights are updated.",
          "userVisibleActions": [
            "View AI-generated architecture insights in a tree structure in the VS Code sidebar",
            "Browse project purpose, features, architecture, and technical stack information",
            "Expand/collapse sections to see detailed insights about different aspects of the codebase",
            "Click on insights to view detailed information in the editor",
            "See real-time updates when architecture insights are regenerated",
            "Access insights from both main insights file and purpose documentation file",
            "View insights organized by categories: Project Purpose, Features, Architecture, and Technical Stack"
          ],
          "developerVisibleActions": [
            "Automatically watches .shadow/docs/insights.json for changes and refreshes the tree view",
            "Automatically watches .shadow/docs/purpose.md for changes and refreshes the tree view",
            "Loads insights from JSON file in the .shadow/docs directory",
            "Creates .shadow and .shadow/docs directories if they don't exist",
            "Parses and structures insights data into a hierarchical tree format",
            "Handles missing or invalid insights files gracefully",
            "Manages file watcher lifecycle with proper cleanup on disposal",
            "Integrates with FileWatcherService for centralized file monitoring"
          ],
          "keyFunctions": [
            {
              "name": "refresh",
              "desc": "Reloads insights from disk and updates the tree view display",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts an InsightItem into a displayable tree item for VS Code",
              "inputs": "InsightItem element",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node or root-level items if no parent",
              "inputs": "InsightItem or undefined",
              "outputs": "Promise<InsightItem[]>"
            },
            {
              "name": "loadInsights",
              "desc": "Reads and parses the insights.json file from .shadow/docs directory",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Creates file system watchers for insights.json and purpose.md to auto-refresh the view",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file watchers and disposable resources when the provider is destroyed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs",
            "llmService",
            "domain/services/fileWatcherService"
          ],
          "intent": "This file exists to provide developers with a convenient, always-visible sidebar view of AI-generated architecture insights about their codebase. It solves the problem of accessing and browsing architectural documentation by presenting it in an organized tree structure that automatically updates when the AI generates new insights, eliminating the need to manually open and read documentation files.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, with automatic refresh when insights are updated.\",\n  \"userVisibleActions\": [\n    \"View AI-generated architecture insights in a tree structure in the VS Code sidebar\",\n    \"Browse project purpose, features, architecture, and technical stack information\",\n    \"Expand/collapse sections to see detailed insights about different aspects of the codebase\",\n    \"Click on insights to view detailed information in the editor\",\n    \"See real-time updates when architecture insights are regenerated\",\n    \"Access insights from both main insights file and purpose documentation file\",\n    \"View insights organized by categories: Project Purpose, Features, Architecture, and Technical Stack\"\n  ],\n  \"developerVisibleActions\": [\n    \"Automatically watches .shadow/docs/insights.json for changes and refreshes the tree view\",\n    \"Automatically watches .shadow/docs/purpose.md for changes and refreshes the tree view\",\n    \"Loads insights from JSON file in the .shadow/docs directory\",\n    \"Creates .shadow and .shadow/docs directories if they don't exist\",\n    \"Parses and structures insights data into a hierarchical tree format\",\n    \"Handles missing or invalid insights files gracefully\",\n    \"Manages file watcher lifecycle with proper cleanup on disposal\",\n    \"Integrates with FileWatcherService for centralized file monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from disk and updates the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a displayable tree item for VS Code\",\n      \"inputs\": \"InsightItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root-level items if no parent\",\n      \"inputs\": \"InsightItem or undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"loadInsights\",\n      \"desc\": \"Reads and parses the insights.json file from .shadow/docs directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers for insights.json and purpose.md to auto-refresh the view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and disposable resources when the provider is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"llmService\",\n    \"domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with a convenient, always-visible sidebar view of AI-generated architecture insights about their codebase. It solves the problem of accessing and browsing architectural documentation by presenting it in an organized tree structure that automatically updates when the AI generates new insights, eliminating the need to manually open and read documentation files.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different output formats optimized for various LLM interfaces and readability preferences.",
          "userVisibleActions": [
            "View architecture issues formatted specifically for Cursor AI with emoji-enhanced sections",
            "View architecture issues formatted for ChatGPT with conversational context",
            "View architecture issues in a compact format with minimal formatting",
            "View architecture issues in a generic format suitable for any LLM",
            "See issues grouped by severity (errors, warnings, info)",
            "Receive actionable prompts requesting help with prioritization and refactoring",
            "Get insights presented with file locations, issue descriptions, and suggested fixes"
          ],
          "developerVisibleActions": [
            "Call formatInsights() to transform raw insights into LLM-ready formatted text",
            "Select different output formats by passing format parameter (cursor, chatgpt, compact, generic)",
            "Receive markdown-formatted strings ready to paste into LLM chat interfaces",
            "Get insights automatically organized by severity level",
            "Use formatted output that includes file paths, line numbers, issue descriptions, and suggestions",
            "Leverage pre-built prompts that ask LLMs for specific help (prioritization, refactoring steps, reorganization plans)"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Main entry point that routes to appropriate formatter based on target LLM",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "Formatted string ready for LLM consumption"
            },
            {
              "name": "formatForCursor",
              "desc": "Creates Cursor AI optimized format with emojis, severity sections, and actionable prompts",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown-formatted string with emoji headers and grouped issues"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Creates ChatGPT optimized format with conversational framing and context",
              "inputs": "insights: Insight[]",
              "outputs": "Conversational markdown string suited for ChatGPT interface"
            },
            {
              "name": "formatCompact",
              "desc": "Creates minimal format with just essential information and no extra formatting",
              "inputs": "insights: Insight[]",
              "outputs": "Compact text listing of issues"
            },
            {
              "name": "formatGeneric",
              "desc": "Creates standard format that works with any LLM without special optimizations",
              "inputs": "insights: Insight[]",
              "outputs": "Generic markdown-formatted string"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats individual insight with file info, description, and suggestions for Cursor",
              "inputs": "insight: Insight",
              "outputs": "Formatted markdown block for single insight"
            }
          ],
          "dependencies": [
            "./insightGenerator"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis results and LLM interfaces by transforming technical insights into well-formatted, context-rich prompts that are optimized for different AI coding assistants. It solves the problem of presenting architecture issues in a way that maximizes the effectiveness of LLM responses by providing proper context, organization, and actionable prompts.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various LLM interfaces and readability preferences.\",\n  \"userVisibleActions\": [\n    \"View architecture issues formatted specifically for Cursor AI with emoji-enhanced sections\",\n    \"View architecture issues formatted for ChatGPT with conversational context\",\n    \"View architecture issues in a compact format with minimal formatting\",\n    \"View architecture issues in a generic format suitable for any LLM\",\n    \"See issues grouped by severity (errors, warnings, info)\",\n    \"Receive actionable prompts requesting help with prioritization and refactoring\",\n    \"Get insights presented with file locations, issue descriptions, and suggested fixes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatInsights() to transform raw insights into LLM-ready formatted text\",\n    \"Select different output formats by passing format parameter (cursor, chatgpt, compact, generic)\",\n    \"Receive markdown-formatted strings ready to paste into LLM chat interfaces\",\n    \"Get insights automatically organized by severity level\",\n    \"Use formatted output that includes file paths, line numbers, issue descriptions, and suggestions\",\n    \"Leverage pre-built prompts that ask LLMs for specific help (prioritization, refactoring steps, reorganization plans)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes to appropriate formatter based on target LLM\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string ready for LLM consumption\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI optimized format with emojis, severity sections, and actionable prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string with emoji headers and grouped issues\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT optimized format with conversational framing and context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Conversational markdown string suited for ChatGPT interface\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates minimal format with just essential information and no extra formatting\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact text listing of issues\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format that works with any LLM without special optimizations\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown-formatted string\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file info, description, and suggestions for Cursor\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown block for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis results and LLM interfaces by transforming technical insights into well-formatted, context-rich prompts that are optimized for different AI coding assistants. It solves the problem of presenting architecture issues in a way that maximizes the effectiveness of LLM responses by providing proper context, organization, and actionable prompts.\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Integrates LLM-powered code analysis features into VSCode, managing documentation generation, insights, and code analysis visualization through various tree view providers and command handlers.",
          "userVisibleActions": [
            "Generate product documentation from codebase with progress notifications",
            "View generated documentation in formatted output channel and webview",
            "Analyze codebase to extract architecture insights and patterns",
            "View insights organized in tree view with categories (Entry Points, Components, etc.)",
            "Navigate codebase through product navigator showing modules and components",
            "View analysis results in interactive viewer with file structure",
            "Search and filter analysis results and insights",
            "Jump to code locations from tree views and documentation",
            "Export documentation and insights to files",
            "Refresh analysis and documentation on demand",
            "View unit test coverage and navigate to test files",
            "See error messages when API keys are missing or invalid",
            "Receive notifications when documentation or analysis completes"
          ],
          "developerVisibleActions": [
            "Trigger analysis through command palette or tree view actions",
            "Configure LLM API keys and providers in settings",
            "Access cached analysis results to avoid redundant processing",
            "Monitor analysis progress through status bar and notifications",
            "Debug LLM interactions through logging output",
            "Access saved analysis state across sessions",
            "Handle API rate limits and errors gracefully",
            "Customize documentation formatting through settings",
            "Integrate analysis results into custom workflows",
            "Load and save analysis contexts programmatically"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Initializes LLM service, registers configuration change handlers, and loads saved analysis state",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "generateProductDocumentation",
              "desc": "Analyzes codebase and generates comprehensive product documentation using LLM",
              "inputs": "workspace folder",
              "outputs": "Promise<EnhancedProductDocumentation>"
            },
            {
              "name": "analyzeCodebase",
              "desc": "Performs deep code analysis to extract architecture, patterns, and insights",
              "inputs": "workspace folder, options",
              "outputs": "Promise<CodeAnalysis>"
            },
            {
              "name": "getInsights",
              "desc": "Retrieves LLM-generated insights from analyzed codebase",
              "inputs": "analysis context",
              "outputs": "Promise<LLMInsights>"
            },
            {
              "name": "refreshInsights",
              "desc": "Re-analyzes codebase and updates insights tree view",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "showDocumentation",
              "desc": "Displays generated documentation in formatted output channel or webview",
              "inputs": "documentation object",
              "outputs": "void"
            },
            {
              "name": "exportDocumentation",
              "desc": "Saves documentation to markdown or HTML file",
              "inputs": "documentation, format, output path",
              "outputs": "Promise<void>"
            },
            {
              "name": "loadSavedCodeAnalysis",
              "desc": "Loads previously saved analysis results from disk",
              "inputs": "workspace folder",
              "outputs": "Promise<CodeAnalysis | null>"
            },
            {
              "name": "saveAnalysisResults",
              "desc": "Persists analysis results and insights to disk for later use",
              "inputs": "analysis data, workspace folder",
              "outputs": "Promise<void>"
            },
            {
              "name": "registerCommands",
              "desc": "Registers all VSCode commands for LLM features in command palette",
              "inputs": "extension context",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "llmService",
            "insightsTreeView",
            "fileDocumentation",
            "analyzer",
            "productNavigator",
            "analysisViewer",
            "insightsViewer",
            "unitTestsNavigator",
            "logger",
            "llmStateManager",
            "analysisContextBuilder",
            "documentationFormatter",
            "analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis and user-friendly LLM-powered features in VSCode. It solves the problem of understanding large codebases by providing automated documentation generation, architectural insights extraction, and interactive navigation through analysis results. It manages the entire lifecycle of LLM-powered analysis including initialization, execution, caching, persistence, and presentation through various UI components like tree views and webviews.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered code analysis features into VSCode, managing documentation generation, insights, and code analysis visualization through various tree view providers and command handlers.\",\n  \"userVisibleActions\": [\n    \"Generate product documentation from codebase with progress notifications\",\n    \"View generated documentation in formatted output channel and webview\",\n    \"Analyze codebase to extract architecture insights and patterns\",\n    \"View insights organized in tree view with categories (Entry Points, Components, etc.)\",\n    \"Navigate codebase through product navigator showing modules and components\",\n    \"View analysis results in interactive viewer with file structure\",\n    \"Search and filter analysis results and insights\",\n    \"Jump to code locations from tree views and documentation\",\n    \"Export documentation and insights to files\",\n    \"Refresh analysis and documentation on demand\",\n    \"View unit test coverage and navigate to test files\",\n    \"See error messages when API keys are missing or invalid\",\n    \"Receive notifications when documentation or analysis completes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger analysis through command palette or tree view actions\",\n    \"Configure LLM API keys and providers in settings\",\n    \"Access cached analysis results to avoid redundant processing\",\n    \"Monitor analysis progress through status bar and notifications\",\n    \"Debug LLM interactions through logging output\",\n    \"Access saved analysis state across sessions\",\n    \"Handle API rate limits and errors gracefully\",\n    \"Customize documentation formatting through settings\",\n    \"Integrate analysis results into custom workflows\",\n    \"Load and save analysis contexts programmatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Initializes LLM service, registers configuration change handlers, and loads saved analysis state\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Analyzes codebase and generates comprehensive product documentation using LLM\",\n      \"inputs\": \"workspace folder\",\n      \"outputs\": \"Promise<EnhancedProductDocumentation>\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Performs deep code analysis to extract architecture, patterns, and insights\",\n      \"inputs\": \"workspace folder, options\",\n      \"outputs\": \"Promise<CodeAnalysis>\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Retrieves LLM-generated insights from analyzed codebase\",\n      \"inputs\": \"analysis context\",\n      \"outputs\": \"Promise<LLMInsights>\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Re-analyzes codebase and updates insights tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showDocumentation\",\n      \"desc\": \"Displays generated documentation in formatted output channel or webview\",\n      \"inputs\": \"documentation object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"exportDocumentation\",\n      \"desc\": \"Saves documentation to markdown or HTML file\",\n      \"inputs\": \"documentation, format, output path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Loads previously saved analysis results from disk\",\n      \"inputs\": \"workspace folder\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"saveAnalysisResults\",\n      \"desc\": \"Persists analysis results and insights to disk for later use\",\n      \"inputs\": \"analysis data, workspace folder\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VSCode commands for LLM features in command palette\",\n      \"inputs\": \"extension context\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"llmStateManager\",\n    \"analysisContextBuilder\",\n    \"documentationFormatter\",\n    \"analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and user-friendly LLM-powered features in VSCode. It solves the problem of understanding large codebases by providing automated documentation generation, architectural insights extraction, and interactive navigation through analysis results. It manages the entire lifecycle of LLM-powered analysis including initialization, execution, caching, persistence, and presentation through various UI components like tree views and webviews.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure LLM responses to ensure valid, parseable output for product analysis, code health assessment, and documentation generation.",
          "userVisibleActions": [
            "Receives structured analysis of product purpose and user goals",
            "Gets organized lists of code health issues with clear titles and descriptions",
            "Sees categorized architectural problems and design decisions",
            "Receives formatted proposed fixes for identified issues",
            "Gets structured documentation with sections for behaviors, functions, and dependencies"
          ],
          "developerVisibleActions": [
            "Sends codebase information to LLM and receives guaranteed JSON structure back",
            "Uses schemas to validate LLM responses match expected format",
            "Relies on schema enforcement to avoid manual parsing of LLM output",
            "Gets predictable data structures for product purpose analysis including architecture rationale and user goals",
            "Receives code health issues with required fields: title, description, relevant files, functions, and severity",
            "Obtains structured file analysis with purpose, user/developer-facing actions, key functions, and dependencies"
          ],
          "keyFunctions": [
            {
              "name": "productPurposeAnalysisSchema",
              "desc": "Schema ensuring LLM returns structured product purpose analysis",
              "inputs": "Used by LLM to structure response",
              "outputs": "Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
            },
            {
              "name": "issueItemSchema",
              "desc": "Schema defining structure for individual code health issues",
              "inputs": "Nested within other schemas",
              "outputs": "Object with title, description, relevantFiles, relevantFunctions, severity, priority"
            },
            {
              "name": "codeHealthAnalysisSchema",
              "desc": "Schema ensuring LLM returns organized list of code health problems",
              "inputs": "Used by LLM to structure code analysis response",
              "outputs": "Object with issues array containing structured problem reports"
            },
            {
              "name": "fileAnalysisSchema",
              "desc": "Schema ensuring LLM returns structured file documentation",
              "inputs": "Used by LLM to structure file analysis response",
              "outputs": "Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent"
            }
          ],
          "dependencies": [],
          "intent": "Eliminates unreliable LLM response parsing by enforcing strict JSON schemas that guarantee valid, structured output for product analysis, code health assessment, and documentation generation tasks.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure LLM responses to ensure valid, parseable output for product analysis, code health assessment, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and user goals\",\n    \"Gets organized lists of code health issues with clear titles and descriptions\",\n    \"Sees categorized architectural problems and design decisions\",\n    \"Receives formatted proposed fixes for identified issues\",\n    \"Gets structured documentation with sections for behaviors, functions, and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Sends codebase information to LLM and receives guaranteed JSON structure back\",\n    \"Uses schemas to validate LLM responses match expected format\",\n    \"Relies on schema enforcement to avoid manual parsing of LLM output\",\n    \"Gets predictable data structures for product purpose analysis including architecture rationale and user goals\",\n    \"Receives code health issues with required fields: title, description, relevant files, functions, and severity\",\n    \"Obtains structured file analysis with purpose, user/developer-facing actions, key functions, and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns structured product purpose analysis\",\n      \"inputs\": \"Used by LLM to structure response\",\n      \"outputs\": \"Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema defining structure for individual code health issues\",\n      \"inputs\": \"Nested within other schemas\",\n      \"outputs\": \"Object with title, description, relevantFiles, relevantFunctions, severity, priority\"\n    },\n    {\n      \"name\": \"codeHealthAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns organized list of code health problems\",\n      \"inputs\": \"Used by LLM to structure code analysis response\",\n      \"outputs\": \"Object with issues array containing structured problem reports\"\n    },\n    {\n      \"name\": \"fileAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns structured file documentation\",\n      \"inputs\": \"Used by LLM to structure file analysis response\",\n      \"outputs\": \"Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Eliminates unreliable LLM response parsing by enforcing strict JSON schemas that guarantee valid, structured output for product analysis, code health assessment, and documentation generation tasks.\"\n}\n```"
        },
        {
          "file": "src/llmService.ts",
          "role": "Core Logic",
          "purpose": "Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.",
          "userVisibleActions": [
            "Receives AI-generated explanations of what the product/codebase does",
            "Gets intelligent insights about code architecture and design patterns",
            "Views AI-generated product documentation with purpose, features, and architecture",
            "Sees automated test plans and suggestions for code improvements",
            "Receives refactoring suggestions for complex functions",
            "Gets incremental analysis updates as code changes"
          ],
          "developerVisibleActions": [
            "Calls AI providers to analyze entire codebases and generate product purpose summaries",
            "Requests AI analysis of code structure, entry points, and module relationships",
            "Generates enhanced product documentation by analyzing file summaries and module structure",
            "Creates unit test plans by analyzing code coverage and function signatures",
            "Obtains refactoring suggestions for specific functions or code sections",
            "Triggers incremental analysis for file changes without re-analyzing entire codebase",
            "Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration",
            "Handles rate limiting and retry logic for LLM API calls automatically",
            "Parses and validates LLM responses using predefined schemas",
            "Accesses detailed function metadata and code analysis results"
          ],
          "keyFunctions": [
            {
              "name": "analyzeProductPurpose",
              "desc": "Analyzes the entire codebase to determine the product's main purpose and architecture",
              "inputs": "CodeAnalysis object containing all analyzed files and their metadata",
              "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules"
            },
            {
              "name": "generateInsights",
              "desc": "Generates AI-powered insights about code quality, patterns, and potential issues",
              "inputs": "CodeAnalysis with file information and analysis context",
              "outputs": "LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions"
            },
            {
              "name": "generateEnhancedProductDocumentation",
              "desc": "Creates comprehensive product documentation by analyzing file summaries and module structure",
              "inputs": "Array of FileSummary and ModuleSummary objects",
              "outputs": "EnhancedProductDocumentation with product overview, architecture, features, and technical details"
            },
            {
              "name": "generateUnitTestPlan",
              "desc": "Analyzes code to create a test plan identifying untested functions and suggesting test cases",
              "inputs": "CodeAnalysis and list of existing test files",
              "outputs": "UnitTestPlan with prioritized list of functions to test and suggested test cases"
            },
            {
              "name": "generateRefactoringSuggestions",
              "desc": "Analyzes a specific function and provides refactoring recommendations",
              "inputs": "Function code, metadata, and surrounding context",
              "outputs": "RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps"
            },
            {
              "name": "performIncrementalAnalysis",
              "desc": "Analyzes changes to specific files without re-analyzing the entire codebase",
              "inputs": "Array of changed file paths and full code analysis",
              "outputs": "Updated analysis focusing only on changed files and their immediate dependencies"
            },
            {
              "name": "callLLM",
              "desc": "Makes authenticated API calls to configured LLM provider with rate limiting and retry logic",
              "inputs": "Prompt string, expected response schema, and optional provider override",
              "outputs": "Parsed and validated response from the LLM matching the specified schema"
            }
          ],
          "dependencies": [
            "vscode",
            "./fileDocumentation",
            "./analyzer",
            "./analysis/enhancedAnalyzer",
            "./llmSchemas",
            "./fileAccessHelper",
            "./logger",
            "./config/configurationManager",
            "./ai/providers/providerFactory",
            "./ai/llmResponseParser",
            "./ai/llmRateLimiter",
            "./ai/llmRetryHandler",
            "./domain/prompts/promptBuilder",
            "./domain/services/incrementalAnalysisService",
            "./domain/prompts/refactoringPromptBuilder",
            "./analysis/functionAnalyzer"
          ],
          "intent": "This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated explanations of what the product/codebase does\",\n    \"Gets intelligent insights about code architecture and design patterns\",\n    \"Views AI-generated product documentation with purpose, features, and architecture\",\n    \"Sees automated test plans and suggestions for code improvements\",\n    \"Receives refactoring suggestions for complex functions\",\n    \"Gets incremental analysis updates as code changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls AI providers to analyze entire codebases and generate product purpose summaries\",\n    \"Requests AI analysis of code structure, entry points, and module relationships\",\n    \"Generates enhanced product documentation by analyzing file summaries and module structure\",\n    \"Creates unit test plans by analyzing code coverage and function signatures\",\n    \"Obtains refactoring suggestions for specific functions or code sections\",\n    \"Triggers incremental analysis for file changes without re-analyzing entire codebase\",\n    \"Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration\",\n    \"Handles rate limiting and retry logic for LLM API calls automatically\",\n    \"Parses and validates LLM responses using predefined schemas\",\n    \"Accesses detailed function metadata and code analysis results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine the product's main purpose and architecture\",\n      \"inputs\": \"CodeAnalysis object containing all analyzed files and their metadata\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules\"\n    },\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates AI-powered insights about code quality, patterns, and potential issues\",\n      \"inputs\": \"CodeAnalysis with file information and analysis context\",\n      \"outputs\": \"LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation by analyzing file summaries and module structure\",\n      \"inputs\": \"Array of FileSummary and ModuleSummary objects\",\n      \"outputs\": \"EnhancedProductDocumentation with product overview, architecture, features, and technical details\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Analyzes code to create a test plan identifying untested functions and suggesting test cases\",\n      \"inputs\": \"CodeAnalysis and list of existing test files\",\n      \"outputs\": \"UnitTestPlan with prioritized list of functions to test and suggested test cases\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Analyzes a specific function and provides refactoring recommendations\",\n      \"inputs\": \"Function code, metadata, and surrounding context\",\n      \"outputs\": \"RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps\"\n    },\n    {\n      \"name\": \"performIncrementalAnalysis\",\n      \"desc\": \"Analyzes changes to specific files without re-analyzing the entire codebase\",\n      \"inputs\": \"Array of changed file paths and full code analysis\",\n      \"outputs\": \"Updated analysis focusing only on changed files and their immediate dependencies\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Makes authenticated API calls to configured LLM provider with rate limiting and retry logic\",\n      \"inputs\": \"Prompt string, expected response schema, and optional provider override\",\n      \"outputs\": \"Parsed and validated response from the LLM matching the specified schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.\"\n}\n```"
        },
        {
          "file": "src/logger.ts",
          "role": "Core Logic",
          "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
          "userVisibleActions": [
            "Creates a .shadow/logs directory in the workspace root if it doesn't exist",
            "Writes log entries to a shadow-watch.log file with timestamps",
            "Logs are persistent and can be reviewed to troubleshoot extension behavior"
          ],
          "developerVisibleActions": [
            "Call SWLogger.log() to write timestamped messages to the log file",
            "Call SWLogger.section() to create visual separators in the log with section titles",
            "Logging automatically handles errors silently without crashing the extension",
            "Log files are stored at workspace-root/.shadow/logs/shadow-watch.log"
          ],
          "keyFunctions": [
            {
              "name": "log",
              "desc": "Writes a timestamped message to the shadow-watch.log file",
              "inputs": "message (string): The text to log",
              "outputs": "void (no return value)"
            },
            {
              "name": "section",
              "desc": "Creates a formatted section header in the log file with blank lines for readability",
              "inputs": "title (string): The section heading text",
              "outputs": "void (no return value)"
            },
            {
              "name": "getLogPath",
              "desc": "Determines the file path where logs should be written, creating directories if needed",
              "inputs": "none",
              "outputs": "string | null: The log file path, or null if no workspace is open"
            },
            {
              "name": "ensureDir",
              "desc": "Creates a directory and its parent directories if they don't exist",
              "inputs": "dir (string): The directory path to create",
              "outputs": "void (no return value)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "vscode"
          ],
          "intent": "This file exists to provide a centralized, reliable logging mechanism for debugging and monitoring the extension's behavior, storing logs in a predictable location within the workspace that users can access to troubleshoot issues without interfering with normal extension operation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Creates a .shadow/logs directory in the workspace root if it doesn't exist\",\n    \"Writes log entries to a shadow-watch.log file with timestamps\",\n    \"Logs are persistent and can be reviewed to troubleshoot extension behavior\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call SWLogger.log() to write timestamped messages to the log file\",\n    \"Call SWLogger.section() to create visual separators in the log with section titles\",\n    \"Logging automatically handles errors silently without crashing the extension\",\n    \"Log files are stored at workspace-root/.shadow/logs/shadow-watch.log\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message (string): The text to log\",\n      \"outputs\": \"void (no return value)\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a formatted section header in the log file with blank lines for readability\",\n      \"inputs\": \"title (string): The section heading text\",\n      \"outputs\": \"void (no return value)\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path where logs should be written, creating directories if needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null: The log file path, or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory and its parent directories if they don't exist\",\n      \"inputs\": \"dir (string): The directory path to create\",\n      \"outputs\": \"void (no return value)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, reliable logging mechanism for debugging and monitoring the extension's behavior, storing logs in a predictable location within the workspace that users can access to troubleshoot issues without interfering with normal extension operation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadow-watch.analyzeWorkspace",
          "description": "Analyze entire workspace to extract code structure, metrics, and quality insights"
        },
        {
          "command": "shadow-watch.analyzeFile",
          "description": "Analyze currently active file to generate file-specific insights"
        },
        {
          "command": "shadow-watch.refreshInsights",
          "description": "Refresh the insights tree view to show updated analysis results"
        },
        {
          "command": "shadow-watch.clearCache",
          "description": "Clear analysis cache to force fresh analysis of workspace"
        },
        {
          "command": "shadow-watch.exportAnalysis",
          "description": "Export analysis results in selected format (Markdown or JSON)"
        },
        {
          "command": "shadow-watch.generateProductDocs",
          "description": "Generate AI-powered product documentation from codebase analysis"
        },
        {
          "command": "shadow-watch.generateArchitectureInsights",
          "description": "Generate AI-powered architecture insights and design pattern analysis"
        },
        {
          "command": "shadow-watch.viewInEditor",
          "description": "Open analysis results or documentation in editor view"
        },
        {
          "command": "shadow-watch.navigateToCode",
          "description": "Jump to specific code location from tree view item"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized management of all Shadow Watch extension settings with type-safe access",
        "Automatic detection and propagation of configuration changes across the extension",
        "Control of analysis behavior including auto-trigger on file save and timeout limits",
        "Customization of editor display features like inline hints and diagnostic severity filtering",
        "Selection and configuration of AI provider (OpenAI or Claude) for security analysis",
        "Control of analysis output format and presentation",
        "Real-time configuration updates without requiring extension reload"
      ],
      "summary": "The config module serves as the central configuration hub for Shadow Watch, providing type-safe access to all extension settings and automatically detecting when users modify preferences. It acts as the bridge between VS Code's settings system and the extension's runtime behavior, ensuring that configuration changes immediately affect how the extension operates.\n\nUsers interact with this module indirectly through VS Code's settings interface. When they modify Shadow Watch preferences, the configuration manager detects these changes and notifies relevant extension components. This enables workflows like enabling 'analyze on save' to automatically trigger security analysis whenever a file is saved, adjusting diagnostic severity thresholds to filter which security issues are displayed in the editor, or switching between OpenAI and Claude as the AI provider.\n\nThe module manages critical settings that control the entire user experience: whether inline security hints appear in the editor, how long analysis operations can run before timing out, which severity level of issues should be shown as VS Code diagnostics, and how analysis results are formatted in the output panel. All configuration access is type-safe, preventing runtime errors from misconfigured settings and ensuring consistent behavior across the extension.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all Shadow Watch extension settings with type-safe access and automatic change detection",
          "userVisibleActions": [
            "Extension behavior changes when user modifies settings in VS Code preferences",
            "Analysis triggers automatically on save if analyzeOnSave is enabled",
            "Inline hints appear in editor based on showInlineHints setting",
            "Analysis respects configured timeout limits",
            "Diagnostic severity threshold filters which issues are shown",
            "LLM provider (OpenAI/Claude) determines which AI service is used",
            "Output format controls how analysis results are displayed"
          ],
          "developerVisibleActions": [
            "Provides centralized access to all extension configuration values",
            "Automatically reloads configuration when VS Code settings change",
            "Notifies registered listeners when configuration updates occur",
            "Validates configuration settings and returns validation errors",
            "Exposes typed getters for each configuration property",
            "Handles missing configuration values with sensible defaults",
            "Manages LLM provider selection (OpenAI vs Claude)",
            "Controls analysis behavior through boolean flags"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes configuration manager and sets up change watcher",
              "inputs": "none",
              "outputs": "ConfigurationManager instance"
            },
            {
              "name": "setupWatcher",
              "desc": "Monitors VS Code settings changes and triggers listener callbacks",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "onConfigurationChange",
              "desc": "Registers callback to be invoked when configuration changes",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Unregisters a configuration change callback",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "enabled (getter)",
              "desc": "Returns whether Shadow Watch extension is enabled",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave (getter)",
              "desc": "Returns whether to automatically analyze files on save",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "showInlineHints (getter)",
              "desc": "Returns whether to display inline hints in editor",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "llmProvider (getter)",
              "desc": "Returns configured LLM provider (openai or claude)",
              "inputs": "none",
              "outputs": "LLMProvider"
            },
            {
              "name": "llmFormat (getter)",
              "desc": "Returns output format for LLM responses",
              "inputs": "none",
              "outputs": "LLMFormat"
            },
            {
              "name": "severityThreshold (getter)",
              "desc": "Returns minimum severity level for displaying diagnostics",
              "inputs": "none",
              "outputs": "SeverityThreshold"
            },
            {
              "name": "validate",
              "desc": "Validates current configuration and returns errors if any",
              "inputs": "none",
              "outputs": "ConfigValidationResult"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "Provides a single source of truth for all extension settings, ensuring type safety, automatic updates when settings change, and consistent access to configuration values throughout the extension. Eliminates direct workspace.getConfiguration calls scattered across the codebase and ensures all components react to setting changes uniformly.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings with type-safe access and automatic change detection\",\n  \"userVisibleActions\": [\n    \"Extension behavior changes when user modifies settings in VS Code preferences\",\n    \"Analysis triggers automatically on save if analyzeOnSave is enabled\",\n    \"Inline hints appear in editor based on showInlineHints setting\",\n    \"Analysis respects configured timeout limits\",\n    \"Diagnostic severity threshold filters which issues are shown\",\n    \"LLM provider (OpenAI/Claude) determines which AI service is used\",\n    \"Output format controls how analysis results are displayed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized access to all extension configuration values\",\n    \"Automatically reloads configuration when VS Code settings change\",\n    \"Notifies registered listeners when configuration updates occur\",\n    \"Validates configuration settings and returns validation errors\",\n    \"Exposes typed getters for each configuration property\",\n    \"Handles missing configuration values with sensible defaults\",\n    \"Manages LLM provider selection (OpenAI vs Claude)\",\n    \"Controls analysis behavior through boolean flags\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes configuration manager and sets up change watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Monitors VS Code settings changes and triggers listener callbacks\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers callback to be invoked when configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled (getter)\",\n      \"desc\": \"Returns whether Shadow Watch extension is enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave (getter)\",\n      \"desc\": \"Returns whether to automatically analyze files on save\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints (getter)\",\n      \"desc\": \"Returns whether to display inline hints in editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider (getter)\",\n      \"desc\": \"Returns configured LLM provider (openai or claude)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider\"\n    },\n    {\n      \"name\": \"llmFormat (getter)\",\n      \"desc\": \"Returns output format for LLM responses\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMFormat\"\n    },\n    {\n      \"name\": \"severityThreshold (getter)\",\n      \"desc\": \"Returns minimum severity level for displaying diagnostics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"SeverityThreshold\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Validates current configuration and returns errors if any\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Provides a single source of truth for all extension settings, ensuring type safety, automatic updates when settings change, and consistent access to configuration values throughout the extension. Eliminates direct workspace.getConfiguration calls scattered across the codebase and ensures all components react to setting changes uniformly.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Automatically converts code analysis results into LLM-compatible context format",
        "Persists analysis data to workspace storage for future reference",
        "Generates timestamped metadata for tracking analysis provenance",
        "Stores analysis documentation in a structured .shadow/docs directory",
        "Provides formatted context data suitable for AI-powered code understanding"
      ],
      "summary": "This module bridges the gap between code analysis and AI language model services by transforming raw analysis results into a structured format optimized for LLM consumption. When code analysis is performed, this module automatically processes the results and saves them to the workspace in a standardized context format.\n\nThe module manages persistent storage of analysis data within a dedicated .shadow/docs directory structure in your workspace. Each analysis result is saved with comprehensive metadata including generation timestamps, ensuring you have a historical record of code analysis for reference and tracking purposes. This persistent storage enables AI services to access and utilize analysis data efficiently without requiring re-analysis.\n\nFrom a user perspective, this module operates automatically in the background - whenever code analysis occurs, the results are seamlessly converted and stored without manual intervention. The stored context data becomes available for AI-powered features like code explanations, refactoring suggestions, and intelligent code completion, providing a foundation for enhanced developer productivity through AI assistance.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis data into a context format suitable for LLM services and saves it to persistent storage.",
          "userVisibleActions": [
            "Code analysis results are automatically saved to the workspace",
            "Analysis data is stored in a .shadow/docs directory for future reference",
            "Analysis includes metadata with generation timestamp"
          ],
          "developerVisibleActions": [
            "Convert CodeAnalysis objects to AnalysisContext format for LLM processing",
            "Save analysis results as JSON files in the .shadow/docs directory",
            "Creates .shadow and .shadow/docs directories automatically if they don't exist",
            "Adds metadata (generation timestamp) to saved analysis files",
            "Handles workspace folder validation before saving"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms CodeAnalysis data structure into AnalysisContext format",
              "inputs": "analysis: CodeAnalysis object containing files, imports, entry points, and statistics",
              "outputs": "AnalysisContext object with formatted file paths, imports, entry points, and metrics"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to a JSON file in the workspace",
              "inputs": "analysis: CodeAnalysis object to save",
              "outputs": "void (creates/updates code-analysis.json file with metadata)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between code analysis results and LLM service requirements by transforming data formats and providing persistent storage of analysis results for future use and debugging.",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis data into a context format suitable for LLM services and saves it to persistent storage.\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to the workspace\",\n    \"Analysis data is stored in a .shadow/docs directory for future reference\",\n    \"Analysis includes metadata with generation timestamp\"\n  ],\n  \"developerVisibleActions\": [\n    \"Convert CodeAnalysis objects to AnalysisContext format for LLM processing\",\n    \"Save analysis results as JSON files in the .shadow/docs directory\",\n    \"Creates .shadow and .shadow/docs directories automatically if they don't exist\",\n    \"Adds metadata (generation timestamp) to saved analysis files\",\n    \"Handles workspace folder validation before saving\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format\",\n      \"inputs\": \"analysis: CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file paths, imports, entry points, and metrics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to a JSON file in the workspace\",\n      \"inputs\": \"analysis: CodeAnalysis object to save\",\n      \"outputs\": \"void (creates/updates code-analysis.json file with metadata)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM service requirements by transforming data formats and providing persistent storage of analysis results for future use and debugging.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Initialize and activate the VS Code extension with all required components",
        "Register and manage all extension commands for code analysis operations",
        "Set up UI components including status bar, tree views, and diagnostics",
        "Enable automatic file watching for continuous analysis",
        "Provide command palette access to all extension features",
        "Configure multiple sidebar views for insights, reports, and navigation",
        "Manage LLM provider switching and configuration"
      ],
      "summary": "The bootstrap module serves as the initialization and command coordination layer for the code analysis extension. It handles the complete startup sequence when the extension activates in VS Code, setting up all necessary UI components, registering commands, and preparing the extension for user interaction. This module acts as the entry point that transforms the extension from an inactive state to a fully operational code analysis tool.\n\nThe module provides comprehensive command registration covering the entire extension workflow - from analyzing code (workspace-wide or single files) to managing insights, viewing reports, switching between AI providers, and navigating analyzed code structures. Users interact with these commands through the VS Code command palette, context menus, and custom UI elements like tree views and status bars.\n\nThrough this module, users gain access to a complete suite of code analysis capabilities including generating insights, copying analysis results, clearing cached data, viewing detailed reports, managing unit test information, accessing static analysis results, and navigating through their codebase using the product navigator. The module ensures all these features are properly initialized and ready to respond to user actions from the moment the extension activates.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers and manages all VS Code commands for the code analysis extension, mapping command IDs to their handler functions.",
          "userVisibleActions": [
            "Analyze entire workspace to generate insights",
            "Analyze current file being edited",
            "Copy all analysis insights to clipboard",
            "Copy insights for a specific file",
            "Copy a single insight item",
            "Clear cached analysis data",
            "Clear all extension data",
            "Open extension settings",
            "View latest analysis report",
            "View latest unit test report",
            "Switch between LLM providers (e.g., OpenAI, Anthropic)",
            "View menu structure of analyzed code",
            "Check current LLM provider status",
            "Navigate to specific product/code items",
            "View detailed information about insights",
            "View detailed information about unit tests"
          ],
          "developerVisibleActions": [
            "Commands are registered during extension activation and bound to handler functions",
            "Command handlers interact with analyzer, insight generator, cache, and tree view components",
            "Command registration is centralized for easier maintenance and testing",
            "All command subscriptions are added to context for proper cleanup",
            "Configuration manager is accessed to retrieve user settings during command execution"
          ],
          "keyFunctions": [
            {
              "name": "register",
              "desc": "Registers all VS Code commands with their corresponding handler functions",
              "inputs": "context: vscode.ExtensionContext, components: ExtensionComponents",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "This file exists to separate command registration logic from the main extension activation code, providing a clean interface for registering all user-facing commands and making the command structure easier to maintain and test. It solves the problem of command sprawl by centralizing all command definitions and their handlers in one place.",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers and manages all VS Code commands for the code analysis extension, mapping command IDs to their handler functions.\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to generate insights\",\n    \"Analyze current file being edited\",\n    \"Copy all analysis insights to clipboard\",\n    \"Copy insights for a specific file\",\n    \"Copy a single insight item\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers (e.g., OpenAI, Anthropic)\",\n    \"View menu structure of analyzed code\",\n    \"Check current LLM provider status\",\n    \"Navigate to specific product/code items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Commands are registered during extension activation and bound to handler functions\",\n    \"Command handlers interact with analyzer, insight generator, cache, and tree view components\",\n    \"Command registration is centralized for easier maintenance and testing\",\n    \"All command subscriptions are added to context for proper cleanup\",\n    \"Configuration manager is accessed to retrieve user settings during command execution\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their corresponding handler functions\",\n      \"inputs\": \"context: vscode.ExtensionContext, components: ExtensionComponents\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file exists to separate command registration logic from the main extension activation code, providing a clean interface for registering all user-facing commands and making the command structure easier to maintain and test. It solves the problem of command sprawl by centralizing all command definitions and their handlers in one place.\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Initializes and bootstraps all extension components during VS Code extension activation",
          "userVisibleActions": [
            "Extension activates and becomes ready to use in VS Code",
            "Status bar item appears showing extension status",
            "Multiple tree views become available in the sidebar (Insights, Analysis, Reports, Product Navigator, Unit Tests, Static Analysis)",
            "Code diagnostics and insights start appearing in the editor",
            "File watching begins for automatic analysis on file changes",
            "Commands become available in the command palette for interacting with the extension"
          ],
          "developerVisibleActions": [
            "Call bootstrap function to initialize all extension components during activation",
            "Receive initialized component instances (analyzer, insight generator, formatters, viewers, etc.)",
            "Access centralized extension state through state manager",
            "Configure components through configuration manager",
            "Handle extension lifecycle through bootstrapper setup",
            "Register all tree views, commands, and UI providers automatically",
            "Set up error handling and caching mechanisms"
          ],
          "keyFunctions": [
            {
              "name": "bootstrap",
              "desc": "Main entry point that initializes all extension components and wires them together",
              "inputs": "vscode.ExtensionContext - VS Code extension context for registration",
              "outputs": "ExtensionComponents - Object containing all initialized component instances"
            },
            {
              "name": "ExtensionComponents interface",
              "desc": "Defines the structure of all components that make up the extension",
              "inputs": "N/A - Type definition",
              "outputs": "Type containing analyzer, generators, viewers, providers, cache, status bar, and tree views"
            }
          ],
          "dependencies": [
            "vscode",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "FileWatcher",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "llmIntegration",
            "ProductNavigatorProvider",
            "AnalysisViewerProvider",
            "InsightsViewerProvider",
            "StaticAnalysisViewerProvider",
            "UnitTestsNavigatorProvider",
            "configurationManager",
            "ErrorHandler",
            "FileWatcherService",
            "ReportsViewer",
            "ReportsTreeProvider",
            "llmStateManager"
          ],
          "intent": "This file exists to centralize and organize the complex initialization sequence of all extension components. It solves the problem of scattered initialization logic by providing a single bootstrap function that creates all components in the correct order, wires dependencies between them, and returns a structured object for use by the main extension. This separation makes the extension more maintainable and testable by isolating activation logic from the main extension entry point.",
          "rawContent": "```json\n{\n  \"purpose\": \"Initializes and bootstraps all extension components during VS Code extension activation\",\n  \"userVisibleActions\": [\n    \"Extension activates and becomes ready to use in VS Code\",\n    \"Status bar item appears showing extension status\",\n    \"Multiple tree views become available in the sidebar (Insights, Analysis, Reports, Product Navigator, Unit Tests, Static Analysis)\",\n    \"Code diagnostics and insights start appearing in the editor\",\n    \"File watching begins for automatic analysis on file changes\",\n    \"Commands become available in the command palette for interacting with the extension\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call bootstrap function to initialize all extension components during activation\",\n    \"Receive initialized component instances (analyzer, insight generator, formatters, viewers, etc.)\",\n    \"Access centralized extension state through state manager\",\n    \"Configure components through configuration manager\",\n    \"Handle extension lifecycle through bootstrapper setup\",\n    \"Register all tree views, commands, and UI providers automatically\",\n    \"Set up error handling and caching mechanisms\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components and wires them together\",\n      \"inputs\": \"vscode.ExtensionContext - VS Code extension context for registration\",\n      \"outputs\": \"ExtensionComponents - Object containing all initialized component instances\"\n    },\n    {\n      \"name\": \"ExtensionComponents interface\",\n      \"desc\": \"Defines the structure of all components that make up the extension\",\n      \"inputs\": \"N/A - Type definition\",\n      \"outputs\": \"Type containing analyzer, generators, viewers, providers, cache, status bar, and tree views\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and organize the complex initialization sequence of all extension components. It solves the problem of scattered initialization logic by providing a single bootstrap function that creates all components in the correct order, wires dependencies between them, and returns a structured object for use by the main extension. This separation makes the extension more maintainable and testable by isolating activation logic from the main extension entry point.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "analyzeWorkspace",
          "description": "Analyze the entire workspace to generate comprehensive code insights"
        },
        {
          "command": "analyzeCurrentFile",
          "description": "Analyze only the currently active file in the editor"
        },
        {
          "command": "copyAllInsights",
          "description": "Copy all generated analysis insights to the clipboard"
        },
        {
          "command": "copyFileInsights",
          "description": "Copy insights for a specific file to the clipboard"
        },
        {
          "command": "copyInsightItem",
          "description": "Copy a single insight item to the clipboard"
        },
        {
          "command": "clearCache",
          "description": "Clear cached analysis data to force fresh analysis"
        },
        {
          "command": "clearAllData",
          "description": "Clear all extension data including cache and settings"
        },
        {
          "command": "openSettings",
          "description": "Open the extension settings panel"
        },
        {
          "command": "viewAnalysisReport",
          "description": "View the latest analysis report"
        },
        {
          "command": "viewUnitTestReport",
          "description": "View the latest unit test report"
        },
        {
          "command": "switchLLMProvider",
          "description": "Switch between different LLM providers (OpenAI, Anthropic, etc.)"
        },
        {
          "command": "viewMenuStructure",
          "description": "View the menu structure of the analyzed codebase"
        },
        {
          "command": "checkProviderStatus",
          "description": "Check the current status of the active LLM provider"
        },
        {
          "command": "navigateToItem",
          "description": "Navigate to a specific product or code item in the codebase"
        },
        {
          "command": "viewInsightDetails",
          "description": "View detailed information about a specific insight"
        },
        {
          "command": "viewUnitTestDetails",
          "description": "View detailed information about unit tests"
        }
      ],
      "workers": []
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Transforms raw product documentation into structured, human-readable Markdown format with consistent sections",
        "Formats LLM-generated code analysis insights into organized documentation with clear behavioral descriptions",
        "Organizes documentation by user perspective (GUI, CLI, API) to support different interaction patterns",
        "Structures technical details, features, and workflows into scannable sections with timestamps",
        "Presents file-by-file code behavior analysis grouped by role and type for easy comprehension",
        "Formats usage examples, configuration requirements, and deployment considerations into readable guides"
      ],
      "summary": "This module provides documentation formatting capabilities that transform technical analysis and product information into well-structured Markdown documents. It serves as the presentation layer for both product documentation and code analysis insights, ensuring consistent formatting and organization that makes complex technical information accessible to human readers.\n\nUsers receive documentation organized into logical sections including overview summaries, feature lists, user perspectives for different interaction modes (GUI, CLI, API), and detailed technical specifications. The module formats code analysis results by grouping file behaviors by their roles and types, making it easy to understand how different components work together. All output includes timestamps and follows a consistent structure that supports quick scanning and comprehension.\n\nThe formatting workflow takes raw analysis data and product information as input, then applies structured templates to produce Markdown documents suitable for technical documentation, developer guides, and system understanding. This enables teams to quickly generate readable documentation from automated code analysis and maintain consistent documentation standards across products.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and code analysis insights into structured Markdown documents for human reading.",
          "userVisibleActions": [
            "Receives formatted product documentation in Markdown with timestamps, overview, features, and user perspectives",
            "Sees documentation organized by sections: What It Does, User Perspective (GUI/CLI/API), Key Features, Technical Details",
            "Views LLM analysis insights formatted as Markdown with file-by-file behavioral descriptions",
            "Reads structured sections for product patterns, architecture decisions, user workflows, and technical stack",
            "Sees formatted usage examples, configuration requirements, and deployment considerations",
            "Gets human-readable summaries of code behavior grouped by file role and type"
          ],
          "developerVisibleActions": [
            "Calls formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects to Markdown strings",
            "Calls formatLLMInsightsAsMarkdown() to convert LLMInsights objects to Markdown strings",
            "Receives Markdown with timestamps (both UTC and local time) automatically included",
            "Gets documentation sections conditionally included based on data availability",
            "Obtains formatted lists with bullet points for features, workflows, and technical details",
            "Receives structured file analysis organized by user-facing, developer-facing, and technical aspects"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation object into a formatted Markdown document with sections for overview, features, user perspectives, and technical details",
              "inputs": "EnhancedProductDocumentation object containing overview, features, user perspectives, technical details, etc.",
              "outputs": "String containing formatted Markdown document with headers, timestamps, and structured sections"
            },
            {
              "name": "formatLLMInsightsAsMarkdown",
              "desc": "Converts LLM analysis insights into a formatted Markdown document with product summary and per-file behavioral descriptions",
              "inputs": "LLMInsights object containing product summary and array of file insights with behavior descriptions",
              "outputs": "String containing formatted Markdown document with product overview and file-by-file analysis sections"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "Separates formatting concerns from business logic by providing dedicated functions to transform structured documentation data into human-readable Markdown format, making it easier to generate consistent, well-organized documentation output for users and developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and code analysis insights into structured Markdown documents for human reading.\",\n  \"userVisibleActions\": [\n    \"Receives formatted product documentation in Markdown with timestamps, overview, features, and user perspectives\",\n    \"Sees documentation organized by sections: What It Does, User Perspective (GUI/CLI/API), Key Features, Technical Details\",\n    \"Views LLM analysis insights formatted as Markdown with file-by-file behavioral descriptions\",\n    \"Reads structured sections for product patterns, architecture decisions, user workflows, and technical stack\",\n    \"Sees formatted usage examples, configuration requirements, and deployment considerations\",\n    \"Gets human-readable summaries of code behavior grouped by file role and type\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects to Markdown strings\",\n    \"Calls formatLLMInsightsAsMarkdown() to convert LLMInsights objects to Markdown strings\",\n    \"Receives Markdown with timestamps (both UTC and local time) automatically included\",\n    \"Gets documentation sections conditionally included based on data availability\",\n    \"Obtains formatted lists with bullet points for features, workflows, and technical details\",\n    \"Receives structured file analysis organized by user-facing, developer-facing, and technical aspects\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into a formatted Markdown document with sections for overview, features, user perspectives, and technical details\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, user perspectives, technical details, etc.\",\n      \"outputs\": \"String containing formatted Markdown document with headers, timestamps, and structured sections\"\n    },\n    {\n      \"name\": \"formatLLMInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM analysis insights into a formatted Markdown document with product summary and per-file behavioral descriptions\",\n      \"inputs\": \"LLMInsights object containing product summary and array of file insights with behavior descriptions\",\n      \"outputs\": \"String containing formatted Markdown document with product overview and file-by-file analysis sections\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates formatting concerns from business logic by providing dedicated functions to transform structured documentation data into human-readable Markdown format, making it easier to generate consistent, well-organized documentation output for users and developers.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate to specific files in the workspace editor",
        "Jump to function definitions and scroll to their exact location in code",
        "Navigate to API endpoints and their implementations",
        "View detailed information panels about code elements including signatures and parameters",
        "Access entry points in the codebase through navigation items",
        "Display formatted details about analyzed code structures",
        "Handle navigation errors with informative error messages"
      ],
      "summary": "The Navigation Handler module provides comprehensive code navigation capabilities within the workspace. It enables users to seamlessly move between different code locations, whether they're files, functions, API endpoints, or other code elements that have been analyzed.\n\nThe module supports multiple navigation workflows: direct file opening in the editor, precise function location with automatic scrolling, and endpoint-to-implementation navigation. When users interact with analyzed code items, they can click to navigate to the source or view detailed information in a separate panel that displays signatures, parameters, and relationships.\n\nError handling is built into the navigation flow, providing clear feedback when files cannot be opened or navigation targets are unavailable. This makes code exploration intuitive and reliable, helping users understand and traverse their codebase structure efficiently.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation to files, functions, endpoints, and other code locations within the workspace, and displays detailed information about analyzed items.",
          "userVisibleActions": [
            "Navigate to a specific file in the editor when clicking on file items",
            "Navigate to a specific function definition within a file and scroll to its location",
            "Navigate to API endpoints and their implementations in code",
            "View detailed information panel showing function signatures, parameters, and relationships",
            "See error messages when files cannot be opened or navigation fails",
            "Jump to entry points in the codebase from navigation items",
            "View formatted details about analyzed code elements in a separate panel"
          ],
          "developerVisibleActions": [
            "Triggers file opening in VS Code editor with proper error handling",
            "Performs intelligent search for function definitions within files using AST parsing",
            "Resolves absolute and relative file paths based on workspace root",
            "Opens text documents and positions cursor at specific line numbers",
            "Handles navigation for different item types: files, functions, endpoints, entry points",
            "Displays formatted analysis details in webview panels with HTML rendering",
            "Manages editor revealing and selection of code ranges",
            "Searches for function definitions across multiple potential formats and languages"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to a product navigation item (file, function, or endpoint) in the editor",
              "inputs": "ProductNavItem containing type and data with file/function information",
              "outputs": "Promise<void> - completes when navigation is finished or fails with error message"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to an analysis item and optionally shows its details",
              "inputs": "AnalysisItem with file path and optional line number",
              "outputs": "Promise<void> - opens document and positions cursor at specified location"
            },
            {
              "name": "showAnalysisItemDetails",
              "desc": "Displays detailed information about an analyzed item in a webview panel",
              "inputs": "AnalysisItem containing element details, dependencies, and metadata",
              "outputs": "void - creates and shows a webview panel with formatted HTML content"
            },
            {
              "name": "navigateToEntryPoint",
              "desc": "Navigates to an entry point in the codebase",
              "inputs": "EntryPoint object with file path and optional line/column information",
              "outputs": "Promise<void> - opens file and positions at entry point location"
            },
            {
              "name": "findFunctionInDocument",
              "desc": "Searches for a function definition within a document to determine its line number",
              "inputs": "TextDocument and function name string",
              "outputs": "number or undefined - line number where function is defined"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "ProductNavItem from productNavigator",
            "AnalysisItem from analysisViewer",
            "EntryPoint from analyzer"
          ],
          "intent": "This file exists to centralize all navigation logic in the extension, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to specific code locations and display detailed information about code elements.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations within the workspace, and displays detailed information about analyzed items.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the editor when clicking on file items\",\n    \"Navigate to a specific function definition within a file and scroll to its location\",\n    \"Navigate to API endpoints and their implementations in code\",\n    \"View detailed information panel showing function signatures, parameters, and relationships\",\n    \"See error messages when files cannot be opened or navigation fails\",\n    \"Jump to entry points in the codebase from navigation items\",\n    \"View formatted details about analyzed code elements in a separate panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers file opening in VS Code editor with proper error handling\",\n    \"Performs intelligent search for function definitions within files using AST parsing\",\n    \"Resolves absolute and relative file paths based on workspace root\",\n    \"Opens text documents and positions cursor at specific line numbers\",\n    \"Handles navigation for different item types: files, functions, endpoints, entry points\",\n    \"Displays formatted analysis details in webview panels with HTML rendering\",\n    \"Manages editor revealing and selection of code ranges\",\n    \"Searches for function definitions across multiple potential formats and languages\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, or endpoint) in the editor\",\n      \"inputs\": \"ProductNavItem containing type and data with file/function information\",\n      \"outputs\": \"Promise<void> - completes when navigation is finished or fails with error message\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item and optionally shows its details\",\n      \"inputs\": \"AnalysisItem with file path and optional line number\",\n      \"outputs\": \"Promise<void> - opens document and positions cursor at specified location\"\n    },\n    {\n      \"name\": \"showAnalysisItemDetails\",\n      \"desc\": \"Displays detailed information about an analyzed item in a webview panel\",\n      \"inputs\": \"AnalysisItem containing element details, dependencies, and metadata\",\n      \"outputs\": \"void - creates and shows a webview panel with formatted HTML content\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point in the codebase\",\n      \"inputs\": \"EntryPoint object with file path and optional line/column information\",\n      \"outputs\": \"Promise<void> - opens file and positions at entry point location\"\n    },\n    {\n      \"name\": \"findFunctionInDocument\",\n      \"desc\": \"Searches for a function definition within a document to determine its line number\",\n      \"inputs\": \"TextDocument and function name string\",\n      \"outputs\": \"number or undefined - line number where function is defined\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic in the extension, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to specific code locations and display detailed information about code elements.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Generate AI prompts for comprehensive code analysis and architecture documentation",
        "Create structured prompts for automated test generation and test planning",
        "Build detailed refactoring recommendations with step-by-step extraction plans",
        "Extract product documentation and value propositions from codebases",
        "Produce file-level and module-level documentation summaries",
        "Analyze test configurations and recommend optimal testing strategies",
        "Generate prescriptive migration instructions for code reorganization"
      ],
      "summary": "This module serves as the prompt engineering foundation for AI-powered code analysis and transformation. It constructs carefully designed prompts that guide large language models to analyze codebases, generate documentation, create tests, and recommend refactorings. Users interact with this module through the various AI-assisted features in the application, where it translates their code into structured queries that produce actionable insights.\n\nThe module supports multiple user workflows: documentation generation (from architecture analysis to product summaries), test creation (from test planning to implementation guidance), and code refactoring (from analysis to prescriptive extraction steps). Each workflow produces structured, consistent output that helps developers understand their codebase, improve test coverage, and maintain code quality through systematic refactoring.\n\nBy centralizing all prompt construction logic, the module ensures consistency across different AI-powered features while providing specialized templates for distinct tasks like configuration analysis, function extraction planning, and mock requirement identification. This enables users to leverage AI assistance for complex development tasks without needing to craft prompts themselves.",
      "files": [
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Centralizes construction of all LLM prompts for code analysis, documentation, and test generation tasks",
          "userVisibleActions": [
            "Receives architecture analysis of their codebase structure and patterns",
            "Gets product documentation generated from their code",
            "Sees product purpose and value proposition extracted from documentation",
            "Views file-level analysis summaries with behavior descriptions",
            "Receives module-level rollup documentation combining related files",
            "Gets test plans generated for their source code files",
            "Receives generated test code based on test plans"
          ],
          "developerVisibleActions": [
            "Provides standardized prompt templates for all LLM interactions",
            "Builds architecture analysis prompts using context, code analysis, and product docs",
            "Constructs product documentation prompts from analysis context",
            "Creates product purpose extraction prompts from existing documentation",
            "Generates file analysis prompts with role-based context",
            "Builds module rollup prompts combining multiple file summaries",
            "Creates product-level documentation prompts from all summaries and analysis",
            "Generates per-file test plan prompts with existing test awareness",
            "Constructs test code generation prompts from test plans and source code"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Creates prompt for analyzing codebase architecture patterns and structure",
              "inputs": "AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Creates prompt for generating product-level documentation",
              "inputs": "AnalysisContext",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Creates prompt for extracting product purpose and value proposition",
              "inputs": "EnhancedProductDocumentation, AnalysisContext",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Creates prompt for analyzing individual file behavior and role",
              "inputs": "FileInfo, file content string, role classification",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Creates prompt for rolling up multiple file summaries into module documentation",
              "inputs": "Module path, module type, array of FileSummary objects",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Creates prompt for generating comprehensive product-level documentation",
              "inputs": "FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Creates prompt for generating test plans for a specific file",
              "inputs": "File path, content, function metadata, existing tests, language, test framework, optional project summary",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Creates prompt for generating actual test code from test plans",
              "inputs": "Test plan item, source code, function code, language, test framework",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "../../llmService",
            "../../analyzer",
            "../../fileDocumentation",
            "../../fileAccessHelper"
          ],
          "intent": "This file exists to eliminate duplication and centralize all LLM prompt construction logic. Previously scattered across multiple files, this builder provides a single source of truth for how prompts are formatted, ensuring consistency in LLM interactions and making prompt engineering changes easier to manage across architecture analysis, documentation generation, and test creation workflows.",
          "rawContent": "```json\n{\n  \"purpose\": \"Centralizes construction of all LLM prompts for code analysis, documentation, and test generation tasks\",\n  \"userVisibleActions\": [\n    \"Receives architecture analysis of their codebase structure and patterns\",\n    \"Gets product documentation generated from their code\",\n    \"Sees product purpose and value proposition extracted from documentation\",\n    \"Views file-level analysis summaries with behavior descriptions\",\n    \"Receives module-level rollup documentation combining related files\",\n    \"Gets test plans generated for their source code files\",\n    \"Receives generated test code based on test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides standardized prompt templates for all LLM interactions\",\n    \"Builds architecture analysis prompts using context, code analysis, and product docs\",\n    \"Constructs product documentation prompts from analysis context\",\n    \"Creates product purpose extraction prompts from existing documentation\",\n    \"Generates file analysis prompts with role-based context\",\n    \"Builds module rollup prompts combining multiple file summaries\",\n    \"Creates product-level documentation prompts from all summaries and analysis\",\n    \"Generates per-file test plan prompts with existing test awareness\",\n    \"Constructs test code generation prompts from test plans and source code\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Creates prompt for analyzing codebase architecture patterns and structure\",\n      \"inputs\": \"AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates prompt for generating product-level documentation\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates prompt for extracting product purpose and value proposition\",\n      \"inputs\": \"EnhancedProductDocumentation, AnalysisContext\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates prompt for analyzing individual file behavior and role\",\n      \"inputs\": \"FileInfo, file content string, role classification\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Creates prompt for rolling up multiple file summaries into module documentation\",\n      \"inputs\": \"Module path, module type, array of FileSummary objects\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Creates prompt for generating comprehensive product-level documentation\",\n      \"inputs\": \"FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates prompt for generating test plans for a specific file\",\n      \"inputs\": \"File path, content, function metadata, existing tests, language, test framework, optional project summary\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Creates prompt for generating actual test code from test plans\",\n      \"inputs\": \"Test plan item, source code, function code, language, test framework\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and centralize all LLM prompt construction logic. Previously scattered across multiple files, this builder provides a single source of truth for how prompts are formatted, ensuring consistency in LLM interactions and making prompt engineering changes easier to manage across architecture analysis, documentation generation, and test creation workflows.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Builds detailed, prescriptive prompts for AI-powered code refactoring by analyzing functions and creating structured extraction plans",
          "userVisibleActions": [
            "Receives detailed refactoring recommendations with specific function extraction plans",
            "Sees migration steps explaining how to move code between files",
            "Views before/after code examples showing proposed refactoring changes",
            "Gets prescriptive instructions for breaking down large files into smaller modules"
          ],
          "developerVisibleActions": [
            "Provides code analysis data including file information and function metadata",
            "Supplies optional product documentation to guide refactoring decisions",
            "Passes architecture insights to inform refactoring strategy",
            "Receives structured refactoring prompts ready to send to LLM services",
            "Gets function dependency analysis showing which functions call each other",
            "Obtains extraction plans specifying source files, target files, and migration steps"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Creates a comprehensive refactoring prompt by combining code analysis, product documentation, architecture insights, and function analyses",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]",
              "outputs": "string prompt ready for LLM consumption"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Constructs the foundational refactoring prompt with context and code analysis",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
              "outputs": "string base prompt"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Adds detailed function-level analysis to the prompt showing dependencies, responsibilities, and metrics",
              "inputs": "FunctionAnalysis[]",
              "outputs": "string section describing function details"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Generates requirements for code extraction including target files, dependencies, and migration steps",
              "inputs": "none apparent",
              "outputs": "string section with extraction guidelines"
            }
          ],
          "dependencies": [
            "../../analyzer",
            "../../llmService",
            "../../fileDocumentation"
          ],
          "intent": "This file exists to transform raw code analysis data into structured, actionable refactoring instructions that an LLM can understand and execute. It solves the problem of providing enough context and detail so that AI-generated refactoring recommendations are accurate, safe, and preserve code relationships like dependencies between functions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed, prescriptive prompts for AI-powered code refactoring by analyzing functions and creating structured extraction plans\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with specific function extraction plans\",\n    \"Sees migration steps explaining how to move code between files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Gets prescriptive instructions for breaking down large files into smaller modules\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides code analysis data including file information and function metadata\",\n    \"Supplies optional product documentation to guide refactoring decisions\",\n    \"Passes architecture insights to inform refactoring strategy\",\n    \"Receives structured refactoring prompts ready to send to LLM services\",\n    \"Gets function dependency analysis showing which functions call each other\",\n    \"Obtains extraction plans specifying source files, target files, and migration steps\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive refactoring prompt by combining code analysis, product documentation, architecture insights, and function analyses\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]\",\n      \"outputs\": \"string prompt ready for LLM consumption\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational refactoring prompt with context and code analysis\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"string base prompt\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function-level analysis to the prompt showing dependencies, responsibilities, and metrics\",\n      \"inputs\": \"FunctionAnalysis[]\",\n      \"outputs\": \"string section describing function details\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates requirements for code extraction including target files, dependencies, and migration steps\",\n      \"inputs\": \"none apparent\",\n      \"outputs\": \"string section with extraction guidelines\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../../llmService\",\n    \"../../fileDocumentation\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into structured, actionable refactoring instructions that an LLM can understand and execute. It solves the problem of providing enough context and detail so that AI-generated refactoring recommendations are accurate, safe, and preserve code relationships like dependencies between functions.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides prompt templates for LLM-based test generation, configuration analysis, and test planning strategies.",
          "userVisibleActions": [
            "Analyzes codebase to recommend optimal test setup and configuration",
            "Generates prioritized test plans identifying critical functions to test",
            "Creates detailed test specifications for individual functions",
            "Provides test implementation guidance with examples and patterns",
            "Suggests mock requirements for external dependencies like VSCode APIs"
          ],
          "developerVisibleActions": [
            "Developer calls buildSetupPrompt() to analyze workspace and get test framework recommendations",
            "Developer calls buildPlanningPrompt() to create a prioritized test strategy based on code analysis",
            "Developer calls buildTestSpecPrompt() to generate detailed test specifications for specific functions",
            "Developer calls buildImplementationPrompt() to get test implementation guidance with code examples",
            "Receives structured JSON responses with dependencies, configurations, and test strategies",
            "Gets language detection, framework selection, and mock requirements automatically",
            "Receives prioritized function lists with complexity scores and coverage recommendations"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Creates a prompt to analyze codebase and recommend test setup configuration",
              "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
              "outputs": "Prompt string requesting JSON with language, framework, dependencies, config files, and mock requirements"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Generates a prompt to create a prioritized test plan based on code analysis",
              "inputs": "context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any",
              "outputs": "Prompt string requesting JSON with prioritized functions, complexity scores, and testing strategy"
            },
            {
              "name": "buildTestSpecPrompt",
              "desc": "Creates a prompt to generate detailed test specifications for a specific function",
              "inputs": "testableFunction: TestableFunction, codeContext: string, existingTests?: string",
              "outputs": "Prompt string requesting JSON with test scenarios, edge cases, assertions, and mocking needs"
            },
            {
              "name": "buildImplementationPrompt",
              "desc": "Generates a prompt to provide test implementation guidance and code examples",
              "inputs": "testSpec: any, framework: string, existingPatterns?: string",
              "outputs": "Prompt string requesting JSON with implementation strategy, code examples, and best practices"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis type)",
            "../services/testing/types/testPlanTypes (TestableFunction type)"
          ],
          "intent": "This file exists to standardize and structure LLM interactions for automated test generation. It solves the problem of consistently prompting LLMs to analyze code, plan test strategies, and generate test specifications by providing reusable prompt templates that request structured JSON responses. This enables automated test creation workflows where LLM recommendations can be programmatically processed and applied to codebases.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based test generation, configuration analysis, and test planning strategies.\",\n  \"userVisibleActions\": [\n    \"Analyzes codebase to recommend optimal test setup and configuration\",\n    \"Generates prioritized test plans identifying critical functions to test\",\n    \"Creates detailed test specifications for individual functions\",\n    \"Provides test implementation guidance with examples and patterns\",\n    \"Suggests mock requirements for external dependencies like VSCode APIs\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildSetupPrompt() to analyze workspace and get test framework recommendations\",\n    \"Developer calls buildPlanningPrompt() to create a prioritized test strategy based on code analysis\",\n    \"Developer calls buildTestSpecPrompt() to generate detailed test specifications for specific functions\",\n    \"Developer calls buildImplementationPrompt() to get test implementation guidance with code examples\",\n    \"Receives structured JSON responses with dependencies, configurations, and test strategies\",\n    \"Gets language detection, framework selection, and mock requirements automatically\",\n    \"Receives prioritized function lists with complexity scores and coverage recommendations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"Prompt string requesting JSON with language, framework, dependencies, config files, and mock requirements\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Generates a prompt to create a prioritized test plan based on code analysis\",\n      \"inputs\": \"context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"Prompt string requesting JSON with prioritized functions, complexity scores, and testing strategy\"\n    },\n    {\n      \"name\": \"buildTestSpecPrompt\",\n      \"desc\": \"Creates a prompt to generate detailed test specifications for a specific function\",\n      \"inputs\": \"testableFunction: TestableFunction, codeContext: string, existingTests?: string\",\n      \"outputs\": \"Prompt string requesting JSON with test scenarios, edge cases, assertions, and mocking needs\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Generates a prompt to provide test implementation guidance and code examples\",\n      \"inputs\": \"testSpec: any, framework: string, existingPatterns?: string\",\n      \"outputs\": \"Prompt string requesting JSON with implementation strategy, code examples, and best practices\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis type)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction type)\"\n  ],\n  \"intent\": \"This file exists to standardize and structure LLM interactions for automated test generation. It solves the problem of consistently prompting LLMs to analyze code, plan test strategies, and generate test specifications by providing reusable prompt templates that request structured JSON responses. This enables automated test creation workflows where LLM recommendations can be programmatically processed and applied to codebases.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatic file system monitoring that detects when files are created, modified, or deleted",
        "Multi-round intelligent analysis that iteratively requests additional context until sufficient information is gathered",
        "Automatic test framework detection and configuration setup for Jest, Mocha, Vitest, and Pytest",
        "Event-driven architecture that triggers appropriate handlers when workspace files change",
        "Dynamic file and pattern searching across the codebase during analysis",
        "Zero-configuration test generation with automatic dependency and configuration detection"
      ],
      "summary": "This services module provides the core automation and intelligence layer that makes the extension reactive and context-aware. It handles three critical workflows: monitoring the file system for changes and triggering appropriate responses, managing iterative analysis sessions where the LLM can request additional files or search for patterns across multiple rounds until it has enough context, and automatically detecting and configuring test frameworks to ensure generated tests work without manual setup.\n\nUsers benefit from automatic change detection - when they create, modify, or delete files, the system automatically updates relevant views and features without manual refresh. When the LLM needs more information to complete a task, the incremental analysis service orchestrates multiple rounds of context gathering, dynamically including additional files and performing grep searches until the analysis is complete or reaches maximum iterations.\n\nThe test configuration service eliminates manual setup by detecting which testing framework is in use (Jest, Mocha, Vitest, or Pytest), identifying missing dependencies and configuration files, and providing setup guidance. This ensures that generated tests are immediately executable without requiring users to manually configure their test environment, creating a seamless test generation experience.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides centralized file system watching to detect when files are created, modified, or deleted in the workspace",
          "userVisibleActions": [
            "When user creates a new file matching a watched pattern, registered handlers are automatically triggered",
            "When user modifies an existing file, change detection triggers updates to relevant views or features",
            "When user deletes a file, cleanup and refresh actions occur automatically",
            "When user saves a document, save handlers execute to update related features"
          ],
          "developerVisibleActions": [
            "Provides a unified service to watch file system changes without creating duplicate watchers",
            "Allows multiple components to register handlers for the same file patterns efficiently",
            "Automatically manages watcher lifecycle and cleanup to prevent memory leaks",
            "Supports pattern-based filtering with ignore patterns to exclude specific files",
            "Consolidates document save event handling across multiple features",
            "Provides disposable pattern for proper cleanup of watch registrations"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Registers a handler to be called when files matching a pattern are created, changed, or deleted",
              "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (watch create/change/delete flags, ignore patterns)",
              "outputs": "Disposable object to unregister the watch"
            },
            {
              "name": "onDocumentSave",
              "desc": "Registers a handler to be called whenever a document is saved in the editor",
              "inputs": "handler (callback function receiving the saved document)",
              "outputs": "Disposable object to unregister the handler"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all file watchers and handlers, releasing system resources",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getPatternKey",
              "desc": "Generates a unique key for a file pattern to enable watcher reuse",
              "inputs": "pattern (string or RelativePattern)",
              "outputs": "string key"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to eliminate duplication of file watching logic across multiple extension features. Previously, separate components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) each created their own file watchers, leading to redundant system resource usage and inconsistent behavior. This service consolidates all file watching into a single, efficient implementation that can be shared across the extension, ensuring consistent file change detection and proper resource management.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides centralized file system watching to detect when files are created, modified, or deleted in the workspace\",\n  \"userVisibleActions\": [\n    \"When user creates a new file matching a watched pattern, registered handlers are automatically triggered\",\n    \"When user modifies an existing file, change detection triggers updates to relevant views or features\",\n    \"When user deletes a file, cleanup and refresh actions occur automatically\",\n    \"When user saves a document, save handlers execute to update related features\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a unified service to watch file system changes without creating duplicate watchers\",\n    \"Allows multiple components to register handlers for the same file patterns efficiently\",\n    \"Automatically manages watcher lifecycle and cleanup to prevent memory leaks\",\n    \"Supports pattern-based filtering with ignore patterns to exclude specific files\",\n    \"Consolidates document save event handling across multiple features\",\n    \"Provides disposable pattern for proper cleanup of watch registrations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a handler to be called when files matching a pattern are created, changed, or deleted\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (watch create/change/delete flags, ignore patterns)\",\n      \"outputs\": \"Disposable object to unregister the watch\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever a document is saved in the editor\",\n      \"inputs\": \"handler (callback function receiving the saved document)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all file watchers and handlers, releasing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to enable watcher reuse\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication of file watching logic across multiple extension features. Previously, separate components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) each created their own file watchers, leading to redundant system resource usage and inconsistent behavior. This service consolidates all file watching into a single, efficient implementation that can be shared across the extension, ensuring consistent file change detection and proper resource management.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative analysis where an LLM can request additional files or grep searches across multiple rounds until it has enough information to complete its task",
          "userVisibleActions": [
            "Analysis progresses through multiple iterations automatically when the LLM needs more context",
            "Additional files are read and included in the analysis when requested",
            "Grep searches are performed across the codebase when the LLM needs to find specific patterns",
            "Analysis stops after reaching maximum iterations or when the LLM has sufficient information"
          ],
          "developerVisibleActions": [
            "Create an IncrementalAnalysisService instance with a FileAccessHelper",
            "Call processRequests() to handle LLM file and grep requests within an iteration",
            "Receive ProcessRequestsResult containing formatted additional information and updated conversation messages",
            "Use IterationCallbacks to monitor iteration start and completion events",
            "Access IterationResult to see final result, iteration count, all requests made, and continuation status",
            "LLM requests are automatically limited to 5 per iteration to prevent excessive processing"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes LLM-requested file reads and grep searches, returning formatted results and updated conversation messages",
              "inputs": "requests (array of LLMRequest), currentResult (any), messages (conversation history)",
              "outputs": "ProcessRequestsResult containing additionalInfo string and updated messages array"
            }
          ],
          "dependencies": [
            "FileAccessHelper",
            "LLMRequest"
          ],
          "intent": "This file exists to eliminate code duplication from llmService.ts by extracting the iterative analysis logic into a reusable, testable service. It solves the problem of LLMs needing multiple rounds of context gathering (files and grep searches) before producing a final analysis, converting while-loop patterns into structured async iteration patterns for better testing and maintainability.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative analysis where an LLM can request additional files or grep searches across multiple rounds until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"Analysis progresses through multiple iterations automatically when the LLM needs more context\",\n    \"Additional files are read and included in the analysis when requested\",\n    \"Grep searches are performed across the codebase when the LLM needs to find specific patterns\",\n    \"Analysis stops after reaching maximum iterations or when the LLM has sufficient information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Create an IncrementalAnalysisService instance with a FileAccessHelper\",\n    \"Call processRequests() to handle LLM file and grep requests within an iteration\",\n    \"Receive ProcessRequestsResult containing formatted additional information and updated conversation messages\",\n    \"Use IterationCallbacks to monitor iteration start and completion events\",\n    \"Access IterationResult to see final result, iteration count, all requests made, and continuation status\",\n    \"LLM requests are automatically limited to 5 per iteration to prevent excessive processing\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, returning formatted results and updated conversation messages\",\n      \"inputs\": \"requests (array of LLMRequest), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult containing additionalInfo string and updated messages array\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest\"\n  ],\n  \"intent\": \"This file exists to eliminate code duplication from llmService.ts by extracting the iterative analysis logic into a reusable, testable service. It solves the problem of LLMs needing multiple rounds of context gathering (files and grep searches) before producing a final analysis, converting while-loop patterns into structured async iteration patterns for better testing and maintainability.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) to ensure generated tests work without manual user setup",
          "userVisibleActions": [
            "Automatically detects which test framework is being used in the project",
            "Identifies missing test dependencies and configuration files",
            "Provides setup actions needed to make tests work",
            "Ensures generated tests run without manual configuration"
          ],
          "developerVisibleActions": [
            "Scans workspace for package.json to detect test framework from scripts and dependencies",
            "Checks for framework-specific config files (jest.config.js, vitest.config.ts, pytest.ini, etc.)",
            "Validates that required test dependencies are installed",
            "Returns configuration status with framework type, missing dependencies, and setup requirements",
            "Detects TypeScript test setups (ts-jest, @jest/globals) for Jest projects",
            "Identifies Python virtual environments and pytest installations"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Analyzes workspace to detect test framework and configuration completeness",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestConfigStatus object with framework type, configuration state, missing dependencies, and required setup actions"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "../../logger"
          ],
          "intent": "This file exists to eliminate the friction of setting up test environments by automatically detecting what test framework a project uses and determining if it's properly configured. It solves the problem of generated tests failing due to missing configuration, making the test generation feature work seamlessly across different project setups without requiring users to manually configure test frameworks.",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used in the project\",\n    \"Identifies missing test dependencies and configuration files\",\n    \"Provides setup actions needed to make tests work\",\n    \"Ensures generated tests run without manual configuration\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace for package.json to detect test framework from scripts and dependencies\",\n    \"Checks for framework-specific config files (jest.config.js, vitest.config.ts, pytest.ini, etc.)\",\n    \"Validates that required test dependencies are installed\",\n    \"Returns configuration status with framework type, missing dependencies, and setup requirements\",\n    \"Detects TypeScript test setups (ts-jest, @jest/globals) for Jest projects\",\n    \"Identifies Python virtual environments and pytest installations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration completeness\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../logger\"\n  ],\n  \"intent\": \"This file exists to eliminate the friction of setting up test environments by automatically detecting what test framework a project uses and determining if it's properly configured. It solves the problem of generated tests failing due to missing configuration, making the test generation feature work seamlessly across different project setups without requiring users to manually configure test frameworks.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automated test generation for code functions using AI-powered analysis",
        "Intelligent test planning with prioritized recommendations based on code structure",
        "Automatic test environment detection and setup for multiple frameworks and languages",
        "Test execution across multiple test frameworks (Jest, Mocha, Pytest, Vitest)",
        "Automated test validation and fixing of failing tests using LLM analysis",
        "Real-time progress tracking during test generation and execution",
        "Test coverage analysis and reporting"
      ],
      "summary": "This module provides a comprehensive AI-powered testing workflow that automates the entire testing lifecycle from environment setup through test generation, execution, and validation. Users can leverage LLM capabilities to automatically generate unit tests for their code functions, receive intelligent recommendations on which functions should be tested, and get prioritized test plans organized by testing areas such as core logic, edge cases, and integration points.\n\nThe module supports multiple programming languages (TypeScript, JavaScript, Python, Java, C++) and test frameworks (Jest, Mocha, Pytest, Vitest), automatically detecting the project's configuration and setting up the necessary test environment. During test generation, users receive incremental progress updates showing which functions are being tested and can view the generated test code along with execution results. The system executes tests in small batches to provide immediate feedback on test outcomes.\n\nWhen tests fail, the module automatically attempts to fix them using LLM analysis, making multiple fix attempts if needed and providing detailed error messages and stack traces. Users can run tests for specific files or the entire workspace, view comprehensive test results including pass/fail counts, execution duration, and coverage information, all without requiring manual intervention for test creation or failure remediation.",
      "files": [
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates unit tests for code functions incrementally using an LLM service, executing tests in small batches and providing progress feedback.",
          "userVisibleActions": [
            "Receive progress updates showing which function is currently being tested (e.g., 'Generating test 5 of 20 for functionName')",
            "See test generation results for each function including success/failure status",
            "View generated test code for functions",
            "Get feedback on test execution results including pass/fail outcomes"
          ],
          "developerVisibleActions": [
            "Call generateTestBatch() to generate tests for multiple functions at once",
            "Provide a progress callback to monitor test generation as it proceeds",
            "Receive a Map of test generation results keyed by function name",
            "Access generated test code, mock requirements, and execution status for each function",
            "Integrate with LLM service to automatically generate test code based on source code analysis",
            "Automatically check for and reuse existing mock files (e.g., vscode mocks)",
            "Get structured results indicating which tests passed, failed, or couldn't be generated"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for a batch of functions by calling the LLM service for each one and tracking progress",
              "inputs": "functions array, workspace root path, LLM service instance, optional progress callback",
              "outputs": "Map of function names to TestGenerationResult objects"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Extracts the source code for a specific function from the workspace",
              "inputs": "TestableFunction object, workspace root path",
              "outputs": "Source code string for the function"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestableFunction",
            "TestGenerationState",
            "TestGenerationResult",
            "buildGenerationPrompt",
            "TestExecutionService",
            "SWLogger"
          ],
          "intent": "This file exists to automate the creation of unit tests by leveraging LLM capabilities to analyze source code and generate appropriate test cases. It solves the problem of manually writing repetitive test code by processing functions in batches, providing real-time progress feedback, and handling the complete workflow from test generation through execution and result reporting.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions incrementally using an LLM service, executing tests in small batches and providing progress feedback.\",\n  \"userVisibleActions\": [\n    \"Receive progress updates showing which function is currently being tested (e.g., 'Generating test 5 of 20 for functionName')\",\n    \"See test generation results for each function including success/failure status\",\n    \"View generated test code for functions\",\n    \"Get feedback on test execution results including pass/fail outcomes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateTestBatch() to generate tests for multiple functions at once\",\n    \"Provide a progress callback to monitor test generation as it proceeds\",\n    \"Receive a Map of test generation results keyed by function name\",\n    \"Access generated test code, mock requirements, and execution status for each function\",\n    \"Integrate with LLM service to automatically generate test code based on source code analysis\",\n    \"Automatically check for and reuse existing mock files (e.g., vscode mocks)\",\n    \"Get structured results indicating which tests passed, failed, or couldn't be generated\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for a batch of functions by calling the LLM service for each one and tracking progress\",\n      \"inputs\": \"functions array, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Extracts the source code for a specific function from the workspace\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the creation of unit tests by leveraging LLM capabilities to analyze source code and generate appropriate test cases. It solves the problem of manually writing repetitive test code by processing functions in batches, providing real-time progress feedback, and handling the complete workflow from test generation through execution and result reporting.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code and creates prioritized test plans using LLM to recommend which functions should be tested and how",
          "userVisibleActions": [
            "Receives automated test recommendations for code functions",
            "Gets prioritized list of functions that should be tested",
            "Views test plans organized by testing areas (e.g., core logic, edge cases, integration points)",
            "Sees confidence scores and rationale for each test recommendation"
          ],
          "developerVisibleActions": [
            "Calls service to generate test plans from code analysis results",
            "Provides optional product documentation and architecture insights to improve test recommendations",
            "Receives structured test plan with testable functions organized by priority and category",
            "Uses two-phase planning approach: high-level strategy first, then specific function selection",
            "Leverages pre-existing architecture analysis test recommendations when available"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts and normalizes function information from code analysis",
              "inputs": "codeAnalysis object containing functions array",
              "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
            },
            {
              "name": "createTestPlan",
              "desc": "Generates comprehensive test plan using LLM with two-phase approach (strategy then function selection)",
              "inputs": "CodeAnalysis context, functions array, llmService, optional productDocs and architectureInsights",
              "outputs": "TestPlan object with prioritized testable functions and testing strategy"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestPlan types",
            "TestableFunction types",
            "buildPlanningPrompt",
            "CodeAnalysis",
            "SWLogger"
          ],
          "intent": "Automates the test planning process by using AI to analyze code and intelligently recommend which functions need testing, what types of tests to write, and in what order to prioritize them, reducing manual test planning effort and improving test coverage",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code and creates prioritized test plans using LLM to recommend which functions should be tested and how\",\n  \"userVisibleActions\": [\n    \"Receives automated test recommendations for code functions\",\n    \"Gets prioritized list of functions that should be tested\",\n    \"Views test plans organized by testing areas (e.g., core logic, edge cases, integration points)\",\n    \"Sees confidence scores and rationale for each test recommendation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls service to generate test plans from code analysis results\",\n    \"Provides optional product documentation and architecture insights to improve test recommendations\",\n    \"Receives structured test plan with testable functions organized by priority and category\",\n    \"Uses two-phase planning approach: high-level strategy first, then specific function selection\",\n    \"Leverages pre-existing architecture analysis test recommendations when available\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function information from code analysis\",\n      \"inputs\": \"codeAnalysis object containing functions array\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates comprehensive test plan using LLM with two-phase approach (strategy then function selection)\",\n      \"inputs\": \"CodeAnalysis context, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with prioritized testable functions and testing strategy\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestPlan types\",\n    \"TestableFunction types\",\n    \"buildPlanningPrompt\",\n    \"CodeAnalysis\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Automates the test planning process by using AI to analyze code and intelligently recommend which functions need testing, what types of tests to write, and in what order to prioritize them, reducing manual test planning effort and improving test coverage\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Detects test environment configuration and generates test setup plans using LLM-based analysis of the workspace.",
          "userVisibleActions": [
            "Automatically detects the programming language used in the project (TypeScript, JavaScript, Python, Java, C++)",
            "Identifies existing test framework configuration (Jest, package.json, tsconfig.json)",
            "Generates a test setup plan with required dependencies and configuration files",
            "Executes test setup by installing dependencies and creating configuration files",
            "Verifies test setup by running a test command and checking for success"
          ],
          "developerVisibleActions": [
            "Scans workspace to detect test environment (test directories, config files, language distribution)",
            "Analyzes package.json and tsconfig.json to understand project structure",
            "Uses LLM to generate appropriate test setup based on detected environment",
            "Installs test framework dependencies via package manager (npm/yarn)",
            "Creates or updates test configuration files (jest.config.js, tsconfig.json)",
            "Runs test verification command and reports success or failure with error messages",
            "Provides detailed execution results including stdout, stderr, and exit codes"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Scans workspace to identify project language, existing test configurations, and test directories",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestEnvironment object with framework, language, directories, and config file information"
            },
            {
              "name": "generateSetupPlan",
              "desc": "Uses LLM to create a test setup plan based on detected environment",
              "inputs": "environment: TestEnvironment, llmResponse: function",
              "outputs": "Promise<TestSetupPlan> with dependencies, config files, and setup steps"
            },
            {
              "name": "executeSetup",
              "desc": "Executes the generated setup plan by installing dependencies and creating config files",
              "inputs": "plan: TestSetupPlan, workspaceRoot: string",
              "outputs": "Promise<SetupExecutionResult> with success status, messages, and any errors"
            },
            {
              "name": "verifySetup",
              "desc": "Runs test command to verify the test environment is correctly configured",
              "inputs": "workspaceRoot: string, testCommand: string",
              "outputs": "Promise<SetupExecutionResult> indicating if tests can run successfully"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively retrieves all files in a directory for language detection",
              "inputs": "dir: string (directory path)",
              "outputs": "string[] (array of file paths)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "./types/testSetupTypes",
            "../../prompts/testPrompts",
            "../../../logger"
          ],
          "intent": "This service automates test environment setup by intelligently detecting the project's configuration and generating appropriate test framework setup. It solves the problem of manual test configuration by analyzing the workspace, determining the best test setup approach using LLM, and automatically installing and configuring the necessary testing infrastructure. This eliminates the need for developers to manually configure test frameworks and ensures consistent test setup across projects.",
          "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates test setup plans using LLM-based analysis of the workspace.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language used in the project (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Identifies existing test framework configuration (Jest, package.json, tsconfig.json)\",\n    \"Generates a test setup plan with required dependencies and configuration files\",\n    \"Executes test setup by installing dependencies and creating configuration files\",\n    \"Verifies test setup by running a test command and checking for success\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace to detect test environment (test directories, config files, language distribution)\",\n    \"Analyzes package.json and tsconfig.json to understand project structure\",\n    \"Uses LLM to generate appropriate test setup based on detected environment\",\n    \"Installs test framework dependencies via package manager (npm/yarn)\",\n    \"Creates or updates test configuration files (jest.config.js, tsconfig.json)\",\n    \"Runs test verification command and reports success or failure with error messages\",\n    \"Provides detailed execution results including stdout, stderr, and exit codes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Scans workspace to identify project language, existing test configurations, and test directories\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object with framework, language, directories, and config file information\"\n    },\n    {\n      \"name\": \"generateSetupPlan\",\n      \"desc\": \"Uses LLM to create a test setup plan based on detected environment\",\n      \"inputs\": \"environment: TestEnvironment, llmResponse: function\",\n      \"outputs\": \"Promise<TestSetupPlan> with dependencies, config files, and setup steps\"\n    },\n    {\n      \"name\": \"executeSetup\",\n      \"desc\": \"Executes the generated setup plan by installing dependencies and creating config files\",\n      \"inputs\": \"plan: TestSetupPlan, workspaceRoot: string\",\n      \"outputs\": \"Promise<SetupExecutionResult> with success status, messages, and any errors\"\n    },\n    {\n      \"name\": \"verifySetup\",\n      \"desc\": \"Runs test command to verify the test environment is correctly configured\",\n      \"inputs\": \"workspaceRoot: string, testCommand: string\",\n      \"outputs\": \"Promise<SetupExecutionResult> indicating if tests can run successfully\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively retrieves all files in a directory for language detection\",\n      \"inputs\": \"dir: string (directory path)\",\n      \"outputs\": \"string[] (array of file paths)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This service automates test environment setup by intelligently detecting the project's configuration and generating appropriate test framework setup. It solves the problem of manual test configuration by analyzing the workspace, determining the best test setup approach using LLM, and automatically installing and configuring the necessary testing infrastructure. This eliminates the need for developers to manually configure test frameworks and ensures consistent test setup across projects.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates tests by running them, capturing failures, and automatically fixing failing tests using LLM analysis and code generation.",
          "userVisibleActions": [
            "Tests are automatically run and validated in the workspace",
            "Failing tests are automatically fixed without manual intervention",
            "Test results show pass/fail counts and error messages",
            "Multiple fix attempts are made automatically if initial fixes don't work",
            "Final test results indicate whether fixes were successful"
          ],
          "developerVisibleActions": [
            "Run all tests or a specific test file in the workspace",
            "Get detailed test execution results with pass/fail counts",
            "Automatically fix failing tests by providing test file path and execution results",
            "Configure maximum retry attempts for test fixes (default 3)",
            "Receive feedback on fix success/failure with attempt counts",
            "Test fixes are applied by reading test code, analyzing errors, generating fixes via LLM, and writing corrected code back",
            "Each fix attempt re-runs tests to verify the correction worked"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or a specific test file and returns results with pass/fail counts",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]> - Array of test results with passed/failed/error counts"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to fix a failing test by analyzing errors and generating corrected code using LLM",
              "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)",
              "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}> - Fix result with success status and attempt count"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "TestExecutionResult",
            "TestReport",
            "TestReportSummary",
            "buildFixPrompt",
            "SWLogger"
          ],
          "intent": "This file exists to automate the test validation and correction workflow, allowing failing tests to be automatically fixed using AI analysis rather than requiring manual debugging and code changes by developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them, capturing failures, and automatically fixing failing tests using LLM analysis and code generation.\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and validated in the workspace\",\n    \"Failing tests are automatically fixed without manual intervention\",\n    \"Test results show pass/fail counts and error messages\",\n    \"Multiple fix attempts are made automatically if initial fixes don't work\",\n    \"Final test results indicate whether fixes were successful\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run all tests or a specific test file in the workspace\",\n    \"Get detailed test execution results with pass/fail counts\",\n    \"Automatically fix failing tests by providing test file path and execution results\",\n    \"Configure maximum retry attempts for test fixes (default 3)\",\n    \"Receive feedback on fix success/failure with attempt counts\",\n    \"Test fixes are applied by reading test code, analyzing errors, generating fixes via LLM, and writing corrected code back\",\n    \"Each fix attempt re-runs tests to verify the correction worked\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns results with pass/fail counts\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - Array of test results with passed/failed/error counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to fix a failing test by analyzing errors and generating corrected code using LLM\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}> - Fix result with success status and attempt count\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation and correction workflow, allowing failing tests to be automatically fixed using AI analysis rather than requiring manual debugging and code changes by developers.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes test suites (Jest, Mocha, Pytest, Vitest) and captures their results for display and analysis",
          "userVisibleActions": [
            "Run tests for a specific file or all tests in the workspace",
            "View test execution results including pass/fail status and duration",
            "See detailed error messages and stack traces when tests fail",
            "Get notified when test execution fails or times out",
            "View test coverage information when available"
          ],
          "developerVisibleActions": [
            "Execute Jest tests with JSON output parsing",
            "Execute Mocha tests with JSON reporter",
            "Execute Pytest tests with JSON output",
            "Execute Vitest tests with JSON reporter",
            "Parse test framework output into standardized result format",
            "Handle test execution errors and timeouts gracefully",
            "Extract error details including test names, messages, and stack traces",
            "Configure test execution with custom buffer sizes and timeouts"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Runs Jest tests for a specific file or entire test suite",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runMocha",
              "desc": "Runs Mocha tests for a specific file or entire test suite",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runPytest",
              "desc": "Runs Pytest tests for a specific file or entire test suite",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runVitest",
              "desc": "Runs Vitest tests for a specific file or entire test suite",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "parseJestOutput",
              "desc": "Parses Jest JSON output into standardized test results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parseMochaOutput",
              "desc": "Parses Mocha JSON output into standardized test results",
              "inputs": "stdout: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parsePytestOutput",
              "desc": "Parses Pytest JSON output into standardized test results",
              "inputs": "stdout: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parseVitestOutput",
              "desc": "Parses Vitest JSON output into standardized test results",
              "inputs": "stdout: string",
              "outputs": "TestExecutionResult[]"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "This file exists to provide a unified interface for executing different test frameworks (Jest, Mocha, Pytest, Vitest) and normalizing their output into a consistent format. It solves the problem of supporting multiple testing frameworks with different output formats by handling execution, parsing, and error handling for each framework, making test results available in a standardized structure for display and analysis.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest, Vitest) and captures their results for display and analysis\",\n  \"userVisibleActions\": [\n    \"Run tests for a specific file or all tests in the workspace\",\n    \"View test execution results including pass/fail status and duration\",\n    \"See detailed error messages and stack traces when tests fail\",\n    \"Get notified when test execution fails or times out\",\n    \"View test coverage information when available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Execute Jest tests with JSON output parsing\",\n    \"Execute Mocha tests with JSON reporter\",\n    \"Execute Pytest tests with JSON output\",\n    \"Execute Vitest tests with JSON reporter\",\n    \"Parse test framework output into standardized result format\",\n    \"Handle test execution errors and timeouts gracefully\",\n    \"Extract error details including test names, messages, and stack traces\",\n    \"Configure test execution with custom buffer sizes and timeouts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Runs Jest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Runs Mocha tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Runs Pytest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runVitest\",\n      \"desc\": \"Runs Vitest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses Mocha JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses Pytest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseVitestOutput\",\n      \"desc\": \"Parses Vitest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This file exists to provide a unified interface for executing different test frameworks (Jest, Mocha, Pytest, Vitest) and normalizing their output into a consistent format. It solves the problem of supporting multiple testing frameworks with different output formats by handling execution, parsing, and error handling for each framework, making test results available in a standardized structure for display and analysis.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": [
        {
          "name": "Test Generation Workflow",
          "description": "Generates unit tests for code functions using LLM analysis",
          "jobFlow": "1) User initiates test generation for a code file or function. 2) System analyzes code structure and generates tests incrementally. 3) Progress updates show which function is being tested (e.g., 'Generating test 5 of 20 for functionName'). 4) Tests are executed in small batches. 5) Results display generated test code, success/failure status, and execution outcomes for each function."
        },
        {
          "name": "Test Planning Workflow",
          "description": "Creates prioritized test plans using LLM-based code analysis",
          "jobFlow": "1) User requests test recommendations for their codebase. 2) System analyzes code structure and complexity. 3) LLM generates prioritized list of functions that should be tested. 4) Results include confidence scores, rationale, and organization by testing areas (core logic, edge cases, integration points). 5) User can use recommendations to guide manual or automated test generation."
        },
        {
          "name": "Test Setup Workflow",
          "description": "Detects and configures test environment automatically",
          "jobFlow": "1) System detects project programming language and existing test framework configuration. 2) Generates test setup plan with required dependencies and configuration files. 3) Executes setup by installing dependencies (npm/pip packages) and creating config files. 4) Verifies setup by running test command and checking for successful execution. 5) Reports setup status and any configuration issues."
        },
        {
          "name": "Test Validation and Fixing Workflow",
          "description": "Validates tests and automatically fixes failures",
          "jobFlow": "1) Tests are executed in the workspace. 2) System captures test results including pass/fail counts and error messages. 3) For failing tests, LLM analyzes errors and generates fixes. 4) Fixed tests are re-executed automatically. 5) Multiple fix attempts are made if initial fixes don't resolve issues. 6) Final results show whether all tests pass and details of any remaining failures."
        },
        {
          "name": "Test Execution Workflow",
          "description": "Runs test suites and captures results",
          "jobFlow": "1) User triggers test execution for specific file or entire workspace. 2) System detects test framework (Jest, Mocha, Pytest, Vitest) and runs appropriate test command. 3) Captures test output including pass/fail status, duration, and coverage. 4) Displays detailed error messages and stack traces for failures. 5) Notifies user of execution completion or timeout. 6) Presents comprehensive test results for analysis."
        }
      ]
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Track automated test generation progress through multiple phases (setup, planning, generation, validation, completion)",
        "Monitor test coverage metrics showing total functions, testable functions, and tested functions",
        "View test execution results with pass/fail/error statistics and detailed error information",
        "Organize and prioritize functions for testing based on complexity and importance",
        "Validate generated tests to ensure they execute correctly",
        "Review comprehensive test reports with summary statistics and actionable recommendations",
        "Track test setup configuration including frameworks, dependencies, and generated files",
        "Monitor failed test generation attempts with detailed error diagnostics"
      ],
      "summary": "This module provides comprehensive type definitions for the automated testing system, enabling users to track and monitor the entire test generation lifecycle. It defines the data structures that power test planning, generation, validation, and reporting capabilities throughout the application.\n\nUsers can monitor test generation progress through distinct phases, from initial setup through planning, generation, validation, and completion. The module supports tracking which functions are testable, which have been tested, and how they're prioritized. Users receive detailed feedback on test execution results, including pass/fail statistics, error details with stack traces, and overall test coverage metrics.\n\nThe type system enables users to review test setup plans showing required frameworks and dependencies, see which configuration files will be created, and get feedback on setup execution. Users can access comprehensive test reports that provide summary statistics, pass rates, and actionable recommendations for improving test coverage and quality.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for organizing and tracking automated test plan generation and validation",
          "userVisibleActions": [
            "View test generation progress through different phases (setup, planning, generation, validation, complete)",
            "See total number of functions and how many are testable",
            "Track which functions have been tested and validated",
            "Review functions organized by priority groups",
            "See which test generation attempts failed and why"
          ],
          "developerVisibleActions": [
            "Define structure for test plans containing function groups organized by priority",
            "Track test generation state across multiple phases",
            "Identify functions that need mocking based on their dependencies",
            "Group related functions together for batch test generation",
            "Monitor test generation failures with error details and retry attempts",
            "Access function metadata including complexity, parameters, return types, and code location"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides type safety and structure for the test planning service by defining how testable functions are organized into prioritized groups, how test generation progress is tracked across phases, and how failures are recorded for retry logic",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for organizing and tracking automated test plan generation and validation\",\n  \"userVisibleActions\": [\n    \"View test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"See total number of functions and how many are testable\",\n    \"Track which functions have been tested and validated\",\n    \"Review functions organized by priority groups\",\n    \"See which test generation attempts failed and why\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test plans containing function groups organized by priority\",\n    \"Track test generation state across multiple phases\",\n    \"Identify functions that need mocking based on their dependencies\",\n    \"Group related functions together for batch test generation\",\n    \"Monitor test generation failures with error details and retry attempts\",\n    \"Access function metadata including complexity, parameters, return types, and code location\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for the test planning service by defining how testable functions are organized into prioritized groups, how test generation progress is tracked across phases, and how failures are recorded for retry logic\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type interfaces for test generation, validation, execution results, and reporting in the testing framework.",
          "userVisibleActions": [
            "View test execution results showing passed, failed, and error counts",
            "See test validation status indicating if tests pass, fail, or have errors",
            "Review test reports with summary statistics and recommendations",
            "Access detailed error information for failed tests including error messages and stack traces",
            "View test pass rates and overall testing metrics"
          ],
          "developerVisibleActions": [
            "Define structure for test generation results including file paths, imports, mocks, and test code",
            "Specify test validation outcomes with fixed code and explanations",
            "Structure test execution data with status, counts, duration, and error details",
            "Create comprehensive test reports with summaries and recommendations",
            "Type-check mock statements with explanations",
            "Track test setup and teardown code requirements",
            "Define error detail structures for debugging failed tests"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a strongly-typed contract for test generation, validation, and reporting features, ensuring consistent data structures across the testing workflow and enabling proper TypeScript type checking for test-related operations and results.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type interfaces for test generation, validation, execution results, and reporting in the testing framework.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed, failed, and error counts\",\n    \"See test validation status indicating if tests pass, fail, or have errors\",\n    \"Review test reports with summary statistics and recommendations\",\n    \"Access detailed error information for failed tests including error messages and stack traces\",\n    \"View test pass rates and overall testing metrics\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test generation results including file paths, imports, mocks, and test code\",\n    \"Specify test validation outcomes with fixed code and explanations\",\n    \"Structure test execution data with status, counts, duration, and error details\",\n    \"Create comprehensive test reports with summaries and recommendations\",\n    \"Type-check mock statements with explanations\",\n    \"Track test setup and teardown code requirements\",\n    \"Define error detail structures for debugging failed tests\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for test generation, validation, and reporting features, ensuring consistent data structures across the testing workflow and enabling proper TypeScript type checking for test-related operations and results.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces for test setup planning, environment detection, and execution results used throughout the testing setup service.",
          "userVisibleActions": [
            "User receives information about test setup plans including frameworks and dependencies",
            "User sees which configuration files will be created",
            "User gets feedback on setup execution success or failures",
            "User views list of files created and dependencies installed during setup"
          ],
          "developerVisibleActions": [
            "Developer structures test setup plans with language, framework, and dependency information",
            "Developer accesses environment detection results showing existing test infrastructure",
            "Developer receives structured execution results with success status and error details",
            "Developer defines mock requirements with types and reasons for test setup"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides type safety and contract definitions for the test setup service, ensuring consistent data structures across test environment detection, setup planning, and execution phases. Enables developers to work with strongly-typed data when configuring and setting up testing infrastructure.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup planning, environment detection, and execution results used throughout the testing setup service.\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including frameworks and dependencies\",\n    \"User sees which configuration files will be created\",\n    \"User gets feedback on setup execution success or failures\",\n    \"User views list of files created and dependencies installed during setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer structures test setup plans with language, framework, and dependency information\",\n    \"Developer accesses environment detection results showing existing test infrastructure\",\n    \"Developer receives structured execution results with success status and error details\",\n    \"Developer defines mock requirements with types and reasons for test setup\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and contract definitions for the test setup service, ensuring consistent data structures across test environment detection, setup planning, and execution phases. Enables developers to work with strongly-typed data when configuring and setting up testing infrastructure.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Intelligently caches file contents in memory to avoid redundant disk reads",
        "Automatically invalidates cache when files are modified, created, or deleted",
        "Provides a reusable framework for processing multiple files with built-in filtering",
        "Processes files in parallel for improved performance on large codebases",
        "Automatically excludes common non-source directories from processing",
        "Handles processing errors gracefully without stopping overall operations"
      ],
      "summary": "This module provides high-performance file system operations for the application by combining intelligent caching and efficient batch processing. It dramatically reduces disk I/O by caching file contents in memory and automatically keeping the cache synchronized with file system changes, ensuring that multiple components can access the same files quickly without repeated disk reads.\n\nThe module offers a robust file processing framework that can handle large codebases efficiently. It automatically filters out non-source directories (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea) and processes multiple files simultaneously using parallel execution. The processing engine is fault-tolerant, logging errors for individual files while continuing to process the remaining files.\n\nUsers benefit from faster application responsiveness when analyzing or working with large projects, as the caching mechanism reduces latency for repeated file access, and the parallel processing capabilities significantly speed up operations that need to read or analyze many files at once. The module handles all the complexity of cache management and parallel execution automatically, requiring no manual intervention.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Caches file contents in memory to reduce redundant disk reads and improve performance when multiple components need the same files",
          "userVisibleActions": [
            "Faster file loading when the same files are accessed multiple times",
            "Automatic updates when files are modified, created, or deleted on disk",
            "Reduced disk activity during operations that read many files",
            "Improved responsiveness when analyzing or processing large codebases"
          ],
          "developerVisibleActions": [
            "Retrieve file contents with automatic caching via getFile()",
            "Cache automatically invalidates when files change on disk",
            "LRU eviction policy removes oldest entries when cache reaches size limit",
            "Track cache performance with hit/miss/eviction statistics",
            "Set cached values directly with setFile()",
            "Clear specific files or entire cache programmatically",
            "Configure maximum cache size and time-to-live (TTL) settings",
            "File hashes verify content hasn't changed before returning cached data"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "setFile",
              "desc": "Manually sets a file's cached content and metadata",
              "inputs": "filePath: string, content: string",
              "outputs": "void"
            },
            {
              "name": "invalidate",
              "desc": "Removes a specific file from the cache, forcing next access to read from disk",
              "inputs": "filePath: string",
              "outputs": "void"
            },
            {
              "name": "clear",
              "desc": "Removes all cached files and resets cache statistics",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getStats",
              "desc": "Returns cache performance metrics including hits, misses, evictions, and total size",
              "inputs": "none",
              "outputs": "CacheStats object"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file system watchers and resources",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "This file exists to optimize file system performance by caching frequently accessed files in memory, preventing redundant disk reads when multiple components need the same file content. It solves the problem of slow file I/O operations by intelligently caching with automatic invalidation when files change, reducing latency and improving overall extension responsiveness.",
          "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to reduce redundant disk reads and improve performance when multiple components need the same files\",\n  \"userVisibleActions\": [\n    \"Faster file loading when the same files are accessed multiple times\",\n    \"Automatic updates when files are modified, created, or deleted on disk\",\n    \"Reduced disk activity during operations that read many files\",\n    \"Improved responsiveness when analyzing or processing large codebases\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file contents with automatic caching via getFile()\",\n    \"Cache automatically invalidates when files change on disk\",\n    \"LRU eviction policy removes oldest entries when cache reaches size limit\",\n    \"Track cache performance with hit/miss/eviction statistics\",\n    \"Set cached values directly with setFile()\",\n    \"Clear specific files or entire cache programmatically\",\n    \"Configure maximum cache size and time-to-live (TTL) settings\",\n    \"File hashes verify content hasn't changed before returning cached data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"setFile\",\n      \"desc\": \"Manually sets a file's cached content and metadata\",\n      \"inputs\": \"filePath: string, content: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing next access to read from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached files and resets cache statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, evictions, and total size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file system watchers and resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to optimize file system performance by caching frequently accessed files in memory, preventing redundant disk reads when multiple components need the same file content. It solves the problem of slow file I/O operations by intelligently caching with automatic invalidation when files change, reducing latency and improving overall extension responsiveness.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Consolidates file processing logic across the codebase by providing a reusable framework for filtering, reading, and processing files in parallel or sequentially.",
          "userVisibleActions": [
            "Files are automatically filtered to skip non-source directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea",
            "Multiple files are processed simultaneously for faster operation",
            "Processing continues even if individual files fail, with errors logged but not stopping the overall operation",
            "File processing can be controlled with custom filters to include or exclude specific file patterns"
          ],
          "developerVisibleActions": [
            "Provides a unified API for processing multiple files with consistent filtering and error handling",
            "Allows developers to inject custom file filters to control which files are processed",
            "Allows developers to inject custom file readers for different file access strategies",
            "Supports both parallel and sequential file processing based on performance needs",
            "Automatically handles file reading and passes content to developer-provided processing functions",
            "Integrates with ErrorHandler to track processing errors with context",
            "Returns processed results in the same order as input files, making results predictable"
          ],
          "keyFunctions": [
            {
              "name": "DefaultFileFilter.shouldProcess",
              "desc": "Determines if a file should be processed based on common skip patterns",
              "inputs": "filePath: string",
              "outputs": "boolean - true if file should be processed"
            },
            {
              "name": "DefaultFileReader.readFile",
              "desc": "Reads file content from disk as UTF-8 text",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "FileProcessor.processFiles",
              "desc": "Processes multiple files in parallel with filtering, reading, and custom processing logic",
              "inputs": "files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext",
              "outputs": "Promise<T[]> - array of processed results"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "../../utils/errorHandler"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and error handling by providing a single, testable, and reusable file processing framework. It allows developers to focus on the 'what to do with file content' logic while handling the 'how to find, filter, and read files' boilerplate consistently.",
          "rawContent": "```json\n{\n  \"purpose\": \"Consolidates file processing logic across the codebase by providing a reusable framework for filtering, reading, and processing files in parallel or sequentially.\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip non-source directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea\",\n    \"Multiple files are processed simultaneously for faster operation\",\n    \"Processing continues even if individual files fail, with errors logged but not stopping the overall operation\",\n    \"File processing can be controlled with custom filters to include or exclude specific file patterns\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a unified API for processing multiple files with consistent filtering and error handling\",\n    \"Allows developers to inject custom file filters to control which files are processed\",\n    \"Allows developers to inject custom file readers for different file access strategies\",\n    \"Supports both parallel and sequential file processing based on performance needs\",\n    \"Automatically handles file reading and passes content to developer-provided processing functions\",\n    \"Integrates with ErrorHandler to track processing errors with context\",\n    \"Returns processed results in the same order as input files, making results predictable\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"DefaultFileFilter.shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on common skip patterns\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean - true if file should be processed\"\n    },\n    {\n      \"name\": \"DefaultFileReader.readFile\",\n      \"desc\": \"Reads file content from disk as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"FileProcessor.processFiles\",\n      \"desc\": \"Processes multiple files in parallel with filtering, reading, and custom processing logic\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> - array of processed results\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and error handling by providing a single, testable, and reusable file processing framework. It allows developers to focus on the 'what to do with file content' logic while handling the 'how to find, filter, and read files' boilerplate consistently.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Automatically saves all analysis results to organized disk storage",
        "Creates timestamped directories for each analysis run to maintain history",
        "Organizes documentation into separate folders for product docs and architecture insights",
        "Generates markdown-formatted documentation files for easy reading and version control",
        "Provides progress summaries showing files processed and execution time",
        "Maintains a structured file hierarchy under .shadow/docs directory"
      ],
      "summary": "The persistence module handles the automatic storage and organization of all documentation generated during codebase analysis. When you run an analysis, this module creates a timestamped directory structure under .shadow/docs that preserves the complete results of that analysis run. Each analysis session generates organized folders containing product documentation (one file per analyzed source file) and architecture insights (consolidated summaries).\n\nThe module ensures that all generated documentation is properly saved in markdown format, making it easy to review, compare across different analysis runs, and commit to version control. It automatically creates the necessary directory structure, handles file naming conventions, and provides feedback on what was saved and where. This allows you to maintain a historical record of your codebase documentation, track how your architecture evolves over time, and easily reference documentation from specific points in time.\n\nUsers don't need to interact directly with this moduleit works automatically in the background whenever an analysis is performed. The timestamped folder structure means you never lose previous analysis results, and the organized layout makes it simple to find specific documentation files or compare insights across different analysis runs.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages saving and organizing analysis results (product documentation, architecture insights, and summaries) to disk in timestamped directories.",
          "userVisibleActions": [
            "Analysis results are automatically saved to .shadow/docs directory",
            "Each analysis run creates a timestamped folder with organized documentation",
            "Product documentation is saved as individual files per analyzed file",
            "Architecture insights are saved as a consolidated summary",
            "Progress summaries show files processed and time taken",
            "All documentation files are formatted in markdown"
          ],
          "developerVisibleActions": [
            "Initialize product documentation runs to start saving results",
            "Initialize architecture insights runs for system-level analysis",
            "Save individual file documentation with metadata",
            "Save architecture insights with processing statistics",
            "Append incremental documentation as files are processed",
            "Generate summary reports at the end of analysis runs",
            "Store results in .shadow/docs with timestamped run directories",
            "Access run metadata like start time and directory paths"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Creates a new timestamped directory for storing product documentation",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Creates a new timestamped directory for storing architecture insights",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "saveProductDocumentation",
              "desc": "Saves enhanced product documentation for a single file",
              "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Saves architecture insights with processing metadata",
              "inputs": "insights: LLMInsights, filesProcessed: number, timeElapsed: number, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "appendProductDocumentation",
              "desc": "Appends documentation incrementally during processing",
              "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "generateProductDocsSummary",
              "desc": "Creates a summary report of all processed files",
              "inputs": "filesProcessed: number, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "generateArchitectureInsightsSummary",
              "desc": "Creates a summary report of architecture analysis",
              "inputs": "insights: LLMInsights, filesProcessed: number, workspaceRoot: string",
              "outputs": "Promise<void>"
            },
            {
              "name": "getCurrentProductDocsRunDir",
              "desc": "Gets the current product docs run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "getCurrentArchitectureInsightsRunDir",
              "desc": "Gets the current architecture insights run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "resetProductDocsRun",
              "desc": "Clears the current product docs run context",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "resetArchitectureInsightsRun",
              "desc": "Clears the current architecture insights run context",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../../fileDocumentation (EnhancedProductDocumentation)",
            "../../llmService (LLMInsights)",
            "../../domain/formatters/documentationFormatter (DocumentationFormatter)",
            "../../storage/incrementalStorage (createTimestampedStorage)"
          ],
          "intent": "This repository separates persistence concerns from analysis logic, providing a dedicated layer for saving analysis results to disk in an organized, timestamped structure that allows multiple runs to coexist and makes it easy to track when analyses were performed.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages saving and organizing analysis results (product documentation, architecture insights, and summaries) to disk in timestamped directories.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to .shadow/docs directory\",\n    \"Each analysis run creates a timestamped folder with organized documentation\",\n    \"Product documentation is saved as individual files per analyzed file\",\n    \"Architecture insights are saved as a consolidated summary\",\n    \"Progress summaries show files processed and time taken\",\n    \"All documentation files are formatted in markdown\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to start saving results\",\n    \"Initialize architecture insights runs for system-level analysis\",\n    \"Save individual file documentation with metadata\",\n    \"Save architecture insights with processing statistics\",\n    \"Append incremental documentation as files are processed\",\n    \"Generate summary reports at the end of analysis runs\",\n    \"Store results in .shadow/docs with timestamped run directories\",\n    \"Access run metadata like start time and directory paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves enhanced product documentation for a single file\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights with processing metadata\",\n      \"inputs\": \"insights: LLMInsights, filesProcessed: number, timeElapsed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"appendProductDocumentation\",\n      \"desc\": \"Appends documentation incrementally during processing\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateProductDocsSummary\",\n      \"desc\": \"Creates a summary report of all processed files\",\n      \"inputs\": \"filesProcessed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateArchitectureInsightsSummary\",\n      \"desc\": \"Creates a summary report of architecture analysis\",\n      \"inputs\": \"insights: LLMInsights, filesProcessed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Gets the current product docs run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Gets the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product docs run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\",\n    \"../../llmService (LLMInsights)\",\n    \"../../domain/formatters/documentationFormatter (DocumentationFormatter)\",\n    \"../../storage/incrementalStorage (createTimestampedStorage)\"\n  ],\n  \"intent\": \"This repository separates persistence concerns from analysis logic, providing a dedicated layer for saving analysis results to disk in an organized, timestamped structure that allows multiple runs to coexist and makes it easy to track when analyses were performed.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display progress notifications to users during long-running operations",
        "Allow users to cancel ongoing operations through interactive progress notifications",
        "Show progress indicators in multiple UI locations (notification area, window status, source control view)",
        "Provide consistent progress reporting with titles and status messages across the application",
        "Support both cancellable and non-cancellable progress notifications"
      ],
      "summary": "The infrastructure module provides a centralized progress notification service that keeps users informed during long-running operations. It displays standardized progress indicators with clear titles and status messages, ensuring users understand what tasks are currently executing and their progress.\n\nUsers can interact with progress notifications by canceling operations when needed, using the cancellation button that appears in the notification. The service intelligently displays progress in appropriate locations within the interface, including the notification area for prominent alerts, the window status bar for less intrusive updates, and the source control view for version control operations.\n\nThis module standardizes how the application communicates ongoing work to users, creating a consistent experience across all features that require user feedback during processing. It handles the complexity of progress reporting while providing a simple interface for displaying status updates and respecting user cancellation requests.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations with optional cancellation support",
          "userVisibleActions": [
            "See progress notifications with titles and status messages during operations",
            "Cancel long-running operations using the cancellation button in progress notifications",
            "View progress indicators in different locations (notification, window, source control)"
          ],
          "developerVisibleActions": [
            "Wrap async operations with standardized progress reporting using withProgress method",
            "Report incremental progress updates with custom messages during task execution",
            "Configure progress location (notification, window, source control) and cancellability",
            "Access cancellation token to respond to user cancellation requests",
            "Use simplified string title or full options object for progress configuration"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying progress notifications to the user with customizable title, location, and cancellation support",
              "inputs": "options (title, cancellable flag, location) and async task function that receives a ProgressReporter",
              "outputs": "Promise resolving to the result of the executed task"
            },
            {
              "name": "ProgressReporter.report",
              "desc": "Updates the progress notification with a new message and optional increment value",
              "inputs": "message string and optional increment number",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to eliminate boilerplate code and ensure consistent progress reporting across the codebase. It wraps VSCode's native progress API to provide a simpler, standardized interface for showing progress notifications during async operations, making it easier for developers to provide user feedback and handle cancellation uniformly.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations with optional cancellation support\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and status messages during operations\",\n    \"Cancel long-running operations using the cancellation button in progress notifications\",\n    \"View progress indicators in different locations (notification, window, source control)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async operations with standardized progress reporting using withProgress method\",\n    \"Report incremental progress updates with custom messages during task execution\",\n    \"Configure progress location (notification, window, source control) and cancellability\",\n    \"Access cancellation token to respond to user cancellation requests\",\n    \"Use simplified string title or full options object for progress configuration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying progress notifications to the user with customizable title, location, and cancellation support\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise resolving to the result of the executed task\"\n    },\n    {\n      \"name\": \"ProgressReporter.report\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment value\",\n      \"inputs\": \"message string and optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to eliminate boilerplate code and ensure consistent progress reporting across the codebase. It wraps VSCode's native progress API to provide a simpler, standardized interface for showing progress notifications during async operations, making it easier for developers to provide user feedback and handle cancellation uniformly.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest testing framework for TypeScript test execution with coverage reporting and module resolution.",
      "userVisibleActions": [
        "No direct user-visible actions - this is a testing configuration file"
      ],
      "developerVisibleActions": [
        "Developer runs test suites located in src and UnitTests directories",
        "Developer views test coverage reports in text, lcov, and HTML formats",
        "Developer writes tests in TypeScript with .spec.ts or .test.ts extensions",
        "Developer sees test results with a 10 second timeout per test",
        "Developer gets code coverage metrics excluding test files, type definitions, and mock files"
      ],
      "keyFunctions": [],
      "dependencies": [
        "ts-jest",
        "jest",
        "typescript"
      ],
      "intent": "This file exists to configure the Jest testing framework for a TypeScript-based VSCode extension project, ensuring tests can be run with proper TypeScript compilation, module resolution (including VSCode API mocking), and coverage reporting to maintain code quality.",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript test execution with coverage reporting and module resolution.\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a testing configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer runs test suites located in src and UnitTests directories\",\n    \"Developer views test coverage reports in text, lcov, and HTML formats\",\n    \"Developer writes tests in TypeScript with .spec.ts or .test.ts extensions\",\n    \"Developer sees test results with a 10 second timeout per test\",\n    \"Developer gets code coverage metrics excluding test files, type definitions, and mock files\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript-based VSCode extension project, ensuring tests can be run with proper TypeScript compilation, module resolution (including VSCode API mocking), and coverage reporting to maintain code quality.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Manages rate limiting for LLM API requests to prevent exceeding provider rate limits",
      "userVisibleActions": [
        "User's AI requests are automatically throttled to prevent API rate limit errors",
        "User experiences smooth AI interactions without hitting rate limit errors from OpenAI or Claude",
        "User's rapid successive AI requests are controlled to stay within provider limits"
      ],
      "developerVisibleActions": [
        "Developer can check if an AI request is allowed before making it to avoid rate limit errors",
        "Developer records each AI API request to track usage against rate limits",
        "Developer can configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)",
        "System automatically cleans up old request history outside the time window"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes rate limiter with default limits for OpenAI (60 req/min) and Claude (50 req/min)",
          "inputs": "none",
          "outputs": "RateLimiter instance"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limit configuration for a specific LLM provider",
          "inputs": "provider (openai or claude), config (maxRequests and windowMs)",
          "outputs": "void"
        },
        {
          "name": "canMakeRequest",
          "desc": "Checks if a new request can be made without exceeding the rate limit",
          "inputs": "provider (openai or claude)",
          "outputs": "boolean (true if request allowed, false if rate limited)"
        },
        {
          "name": "recordRequest",
          "desc": "Records timestamp of a completed request for rate limit tracking",
          "inputs": "provider (openai or claude)",
          "outputs": "void"
        }
      ],
      "dependencies": [],
      "intent": "Prevents the application from exceeding LLM provider API rate limits by tracking request frequency per provider, protecting against rate limit errors and potential API access suspension",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages rate limiting for LLM API requests to prevent exceeding provider rate limits\",\n  \"userVisibleActions\": [\n    \"User's AI requests are automatically throttled to prevent API rate limit errors\",\n    \"User experiences smooth AI interactions without hitting rate limit errors from OpenAI or Claude\",\n    \"User's rapid successive AI requests are controlled to stay within provider limits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can check if an AI request is allowed before making it to avoid rate limit errors\",\n    \"Developer records each AI API request to track usage against rate limits\",\n    \"Developer can configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)\",\n    \"System automatically cleans up old request history outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits for OpenAI (60 req/min) and Claude (50 req/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (openai or claude), config (maxRequests and windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request can be made without exceeding the rate limit\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"boolean (true if request allowed, false if rate limited)\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records timestamp of a completed request for rate limit tracking\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Prevents the application from exceeding LLM provider API rate limits by tracking request frequency per provider, protecting against rate limit errors and potential API access suspension\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Parses and extracts structured data from LLM text responses into typed objects for file summaries, module summaries, and product documentation.",
      "userVisibleActions": [
        "Converts AI-generated text responses into structured documentation format",
        "Extracts meaningful information from AI responses even when JSON parsing fails",
        "Provides fallback text extraction when AI responses are not in expected format"
      ],
      "developerVisibleActions": [
        "Call parseFileSummary() to convert LLM text into FileSummary object with file path, role, purpose, actions, and dependencies",
        "Call parseModuleSummary() to convert LLM text into ModuleSummary object with module overview and file relationships",
        "Call parseProductDocumentation() to convert LLM text into EnhancedProductDocumentation with product purpose, features, and user flows",
        "Call parseLLMInsights() to extract analysis insights about product behavior and architecture",
        "Call parseProductPurposeAnalysis() to get structured product purpose information",
        "Automatically handles both JSON-formatted and plain text LLM responses",
        "Receives original LLM response content plus metadata like file paths and roles",
        "Gets structured objects back with typed fields ready for documentation generation"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into FileSummary object with file metadata, purpose, actions, and dependencies",
          "inputs": "content (string), filePath (string), role (string)",
          "outputs": "FileSummary object"
        },
        {
          "name": "parseModuleSummary",
          "desc": "Converts LLM response text into ModuleSummary object with module overview and file relationships",
          "inputs": "content (string)",
          "outputs": "ModuleSummary object"
        },
        {
          "name": "parseProductDocumentation",
          "desc": "Converts LLM response text into EnhancedProductDocumentation with complete product information",
          "inputs": "content (string)",
          "outputs": "EnhancedProductDocumentation object"
        },
        {
          "name": "parseLLMInsights",
          "desc": "Extracts LLM analysis insights about product behavior and architecture from response text",
          "inputs": "content (string)",
          "outputs": "LLMInsights object"
        },
        {
          "name": "parseProductPurposeAnalysis",
          "desc": "Extracts structured product purpose information from LLM response",
          "inputs": "content (string)",
          "outputs": "ProductPurposeAnalysis object"
        },
        {
          "name": "extractSection",
          "desc": "Helper that extracts a specific named section from text content",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Extracted section text as string"
        },
        {
          "name": "extractListSection",
          "desc": "Helper that extracts a list of items from a named section in text",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Array of strings"
        }
      ],
      "dependencies": [
        "../fileDocumentation",
        "../llmService"
      ],
      "intent": "This file exists to reliably transform free-form AI-generated text responses into consistent, typed data structures that the application can use programmatically. It solves the problem of working with unpredictable LLM output formats by providing intelligent parsing with JSON fallback to text extraction, ensuring the application always gets usable structured data regardless of how the AI formats its response.",
      "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into typed objects for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"Converts AI-generated text responses into structured documentation format\",\n    \"Extracts meaningful information from AI responses even when JSON parsing fails\",\n    \"Provides fallback text extraction when AI responses are not in expected format\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM text into FileSummary object with file path, role, purpose, actions, and dependencies\",\n    \"Call parseModuleSummary() to convert LLM text into ModuleSummary object with module overview and file relationships\",\n    \"Call parseProductDocumentation() to convert LLM text into EnhancedProductDocumentation with product purpose, features, and user flows\",\n    \"Call parseLLMInsights() to extract analysis insights about product behavior and architecture\",\n    \"Call parseProductPurposeAnalysis() to get structured product purpose information\",\n    \"Automatically handles both JSON-formatted and plain text LLM responses\",\n    \"Receives original LLM response content plus metadata like file paths and roles\",\n    \"Gets structured objects back with typed fields ready for documentation generation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into FileSummary object with file metadata, purpose, actions, and dependencies\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Converts LLM response text into ModuleSummary object with module overview and file relationships\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Converts LLM response text into EnhancedProductDocumentation with complete product information\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts LLM analysis insights about product behavior and architecture from response text\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductPurposeAnalysis\",\n      \"desc\": \"Extracts structured product purpose information from LLM response\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Helper that extracts a specific named section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted section text as string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Helper that extracts a list of items from a named section in text\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to reliably transform free-form AI-generated text responses into consistent, typed data structures that the application can use programmatically. It solves the problem of working with unpredictable LLM output formats by providing intelligent parsing with JSON fallback to text extraction, ensuring the application always gets usable structured data regardless of how the AI formats its response.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles automatic retries of failed LLM API requests with exponential backoff and intelligent error classification",
      "userVisibleActions": [
        "When LLM API requests fail temporarily, they automatically retry without user intervention",
        "Users experience fewer failures from rate limits, timeouts, and temporary network issues",
        "Failed requests wait progressively longer between retries to avoid overwhelming the API",
        "Non-recoverable errors fail immediately instead of wasting time retrying"
      ],
      "developerVisibleActions": [
        "Wrap any LLM API call with retry logic to handle transient failures automatically",
        "Configure retry behavior (max attempts, delays, backoff multiplier)",
        "Specify which error types should trigger retries vs fail immediately",
        "Receive callbacks on each retry attempt to log or monitor retry behavior",
        "Get final result with total number of attempts made"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an async operation with automatic retry logic and exponential backoff",
          "inputs": "operation function that returns a Promise, optional retry configuration (maxRetries, delays, error types, callback)",
          "outputs": "Promise resolving to operation result along with number of attempts made"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines if an error should trigger a retry or fail immediately",
          "inputs": "error object, list of retryable error patterns",
          "outputs": "boolean indicating whether the error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, timeouts, network issues) through intelligent retry logic, preventing unnecessary failures while avoiding infinite retry loops on permanent errors",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of failed LLM API requests with exponential backoff and intelligent error classification\",\n  \"userVisibleActions\": [\n    \"When LLM API requests fail temporarily, they automatically retry without user intervention\",\n    \"Users experience fewer failures from rate limits, timeouts, and temporary network issues\",\n    \"Failed requests wait progressively longer between retries to avoid overwhelming the API\",\n    \"Non-recoverable errors fail immediately instead of wasting time retrying\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic to handle transient failures automatically\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries vs fail immediately\",\n    \"Receive callbacks on each retry attempt to log or monitor retry behavior\",\n    \"Get final result with total number of attempts made\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation function that returns a Promise, optional retry configuration (maxRetries, delays, error types, callback)\",\n      \"outputs\": \"Promise resolving to operation result along with number of attempts made\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry or fail immediately\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating whether the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, timeouts, network issues) through intelligent retry logic, preventing unnecessary failures while avoiding infinite retry loops on permanent errors\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system",
      "userVisibleActions": [
        "User receives text responses from AI models through any configured provider",
        "User receives structured JSON responses from AI models for data parsing",
        "User gets appropriate error handling when AI provider is not configured"
      ],
      "developerVisibleActions": [
        "Developer implements this interface to add support for new AI providers",
        "Developer sends text prompts with optional system instructions and conversation history",
        "Developer requests structured JSON output with optional schema validation",
        "Developer checks if a provider is properly configured before use",
        "Developer controls AI behavior via temperature and token limits",
        "Developer receives file and grep requests from AI responses for code exploration"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if the AI provider has valid credentials and is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt with messages to the AI and gets back a text response",
          "inputs": "LLMRequestOptions with model, messages, system prompt, temperature, max tokens",
          "outputs": "LLMResponse with content string and metadata"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt and gets back parsed JSON data with optional follow-up requests",
          "inputs": "LLMRequestOptions and optional JSON schema for validation",
          "outputs": "StructuredOutputResponse with typed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the identifier name of the provider",
          "inputs": "none",
          "outputs": "string with provider name"
        }
      ],
      "dependencies": [],
      "intent": "This interface exists to provide a unified abstraction layer over different AI language model providers (like OpenAI, Claude, or custom models), allowing the application to switch between providers or use multiple providers without changing the consuming code. It solves the problem of vendor lock-in and enables flexible AI provider selection while maintaining consistent request/response handling across all implementations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for integrating different AI language model providers (OpenAI, Claude, etc.) into the system\",\n  \"userVisibleActions\": [\n    \"User receives text responses from AI models through any configured provider\",\n    \"User receives structured JSON responses from AI models for data parsing\",\n    \"User gets appropriate error handling when AI provider is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add support for new AI providers\",\n    \"Developer sends text prompts with optional system instructions and conversation history\",\n    \"Developer requests structured JSON output with optional schema validation\",\n    \"Developer checks if a provider is properly configured before use\",\n    \"Developer controls AI behavior via temperature and token limits\",\n    \"Developer receives file and grep requests from AI responses for code exploration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the AI provider has valid credentials and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt with messages to the AI and gets back a text response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, system prompt, temperature, max tokens\",\n      \"outputs\": \"LLMResponse with content string and metadata\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt and gets back parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema for validation\",\n      \"outputs\": \"StructuredOutputResponse with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name of the provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to provide a unified abstraction layer over different AI language model providers (like OpenAI, Claude, or custom models), allowing the application to switch between providers or use multiple providers without changing the consuming code. It solves the problem of vendor lock-in and enables flexible AI provider selection while maintaining consistent request/response handling across all implementations.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with Anthropic's Claude AI models for text generation and structured output requests",
      "userVisibleActions": [
        "Sends prompts to Claude AI and receives text responses",
        "Generates structured JSON outputs from Claude based on schemas",
        "Receives error messages when Claude API is not configured",
        "Experiences 5-minute timeout for long-running requests"
      ],
      "developerVisibleActions": [
        "Configure Claude API key through configuration manager",
        "Send text generation requests with custom prompts and parameters",
        "Request structured JSON outputs by providing JSON schemas",
        "Receive responses with content and token usage information",
        "Handle provider availability checks before making requests",
        "Access Claude-specific models like claude-sonnet-4-5"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is configured and provider is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a text generation request to Claude with messages and system prompt",
          "inputs": "LLMRequestOptions (messages, model, systemPrompt, maxTokens)",
          "outputs": "LLMResponse with content and token usage"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Requests Claude to generate output matching a specific JSON schema",
          "inputs": "LLMRequestOptions with jsonSchema",
          "outputs": "StructuredOutputResponse with parsed JSON object"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier name",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Anthropic client with API key from configuration",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to enable the application to use Anthropic's Claude AI models as an alternative to OpenAI, providing AI-powered text generation and structured output capabilities with Claude-specific message formatting and API integration",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for text generation and structured output requests\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives text responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Receives error messages when Claude API is not configured\",\n    \"Experiences 5-minute timeout for long-running requests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through configuration manager\",\n    \"Send text generation requests with custom prompts and parameters\",\n    \"Request structured JSON outputs by providing JSON schemas\",\n    \"Receive responses with content and token usage information\",\n    \"Handle provider availability checks before making requests\",\n    \"Access Claude-specific models like claude-sonnet-4-5\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text generation request to Claude with messages and system prompt\",\n      \"inputs\": \"LLMRequestOptions (messages, model, systemPrompt, maxTokens)\",\n      \"outputs\": \"LLMResponse with content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests Claude to generate output matching a specific JSON schema\",\n      \"inputs\": \"LLMRequestOptions with jsonSchema\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON object\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier name\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to enable the application to use Anthropic's Claude AI models as an alternative to OpenAI, providing AI-powered text generation and structured output capabilities with Claude-specific message formatting and API integration\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with OpenAI's API to send chat completion requests and receive AI-generated responses",
      "userVisibleActions": [
        "Receives AI-generated text responses from OpenAI models (like GPT-4)",
        "Gets structured JSON responses when requesting formatted output",
        "Experiences timeout after 5 minutes if AI response takes too long",
        "Sees error messages when OpenAI API key is not configured"
      ],
      "developerVisibleActions": [
        "Configure OpenAI API key through configuration manager to enable the provider",
        "Send chat completion requests with system prompts and conversation messages",
        "Request structured JSON output by specifying response format",
        "Check if provider is configured before making requests",
        "Receive responses with content, finish reason, and token usage information",
        "Handle errors when API key is missing or requests fail"
      ],
      "keyFunctions": [
        {
          "name": "initialize",
          "desc": "Sets up the OpenAI client with API key from configuration",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "isConfigured",
          "desc": "Checks if the provider has a valid API key and is ready to use",
          "inputs": "None",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "None",
          "outputs": "string 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a chat completion request to OpenAI and returns the response",
          "inputs": "LLMRequestOptions (model, messages, system prompt, response format)",
          "outputs": "Promise<LLMResponse> with content, finish reason, and usage"
        },
        {
          "name": "sendRequestStructured",
          "desc": "Sends a request expecting structured JSON output and parses the result",
          "inputs": "LLMRequestOptions with json_object response format",
          "outputs": "Promise<StructuredOutputResponse> with parsed JSON data and raw content"
        }
      ],
      "dependencies": [
        "openai",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to abstract OpenAI's API behind a common provider interface, allowing the application to send AI requests and receive responses while handling configuration, error cases, and both text and structured JSON outputs consistently with other AI providers",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with OpenAI's API to send chat completion requests and receive AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated text responses from OpenAI models (like GPT-4)\",\n    \"Gets structured JSON responses when requesting formatted output\",\n    \"Experiences timeout after 5 minutes if AI response takes too long\",\n    \"Sees error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager to enable the provider\",\n    \"Send chat completion requests with system prompts and conversation messages\",\n    \"Request structured JSON output by specifying response format\",\n    \"Check if provider is configured before making requests\",\n    \"Receive responses with content, finish reason, and token usage information\",\n    \"Handle errors when API key is missing or requests fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has a valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, system prompt, response format)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, and usage\"\n    },\n    {\n      \"name\": \"sendRequestStructured\",\n      \"desc\": \"Sends a request expecting structured JSON output and parses the result\",\n      \"inputs\": \"LLMRequestOptions with json_object response format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data and raw content\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI's API behind a common provider interface, allowing the application to send AI requests and receive responses while handling configuration, error cases, and both text and structured JSON outputs consistently with other AI providers\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Creates and manages AI language model provider instances (OpenAI and Claude) based on configuration",
      "userVisibleActions": [
        "AI responses come from the configured provider (OpenAI or Claude)",
        "System automatically uses the provider specified in settings",
        "AI features only work when at least one provider is properly configured with API keys"
      ],
      "developerVisibleActions": [
        "Request an AI provider instance by name ('openai' or 'claude')",
        "Get the currently configured provider without specifying which one",
        "Check if a specific provider has valid configuration/API keys",
        "Retrieve a list of all properly configured providers available for use",
        "Provider instances are reused (singleton pattern) to avoid recreating connections"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns a provider instance for the specified AI service",
          "inputs": "provider type ('openai' or 'claude')",
          "outputs": "ILLMProvider instance for making AI requests"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the provider instance that matches the user's current configuration setting",
          "inputs": "none (reads from config)",
          "outputs": "ILLMProvider instance of the configured provider"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks whether a specific provider has valid configuration and can be used",
          "inputs": "provider type ('openai' or 'claude')",
          "outputs": "boolean indicating if the provider is ready to use"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns a list of all providers that are properly configured and available",
          "inputs": "none",
          "outputs": "array of provider names that have valid configuration"
        }
      ],
      "dependencies": [
        "ILLMProvider",
        "OpenAIProvider",
        "AnthropicProvider",
        "configurationManager"
      ],
      "intent": "Centralizes AI provider creation and management so the rest of the application doesn't need to know which AI service is being used or handle provider instantiation - it acts as a single point of access for all AI providers and ensures only one instance of each provider exists throughout the application lifecycle",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI language model provider instances (OpenAI and Claude) based on configuration\",\n  \"userVisibleActions\": [\n    \"AI responses come from the configured provider (OpenAI or Claude)\",\n    \"System automatically uses the provider specified in settings\",\n    \"AI features only work when at least one provider is properly configured with API keys\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request an AI provider instance by name ('openai' or 'claude')\",\n    \"Get the currently configured provider without specifying which one\",\n    \"Check if a specific provider has valid configuration/API keys\",\n    \"Retrieve a list of all properly configured providers available for use\",\n    \"Provider instances are reused (singleton pattern) to avoid recreating connections\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a provider instance for the specified AI service\",\n      \"inputs\": \"provider type ('openai' or 'claude')\",\n      \"outputs\": \"ILLMProvider instance for making AI requests\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the provider instance that matches the user's current configuration setting\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"ILLMProvider instance of the configured provider\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks whether a specific provider has valid configuration and can be used\",\n      \"inputs\": \"provider type ('openai' or 'claude')\",\n      \"outputs\": \"boolean indicating if the provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all providers that are properly configured and available\",\n      \"inputs\": \"none\",\n      \"outputs\": \"array of provider names that have valid configuration\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and management so the rest of the application doesn't need to know which AI service is being used or handle provider instantiation - it acts as a single point of access for all AI providers and ensures only one instance of each provider exists throughout the application lifecycle\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Provides deep code analysis capabilities by parsing TypeScript/JavaScript files to extract function metadata, including branch complexity, dependencies, state mutations, and behavioral hints",
      "userVisibleActions": [
        "Receives detailed analysis of code functions including complexity metrics",
        "Gets insights into function behavior and side effects",
        "Views branch analysis showing decision points in code",
        "Sees dependency relationships between functions and modules",
        "Obtains state mutation information showing what data changes"
      ],
      "developerVisibleActions": [
        "Call analyzeFileMetadata() to extract comprehensive metadata for all functions in a file",
        "Receive FunctionMetadata objects containing branch analysis, dependency info, state mutations, and behavioral hints",
        "Get AST-based analysis for TypeScript/JavaScript files with full type information",
        "Fallback to regex-based analysis for non-TypeScript languages",
        "Extract function content by line ranges for targeted analysis",
        "Analyze function complexity, conditional branches, and control flow",
        "Identify external dependencies and function calls within code",
        "Detect state mutations and side effects in functions",
        "Map test coverage and relationships to test files"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and mutations",
          "inputs": "filePath: string, content: string, language: string, functions: FunctionInfo[]",
          "outputs": "Promise<Map<string, FunctionMetadata>> - Map of function names to their detailed metadata"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed structural and behavioral information",
          "inputs": "filePath: string, content: string, func: FunctionInfo, functionContent: string",
          "outputs": "Promise<FunctionMetadata> - Comprehensive function metadata"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Provides fallback regex-based analysis for non-TypeScript languages to extract basic function metadata",
          "inputs": "filePath: string, func: FunctionInfo, functionContent: string, language: string",
          "outputs": "FunctionMetadata - Basic function metadata"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the source code content of a function given its start and end line numbers",
          "inputs": "content: string, startLine: number, endLine: number",
          "outputs": "string - The function's source code"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer"
      ],
      "intent": "This file exists to provide advanced code analysis beyond basic function detection. It solves the problem of understanding code behavior, complexity, and relationships by parsing Abstract Syntax Trees (AST) to extract branch conditions, dependencies, state changes, and behavioral patterns. This enables intelligent code documentation, test generation, and impact analysis by understanding not just what functions exist, but how they work and what they affect.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities by parsing TypeScript/JavaScript files to extract function metadata, including branch complexity, dependencies, state mutations, and behavioral hints\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including complexity metrics\",\n    \"Gets insights into function behavior and side effects\",\n    \"Views branch analysis showing decision points in code\",\n    \"Sees dependency relationships between functions and modules\",\n    \"Obtains state mutation information showing what data changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzeFileMetadata() to extract comprehensive metadata for all functions in a file\",\n    \"Receive FunctionMetadata objects containing branch analysis, dependency info, state mutations, and behavioral hints\",\n    \"Get AST-based analysis for TypeScript/JavaScript files with full type information\",\n    \"Fallback to regex-based analysis for non-TypeScript languages\",\n    \"Extract function content by line ranges for targeted analysis\",\n    \"Analyze function complexity, conditional branches, and control flow\",\n    \"Identify external dependencies and function calls within code\",\n    \"Detect state mutations and side effects in functions\",\n    \"Map test coverage and relationships to test files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and mutations\",\n      \"inputs\": \"filePath: string, content: string, language: string, functions: FunctionInfo[]\",\n      \"outputs\": \"Promise<Map<string, FunctionMetadata>> - Map of function names to their detailed metadata\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed structural and behavioral information\",\n      \"inputs\": \"filePath: string, content: string, func: FunctionInfo, functionContent: string\",\n      \"outputs\": \"Promise<FunctionMetadata> - Comprehensive function metadata\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for non-TypeScript languages to extract basic function metadata\",\n      \"inputs\": \"filePath: string, func: FunctionInfo, functionContent: string, language: string\",\n      \"outputs\": \"FunctionMetadata - Basic function metadata\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function given its start and end line numbers\",\n      \"inputs\": \"content: string, startLine: number, endLine: number\",\n      \"outputs\": \"string - The function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced code analysis beyond basic function detection. It solves the problem of understanding code behavior, complexity, and relationships by parsing Abstract Syntax Trees (AST) to extract branch conditions, dependencies, state changes, and behavioral patterns. This enables intelligent code documentation, test generation, and impact analysis by understanding not just what functions exist, but how they work and what they affect.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, dependents, and responsibilities for refactoring reports.",
      "userVisibleActions": [
        "Identifies which functions in large files may need refactoring",
        "Shows function dependencies and relationships across the codebase",
        "Reveals which functions are called by many other parts of the code",
        "Displays function signatures and their responsibilities"
      ],
      "developerVisibleActions": [
        "Filters code analysis to focus on files exceeding a size threshold (default 500 lines)",
        "Extracts function metadata from TypeScript files including name, signature, and location",
        "Maps out which functions depend on other functions (dependencies)",
        "Identifies which functions are called by the analyzed function (dependents)",
        "Generates structured function analysis data for refactoring prompt builders",
        "Handles analysis failures gracefully with warnings for individual functions"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in large files to extract detailed information for refactoring",
          "inputs": "codeAnalysis (full code analysis), largeFileThreshold (minimum lines, default 500)",
          "outputs": "Array of FunctionAnalysis objects with detailed metadata"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs deep analysis on a single function to extract dependencies, dependents, and metadata",
          "inputs": "filePath (file location), func (FunctionInfo), codeAnalysis (context)",
          "outputs": "FunctionAnalysis object or null if analysis fails"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves relative file paths to absolute paths for file system access",
          "inputs": "filePath (relative path), codeAnalysis (for base directory)",
          "outputs": "Absolute file path string"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to provide deep function-level analysis for large files that may need refactoring. It solves the problem of understanding complex function relationships and responsibilities when deciding how to break up large code files. By extracting detailed metadata about each function's dependencies, callers, and purpose, it enables automated generation of refactoring recommendations and reports.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, dependents, and responsibilities for refactoring reports.\",\n  \"userVisibleActions\": [\n    \"Identifies which functions in large files may need refactoring\",\n    \"Shows function dependencies and relationships across the codebase\",\n    \"Reveals which functions are called by many other parts of the code\",\n    \"Displays function signatures and their responsibilities\"\n  ],\n  \"developerVisibleActions\": [\n    \"Filters code analysis to focus on files exceeding a size threshold (default 500 lines)\",\n    \"Extracts function metadata from TypeScript files including name, signature, and location\",\n    \"Maps out which functions depend on other functions (dependencies)\",\n    \"Identifies which functions are called by the analyzed function (dependents)\",\n    \"Generates structured function analysis data for refactoring prompt builders\",\n    \"Handles analysis failures gracefully with warnings for individual functions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in large files to extract detailed information for refactoring\",\n      \"inputs\": \"codeAnalysis (full code analysis), largeFileThreshold (minimum lines, default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects with detailed metadata\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs deep analysis on a single function to extract dependencies, dependents, and metadata\",\n      \"inputs\": \"filePath (file location), func (FunctionInfo), codeAnalysis (context)\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file system access\",\n      \"inputs\": \"filePath (relative path), codeAnalysis (for base directory)\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep function-level analysis for large files that may need refactoring. It solves the problem of understanding complex function relationships and responsibilities when deciding how to break up large code files. By extracting detailed metadata about each function's dependencies, callers, and purpose, it enables automated generation of refactoring recommendations and reports.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree-view interface for browsing and exploring code analysis results in the VSCode sidebar",
      "userVisibleActions": [
        "View a hierarchical tree of code analysis results in the sidebar",
        "Browse analysis statistics (total files, lines of code, functions count)",
        "Explore files organized by directory structure",
        "View individual file details (LOC, complexity, functions)",
        "See all functions across the codebase with their signatures",
        "Browse entry points (main functions, exports) in the code",
        "Click on items to jump to specific locations in source files",
        "See message 'No analysis available' when no analysis has been run",
        "Refresh the tree view to see updated analysis results"
      ],
      "developerVisibleActions": [
        "Instantiate AnalysisViewerProvider to create the tree view",
        "Call setAnalysis() to populate the tree with analysis data",
        "Call refresh() to update the tree view display",
        "Implement vscode.TreeDataProvider interface for VSCode integration",
        "Subscribe to onDidChangeTreeData events for tree updates",
        "Tree items are clickable and navigate to source code locations",
        "Tree displays nested categories: statistics, files, functions, entry points"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the tree view with new code analysis results",
          "inputs": "analysis: CodeAnalysis | null",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a refresh of the entire tree view display",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the tree item representation for display in the view",
          "inputs": "element: AnalysisItem",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node or root items if no element provided",
          "inputs": "element?: AnalysisItem",
          "outputs": "Thenable<AnalysisItem[]>"
        },
        {
          "name": "getRootItems",
          "desc": "Generates top-level categories shown in the tree (statistics, files, functions, entry points)",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Creates tree items showing code metrics like file count, LOC, function count",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFilesItems",
          "desc": "Organizes files into a directory tree structure for browsing",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFileDetails",
          "desc": "Shows detailed information about a specific file (functions, complexity, LOC)",
          "inputs": "element: AnalysisItem",
          "outputs": "AnalysisItem[]"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)"
      ],
      "intent": "This file exists to provide a visual, interactive way for users to explore code analysis results directly within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree-view interface, allowing users to drill down from high-level statistics to specific files and functions, and jump directly to source code locations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree-view interface for browsing and exploring code analysis results in the VSCode sidebar\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"Browse analysis statistics (total files, lines of code, functions count)\",\n    \"Explore files organized by directory structure\",\n    \"View individual file details (LOC, complexity, functions)\",\n    \"See all functions across the codebase with their signatures\",\n    \"Browse entry points (main functions, exports) in the code\",\n    \"Click on items to jump to specific locations in source files\",\n    \"See message 'No analysis available' when no analysis has been run\",\n    \"Refresh the tree view to see updated analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Instantiate AnalysisViewerProvider to create the tree view\",\n    \"Call setAnalysis() to populate the tree with analysis data\",\n    \"Call refresh() to update the tree view display\",\n    \"Implement vscode.TreeDataProvider interface for VSCode integration\",\n    \"Subscribe to onDidChangeTreeData events for tree updates\",\n    \"Tree items are clickable and navigate to source code locations\",\n    \"Tree displays nested categories: statistics, files, functions, entry points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new code analysis results\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the entire tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display in the view\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level categories shown in the tree (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing code metrics like file count, LOC, function count\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes files into a directory tree structure for browsing\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Shows detailed information about a specific file (functions, complexity, LOC)\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive way for users to explore code analysis results directly within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree-view interface, allowing users to drill down from high-level statistics to specific files and functions, and jump directly to source code locations.\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
      "userVisibleActions": [
        "View total file count, line count, and function count in codebase",
        "See list of large files that may need refactoring",
        "Identify orphaned files not imported anywhere",
        "Discover entry points (main files) in the project",
        "Find duplicate code blocks across files",
        "View function complexity and risk levels",
        "See test coverage mapping for source files",
        "Identify uncovered functions without tests"
      ],
      "developerVisibleActions": [
        "Import and use CodeAnalysis interface to structure analysis results",
        "Access file-level metrics (lines, functions, complexity)",
        "Query function metadata including parameters, return types, and visibility",
        "Retrieve branch information (if/else, loops, try/catch)",
        "Track dependencies by type (database, HTTP, filesystem, etc.)",
        "Monitor state mutations (assignments, modifications, deletions)",
        "Map source files to their test files",
        "Identify functions missing test coverage",
        "Access cached analysis results for performance",
        "Determine risk levels for functions based on complexity"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main interface containing complete analysis results for a codebase",
          "inputs": "none (interface/type definition)",
          "outputs": "Structure with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, and optional enhanced metadata"
        },
        {
          "name": "FunctionMetadata",
          "desc": "Detailed information about a single function including signature, complexity, and dependencies",
          "inputs": "none (interface/type definition)",
          "outputs": "Structure with symbolName, parameters, returnType, visibility, branches, dependencies, stateMutations, riskLevel"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source files and functions to their corresponding test files and test cases",
          "inputs": "none (interface/type definition)",
          "outputs": "Structure with sourceFileToTests map, functionToTests map, and uncoveredFunctions list"
        },
        {
          "name": "DependencyInfo",
          "desc": "Describes a single dependency with its type and whether it's internal or external",
          "inputs": "none (interface/type definition)",
          "outputs": "Structure with name, type (db/http/filesystem/etc), isInternal flag, and optional lineNumber"
        },
        {
          "name": "BranchInfo",
          "desc": "Represents a branching point in code (if/else, switch, loop, exception handling)",
          "inputs": "none (interface/type definition)",
          "outputs": "Structure with type, human-readable condition, and lineNumber"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache (AnalysisCache)"
      ],
      "intent": "This file exists to provide a standardized schema for representing code analysis results across the application. It solves the problem of inconsistent data structures by defining clear interfaces for file metrics, function metadata, dependencies, test coverage, and code quality indicators, enabling other components to consume and display analysis data in a type-safe manner.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View total file count, line count, and function count in codebase\",\n    \"See list of large files that may need refactoring\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points (main files) in the project\",\n    \"Find duplicate code blocks across files\",\n    \"View function complexity and risk levels\",\n    \"See test coverage mapping for source files\",\n    \"Identify uncovered functions without tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access file-level metrics (lines, functions, complexity)\",\n    \"Query function metadata including parameters, return types, and visibility\",\n    \"Retrieve branch information (if/else, loops, try/catch)\",\n    \"Track dependencies by type (database, HTTP, filesystem, etc.)\",\n    \"Monitor state mutations (assignments, modifications, deletions)\",\n    \"Map source files to their test files\",\n    \"Identify functions missing test coverage\",\n    \"Access cached analysis results for performance\",\n    \"Determine risk levels for functions based on complexity\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface containing complete analysis results for a codebase\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed information about a single function including signature, complexity, and dependencies\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with symbolName, parameters, returnType, visibility, branches, dependencies, stateMutations, riskLevel\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their corresponding test files and test cases\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with sourceFileToTests map, functionToTests map, and uncoveredFunctions list\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Describes a single dependency with its type and whether it's internal or external\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with name, type (db/http/filesystem/etc), isInternal flag, and optional lineNumber\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Represents a branching point in code (if/else, switch, loop, exception handling)\",\n      \"inputs\": \"none (interface/type definition)\",\n      \"outputs\": \"Structure with type, human-readable condition, and lineNumber\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for representing code analysis results across the application. It solves the problem of inconsistent data structures by defining clear interfaces for file metrics, function metadata, dependencies, test coverage, and code quality indicators, enabling other components to consume and display analysis data in a type-safe manner.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent storage and retrieval of code analysis results to avoid redundant analysis operations",
      "userVisibleActions": [
        "Analysis results load instantly when reopening a previously analyzed workspace",
        "Analysis cache automatically expires after 24 hours, ensuring fresh results",
        "Cache can be cleared to force fresh analysis of the workspace"
      ],
      "developerVisibleActions": [
        "Cache is automatically stored in a .shadowwatch-cache directory within the storage path",
        "Cache files are created per workspace using base64-encoded workspace path as identifier",
        "Cache read/write errors are logged to console without interrupting operations",
        "Cache validation checks timestamp to determine if cached data is still valid"
      ],
      "keyFunctions": [
        {
          "name": "get",
          "desc": "Retrieves cached analysis results for a workspace if they exist and are less than 24 hours old",
          "inputs": "workspaceRoot (string path)",
          "outputs": "CodeAnalysis object or null if cache is invalid/missing"
        },
        {
          "name": "set",
          "desc": "Stores analysis results in cache with current timestamp for future retrieval",
          "inputs": "workspaceRoot (string path), data (CodeAnalysis object)",
          "outputs": "void (Promise)"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis files from the cache directory",
          "inputs": "none",
          "outputs": "void (Promise)"
        },
        {
          "name": "getCacheKey",
          "desc": "Generates a safe filename identifier from workspace path using base64 encoding",
          "inputs": "workspaceRoot (string path)",
          "outputs": "string (sanitized cache key)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer (CodeAnalysis type)"
      ],
      "intent": "Improves user experience by caching expensive code analysis operations, allowing instant access to previously analyzed workspace data while maintaining freshness through automatic expiration",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results to avoid redundant analysis operations\",\n  \"userVisibleActions\": [\n    \"Analysis results load instantly when reopening a previously analyzed workspace\",\n    \"Analysis cache automatically expires after 24 hours, ensuring fresh results\",\n    \"Cache can be cleared to force fresh analysis of the workspace\"\n  ],\n  \"developerVisibleActions\": [\n    \"Cache is automatically stored in a .shadowwatch-cache directory within the storage path\",\n    \"Cache files are created per workspace using base64-encoded workspace path as identifier\",\n    \"Cache read/write errors are logged to console without interrupting operations\",\n    \"Cache validation checks timestamp to determine if cached data is still valid\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results for a workspace if they exist and are less than 24 hours old\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"CodeAnalysis object or null if cache is invalid/missing\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Stores analysis results in cache with current timestamp for future retrieval\",\n      \"inputs\": \"workspaceRoot (string path), data (CodeAnalysis object)\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier from workspace path using base64 encoding\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"string (sanitized cache key)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis type)\"\n  ],\n  \"intent\": \"Improves user experience by caching expensive code analysis operations, allowing instant access to previously analyzed workspace data while maintaining freshness through automatic expiration\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all Shadow Watch extension settings with type-safe access and automatic change detection",
      "userVisibleActions": [
        "Extension behavior changes when user modifies settings in VS Code preferences",
        "Analysis triggers automatically on save if analyzeOnSave is enabled",
        "Inline hints appear in editor based on showInlineHints setting",
        "Analysis respects configured timeout limits",
        "Diagnostic severity threshold filters which issues are shown",
        "LLM provider (OpenAI/Claude) determines which AI service is used",
        "Output format controls how analysis results are displayed"
      ],
      "developerVisibleActions": [
        "Provides centralized access to all extension configuration values",
        "Automatically reloads configuration when VS Code settings change",
        "Notifies registered listeners when configuration updates occur",
        "Validates configuration settings and returns validation errors",
        "Exposes typed getters for each configuration property",
        "Handles missing configuration values with sensible defaults",
        "Manages LLM provider selection (OpenAI vs Claude)",
        "Controls analysis behavior through boolean flags"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes configuration manager and sets up change watcher",
          "inputs": "none",
          "outputs": "ConfigurationManager instance"
        },
        {
          "name": "setupWatcher",
          "desc": "Monitors VS Code settings changes and triggers listener callbacks",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "onConfigurationChange",
          "desc": "Registers callback to be invoked when configuration changes",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Unregisters a configuration change callback",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "enabled (getter)",
          "desc": "Returns whether Shadow Watch extension is enabled",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave (getter)",
          "desc": "Returns whether to automatically analyze files on save",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "showInlineHints (getter)",
          "desc": "Returns whether to display inline hints in editor",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "llmProvider (getter)",
          "desc": "Returns configured LLM provider (openai or claude)",
          "inputs": "none",
          "outputs": "LLMProvider"
        },
        {
          "name": "llmFormat (getter)",
          "desc": "Returns output format for LLM responses",
          "inputs": "none",
          "outputs": "LLMFormat"
        },
        {
          "name": "severityThreshold (getter)",
          "desc": "Returns minimum severity level for displaying diagnostics",
          "inputs": "none",
          "outputs": "SeverityThreshold"
        },
        {
          "name": "validate",
          "desc": "Validates current configuration and returns errors if any",
          "inputs": "none",
          "outputs": "ConfigValidationResult"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "Provides a single source of truth for all extension settings, ensuring type safety, automatic updates when settings change, and consistent access to configuration values throughout the extension. Eliminates direct workspace.getConfiguration calls scattered across the codebase and ensures all components react to setting changes uniformly.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings with type-safe access and automatic change detection\",\n  \"userVisibleActions\": [\n    \"Extension behavior changes when user modifies settings in VS Code preferences\",\n    \"Analysis triggers automatically on save if analyzeOnSave is enabled\",\n    \"Inline hints appear in editor based on showInlineHints setting\",\n    \"Analysis respects configured timeout limits\",\n    \"Diagnostic severity threshold filters which issues are shown\",\n    \"LLM provider (OpenAI/Claude) determines which AI service is used\",\n    \"Output format controls how analysis results are displayed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized access to all extension configuration values\",\n    \"Automatically reloads configuration when VS Code settings change\",\n    \"Notifies registered listeners when configuration updates occur\",\n    \"Validates configuration settings and returns validation errors\",\n    \"Exposes typed getters for each configuration property\",\n    \"Handles missing configuration values with sensible defaults\",\n    \"Manages LLM provider selection (OpenAI vs Claude)\",\n    \"Controls analysis behavior through boolean flags\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes configuration manager and sets up change watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Monitors VS Code settings changes and triggers listener callbacks\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers callback to be invoked when configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled (getter)\",\n      \"desc\": \"Returns whether Shadow Watch extension is enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave (getter)\",\n      \"desc\": \"Returns whether to automatically analyze files on save\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints (getter)\",\n      \"desc\": \"Returns whether to display inline hints in editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider (getter)\",\n      \"desc\": \"Returns configured LLM provider (openai or claude)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider\"\n    },\n    {\n      \"name\": \"llmFormat (getter)\",\n      \"desc\": \"Returns output format for LLM responses\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMFormat\"\n    },\n    {\n      \"name\": \"severityThreshold (getter)\",\n      \"desc\": \"Returns minimum severity level for displaying diagnostics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"SeverityThreshold\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Validates current configuration and returns errors if any\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Provides a single source of truth for all extension settings, ensuring type safety, automatic updates when settings change, and consistent access to configuration values throughout the extension. Eliminates direct workspace.getConfiguration calls scattered across the codebase and ensures all components react to setting changes uniformly.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis data into a context format suitable for LLM services and saves it to persistent storage.",
      "userVisibleActions": [
        "Code analysis results are automatically saved to the workspace",
        "Analysis data is stored in a .shadow/docs directory for future reference",
        "Analysis includes metadata with generation timestamp"
      ],
      "developerVisibleActions": [
        "Convert CodeAnalysis objects to AnalysisContext format for LLM processing",
        "Save analysis results as JSON files in the .shadow/docs directory",
        "Creates .shadow and .shadow/docs directories automatically if they don't exist",
        "Adds metadata (generation timestamp) to saved analysis files",
        "Handles workspace folder validation before saving"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms CodeAnalysis data structure into AnalysisContext format",
          "inputs": "analysis: CodeAnalysis object containing files, imports, entry points, and statistics",
          "outputs": "AnalysisContext object with formatted file paths, imports, entry points, and metrics"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to a JSON file in the workspace",
          "inputs": "analysis: CodeAnalysis object to save",
          "outputs": "void (creates/updates code-analysis.json file with metadata)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between code analysis results and LLM service requirements by transforming data formats and providing persistent storage of analysis results for future use and debugging.",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis data into a context format suitable for LLM services and saves it to persistent storage.\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to the workspace\",\n    \"Analysis data is stored in a .shadow/docs directory for future reference\",\n    \"Analysis includes metadata with generation timestamp\"\n  ],\n  \"developerVisibleActions\": [\n    \"Convert CodeAnalysis objects to AnalysisContext format for LLM processing\",\n    \"Save analysis results as JSON files in the .shadow/docs directory\",\n    \"Creates .shadow and .shadow/docs directories automatically if they don't exist\",\n    \"Adds metadata (generation timestamp) to saved analysis files\",\n    \"Handles workspace folder validation before saving\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format\",\n      \"inputs\": \"analysis: CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file paths, imports, entry points, and metrics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to a JSON file in the workspace\",\n      \"inputs\": \"analysis: CodeAnalysis object to save\",\n      \"outputs\": \"void (creates/updates code-analysis.json file with metadata)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM service requirements by transforming data formats and providing persistent storage of analysis results for future use and debugging.\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Displays code insights as visual diagnostic messages (warnings, errors, info) in the VS Code Problems panel and editor gutter",
      "userVisibleActions": [
        "See colored underlines/squiggles in code where insights are detected",
        "View insights listed in the Problems panel (Ctrl+Shift+M)",
        "Hover over underlined code to see insight descriptions",
        "Click on problems to navigate to specific code locations",
        "See insight severity indicated by icon color (error/warning/info)"
      ],
      "developerVisibleActions": [
        "Developer triggers insight generation which updates diagnostics automatically",
        "Diagnostics update in real-time as insights are discovered",
        "Diagnostics are grouped by file for organized viewing",
        "Diagnostics clear when insights are refreshed or extension is reset",
        "Each diagnostic shows source as 'Shadow Watch' and includes insight ID"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Updates all diagnostics across all files based on new insights",
          "inputs": "Array of insights",
          "outputs": "Visual diagnostics in editor and Problems panel"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostics for a single specific file",
          "inputs": "File URI and array of insights for that file",
          "outputs": "Visual diagnostics for that file only"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts an insight into a VS Code diagnostic message with appropriate severity and location",
          "inputs": "Single insight object",
          "outputs": "VS Code Diagnostic object"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostic messages from the editor and Problems panel",
          "inputs": "None",
          "outputs": "Cleared diagnostics UI"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "Bridges the gap between generated code insights and VS Code's native diagnostics system, making insights visible to users through familiar VS Code UI elements (squiggles, Problems panel) rather than requiring custom UI",
      "rawContent": "```json\n{\n  \"purpose\": \"Displays code insights as visual diagnostic messages (warnings, errors, info) in the VS Code Problems panel and editor gutter\",\n  \"userVisibleActions\": [\n    \"See colored underlines/squiggles in code where insights are detected\",\n    \"View insights listed in the Problems panel (Ctrl+Shift+M)\",\n    \"Hover over underlined code to see insight descriptions\",\n    \"Click on problems to navigate to specific code locations\",\n    \"See insight severity indicated by icon color (error/warning/info)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers insight generation which updates diagnostics automatically\",\n    \"Diagnostics update in real-time as insights are discovered\",\n    \"Diagnostics are grouped by file for organized viewing\",\n    \"Diagnostics clear when insights are refreshed or extension is reset\",\n    \"Each diagnostic shows source as 'Shadow Watch' and includes insight ID\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across all files based on new insights\",\n      \"inputs\": \"Array of insights\",\n      \"outputs\": \"Visual diagnostics in editor and Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a single specific file\",\n      \"inputs\": \"File URI and array of insights for that file\",\n      \"outputs\": \"Visual diagnostics for that file only\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic message with appropriate severity and location\",\n      \"inputs\": \"Single insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostic messages from the editor and Problems panel\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Cleared diagnostics UI\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Bridges the gap between generated code insights and VS Code's native diagnostics system, making insights visible to users through familiar VS Code UI elements (squiggles, Problems panel) rather than requiring custom UI\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers and manages all VS Code commands for the code analysis extension, mapping command IDs to their handler functions.",
      "userVisibleActions": [
        "Analyze entire workspace to generate insights",
        "Analyze current file being edited",
        "Copy all analysis insights to clipboard",
        "Copy insights for a specific file",
        "Copy a single insight item",
        "Clear cached analysis data",
        "Clear all extension data",
        "Open extension settings",
        "View latest analysis report",
        "View latest unit test report",
        "Switch between LLM providers (e.g., OpenAI, Anthropic)",
        "View menu structure of analyzed code",
        "Check current LLM provider status",
        "Navigate to specific product/code items",
        "View detailed information about insights",
        "View detailed information about unit tests"
      ],
      "developerVisibleActions": [
        "Commands are registered during extension activation and bound to handler functions",
        "Command handlers interact with analyzer, insight generator, cache, and tree view components",
        "Command registration is centralized for easier maintenance and testing",
        "All command subscriptions are added to context for proper cleanup",
        "Configuration manager is accessed to retrieve user settings during command execution"
      ],
      "keyFunctions": [
        {
          "name": "register",
          "desc": "Registers all VS Code commands with their corresponding handler functions",
          "inputs": "context: vscode.ExtensionContext, components: ExtensionComponents",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "This file exists to separate command registration logic from the main extension activation code, providing a clean interface for registering all user-facing commands and making the command structure easier to maintain and test. It solves the problem of command sprawl by centralizing all command definitions and their handlers in one place.",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers and manages all VS Code commands for the code analysis extension, mapping command IDs to their handler functions.\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to generate insights\",\n    \"Analyze current file being edited\",\n    \"Copy all analysis insights to clipboard\",\n    \"Copy insights for a specific file\",\n    \"Copy a single insight item\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers (e.g., OpenAI, Anthropic)\",\n    \"View menu structure of analyzed code\",\n    \"Check current LLM provider status\",\n    \"Navigate to specific product/code items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Commands are registered during extension activation and bound to handler functions\",\n    \"Command handlers interact with analyzer, insight generator, cache, and tree view components\",\n    \"Command registration is centralized for easier maintenance and testing\",\n    \"All command subscriptions are added to context for proper cleanup\",\n    \"Configuration manager is accessed to retrieve user settings during command execution\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their corresponding handler functions\",\n      \"inputs\": \"context: vscode.ExtensionContext, components: ExtensionComponents\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file exists to separate command registration logic from the main extension activation code, providing a clean interface for registering all user-facing commands and making the command structure easier to maintain and test. It solves the problem of command sprawl by centralizing all command definitions and their handlers in one place.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Initializes and bootstraps all extension components during VS Code extension activation",
      "userVisibleActions": [
        "Extension activates and becomes ready to use in VS Code",
        "Status bar item appears showing extension status",
        "Multiple tree views become available in the sidebar (Insights, Analysis, Reports, Product Navigator, Unit Tests, Static Analysis)",
        "Code diagnostics and insights start appearing in the editor",
        "File watching begins for automatic analysis on file changes",
        "Commands become available in the command palette for interacting with the extension"
      ],
      "developerVisibleActions": [
        "Call bootstrap function to initialize all extension components during activation",
        "Receive initialized component instances (analyzer, insight generator, formatters, viewers, etc.)",
        "Access centralized extension state through state manager",
        "Configure components through configuration manager",
        "Handle extension lifecycle through bootstrapper setup",
        "Register all tree views, commands, and UI providers automatically",
        "Set up error handling and caching mechanisms"
      ],
      "keyFunctions": [
        {
          "name": "bootstrap",
          "desc": "Main entry point that initializes all extension components and wires them together",
          "inputs": "vscode.ExtensionContext - VS Code extension context for registration",
          "outputs": "ExtensionComponents - Object containing all initialized component instances"
        },
        {
          "name": "ExtensionComponents interface",
          "desc": "Defines the structure of all components that make up the extension",
          "inputs": "N/A - Type definition",
          "outputs": "Type containing analyzer, generators, viewers, providers, cache, status bar, and tree views"
        }
      ],
      "dependencies": [
        "vscode",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "FileWatcher",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "llmIntegration",
        "ProductNavigatorProvider",
        "AnalysisViewerProvider",
        "InsightsViewerProvider",
        "StaticAnalysisViewerProvider",
        "UnitTestsNavigatorProvider",
        "configurationManager",
        "ErrorHandler",
        "FileWatcherService",
        "ReportsViewer",
        "ReportsTreeProvider",
        "llmStateManager"
      ],
      "intent": "This file exists to centralize and organize the complex initialization sequence of all extension components. It solves the problem of scattered initialization logic by providing a single bootstrap function that creates all components in the correct order, wires dependencies between them, and returns a structured object for use by the main extension. This separation makes the extension more maintainable and testable by isolating activation logic from the main extension entry point.",
      "rawContent": "```json\n{\n  \"purpose\": \"Initializes and bootstraps all extension components during VS Code extension activation\",\n  \"userVisibleActions\": [\n    \"Extension activates and becomes ready to use in VS Code\",\n    \"Status bar item appears showing extension status\",\n    \"Multiple tree views become available in the sidebar (Insights, Analysis, Reports, Product Navigator, Unit Tests, Static Analysis)\",\n    \"Code diagnostics and insights start appearing in the editor\",\n    \"File watching begins for automatic analysis on file changes\",\n    \"Commands become available in the command palette for interacting with the extension\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call bootstrap function to initialize all extension components during activation\",\n    \"Receive initialized component instances (analyzer, insight generator, formatters, viewers, etc.)\",\n    \"Access centralized extension state through state manager\",\n    \"Configure components through configuration manager\",\n    \"Handle extension lifecycle through bootstrapper setup\",\n    \"Register all tree views, commands, and UI providers automatically\",\n    \"Set up error handling and caching mechanisms\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components and wires them together\",\n      \"inputs\": \"vscode.ExtensionContext - VS Code extension context for registration\",\n      \"outputs\": \"ExtensionComponents - Object containing all initialized component instances\"\n    },\n    {\n      \"name\": \"ExtensionComponents interface\",\n      \"desc\": \"Defines the structure of all components that make up the extension\",\n      \"inputs\": \"N/A - Type definition\",\n      \"outputs\": \"Type containing analyzer, generators, viewers, providers, cache, status bar, and tree views\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and organize the complex initialization sequence of all extension components. It solves the problem of scattered initialization logic by providing a single bootstrap function that creates all components in the correct order, wires dependencies between them, and returns a structured object for use by the main extension. This separation makes the extension more maintainable and testable by isolating activation logic from the main extension entry point.\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and code analysis insights into structured Markdown documents for human reading.",
      "userVisibleActions": [
        "Receives formatted product documentation in Markdown with timestamps, overview, features, and user perspectives",
        "Sees documentation organized by sections: What It Does, User Perspective (GUI/CLI/API), Key Features, Technical Details",
        "Views LLM analysis insights formatted as Markdown with file-by-file behavioral descriptions",
        "Reads structured sections for product patterns, architecture decisions, user workflows, and technical stack",
        "Sees formatted usage examples, configuration requirements, and deployment considerations",
        "Gets human-readable summaries of code behavior grouped by file role and type"
      ],
      "developerVisibleActions": [
        "Calls formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects to Markdown strings",
        "Calls formatLLMInsightsAsMarkdown() to convert LLMInsights objects to Markdown strings",
        "Receives Markdown with timestamps (both UTC and local time) automatically included",
        "Gets documentation sections conditionally included based on data availability",
        "Obtains formatted lists with bullet points for features, workflows, and technical details",
        "Receives structured file analysis organized by user-facing, developer-facing, and technical aspects"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation object into a formatted Markdown document with sections for overview, features, user perspectives, and technical details",
          "inputs": "EnhancedProductDocumentation object containing overview, features, user perspectives, technical details, etc.",
          "outputs": "String containing formatted Markdown document with headers, timestamps, and structured sections"
        },
        {
          "name": "formatLLMInsightsAsMarkdown",
          "desc": "Converts LLM analysis insights into a formatted Markdown document with product summary and per-file behavioral descriptions",
          "inputs": "LLMInsights object containing product summary and array of file insights with behavior descriptions",
          "outputs": "String containing formatted Markdown document with product overview and file-by-file analysis sections"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "Separates formatting concerns from business logic by providing dedicated functions to transform structured documentation data into human-readable Markdown format, making it easier to generate consistent, well-organized documentation output for users and developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and code analysis insights into structured Markdown documents for human reading.\",\n  \"userVisibleActions\": [\n    \"Receives formatted product documentation in Markdown with timestamps, overview, features, and user perspectives\",\n    \"Sees documentation organized by sections: What It Does, User Perspective (GUI/CLI/API), Key Features, Technical Details\",\n    \"Views LLM analysis insights formatted as Markdown with file-by-file behavioral descriptions\",\n    \"Reads structured sections for product patterns, architecture decisions, user workflows, and technical stack\",\n    \"Sees formatted usage examples, configuration requirements, and deployment considerations\",\n    \"Gets human-readable summaries of code behavior grouped by file role and type\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects to Markdown strings\",\n    \"Calls formatLLMInsightsAsMarkdown() to convert LLMInsights objects to Markdown strings\",\n    \"Receives Markdown with timestamps (both UTC and local time) automatically included\",\n    \"Gets documentation sections conditionally included based on data availability\",\n    \"Obtains formatted lists with bullet points for features, workflows, and technical details\",\n    \"Receives structured file analysis organized by user-facing, developer-facing, and technical aspects\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into a formatted Markdown document with sections for overview, features, user perspectives, and technical details\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, user perspectives, technical details, etc.\",\n      \"outputs\": \"String containing formatted Markdown document with headers, timestamps, and structured sections\"\n    },\n    {\n      \"name\": \"formatLLMInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM analysis insights into a formatted Markdown document with product summary and per-file behavioral descriptions\",\n      \"inputs\": \"LLMInsights object containing product summary and array of file insights with behavior descriptions\",\n      \"outputs\": \"String containing formatted Markdown document with product overview and file-by-file analysis sections\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates formatting concerns from business logic by providing dedicated functions to transform structured documentation data into human-readable Markdown format, making it easier to generate consistent, well-organized documentation output for users and developers.\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation to files, functions, endpoints, and other code locations within the workspace, and displays detailed information about analyzed items.",
      "userVisibleActions": [
        "Navigate to a specific file in the editor when clicking on file items",
        "Navigate to a specific function definition within a file and scroll to its location",
        "Navigate to API endpoints and their implementations in code",
        "View detailed information panel showing function signatures, parameters, and relationships",
        "See error messages when files cannot be opened or navigation fails",
        "Jump to entry points in the codebase from navigation items",
        "View formatted details about analyzed code elements in a separate panel"
      ],
      "developerVisibleActions": [
        "Triggers file opening in VS Code editor with proper error handling",
        "Performs intelligent search for function definitions within files using AST parsing",
        "Resolves absolute and relative file paths based on workspace root",
        "Opens text documents and positions cursor at specific line numbers",
        "Handles navigation for different item types: files, functions, endpoints, entry points",
        "Displays formatted analysis details in webview panels with HTML rendering",
        "Manages editor revealing and selection of code ranges",
        "Searches for function definitions across multiple potential formats and languages"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to a product navigation item (file, function, or endpoint) in the editor",
          "inputs": "ProductNavItem containing type and data with file/function information",
          "outputs": "Promise<void> - completes when navigation is finished or fails with error message"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to an analysis item and optionally shows its details",
          "inputs": "AnalysisItem with file path and optional line number",
          "outputs": "Promise<void> - opens document and positions cursor at specified location"
        },
        {
          "name": "showAnalysisItemDetails",
          "desc": "Displays detailed information about an analyzed item in a webview panel",
          "inputs": "AnalysisItem containing element details, dependencies, and metadata",
          "outputs": "void - creates and shows a webview panel with formatted HTML content"
        },
        {
          "name": "navigateToEntryPoint",
          "desc": "Navigates to an entry point in the codebase",
          "inputs": "EntryPoint object with file path and optional line/column information",
          "outputs": "Promise<void> - opens file and positions at entry point location"
        },
        {
          "name": "findFunctionInDocument",
          "desc": "Searches for a function definition within a document to determine its line number",
          "inputs": "TextDocument and function name string",
          "outputs": "number or undefined - line number where function is defined"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "ProductNavItem from productNavigator",
        "AnalysisItem from analysisViewer",
        "EntryPoint from analyzer"
      ],
      "intent": "This file exists to centralize all navigation logic in the extension, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to specific code locations and display detailed information about code elements.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations within the workspace, and displays detailed information about analyzed items.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the editor when clicking on file items\",\n    \"Navigate to a specific function definition within a file and scroll to its location\",\n    \"Navigate to API endpoints and their implementations in code\",\n    \"View detailed information panel showing function signatures, parameters, and relationships\",\n    \"See error messages when files cannot be opened or navigation fails\",\n    \"Jump to entry points in the codebase from navigation items\",\n    \"View formatted details about analyzed code elements in a separate panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers file opening in VS Code editor with proper error handling\",\n    \"Performs intelligent search for function definitions within files using AST parsing\",\n    \"Resolves absolute and relative file paths based on workspace root\",\n    \"Opens text documents and positions cursor at specific line numbers\",\n    \"Handles navigation for different item types: files, functions, endpoints, entry points\",\n    \"Displays formatted analysis details in webview panels with HTML rendering\",\n    \"Manages editor revealing and selection of code ranges\",\n    \"Searches for function definitions across multiple potential formats and languages\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, or endpoint) in the editor\",\n      \"inputs\": \"ProductNavItem containing type and data with file/function information\",\n      \"outputs\": \"Promise<void> - completes when navigation is finished or fails with error message\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item and optionally shows its details\",\n      \"inputs\": \"AnalysisItem with file path and optional line number\",\n      \"outputs\": \"Promise<void> - opens document and positions cursor at specified location\"\n    },\n    {\n      \"name\": \"showAnalysisItemDetails\",\n      \"desc\": \"Displays detailed information about an analyzed item in a webview panel\",\n      \"inputs\": \"AnalysisItem containing element details, dependencies, and metadata\",\n      \"outputs\": \"void - creates and shows a webview panel with formatted HTML content\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point in the codebase\",\n      \"inputs\": \"EntryPoint object with file path and optional line/column information\",\n      \"outputs\": \"Promise<void> - opens file and positions at entry point location\"\n    },\n    {\n      \"name\": \"findFunctionInDocument\",\n      \"desc\": \"Searches for a function definition within a document to determine its line number\",\n      \"inputs\": \"TextDocument and function name string\",\n      \"outputs\": \"number or undefined - line number where function is defined\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic in the extension, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to specific code locations and display detailed information about code elements.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralizes construction of all LLM prompts for code analysis, documentation, and test generation tasks",
      "userVisibleActions": [
        "Receives architecture analysis of their codebase structure and patterns",
        "Gets product documentation generated from their code",
        "Sees product purpose and value proposition extracted from documentation",
        "Views file-level analysis summaries with behavior descriptions",
        "Receives module-level rollup documentation combining related files",
        "Gets test plans generated for their source code files",
        "Receives generated test code based on test plans"
      ],
      "developerVisibleActions": [
        "Provides standardized prompt templates for all LLM interactions",
        "Builds architecture analysis prompts using context, code analysis, and product docs",
        "Constructs product documentation prompts from analysis context",
        "Creates product purpose extraction prompts from existing documentation",
        "Generates file analysis prompts with role-based context",
        "Builds module rollup prompts combining multiple file summaries",
        "Creates product-level documentation prompts from all summaries and analysis",
        "Generates per-file test plan prompts with existing test awareness",
        "Constructs test code generation prompts from test plans and source code"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Creates prompt for analyzing codebase architecture patterns and structure",
          "inputs": "AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Creates prompt for generating product-level documentation",
          "inputs": "AnalysisContext",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Creates prompt for extracting product purpose and value proposition",
          "inputs": "EnhancedProductDocumentation, AnalysisContext",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Creates prompt for analyzing individual file behavior and role",
          "inputs": "FileInfo, file content string, role classification",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Creates prompt for rolling up multiple file summaries into module documentation",
          "inputs": "Module path, module type, array of FileSummary objects",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Creates prompt for generating comprehensive product-level documentation",
          "inputs": "FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Creates prompt for generating test plans for a specific file",
          "inputs": "File path, content, function metadata, existing tests, language, test framework, optional project summary",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Creates prompt for generating actual test code from test plans",
          "inputs": "Test plan item, source code, function code, language, test framework",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "../../llmService",
        "../../analyzer",
        "../../fileDocumentation",
        "../../fileAccessHelper"
      ],
      "intent": "This file exists to eliminate duplication and centralize all LLM prompt construction logic. Previously scattered across multiple files, this builder provides a single source of truth for how prompts are formatted, ensuring consistency in LLM interactions and making prompt engineering changes easier to manage across architecture analysis, documentation generation, and test creation workflows.",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralizes construction of all LLM prompts for code analysis, documentation, and test generation tasks\",\n  \"userVisibleActions\": [\n    \"Receives architecture analysis of their codebase structure and patterns\",\n    \"Gets product documentation generated from their code\",\n    \"Sees product purpose and value proposition extracted from documentation\",\n    \"Views file-level analysis summaries with behavior descriptions\",\n    \"Receives module-level rollup documentation combining related files\",\n    \"Gets test plans generated for their source code files\",\n    \"Receives generated test code based on test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides standardized prompt templates for all LLM interactions\",\n    \"Builds architecture analysis prompts using context, code analysis, and product docs\",\n    \"Constructs product documentation prompts from analysis context\",\n    \"Creates product purpose extraction prompts from existing documentation\",\n    \"Generates file analysis prompts with role-based context\",\n    \"Builds module rollup prompts combining multiple file summaries\",\n    \"Creates product-level documentation prompts from all summaries and analysis\",\n    \"Generates per-file test plan prompts with existing test awareness\",\n    \"Constructs test code generation prompts from test plans and source code\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Creates prompt for analyzing codebase architecture patterns and structure\",\n      \"inputs\": \"AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates prompt for generating product-level documentation\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates prompt for extracting product purpose and value proposition\",\n      \"inputs\": \"EnhancedProductDocumentation, AnalysisContext\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates prompt for analyzing individual file behavior and role\",\n      \"inputs\": \"FileInfo, file content string, role classification\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Creates prompt for rolling up multiple file summaries into module documentation\",\n      \"inputs\": \"Module path, module type, array of FileSummary objects\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Creates prompt for generating comprehensive product-level documentation\",\n      \"inputs\": \"FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates prompt for generating test plans for a specific file\",\n      \"inputs\": \"File path, content, function metadata, existing tests, language, test framework, optional project summary\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Creates prompt for generating actual test code from test plans\",\n      \"inputs\": \"Test plan item, source code, function code, language, test framework\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and centralize all LLM prompt construction logic. Previously scattered across multiple files, this builder provides a single source of truth for how prompts are formatted, ensuring consistency in LLM interactions and making prompt engineering changes easier to manage across architecture analysis, documentation generation, and test creation workflows.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Builds detailed, prescriptive prompts for AI-powered code refactoring by analyzing functions and creating structured extraction plans",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations with specific function extraction plans",
        "Sees migration steps explaining how to move code between files",
        "Views before/after code examples showing proposed refactoring changes",
        "Gets prescriptive instructions for breaking down large files into smaller modules"
      ],
      "developerVisibleActions": [
        "Provides code analysis data including file information and function metadata",
        "Supplies optional product documentation to guide refactoring decisions",
        "Passes architecture insights to inform refactoring strategy",
        "Receives structured refactoring prompts ready to send to LLM services",
        "Gets function dependency analysis showing which functions call each other",
        "Obtains extraction plans specifying source files, target files, and migration steps"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Creates a comprehensive refactoring prompt by combining code analysis, product documentation, architecture insights, and function analyses",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]",
          "outputs": "string prompt ready for LLM consumption"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Constructs the foundational refactoring prompt with context and code analysis",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
          "outputs": "string base prompt"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Adds detailed function-level analysis to the prompt showing dependencies, responsibilities, and metrics",
          "inputs": "FunctionAnalysis[]",
          "outputs": "string section describing function details"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Generates requirements for code extraction including target files, dependencies, and migration steps",
          "inputs": "none apparent",
          "outputs": "string section with extraction guidelines"
        }
      ],
      "dependencies": [
        "../../analyzer",
        "../../llmService",
        "../../fileDocumentation"
      ],
      "intent": "This file exists to transform raw code analysis data into structured, actionable refactoring instructions that an LLM can understand and execute. It solves the problem of providing enough context and detail so that AI-generated refactoring recommendations are accurate, safe, and preserve code relationships like dependencies between functions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed, prescriptive prompts for AI-powered code refactoring by analyzing functions and creating structured extraction plans\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with specific function extraction plans\",\n    \"Sees migration steps explaining how to move code between files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Gets prescriptive instructions for breaking down large files into smaller modules\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides code analysis data including file information and function metadata\",\n    \"Supplies optional product documentation to guide refactoring decisions\",\n    \"Passes architecture insights to inform refactoring strategy\",\n    \"Receives structured refactoring prompts ready to send to LLM services\",\n    \"Gets function dependency analysis showing which functions call each other\",\n    \"Obtains extraction plans specifying source files, target files, and migration steps\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive refactoring prompt by combining code analysis, product documentation, architecture insights, and function analyses\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]\",\n      \"outputs\": \"string prompt ready for LLM consumption\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational refactoring prompt with context and code analysis\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"string base prompt\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function-level analysis to the prompt showing dependencies, responsibilities, and metrics\",\n      \"inputs\": \"FunctionAnalysis[]\",\n      \"outputs\": \"string section describing function details\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates requirements for code extraction including target files, dependencies, and migration steps\",\n      \"inputs\": \"none apparent\",\n      \"outputs\": \"string section with extraction guidelines\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../../llmService\",\n    \"../../fileDocumentation\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into structured, actionable refactoring instructions that an LLM can understand and execute. It solves the problem of providing enough context and detail so that AI-generated refactoring recommendations are accurate, safe, and preserve code relationships like dependencies between functions.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt templates for LLM-based test generation, configuration analysis, and test planning strategies.",
      "userVisibleActions": [
        "Analyzes codebase to recommend optimal test setup and configuration",
        "Generates prioritized test plans identifying critical functions to test",
        "Creates detailed test specifications for individual functions",
        "Provides test implementation guidance with examples and patterns",
        "Suggests mock requirements for external dependencies like VSCode APIs"
      ],
      "developerVisibleActions": [
        "Developer calls buildSetupPrompt() to analyze workspace and get test framework recommendations",
        "Developer calls buildPlanningPrompt() to create a prioritized test strategy based on code analysis",
        "Developer calls buildTestSpecPrompt() to generate detailed test specifications for specific functions",
        "Developer calls buildImplementationPrompt() to get test implementation guidance with code examples",
        "Receives structured JSON responses with dependencies, configurations, and test strategies",
        "Gets language detection, framework selection, and mock requirements automatically",
        "Receives prioritized function lists with complexity scores and coverage recommendations"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates a prompt to analyze codebase and recommend test setup configuration",
          "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
          "outputs": "Prompt string requesting JSON with language, framework, dependencies, config files, and mock requirements"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Generates a prompt to create a prioritized test plan based on code analysis",
          "inputs": "context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any",
          "outputs": "Prompt string requesting JSON with prioritized functions, complexity scores, and testing strategy"
        },
        {
          "name": "buildTestSpecPrompt",
          "desc": "Creates a prompt to generate detailed test specifications for a specific function",
          "inputs": "testableFunction: TestableFunction, codeContext: string, existingTests?: string",
          "outputs": "Prompt string requesting JSON with test scenarios, edge cases, assertions, and mocking needs"
        },
        {
          "name": "buildImplementationPrompt",
          "desc": "Generates a prompt to provide test implementation guidance and code examples",
          "inputs": "testSpec: any, framework: string, existingPatterns?: string",
          "outputs": "Prompt string requesting JSON with implementation strategy, code examples, and best practices"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis type)",
        "../services/testing/types/testPlanTypes (TestableFunction type)"
      ],
      "intent": "This file exists to standardize and structure LLM interactions for automated test generation. It solves the problem of consistently prompting LLMs to analyze code, plan test strategies, and generate test specifications by providing reusable prompt templates that request structured JSON responses. This enables automated test creation workflows where LLM recommendations can be programmatically processed and applied to codebases.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based test generation, configuration analysis, and test planning strategies.\",\n  \"userVisibleActions\": [\n    \"Analyzes codebase to recommend optimal test setup and configuration\",\n    \"Generates prioritized test plans identifying critical functions to test\",\n    \"Creates detailed test specifications for individual functions\",\n    \"Provides test implementation guidance with examples and patterns\",\n    \"Suggests mock requirements for external dependencies like VSCode APIs\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildSetupPrompt() to analyze workspace and get test framework recommendations\",\n    \"Developer calls buildPlanningPrompt() to create a prioritized test strategy based on code analysis\",\n    \"Developer calls buildTestSpecPrompt() to generate detailed test specifications for specific functions\",\n    \"Developer calls buildImplementationPrompt() to get test implementation guidance with code examples\",\n    \"Receives structured JSON responses with dependencies, configurations, and test strategies\",\n    \"Gets language detection, framework selection, and mock requirements automatically\",\n    \"Receives prioritized function lists with complexity scores and coverage recommendations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"Prompt string requesting JSON with language, framework, dependencies, config files, and mock requirements\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Generates a prompt to create a prioritized test plan based on code analysis\",\n      \"inputs\": \"context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"Prompt string requesting JSON with prioritized functions, complexity scores, and testing strategy\"\n    },\n    {\n      \"name\": \"buildTestSpecPrompt\",\n      \"desc\": \"Creates a prompt to generate detailed test specifications for a specific function\",\n      \"inputs\": \"testableFunction: TestableFunction, codeContext: string, existingTests?: string\",\n      \"outputs\": \"Prompt string requesting JSON with test scenarios, edge cases, assertions, and mocking needs\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Generates a prompt to provide test implementation guidance and code examples\",\n      \"inputs\": \"testSpec: any, framework: string, existingPatterns?: string\",\n      \"outputs\": \"Prompt string requesting JSON with implementation strategy, code examples, and best practices\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis type)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction type)\"\n  ],\n  \"intent\": \"This file exists to standardize and structure LLM interactions for automated test generation. It solves the problem of consistently prompting LLMs to analyze code, plan test strategies, and generate test specifications by providing reusable prompt templates that request structured JSON responses. This enables automated test creation workflows where LLM recommendations can be programmatically processed and applied to codebases.\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides centralized file system watching to detect when files are created, modified, or deleted in the workspace",
      "userVisibleActions": [
        "When user creates a new file matching a watched pattern, registered handlers are automatically triggered",
        "When user modifies an existing file, change detection triggers updates to relevant views or features",
        "When user deletes a file, cleanup and refresh actions occur automatically",
        "When user saves a document, save handlers execute to update related features"
      ],
      "developerVisibleActions": [
        "Provides a unified service to watch file system changes without creating duplicate watchers",
        "Allows multiple components to register handlers for the same file patterns efficiently",
        "Automatically manages watcher lifecycle and cleanup to prevent memory leaks",
        "Supports pattern-based filtering with ignore patterns to exclude specific files",
        "Consolidates document save event handling across multiple features",
        "Provides disposable pattern for proper cleanup of watch registrations"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Registers a handler to be called when files matching a pattern are created, changed, or deleted",
          "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (watch create/change/delete flags, ignore patterns)",
          "outputs": "Disposable object to unregister the watch"
        },
        {
          "name": "onDocumentSave",
          "desc": "Registers a handler to be called whenever a document is saved in the editor",
          "inputs": "handler (callback function receiving the saved document)",
          "outputs": "Disposable object to unregister the handler"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all file watchers and handlers, releasing system resources",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getPatternKey",
          "desc": "Generates a unique key for a file pattern to enable watcher reuse",
          "inputs": "pattern (string or RelativePattern)",
          "outputs": "string key"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to eliminate duplication of file watching logic across multiple extension features. Previously, separate components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) each created their own file watchers, leading to redundant system resource usage and inconsistent behavior. This service consolidates all file watching into a single, efficient implementation that can be shared across the extension, ensuring consistent file change detection and proper resource management.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides centralized file system watching to detect when files are created, modified, or deleted in the workspace\",\n  \"userVisibleActions\": [\n    \"When user creates a new file matching a watched pattern, registered handlers are automatically triggered\",\n    \"When user modifies an existing file, change detection triggers updates to relevant views or features\",\n    \"When user deletes a file, cleanup and refresh actions occur automatically\",\n    \"When user saves a document, save handlers execute to update related features\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a unified service to watch file system changes without creating duplicate watchers\",\n    \"Allows multiple components to register handlers for the same file patterns efficiently\",\n    \"Automatically manages watcher lifecycle and cleanup to prevent memory leaks\",\n    \"Supports pattern-based filtering with ignore patterns to exclude specific files\",\n    \"Consolidates document save event handling across multiple features\",\n    \"Provides disposable pattern for proper cleanup of watch registrations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a handler to be called when files matching a pattern are created, changed, or deleted\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (watch create/change/delete flags, ignore patterns)\",\n      \"outputs\": \"Disposable object to unregister the watch\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever a document is saved in the editor\",\n      \"inputs\": \"handler (callback function receiving the saved document)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all file watchers and handlers, releasing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to enable watcher reuse\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication of file watching logic across multiple extension features. Previously, separate components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts) each created their own file watchers, leading to redundant system resource usage and inconsistent behavior. This service consolidates all file watching into a single, efficient implementation that can be shared across the extension, ensuring consistent file change detection and proper resource management.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative analysis where an LLM can request additional files or grep searches across multiple rounds until it has enough information to complete its task",
      "userVisibleActions": [
        "Analysis progresses through multiple iterations automatically when the LLM needs more context",
        "Additional files are read and included in the analysis when requested",
        "Grep searches are performed across the codebase when the LLM needs to find specific patterns",
        "Analysis stops after reaching maximum iterations or when the LLM has sufficient information"
      ],
      "developerVisibleActions": [
        "Create an IncrementalAnalysisService instance with a FileAccessHelper",
        "Call processRequests() to handle LLM file and grep requests within an iteration",
        "Receive ProcessRequestsResult containing formatted additional information and updated conversation messages",
        "Use IterationCallbacks to monitor iteration start and completion events",
        "Access IterationResult to see final result, iteration count, all requests made, and continuation status",
        "LLM requests are automatically limited to 5 per iteration to prevent excessive processing"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes LLM-requested file reads and grep searches, returning formatted results and updated conversation messages",
          "inputs": "requests (array of LLMRequest), currentResult (any), messages (conversation history)",
          "outputs": "ProcessRequestsResult containing additionalInfo string and updated messages array"
        }
      ],
      "dependencies": [
        "FileAccessHelper",
        "LLMRequest"
      ],
      "intent": "This file exists to eliminate code duplication from llmService.ts by extracting the iterative analysis logic into a reusable, testable service. It solves the problem of LLMs needing multiple rounds of context gathering (files and grep searches) before producing a final analysis, converting while-loop patterns into structured async iteration patterns for better testing and maintainability.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative analysis where an LLM can request additional files or grep searches across multiple rounds until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"Analysis progresses through multiple iterations automatically when the LLM needs more context\",\n    \"Additional files are read and included in the analysis when requested\",\n    \"Grep searches are performed across the codebase when the LLM needs to find specific patterns\",\n    \"Analysis stops after reaching maximum iterations or when the LLM has sufficient information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Create an IncrementalAnalysisService instance with a FileAccessHelper\",\n    \"Call processRequests() to handle LLM file and grep requests within an iteration\",\n    \"Receive ProcessRequestsResult containing formatted additional information and updated conversation messages\",\n    \"Use IterationCallbacks to monitor iteration start and completion events\",\n    \"Access IterationResult to see final result, iteration count, all requests made, and continuation status\",\n    \"LLM requests are automatically limited to 5 per iteration to prevent excessive processing\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, returning formatted results and updated conversation messages\",\n      \"inputs\": \"requests (array of LLMRequest), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult containing additionalInfo string and updated messages array\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest\"\n  ],\n  \"intent\": \"This file exists to eliminate code duplication from llmService.ts by extracting the iterative analysis logic into a reusable, testable service. It solves the problem of LLMs needing multiple rounds of context gathering (files and grep searches) before producing a final analysis, converting while-loop patterns into structured async iteration patterns for better testing and maintainability.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) to ensure generated tests work without manual user setup",
      "userVisibleActions": [
        "Automatically detects which test framework is being used in the project",
        "Identifies missing test dependencies and configuration files",
        "Provides setup actions needed to make tests work",
        "Ensures generated tests run without manual configuration"
      ],
      "developerVisibleActions": [
        "Scans workspace for package.json to detect test framework from scripts and dependencies",
        "Checks for framework-specific config files (jest.config.js, vitest.config.ts, pytest.ini, etc.)",
        "Validates that required test dependencies are installed",
        "Returns configuration status with framework type, missing dependencies, and setup requirements",
        "Detects TypeScript test setups (ts-jest, @jest/globals) for Jest projects",
        "Identifies Python virtual environments and pytest installations"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Analyzes workspace to detect test framework and configuration completeness",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestConfigStatus object with framework type, configuration state, missing dependencies, and required setup actions"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../logger"
      ],
      "intent": "This file exists to eliminate the friction of setting up test environments by automatically detecting what test framework a project uses and determining if it's properly configured. It solves the problem of generated tests failing due to missing configuration, making the test generation feature work seamlessly across different project setups without requiring users to manually configure test frameworks.",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used in the project\",\n    \"Identifies missing test dependencies and configuration files\",\n    \"Provides setup actions needed to make tests work\",\n    \"Ensures generated tests run without manual configuration\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace for package.json to detect test framework from scripts and dependencies\",\n    \"Checks for framework-specific config files (jest.config.js, vitest.config.ts, pytest.ini, etc.)\",\n    \"Validates that required test dependencies are installed\",\n    \"Returns configuration status with framework type, missing dependencies, and setup requirements\",\n    \"Detects TypeScript test setups (ts-jest, @jest/globals) for Jest projects\",\n    \"Identifies Python virtual environments and pytest installations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration completeness\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../logger\"\n  ],\n  \"intent\": \"This file exists to eliminate the friction of setting up test environments by automatically detecting what test framework a project uses and determining if it's properly configured. It solves the problem of generated tests failing due to missing configuration, making the test generation feature work seamlessly across different project setups without requiring users to manually configure test frameworks.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates unit tests for code functions incrementally using an LLM service, executing tests in small batches and providing progress feedback.",
      "userVisibleActions": [
        "Receive progress updates showing which function is currently being tested (e.g., 'Generating test 5 of 20 for functionName')",
        "See test generation results for each function including success/failure status",
        "View generated test code for functions",
        "Get feedback on test execution results including pass/fail outcomes"
      ],
      "developerVisibleActions": [
        "Call generateTestBatch() to generate tests for multiple functions at once",
        "Provide a progress callback to monitor test generation as it proceeds",
        "Receive a Map of test generation results keyed by function name",
        "Access generated test code, mock requirements, and execution status for each function",
        "Integrate with LLM service to automatically generate test code based on source code analysis",
        "Automatically check for and reuse existing mock files (e.g., vscode mocks)",
        "Get structured results indicating which tests passed, failed, or couldn't be generated"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for a batch of functions by calling the LLM service for each one and tracking progress",
          "inputs": "functions array, workspace root path, LLM service instance, optional progress callback",
          "outputs": "Map of function names to TestGenerationResult objects"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Extracts the source code for a specific function from the workspace",
          "inputs": "TestableFunction object, workspace root path",
          "outputs": "Source code string for the function"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestableFunction",
        "TestGenerationState",
        "TestGenerationResult",
        "buildGenerationPrompt",
        "TestExecutionService",
        "SWLogger"
      ],
      "intent": "This file exists to automate the creation of unit tests by leveraging LLM capabilities to analyze source code and generate appropriate test cases. It solves the problem of manually writing repetitive test code by processing functions in batches, providing real-time progress feedback, and handling the complete workflow from test generation through execution and result reporting.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions incrementally using an LLM service, executing tests in small batches and providing progress feedback.\",\n  \"userVisibleActions\": [\n    \"Receive progress updates showing which function is currently being tested (e.g., 'Generating test 5 of 20 for functionName')\",\n    \"See test generation results for each function including success/failure status\",\n    \"View generated test code for functions\",\n    \"Get feedback on test execution results including pass/fail outcomes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateTestBatch() to generate tests for multiple functions at once\",\n    \"Provide a progress callback to monitor test generation as it proceeds\",\n    \"Receive a Map of test generation results keyed by function name\",\n    \"Access generated test code, mock requirements, and execution status for each function\",\n    \"Integrate with LLM service to automatically generate test code based on source code analysis\",\n    \"Automatically check for and reuse existing mock files (e.g., vscode mocks)\",\n    \"Get structured results indicating which tests passed, failed, or couldn't be generated\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for a batch of functions by calling the LLM service for each one and tracking progress\",\n      \"inputs\": \"functions array, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Extracts the source code for a specific function from the workspace\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the creation of unit tests by leveraging LLM capabilities to analyze source code and generate appropriate test cases. It solves the problem of manually writing repetitive test code by processing functions in batches, providing real-time progress feedback, and handling the complete workflow from test generation through execution and result reporting.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code and creates prioritized test plans using LLM to recommend which functions should be tested and how",
      "userVisibleActions": [
        "Receives automated test recommendations for code functions",
        "Gets prioritized list of functions that should be tested",
        "Views test plans organized by testing areas (e.g., core logic, edge cases, integration points)",
        "Sees confidence scores and rationale for each test recommendation"
      ],
      "developerVisibleActions": [
        "Calls service to generate test plans from code analysis results",
        "Provides optional product documentation and architecture insights to improve test recommendations",
        "Receives structured test plan with testable functions organized by priority and category",
        "Uses two-phase planning approach: high-level strategy first, then specific function selection",
        "Leverages pre-existing architecture analysis test recommendations when available"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts and normalizes function information from code analysis",
          "inputs": "codeAnalysis object containing functions array",
          "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
        },
        {
          "name": "createTestPlan",
          "desc": "Generates comprehensive test plan using LLM with two-phase approach (strategy then function selection)",
          "inputs": "CodeAnalysis context, functions array, llmService, optional productDocs and architectureInsights",
          "outputs": "TestPlan object with prioritized testable functions and testing strategy"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestPlan types",
        "TestableFunction types",
        "buildPlanningPrompt",
        "CodeAnalysis",
        "SWLogger"
      ],
      "intent": "Automates the test planning process by using AI to analyze code and intelligently recommend which functions need testing, what types of tests to write, and in what order to prioritize them, reducing manual test planning effort and improving test coverage",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code and creates prioritized test plans using LLM to recommend which functions should be tested and how\",\n  \"userVisibleActions\": [\n    \"Receives automated test recommendations for code functions\",\n    \"Gets prioritized list of functions that should be tested\",\n    \"Views test plans organized by testing areas (e.g., core logic, edge cases, integration points)\",\n    \"Sees confidence scores and rationale for each test recommendation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls service to generate test plans from code analysis results\",\n    \"Provides optional product documentation and architecture insights to improve test recommendations\",\n    \"Receives structured test plan with testable functions organized by priority and category\",\n    \"Uses two-phase planning approach: high-level strategy first, then specific function selection\",\n    \"Leverages pre-existing architecture analysis test recommendations when available\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function information from code analysis\",\n      \"inputs\": \"codeAnalysis object containing functions array\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates comprehensive test plan using LLM with two-phase approach (strategy then function selection)\",\n      \"inputs\": \"CodeAnalysis context, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with prioritized testable functions and testing strategy\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestPlan types\",\n    \"TestableFunction types\",\n    \"buildPlanningPrompt\",\n    \"CodeAnalysis\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Automates the test planning process by using AI to analyze code and intelligently recommend which functions need testing, what types of tests to write, and in what order to prioritize them, reducing manual test planning effort and improving test coverage\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Detects test environment configuration and generates test setup plans using LLM-based analysis of the workspace.",
      "userVisibleActions": [
        "Automatically detects the programming language used in the project (TypeScript, JavaScript, Python, Java, C++)",
        "Identifies existing test framework configuration (Jest, package.json, tsconfig.json)",
        "Generates a test setup plan with required dependencies and configuration files",
        "Executes test setup by installing dependencies and creating configuration files",
        "Verifies test setup by running a test command and checking for success"
      ],
      "developerVisibleActions": [
        "Scans workspace to detect test environment (test directories, config files, language distribution)",
        "Analyzes package.json and tsconfig.json to understand project structure",
        "Uses LLM to generate appropriate test setup based on detected environment",
        "Installs test framework dependencies via package manager (npm/yarn)",
        "Creates or updates test configuration files (jest.config.js, tsconfig.json)",
        "Runs test verification command and reports success or failure with error messages",
        "Provides detailed execution results including stdout, stderr, and exit codes"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Scans workspace to identify project language, existing test configurations, and test directories",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestEnvironment object with framework, language, directories, and config file information"
        },
        {
          "name": "generateSetupPlan",
          "desc": "Uses LLM to create a test setup plan based on detected environment",
          "inputs": "environment: TestEnvironment, llmResponse: function",
          "outputs": "Promise<TestSetupPlan> with dependencies, config files, and setup steps"
        },
        {
          "name": "executeSetup",
          "desc": "Executes the generated setup plan by installing dependencies and creating config files",
          "inputs": "plan: TestSetupPlan, workspaceRoot: string",
          "outputs": "Promise<SetupExecutionResult> with success status, messages, and any errors"
        },
        {
          "name": "verifySetup",
          "desc": "Runs test command to verify the test environment is correctly configured",
          "inputs": "workspaceRoot: string, testCommand: string",
          "outputs": "Promise<SetupExecutionResult> indicating if tests can run successfully"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively retrieves all files in a directory for language detection",
          "inputs": "dir: string (directory path)",
          "outputs": "string[] (array of file paths)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "./types/testSetupTypes",
        "../../prompts/testPrompts",
        "../../../logger"
      ],
      "intent": "This service automates test environment setup by intelligently detecting the project's configuration and generating appropriate test framework setup. It solves the problem of manual test configuration by analyzing the workspace, determining the best test setup approach using LLM, and automatically installing and configuring the necessary testing infrastructure. This eliminates the need for developers to manually configure test frameworks and ensures consistent test setup across projects.",
      "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates test setup plans using LLM-based analysis of the workspace.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language used in the project (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Identifies existing test framework configuration (Jest, package.json, tsconfig.json)\",\n    \"Generates a test setup plan with required dependencies and configuration files\",\n    \"Executes test setup by installing dependencies and creating configuration files\",\n    \"Verifies test setup by running a test command and checking for success\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace to detect test environment (test directories, config files, language distribution)\",\n    \"Analyzes package.json and tsconfig.json to understand project structure\",\n    \"Uses LLM to generate appropriate test setup based on detected environment\",\n    \"Installs test framework dependencies via package manager (npm/yarn)\",\n    \"Creates or updates test configuration files (jest.config.js, tsconfig.json)\",\n    \"Runs test verification command and reports success or failure with error messages\",\n    \"Provides detailed execution results including stdout, stderr, and exit codes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Scans workspace to identify project language, existing test configurations, and test directories\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object with framework, language, directories, and config file information\"\n    },\n    {\n      \"name\": \"generateSetupPlan\",\n      \"desc\": \"Uses LLM to create a test setup plan based on detected environment\",\n      \"inputs\": \"environment: TestEnvironment, llmResponse: function\",\n      \"outputs\": \"Promise<TestSetupPlan> with dependencies, config files, and setup steps\"\n    },\n    {\n      \"name\": \"executeSetup\",\n      \"desc\": \"Executes the generated setup plan by installing dependencies and creating config files\",\n      \"inputs\": \"plan: TestSetupPlan, workspaceRoot: string\",\n      \"outputs\": \"Promise<SetupExecutionResult> with success status, messages, and any errors\"\n    },\n    {\n      \"name\": \"verifySetup\",\n      \"desc\": \"Runs test command to verify the test environment is correctly configured\",\n      \"inputs\": \"workspaceRoot: string, testCommand: string\",\n      \"outputs\": \"Promise<SetupExecutionResult> indicating if tests can run successfully\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively retrieves all files in a directory for language detection\",\n      \"inputs\": \"dir: string (directory path)\",\n      \"outputs\": \"string[] (array of file paths)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This service automates test environment setup by intelligently detecting the project's configuration and generating appropriate test framework setup. It solves the problem of manual test configuration by analyzing the workspace, determining the best test setup approach using LLM, and automatically installing and configuring the necessary testing infrastructure. This eliminates the need for developers to manually configure test frameworks and ensures consistent test setup across projects.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates tests by running them, capturing failures, and automatically fixing failing tests using LLM analysis and code generation.",
      "userVisibleActions": [
        "Tests are automatically run and validated in the workspace",
        "Failing tests are automatically fixed without manual intervention",
        "Test results show pass/fail counts and error messages",
        "Multiple fix attempts are made automatically if initial fixes don't work",
        "Final test results indicate whether fixes were successful"
      ],
      "developerVisibleActions": [
        "Run all tests or a specific test file in the workspace",
        "Get detailed test execution results with pass/fail counts",
        "Automatically fix failing tests by providing test file path and execution results",
        "Configure maximum retry attempts for test fixes (default 3)",
        "Receive feedback on fix success/failure with attempt counts",
        "Test fixes are applied by reading test code, analyzing errors, generating fixes via LLM, and writing corrected code back",
        "Each fix attempt re-runs tests to verify the correction worked"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or a specific test file and returns results with pass/fail counts",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]> - Array of test results with passed/failed/error counts"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to fix a failing test by analyzing errors and generating corrected code using LLM",
          "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)",
          "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}> - Fix result with success status and attempt count"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "TestExecutionResult",
        "TestReport",
        "TestReportSummary",
        "buildFixPrompt",
        "SWLogger"
      ],
      "intent": "This file exists to automate the test validation and correction workflow, allowing failing tests to be automatically fixed using AI analysis rather than requiring manual debugging and code changes by developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them, capturing failures, and automatically fixing failing tests using LLM analysis and code generation.\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and validated in the workspace\",\n    \"Failing tests are automatically fixed without manual intervention\",\n    \"Test results show pass/fail counts and error messages\",\n    \"Multiple fix attempts are made automatically if initial fixes don't work\",\n    \"Final test results indicate whether fixes were successful\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run all tests or a specific test file in the workspace\",\n    \"Get detailed test execution results with pass/fail counts\",\n    \"Automatically fix failing tests by providing test file path and execution results\",\n    \"Configure maximum retry attempts for test fixes (default 3)\",\n    \"Receive feedback on fix success/failure with attempt counts\",\n    \"Test fixes are applied by reading test code, analyzing errors, generating fixes via LLM, and writing corrected code back\",\n    \"Each fix attempt re-runs tests to verify the correction worked\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns results with pass/fail counts\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - Array of test results with passed/failed/error counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to fix a failing test by analyzing errors and generating corrected code using LLM\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts: number (default 3)\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}> - Fix result with success status and attempt count\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation and correction workflow, allowing failing tests to be automatically fixed using AI analysis rather than requiring manual debugging and code changes by developers.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes test suites (Jest, Mocha, Pytest, Vitest) and captures their results for display and analysis",
      "userVisibleActions": [
        "Run tests for a specific file or all tests in the workspace",
        "View test execution results including pass/fail status and duration",
        "See detailed error messages and stack traces when tests fail",
        "Get notified when test execution fails or times out",
        "View test coverage information when available"
      ],
      "developerVisibleActions": [
        "Execute Jest tests with JSON output parsing",
        "Execute Mocha tests with JSON reporter",
        "Execute Pytest tests with JSON output",
        "Execute Vitest tests with JSON reporter",
        "Parse test framework output into standardized result format",
        "Handle test execution errors and timeouts gracefully",
        "Extract error details including test names, messages, and stack traces",
        "Configure test execution with custom buffer sizes and timeouts"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Runs Jest tests for a specific file or entire test suite",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runMocha",
          "desc": "Runs Mocha tests for a specific file or entire test suite",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runPytest",
          "desc": "Runs Pytest tests for a specific file or entire test suite",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runVitest",
          "desc": "Runs Vitest tests for a specific file or entire test suite",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "parseJestOutput",
          "desc": "Parses Jest JSON output into standardized test results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parseMochaOutput",
          "desc": "Parses Mocha JSON output into standardized test results",
          "inputs": "stdout: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parsePytestOutput",
          "desc": "Parses Pytest JSON output into standardized test results",
          "inputs": "stdout: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parseVitestOutput",
          "desc": "Parses Vitest JSON output into standardized test results",
          "inputs": "stdout: string",
          "outputs": "TestExecutionResult[]"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "This file exists to provide a unified interface for executing different test frameworks (Jest, Mocha, Pytest, Vitest) and normalizing their output into a consistent format. It solves the problem of supporting multiple testing frameworks with different output formats by handling execution, parsing, and error handling for each framework, making test results available in a standardized structure for display and analysis.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest, Vitest) and captures their results for display and analysis\",\n  \"userVisibleActions\": [\n    \"Run tests for a specific file or all tests in the workspace\",\n    \"View test execution results including pass/fail status and duration\",\n    \"See detailed error messages and stack traces when tests fail\",\n    \"Get notified when test execution fails or times out\",\n    \"View test coverage information when available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Execute Jest tests with JSON output parsing\",\n    \"Execute Mocha tests with JSON reporter\",\n    \"Execute Pytest tests with JSON output\",\n    \"Execute Vitest tests with JSON reporter\",\n    \"Parse test framework output into standardized result format\",\n    \"Handle test execution errors and timeouts gracefully\",\n    \"Extract error details including test names, messages, and stack traces\",\n    \"Configure test execution with custom buffer sizes and timeouts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Runs Jest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Runs Mocha tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Runs Pytest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runVitest\",\n      \"desc\": \"Runs Vitest tests for a specific file or entire test suite\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses Mocha JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses Pytest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseVitestOutput\",\n      \"desc\": \"Parses Vitest JSON output into standardized test results\",\n      \"inputs\": \"stdout: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This file exists to provide a unified interface for executing different test frameworks (Jest, Mocha, Pytest, Vitest) and normalizing their output into a consistent format. It solves the problem of supporting multiple testing frameworks with different output formats by handling execution, parsing, and error handling for each framework, making test results available in a standardized structure for display and analysis.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for organizing and tracking automated test plan generation and validation",
      "userVisibleActions": [
        "View test generation progress through different phases (setup, planning, generation, validation, complete)",
        "See total number of functions and how many are testable",
        "Track which functions have been tested and validated",
        "Review functions organized by priority groups",
        "See which test generation attempts failed and why"
      ],
      "developerVisibleActions": [
        "Define structure for test plans containing function groups organized by priority",
        "Track test generation state across multiple phases",
        "Identify functions that need mocking based on their dependencies",
        "Group related functions together for batch test generation",
        "Monitor test generation failures with error details and retry attempts",
        "Access function metadata including complexity, parameters, return types, and code location"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides type safety and structure for the test planning service by defining how testable functions are organized into prioritized groups, how test generation progress is tracked across phases, and how failures are recorded for retry logic",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for organizing and tracking automated test plan generation and validation\",\n  \"userVisibleActions\": [\n    \"View test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"See total number of functions and how many are testable\",\n    \"Track which functions have been tested and validated\",\n    \"Review functions organized by priority groups\",\n    \"See which test generation attempts failed and why\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test plans containing function groups organized by priority\",\n    \"Track test generation state across multiple phases\",\n    \"Identify functions that need mocking based on their dependencies\",\n    \"Group related functions together for batch test generation\",\n    \"Monitor test generation failures with error details and retry attempts\",\n    \"Access function metadata including complexity, parameters, return types, and code location\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for the test planning service by defining how testable functions are organized into prioritized groups, how test generation progress is tracked across phases, and how failures are recorded for retry logic\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type interfaces for test generation, validation, execution results, and reporting in the testing framework.",
      "userVisibleActions": [
        "View test execution results showing passed, failed, and error counts",
        "See test validation status indicating if tests pass, fail, or have errors",
        "Review test reports with summary statistics and recommendations",
        "Access detailed error information for failed tests including error messages and stack traces",
        "View test pass rates and overall testing metrics"
      ],
      "developerVisibleActions": [
        "Define structure for test generation results including file paths, imports, mocks, and test code",
        "Specify test validation outcomes with fixed code and explanations",
        "Structure test execution data with status, counts, duration, and error details",
        "Create comprehensive test reports with summaries and recommendations",
        "Type-check mock statements with explanations",
        "Track test setup and teardown code requirements",
        "Define error detail structures for debugging failed tests"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a strongly-typed contract for test generation, validation, and reporting features, ensuring consistent data structures across the testing workflow and enabling proper TypeScript type checking for test-related operations and results.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type interfaces for test generation, validation, execution results, and reporting in the testing framework.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed, failed, and error counts\",\n    \"See test validation status indicating if tests pass, fail, or have errors\",\n    \"Review test reports with summary statistics and recommendations\",\n    \"Access detailed error information for failed tests including error messages and stack traces\",\n    \"View test pass rates and overall testing metrics\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test generation results including file paths, imports, mocks, and test code\",\n    \"Specify test validation outcomes with fixed code and explanations\",\n    \"Structure test execution data with status, counts, duration, and error details\",\n    \"Create comprehensive test reports with summaries and recommendations\",\n    \"Type-check mock statements with explanations\",\n    \"Track test setup and teardown code requirements\",\n    \"Define error detail structures for debugging failed tests\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for test generation, validation, and reporting features, ensuring consistent data structures across the testing workflow and enabling proper TypeScript type checking for test-related operations and results.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces for test setup planning, environment detection, and execution results used throughout the testing setup service.",
      "userVisibleActions": [
        "User receives information about test setup plans including frameworks and dependencies",
        "User sees which configuration files will be created",
        "User gets feedback on setup execution success or failures",
        "User views list of files created and dependencies installed during setup"
      ],
      "developerVisibleActions": [
        "Developer structures test setup plans with language, framework, and dependency information",
        "Developer accesses environment detection results showing existing test infrastructure",
        "Developer receives structured execution results with success status and error details",
        "Developer defines mock requirements with types and reasons for test setup"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides type safety and contract definitions for the test setup service, ensuring consistent data structures across test environment detection, setup planning, and execution phases. Enables developers to work with strongly-typed data when configuring and setting up testing infrastructure.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup planning, environment detection, and execution results used throughout the testing setup service.\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including frameworks and dependencies\",\n    \"User sees which configuration files will be created\",\n    \"User gets feedback on setup execution success or failures\",\n    \"User views list of files created and dependencies installed during setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer structures test setup plans with language, framework, and dependency information\",\n    \"Developer accesses environment detection results showing existing test infrastructure\",\n    \"Developer receives structured execution results with success status and error details\",\n    \"Developer defines mock requirements with types and reasons for test setup\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and contract definitions for the test setup service, ensuring consistent data structures across test environment detection, setup planning, and execution phases. Enables developers to work with strongly-typed data when configuring and setting up testing infrastructure.\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "Main entry point that initializes and coordinates the VS Code extension, registering all commands, views, and handlers for code analysis and navigation features.",
      "userVisibleActions": [
        "Analyze entire workspace to understand code structure and behavior",
        "Analyze current file to extract insights about active code",
        "View code insights in a tree view sidebar showing entry points and connections",
        "Navigate to specific code locations by clicking on insights",
        "See analysis progress in status bar showing active analysis state",
        "Refresh insights view to update analysis results",
        "Clear analysis cache to force fresh analysis",
        "Export analysis results in different formats (markdown, JSON)",
        "Navigate through product features using a product navigator panel",
        "View code behavior extracted and formatted for LLM consumption",
        "See diagnostic warnings and errors from code analysis"
      ],
      "developerVisibleActions": [
        "Trigger workspace analysis via command palette or on extension activation",
        "Trigger file analysis when opening or switching between files",
        "Access cached analysis results to avoid re-processing unchanged code",
        "Watch for file system changes that invalidate cached analysis",
        "Register commands that appear in VS Code command palette",
        "Initialize analysis cache with configurable storage backend",
        "Handle errors during analysis with graceful fallback and user notifications",
        "Bootstrap extension components in dependency injection container",
        "Configure analysis behavior through VS Code settings",
        "Access configuration manager for reading extension settings"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Initializes the extension, sets up all components, registers commands and views, and starts file watching",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "void"
        },
        {
          "name": "deactivate",
          "desc": "Cleans up resources when extension is deactivated, disposing watchers and providers",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Analyzes all code files in the workspace to extract entry points, insights, and behavior",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeCurrentFile",
          "desc": "Analyzes the currently active file and updates insights for that file",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "navigateToDefinition",
          "desc": "Navigates the editor to a specific code location based on tree item selection",
          "inputs": "item: TreeItem",
          "outputs": "Promise<void>"
        },
        {
          "name": "refreshInsights",
          "desc": "Forces a refresh of the insights tree view with latest analysis data",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "clearCache",
          "desc": "Clears all cached analysis data and forces re-analysis on next request",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "exportInsights",
          "desc": "Exports analysis results to a file in selected format (markdown or JSON)",
          "inputs": "format: string",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler",
        "./productNavigator"
      ],
      "intent": "This file exists to serve as the central coordination point for the VS Code extension, solving the problem of organizing and connecting all analysis, navigation, and visualization features into a cohesive user experience. It ensures proper initialization, command registration, and lifecycle management so users can seamlessly analyze code behavior and navigate through insights without worrying about underlying complexity.",
      "rawContent": "```json\n{\n  \"purpose\": \"Main entry point that initializes and coordinates the VS Code extension, registering all commands, views, and handlers for code analysis and navigation features.\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to understand code structure and behavior\",\n    \"Analyze current file to extract insights about active code\",\n    \"View code insights in a tree view sidebar showing entry points and connections\",\n    \"Navigate to specific code locations by clicking on insights\",\n    \"See analysis progress in status bar showing active analysis state\",\n    \"Refresh insights view to update analysis results\",\n    \"Clear analysis cache to force fresh analysis\",\n    \"Export analysis results in different formats (markdown, JSON)\",\n    \"Navigate through product features using a product navigator panel\",\n    \"View code behavior extracted and formatted for LLM consumption\",\n    \"See diagnostic warnings and errors from code analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger workspace analysis via command palette or on extension activation\",\n    \"Trigger file analysis when opening or switching between files\",\n    \"Access cached analysis results to avoid re-processing unchanged code\",\n    \"Watch for file system changes that invalidate cached analysis\",\n    \"Register commands that appear in VS Code command palette\",\n    \"Initialize analysis cache with configurable storage backend\",\n    \"Handle errors during analysis with graceful fallback and user notifications\",\n    \"Bootstrap extension components in dependency injection container\",\n    \"Configure analysis behavior through VS Code settings\",\n    \"Access configuration manager for reading extension settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, sets up all components, registers commands and views, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when extension is deactivated, disposing watchers and providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes all code files in the workspace to extract entry points, insights, and behavior\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Analyzes the currently active file and updates insights for that file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToDefinition\",\n      \"desc\": \"Navigates the editor to a specific code location based on tree item selection\",\n      \"inputs\": \"item: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Forces a refresh of the insights tree view with latest analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears all cached analysis data and forces re-analysis on next request\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportInsights\",\n      \"desc\": \"Exports analysis results to a file in selected format (markdown or JSON)\",\n      \"inputs\": \"format: string\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file exists to serve as the central coordination point for the VS Code extension, solving the problem of organizing and connecting all analysis, navigation, and visualization features into a cohesive user experience. It ensures proper initialization, command registration, and lifecycle management so users can seamlessly analyze code behavior and navigate through insights without worrying about underlying complexity.\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and grep search functionality to enable LLM agents to iteratively explore and analyze codebases",
      "userVisibleActions": [
        "LLM agent can request to read specific files from the workspace",
        "LLM agent can search across files using grep patterns to find code",
        "Search results show matching lines with surrounding context",
        "File listings show organized folder structure with file metadata",
        "Results are limited to prevent overwhelming responses"
      ],
      "developerVisibleActions": [
        "Developer provides workspace root path to initialize helper",
        "Developer receives structured file content with line counts",
        "Developer gets grep search results with file, line number, and context",
        "Developer can filter searches by file patterns (e.g., '*.ts', 'src/**/*.ts')",
        "Developer can limit maximum number of search results returned",
        "Developer sees organized file listings grouped by folder with depth sorting"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Organizes and formats a list of files grouped by folder with metadata",
          "inputs": "Array of file objects with path, lines, and language",
          "outputs": "Formatted string showing folder-organized file structure"
        },
        {
          "name": "readFile",
          "desc": "Reads a file from the workspace and returns its content with metadata",
          "inputs": "FileRequest with file path and optional reason",
          "outputs": "FileResponse with content, line count, and existence status"
        },
        {
          "name": "grep",
          "desc": "Searches files for pattern matches and returns results with context",
          "inputs": "GrepRequest with pattern, optional file pattern filter, max results, and reason",
          "outputs": "GrepResponse with matches including file, line number, content, and context lines"
        },
        {
          "name": "processLLMRequest",
          "desc": "Routes LLM file or grep requests to appropriate handler",
          "inputs": "LLMRequest (either FileRequest or GrepRequest)",
          "outputs": "Either FileResponse or GrepResponse based on request type"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to enable LLM agents to dynamically explore codebases through file reading and pattern searching, supporting iterative analysis workflows where the agent discovers what files to examine based on previous results rather than receiving all code upfront",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable LLM agents to iteratively explore and analyze codebases\",\n  \"userVisibleActions\": [\n    \"LLM agent can request to read specific files from the workspace\",\n    \"LLM agent can search across files using grep patterns to find code\",\n    \"Search results show matching lines with surrounding context\",\n    \"File listings show organized folder structure with file metadata\",\n    \"Results are limited to prevent overwhelming responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides workspace root path to initialize helper\",\n    \"Developer receives structured file content with line counts\",\n    \"Developer gets grep search results with file, line number, and context\",\n    \"Developer can filter searches by file patterns (e.g., '*.ts', 'src/**/*.ts')\",\n    \"Developer can limit maximum number of search results returned\",\n    \"Developer sees organized file listings grouped by folder with depth sorting\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by folder with metadata\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing folder-organized file structure\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its content with metadata\",\n      \"inputs\": \"FileRequest with file path and optional reason\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grep\",\n      \"desc\": \"Searches files for pattern matches and returns results with context\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern filter, max results, and reason\",\n      \"outputs\": \"GrepResponse with matches including file, line number, content, and context lines\"\n    },\n    {\n      \"name\": \"processLLMRequest\",\n      \"desc\": \"Routes LLM file or grep requests to appropriate handler\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"Either FileResponse or GrepResponse based on request type\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable LLM agents to dynamically explore codebases through file reading and pattern searching, supporting iterative analysis workflows where the agent discovers what files to examine based on previous results rather than receiving all code upfront\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines type interfaces and structures for organizing extracted documentation from code files into hierarchical summaries (file  module  product  full aggregation).",
      "userVisibleActions": [
        "Users see documentation organized by what actions they can take through GUI, CLI, API, or CI/CD interfaces",
        "Users understand what problems the product solves and how it fits into their workflow",
        "Users view structured capabilities grouped by module type (API endpoints, CLI commands, workers)"
      ],
      "developerVisibleActions": [
        "Developers use FileSummary to document individual files with role, purpose, and key functions",
        "Developers use ModuleSummary to group related files and expose endpoints, commands, or worker flows",
        "Developers use EnhancedProductDocumentation to create complete product documentation with overview, architecture diagrams, and user perspectives",
        "Developers structure documentation with userVisibleActions and developerVisibleActions to separate concerns",
        "Developers can include Mermaid diagrams for component and flow visualization",
        "Developers organize features, modules, and components with titles and descriptions"
      ],
      "keyFunctions": [],
      "dependencies": [
        "fs",
        "path",
        "CodeAnalysis from ./analyzer",
        "FileInfo from ./analyzer"
      ],
      "intent": "This file exists to establish a standardized documentation schema that follows a four-level hierarchy (file  module  product  full aggregation), enabling systematic extraction and organization of codebase documentation with clear separation between user-facing and developer-facing information.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines type interfaces and structures for organizing extracted documentation from code files into hierarchical summaries (file  module  product  full aggregation).\",\n  \"userVisibleActions\": [\n    \"Users see documentation organized by what actions they can take through GUI, CLI, API, or CI/CD interfaces\",\n    \"Users understand what problems the product solves and how it fits into their workflow\",\n    \"Users view structured capabilities grouped by module type (API endpoints, CLI commands, workers)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers use FileSummary to document individual files with role, purpose, and key functions\",\n    \"Developers use ModuleSummary to group related files and expose endpoints, commands, or worker flows\",\n    \"Developers use EnhancedProductDocumentation to create complete product documentation with overview, architecture diagrams, and user perspectives\",\n    \"Developers structure documentation with userVisibleActions and developerVisibleActions to separate concerns\",\n    \"Developers can include Mermaid diagrams for component and flow visualization\",\n    \"Developers organize features, modules, and components with titles and descriptions\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"CodeAnalysis from ./analyzer\",\n    \"FileInfo from ./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a standardized documentation schema that follows a four-level hierarchy (file  module  product  full aggregation), enabling systematic extraction and organization of codebase documentation with clear separation between user-facing and developer-facing information.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file changes in the workspace and automatically triggers code analysis when files are saved",
      "userVisibleActions": [
        "Code is automatically analyzed when a file is saved (if 'analyzeOnSave' is enabled in settings)",
        "Analysis results appear in diagnostics/problems panel after file save",
        "Insights tree view updates automatically after file analysis completes",
        "Analysis is throttled to prevent excessive re-analysis (minimum 1 second between analyses)",
        "Analysis skips if configuration is disabled or invalid workspace"
      ],
      "developerVisibleActions": [
        "FileWatcher coordinates automatic analysis workflow when files are saved",
        "Debounces file save events to avoid duplicate analysis runs",
        "Checks configuration settings to determine if analysis should run",
        "Validates workspace folders exist before triggering analysis",
        "Orchestrates analyzer, insight generator, diagnostics provider, and tree view updates",
        "Maintains analysis state to prevent concurrent analysis runs",
        "Handles errors during analysis and reports them appropriately",
        "Can be started/stopped programmatically to enable/disable file watching",
        "Cleans up resources and timers when stopped or disposed"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins watching for file save events to trigger automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops watching file changes and cleans up pending analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save event by scheduling/triggering code analysis with debouncing",
          "inputs": "document (TextDocument)",
          "outputs": "void"
        },
        {
          "name": "triggerAnalysis",
          "desc": "Executes the full analysis workflow: analyzes code, generates insights, updates diagnostics and tree view",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all resources, stops watching, and cancels pending operations",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "ConfigurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic, background code analysis triggered by file saves. It solves the problem of keeping code insights up-to-date without requiring manual user action, while intelligently throttling analysis to avoid performance issues. It acts as the orchestration layer that connects file system events to the analysis pipeline.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Code is automatically analyzed when a file is saved (if 'analyzeOnSave' is enabled in settings)\",\n    \"Analysis results appear in diagnostics/problems panel after file save\",\n    \"Insights tree view updates automatically after file analysis completes\",\n    \"Analysis is throttled to prevent excessive re-analysis (minimum 1 second between analyses)\",\n    \"Analysis skips if configuration is disabled or invalid workspace\"\n  ],\n  \"developerVisibleActions\": [\n    \"FileWatcher coordinates automatic analysis workflow when files are saved\",\n    \"Debounces file save events to avoid duplicate analysis runs\",\n    \"Checks configuration settings to determine if analysis should run\",\n    \"Validates workspace folders exist before triggering analysis\",\n    \"Orchestrates analyzer, insight generator, diagnostics provider, and tree view updates\",\n    \"Maintains analysis state to prevent concurrent analysis runs\",\n    \"Handles errors during analysis and reports them appropriately\",\n    \"Can be started/stopped programmatically to enable/disable file watching\",\n    \"Cleans up resources and timers when stopped or disposed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events to trigger automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching file changes and cleans up pending analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save event by scheduling/triggering code analysis with debouncing\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis workflow: analyzes code, generates insights, updates diagnostics and tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all resources, stops watching, and cancels pending operations\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, background code analysis triggered by file saves. It solves the problem of keeping code insights up-to-date without requiring manual user action, while intelligently throttling analysis to avoid performance issues. It acts as the orchestration layer that connects file system events to the analysis pipeline.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Caches file contents in memory to reduce redundant disk reads and improve performance when multiple components need the same files",
      "userVisibleActions": [
        "Faster file loading when the same files are accessed multiple times",
        "Automatic updates when files are modified, created, or deleted on disk",
        "Reduced disk activity during operations that read many files",
        "Improved responsiveness when analyzing or processing large codebases"
      ],
      "developerVisibleActions": [
        "Retrieve file contents with automatic caching via getFile()",
        "Cache automatically invalidates when files change on disk",
        "LRU eviction policy removes oldest entries when cache reaches size limit",
        "Track cache performance with hit/miss/eviction statistics",
        "Set cached values directly with setFile()",
        "Clear specific files or entire cache programmatically",
        "Configure maximum cache size and time-to-live (TTL) settings",
        "File hashes verify content hasn't changed before returning cached data"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "setFile",
          "desc": "Manually sets a file's cached content and metadata",
          "inputs": "filePath: string, content: string",
          "outputs": "void"
        },
        {
          "name": "invalidate",
          "desc": "Removes a specific file from the cache, forcing next access to read from disk",
          "inputs": "filePath: string",
          "outputs": "void"
        },
        {
          "name": "clear",
          "desc": "Removes all cached files and resets cache statistics",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getStats",
          "desc": "Returns cache performance metrics including hits, misses, evictions, and total size",
          "inputs": "none",
          "outputs": "CacheStats object"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file system watchers and resources",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "This file exists to optimize file system performance by caching frequently accessed files in memory, preventing redundant disk reads when multiple components need the same file content. It solves the problem of slow file I/O operations by intelligently caching with automatic invalidation when files change, reducing latency and improving overall extension responsiveness.",
      "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to reduce redundant disk reads and improve performance when multiple components need the same files\",\n  \"userVisibleActions\": [\n    \"Faster file loading when the same files are accessed multiple times\",\n    \"Automatic updates when files are modified, created, or deleted on disk\",\n    \"Reduced disk activity during operations that read many files\",\n    \"Improved responsiveness when analyzing or processing large codebases\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file contents with automatic caching via getFile()\",\n    \"Cache automatically invalidates when files change on disk\",\n    \"LRU eviction policy removes oldest entries when cache reaches size limit\",\n    \"Track cache performance with hit/miss/eviction statistics\",\n    \"Set cached values directly with setFile()\",\n    \"Clear specific files or entire cache programmatically\",\n    \"Configure maximum cache size and time-to-live (TTL) settings\",\n    \"File hashes verify content hasn't changed before returning cached data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"setFile\",\n      \"desc\": \"Manually sets a file's cached content and metadata\",\n      \"inputs\": \"filePath: string, content: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing next access to read from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached files and resets cache statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, evictions, and total size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file system watchers and resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to optimize file system performance by caching frequently accessed files in memory, preventing redundant disk reads when multiple components need the same file content. It solves the problem of slow file I/O operations by intelligently caching with automatic invalidation when files change, reducing latency and improving overall extension responsiveness.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Consolidates file processing logic across the codebase by providing a reusable framework for filtering, reading, and processing files in parallel or sequentially.",
      "userVisibleActions": [
        "Files are automatically filtered to skip non-source directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea",
        "Multiple files are processed simultaneously for faster operation",
        "Processing continues even if individual files fail, with errors logged but not stopping the overall operation",
        "File processing can be controlled with custom filters to include or exclude specific file patterns"
      ],
      "developerVisibleActions": [
        "Provides a unified API for processing multiple files with consistent filtering and error handling",
        "Allows developers to inject custom file filters to control which files are processed",
        "Allows developers to inject custom file readers for different file access strategies",
        "Supports both parallel and sequential file processing based on performance needs",
        "Automatically handles file reading and passes content to developer-provided processing functions",
        "Integrates with ErrorHandler to track processing errors with context",
        "Returns processed results in the same order as input files, making results predictable"
      ],
      "keyFunctions": [
        {
          "name": "DefaultFileFilter.shouldProcess",
          "desc": "Determines if a file should be processed based on common skip patterns",
          "inputs": "filePath: string",
          "outputs": "boolean - true if file should be processed"
        },
        {
          "name": "DefaultFileReader.readFile",
          "desc": "Reads file content from disk as UTF-8 text",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "FileProcessor.processFiles",
          "desc": "Processes multiple files in parallel with filtering, reading, and custom processing logic",
          "inputs": "files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext",
          "outputs": "Promise<T[]> - array of processed results"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../utils/errorHandler"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and error handling by providing a single, testable, and reusable file processing framework. It allows developers to focus on the 'what to do with file content' logic while handling the 'how to find, filter, and read files' boilerplate consistently.",
      "rawContent": "```json\n{\n  \"purpose\": \"Consolidates file processing logic across the codebase by providing a reusable framework for filtering, reading, and processing files in parallel or sequentially.\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip non-source directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea\",\n    \"Multiple files are processed simultaneously for faster operation\",\n    \"Processing continues even if individual files fail, with errors logged but not stopping the overall operation\",\n    \"File processing can be controlled with custom filters to include or exclude specific file patterns\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a unified API for processing multiple files with consistent filtering and error handling\",\n    \"Allows developers to inject custom file filters to control which files are processed\",\n    \"Allows developers to inject custom file readers for different file access strategies\",\n    \"Supports both parallel and sequential file processing based on performance needs\",\n    \"Automatically handles file reading and passes content to developer-provided processing functions\",\n    \"Integrates with ErrorHandler to track processing errors with context\",\n    \"Returns processed results in the same order as input files, making results predictable\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"DefaultFileFilter.shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on common skip patterns\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean - true if file should be processed\"\n    },\n    {\n      \"name\": \"DefaultFileReader.readFile\",\n      \"desc\": \"Reads file content from disk as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"FileProcessor.processFiles\",\n      \"desc\": \"Processes multiple files in parallel with filtering, reading, and custom processing logic\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> - array of processed results\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and error handling by providing a single, testable, and reusable file processing framework. It allows developers to focus on the 'what to do with file content' logic while handling the 'how to find, filter, and read files' boilerplate consistently.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages saving and organizing analysis results (product documentation, architecture insights, and summaries) to disk in timestamped directories.",
      "userVisibleActions": [
        "Analysis results are automatically saved to .shadow/docs directory",
        "Each analysis run creates a timestamped folder with organized documentation",
        "Product documentation is saved as individual files per analyzed file",
        "Architecture insights are saved as a consolidated summary",
        "Progress summaries show files processed and time taken",
        "All documentation files are formatted in markdown"
      ],
      "developerVisibleActions": [
        "Initialize product documentation runs to start saving results",
        "Initialize architecture insights runs for system-level analysis",
        "Save individual file documentation with metadata",
        "Save architecture insights with processing statistics",
        "Append incremental documentation as files are processed",
        "Generate summary reports at the end of analysis runs",
        "Store results in .shadow/docs with timestamped run directories",
        "Access run metadata like start time and directory paths"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Creates a new timestamped directory for storing product documentation",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Creates a new timestamped directory for storing architecture insights",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "saveProductDocumentation",
          "desc": "Saves enhanced product documentation for a single file",
          "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Saves architecture insights with processing metadata",
          "inputs": "insights: LLMInsights, filesProcessed: number, timeElapsed: number, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "appendProductDocumentation",
          "desc": "Appends documentation incrementally during processing",
          "inputs": "doc: EnhancedProductDocumentation, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "generateProductDocsSummary",
          "desc": "Creates a summary report of all processed files",
          "inputs": "filesProcessed: number, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "generateArchitectureInsightsSummary",
          "desc": "Creates a summary report of architecture analysis",
          "inputs": "insights: LLMInsights, filesProcessed: number, workspaceRoot: string",
          "outputs": "Promise<void>"
        },
        {
          "name": "getCurrentProductDocsRunDir",
          "desc": "Gets the current product docs run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "getCurrentArchitectureInsightsRunDir",
          "desc": "Gets the current architecture insights run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "resetProductDocsRun",
          "desc": "Clears the current product docs run context",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "resetArchitectureInsightsRun",
          "desc": "Clears the current architecture insights run context",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../../fileDocumentation (EnhancedProductDocumentation)",
        "../../llmService (LLMInsights)",
        "../../domain/formatters/documentationFormatter (DocumentationFormatter)",
        "../../storage/incrementalStorage (createTimestampedStorage)"
      ],
      "intent": "This repository separates persistence concerns from analysis logic, providing a dedicated layer for saving analysis results to disk in an organized, timestamped structure that allows multiple runs to coexist and makes it easy to track when analyses were performed.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages saving and organizing analysis results (product documentation, architecture insights, and summaries) to disk in timestamped directories.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to .shadow/docs directory\",\n    \"Each analysis run creates a timestamped folder with organized documentation\",\n    \"Product documentation is saved as individual files per analyzed file\",\n    \"Architecture insights are saved as a consolidated summary\",\n    \"Progress summaries show files processed and time taken\",\n    \"All documentation files are formatted in markdown\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to start saving results\",\n    \"Initialize architecture insights runs for system-level analysis\",\n    \"Save individual file documentation with metadata\",\n    \"Save architecture insights with processing statistics\",\n    \"Append incremental documentation as files are processed\",\n    \"Generate summary reports at the end of analysis runs\",\n    \"Store results in .shadow/docs with timestamped run directories\",\n    \"Access run metadata like start time and directory paths\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves enhanced product documentation for a single file\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights with processing metadata\",\n      \"inputs\": \"insights: LLMInsights, filesProcessed: number, timeElapsed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"appendProductDocumentation\",\n      \"desc\": \"Appends documentation incrementally during processing\",\n      \"inputs\": \"doc: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateProductDocsSummary\",\n      \"desc\": \"Creates a summary report of all processed files\",\n      \"inputs\": \"filesProcessed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateArchitectureInsightsSummary\",\n      \"desc\": \"Creates a summary report of architecture analysis\",\n      \"inputs\": \"insights: LLMInsights, filesProcessed: number, workspaceRoot: string\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Gets the current product docs run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Gets the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product docs run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\",\n    \"../../llmService (LLMInsights)\",\n    \"../../domain/formatters/documentationFormatter (DocumentationFormatter)\",\n    \"../../storage/incrementalStorage (createTimestampedStorage)\"\n  ],\n  \"intent\": \"This repository separates persistence concerns from analysis logic, providing a dedicated layer for saving analysis results to disk in an organized, timestamped structure that allows multiple runs to coexist and makes it easy to track when analyses were performed.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations with optional cancellation support",
      "userVisibleActions": [
        "See progress notifications with titles and status messages during operations",
        "Cancel long-running operations using the cancellation button in progress notifications",
        "View progress indicators in different locations (notification, window, source control)"
      ],
      "developerVisibleActions": [
        "Wrap async operations with standardized progress reporting using withProgress method",
        "Report incremental progress updates with custom messages during task execution",
        "Configure progress location (notification, window, source control) and cancellability",
        "Access cancellation token to respond to user cancellation requests",
        "Use simplified string title or full options object for progress configuration"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying progress notifications to the user with customizable title, location, and cancellation support",
          "inputs": "options (title, cancellable flag, location) and async task function that receives a ProgressReporter",
          "outputs": "Promise resolving to the result of the executed task"
        },
        {
          "name": "ProgressReporter.report",
          "desc": "Updates the progress notification with a new message and optional increment value",
          "inputs": "message string and optional increment number",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to eliminate boilerplate code and ensure consistent progress reporting across the codebase. It wraps VSCode's native progress API to provide a simpler, standardized interface for showing progress notifications during async operations, making it easier for developers to provide user feedback and handle cancellation uniformly.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations with optional cancellation support\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and status messages during operations\",\n    \"Cancel long-running operations using the cancellation button in progress notifications\",\n    \"View progress indicators in different locations (notification, window, source control)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async operations with standardized progress reporting using withProgress method\",\n    \"Report incremental progress updates with custom messages during task execution\",\n    \"Configure progress location (notification, window, source control) and cancellability\",\n    \"Access cancellation token to respond to user cancellation requests\",\n    \"Use simplified string title or full options object for progress configuration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying progress notifications to the user with customizable title, location, and cancellation support\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise resolving to the result of the executed task\"\n    },\n    {\n      \"name\": \"ProgressReporter.report\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment value\",\n      \"inputs\": \"message string and optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to eliminate boilerplate code and ensure consistent progress reporting across the codebase. It wraps VSCode's native progress API to provide a simpler, standardized interface for showing progress notifications during async operations, making it easier for developers to provide user feedback and handle cancellation uniformly.\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Generates actionable insights and recommendations by analyzing code metrics, identifying issues like large files, orphaned code, circular dependencies, and complexity problems.",
      "userVisibleActions": [
        "Receives insights about large files that exceed recommended line counts",
        "Gets warnings about orphaned files that aren't referenced elsewhere",
        "Sees alerts for missing entry points in the codebase",
        "Views notifications about potential circular dependencies",
        "Receives warnings about god objects (overly complex classes/modules)",
        "Gets alerts about potential dead code that may be unused",
        "Sees recommendations for better file organization",
        "Receives warnings about complex functions that need refactoring"
      ],
      "developerVisibleActions": [
        "Calls generateInsights() to analyze entire codebase and receive all insights",
        "Calls generateInsightsForFile() to get insights for a specific file",
        "Receives structured Insight objects with severity levels (error/warning/info)",
        "Gets actionable suggestions for each identified issue",
        "Sees categorized insights for easier filtering and prioritization",
        "Accesses file path and line number information for navigation to issues",
        "Views code snippets highlighting problematic areas"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Analyzes entire codebase and returns comprehensive list of all identified issues and recommendations",
          "inputs": "CodeAnalysis object containing analyzed code structure",
          "outputs": "Array of Insight objects with issues, warnings, and suggestions"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Generates insights specific to a single file including size, complexity, and organization checks",
          "inputs": "CodeAnalysis object and file path string",
          "outputs": "Array of Insight objects specific to the requested file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Identifies files exceeding recommended line count thresholds",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for oversized files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Finds files that aren't imported or referenced by other files",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for isolated files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Validates presence of required entry points in the project",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Detects potential circular dependency patterns between modules",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for circular dependencies"
        },
        {
          "name": "checkGodObjects",
          "desc": "Identifies overly complex classes or modules with too many responsibilities",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for god objects"
        },
        {
          "name": "checkDeadCode",
          "desc": "Finds potentially unused or unreachable code segments",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Evaluates project structure and file organization patterns",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for organizational improvements"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Analyzes functions for excessive complexity and recommends refactoring",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights for complex functions"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers improve code quality, maintainability, and organization by identifying common problems and anti-patterns with specific suggestions for improvement.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates actionable insights and recommendations by analyzing code metrics, identifying issues like large files, orphaned code, circular dependencies, and complexity problems.\",\n  \"userVisibleActions\": [\n    \"Receives insights about large files that exceed recommended line counts\",\n    \"Gets warnings about orphaned files that aren't referenced elsewhere\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Views notifications about potential circular dependencies\",\n    \"Receives warnings about god objects (overly complex classes/modules)\",\n    \"Gets alerts about potential dead code that may be unused\",\n    \"Sees recommendations for better file organization\",\n    \"Receives warnings about complex functions that need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls generateInsights() to analyze entire codebase and receive all insights\",\n    \"Calls generateInsightsForFile() to get insights for a specific file\",\n    \"Receives structured Insight objects with severity levels (error/warning/info)\",\n    \"Gets actionable suggestions for each identified issue\",\n    \"Sees categorized insights for easier filtering and prioritization\",\n    \"Accesses file path and line number information for navigation to issues\",\n    \"Views code snippets highlighting problematic areas\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns comprehensive list of all identified issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing analyzed code structure\",\n      \"outputs\": \"Array of Insight objects with issues, warnings, and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates insights specific to a single file including size, complexity, and organization checks\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that aren't imported or referenced by other files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry points in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between modules\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies overly complex classes or modules with too many responsibilities\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds potentially unused or unreachable code segments\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file organization patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for organizational improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes functions for excessive complexity and recommends refactoring\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers improve code quality, maintainability, and organization by identifying common problems and anti-patterns with specific suggestions for improvement.\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view UI in VS Code's sidebar that displays code analysis insights, reports, and AI-generated documentation with real-time status updates.",
      "userVisibleActions": [
        "View code insights organized in a hierarchical tree structure in the sidebar",
        "See real-time status indicators (idle, generating, complete) for different analysis types",
        "Click on insights to navigate to specific code locations",
        "Expand/collapse sections to view product docs, architecture analysis, unit tests, and reports",
        "See timestamps showing when each analysis was last generated",
        "View file counts and statistics for different analysis categories",
        "Access generated reports through clickable tree items",
        "See loading spinners and progress indicators during AI analysis generation",
        "View categorized insights with severity indicators and descriptions",
        "Navigate between workspace-level and file-level analysis results"
      ],
      "developerVisibleActions": [
        "Tree view automatically refreshes when new insights are generated",
        "Status updates propagate from LLM services to the UI",
        "Tree structure persists state across VS Code sessions",
        "Icons and tooltips provide visual feedback about analysis status",
        "Tree items become clickable commands when analysis is complete",
        "Background services update tree data without blocking user interaction",
        "Timestamps and file paths are stored and restored on extension reload",
        "Tree view integrates with VS Code's command system for user actions",
        "Static analysis results are displayed alongside AI-generated insights",
        "Report generation status is tracked and displayed independently for each report type"
      ],
      "keyFunctions": [
        {
          "name": "getTreeItem",
          "desc": "Returns a VS Code tree item with appropriate icon, label, and command for display in the sidebar",
          "inputs": "TreeItem element",
          "outputs": "vscode.TreeItem or Thenable<vscode.TreeItem>"
        },
        {
          "name": "getChildren",
          "desc": "Provides the hierarchical structure of insights, reports, and analysis results for the tree view",
          "inputs": "Optional parent TreeItem",
          "outputs": "Array of child TreeItems or Thenable<TreeItem[]>"
        },
        {
          "name": "updateInsights",
          "desc": "Updates the displayed insights and refreshes the tree view UI",
          "inputs": "Array of Insight objects",
          "outputs": "void"
        },
        {
          "name": "setProductDocsStatus",
          "desc": "Updates the status of product documentation generation and refreshes the UI",
          "inputs": "Status string (idle, generating, complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setInsightsStatus",
          "desc": "Updates the status of insights generation and refreshes the UI",
          "inputs": "Status string (idle, generating, complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setUnitTestStatus",
          "desc": "Updates the status of unit test generation and refreshes the UI",
          "inputs": "Status string (idle, generating, complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setAnalysisStatus",
          "desc": "Updates the status of static analysis and refreshes the UI",
          "inputs": "Status string (idle, complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setLLMService",
          "desc": "Connects the tree view to the LLM service for displaying AI-generated insights",
          "inputs": "LLMService instance",
          "outputs": "void"
        },
        {
          "name": "setReportPath",
          "desc": "Sets the file path for a generated report and updates the display with timestamp",
          "inputs": "Report file path string and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Forces a complete refresh of the tree view UI",
          "inputs": "Optional TreeItem to refresh",
          "outputs": "void"
        },
        {
          "name": "loadPersistedState",
          "desc": "Restores saved timestamps and file paths from previous VS Code sessions",
          "inputs": "None",
          "outputs": "Promise<void>"
        },
        {
          "name": "formatTimestamp",
          "desc": "Converts a timestamp into a human-readable relative time string",
          "inputs": "Timestamp number",
          "outputs": "Formatted time string (e.g., '5 minutes ago')"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator",
        "./llmFormatter",
        "./llmService"
      ],
      "intent": "This file exists to provide a visual interface in VS Code's sidebar that organizes and displays all code analysis results, AI-generated documentation, and reports in an easy-to-navigate tree structure. It solves the problem of presenting complex, multi-layered analysis data to users in a way that's accessible, interactive, and provides real-time feedback on generation status. It acts as the main UI bridge between background analysis services and the user's workspace exploration experience.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view UI in VS Code's sidebar that displays code analysis insights, reports, and AI-generated documentation with real-time status updates.\",\n  \"userVisibleActions\": [\n    \"View code insights organized in a hierarchical tree structure in the sidebar\",\n    \"See real-time status indicators (idle, generating, complete) for different analysis types\",\n    \"Click on insights to navigate to specific code locations\",\n    \"Expand/collapse sections to view product docs, architecture analysis, unit tests, and reports\",\n    \"See timestamps showing when each analysis was last generated\",\n    \"View file counts and statistics for different analysis categories\",\n    \"Access generated reports through clickable tree items\",\n    \"See loading spinners and progress indicators during AI analysis generation\",\n    \"View categorized insights with severity indicators and descriptions\",\n    \"Navigate between workspace-level and file-level analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when new insights are generated\",\n    \"Status updates propagate from LLM services to the UI\",\n    \"Tree structure persists state across VS Code sessions\",\n    \"Icons and tooltips provide visual feedback about analysis status\",\n    \"Tree items become clickable commands when analysis is complete\",\n    \"Background services update tree data without blocking user interaction\",\n    \"Timestamps and file paths are stored and restored on extension reload\",\n    \"Tree view integrates with VS Code's command system for user actions\",\n    \"Static analysis results are displayed alongside AI-generated insights\",\n    \"Report generation status is tracked and displayed independently for each report type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns a VS Code tree item with appropriate icon, label, and command for display in the sidebar\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem or Thenable<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Provides the hierarchical structure of insights, reports, and analysis results for the tree view\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of child TreeItems or Thenable<TreeItem[]>\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view UI\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the status of insights generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the status of unit test generation and refreshes the UI\",\n      \"inputs\": \"Status string (idle, generating, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of static analysis and refreshes the UI\",\n      \"inputs\": \"Status string (idle, complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Connects the tree view to the LLM service for displaying AI-generated insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and updates the display with timestamp\",\n      \"inputs\": \"Report file path string and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces a complete refresh of the tree view UI\",\n      \"inputs\": \"Optional TreeItem to refresh\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved timestamps and file paths from previous VS Code sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatTimestamp\",\n      \"desc\": \"Converts a timestamp into a human-readable relative time string\",\n      \"inputs\": \"Timestamp number\",\n      \"outputs\": \"Formatted time string (e.g., '5 minutes ago')\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual interface in VS Code's sidebar that organizes and displays all code analysis results, AI-generated documentation, and reports in an easy-to-navigate tree structure. It solves the problem of presenting complex, multi-layered analysis data to users in a way that's accessible, interactive, and provides real-time feedback on generation status. It acts as the main UI bridge between background analysis services and the user's workspace exploration experience.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, with automatic refresh when insights are updated.",
      "userVisibleActions": [
        "View AI-generated architecture insights in a tree structure in the VS Code sidebar",
        "Browse project purpose, features, architecture, and technical stack information",
        "Expand/collapse sections to see detailed insights about different aspects of the codebase",
        "Click on insights to view detailed information in the editor",
        "See real-time updates when architecture insights are regenerated",
        "Access insights from both main insights file and purpose documentation file",
        "View insights organized by categories: Project Purpose, Features, Architecture, and Technical Stack"
      ],
      "developerVisibleActions": [
        "Automatically watches .shadow/docs/insights.json for changes and refreshes the tree view",
        "Automatically watches .shadow/docs/purpose.md for changes and refreshes the tree view",
        "Loads insights from JSON file in the .shadow/docs directory",
        "Creates .shadow and .shadow/docs directories if they don't exist",
        "Parses and structures insights data into a hierarchical tree format",
        "Handles missing or invalid insights files gracefully",
        "Manages file watcher lifecycle with proper cleanup on disposal",
        "Integrates with FileWatcherService for centralized file monitoring"
      ],
      "keyFunctions": [
        {
          "name": "refresh",
          "desc": "Reloads insights from disk and updates the tree view display",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts an InsightItem into a displayable tree item for VS Code",
          "inputs": "InsightItem element",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node or root-level items if no parent",
          "inputs": "InsightItem or undefined",
          "outputs": "Promise<InsightItem[]>"
        },
        {
          "name": "loadInsights",
          "desc": "Reads and parses the insights.json file from .shadow/docs directory",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Creates file system watchers for insights.json and purpose.md to auto-refresh the view",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file watchers and disposable resources when the provider is destroyed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs",
        "llmService",
        "domain/services/fileWatcherService"
      ],
      "intent": "This file exists to provide developers with a convenient, always-visible sidebar view of AI-generated architecture insights about their codebase. It solves the problem of accessing and browsing architectural documentation by presenting it in an organized tree structure that automatically updates when the AI generates new insights, eliminating the need to manually open and read documentation files.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated architecture insights about the codebase, with automatic refresh when insights are updated.\",\n  \"userVisibleActions\": [\n    \"View AI-generated architecture insights in a tree structure in the VS Code sidebar\",\n    \"Browse project purpose, features, architecture, and technical stack information\",\n    \"Expand/collapse sections to see detailed insights about different aspects of the codebase\",\n    \"Click on insights to view detailed information in the editor\",\n    \"See real-time updates when architecture insights are regenerated\",\n    \"Access insights from both main insights file and purpose documentation file\",\n    \"View insights organized by categories: Project Purpose, Features, Architecture, and Technical Stack\"\n  ],\n  \"developerVisibleActions\": [\n    \"Automatically watches .shadow/docs/insights.json for changes and refreshes the tree view\",\n    \"Automatically watches .shadow/docs/purpose.md for changes and refreshes the tree view\",\n    \"Loads insights from JSON file in the .shadow/docs directory\",\n    \"Creates .shadow and .shadow/docs directories if they don't exist\",\n    \"Parses and structures insights data into a hierarchical tree format\",\n    \"Handles missing or invalid insights files gracefully\",\n    \"Manages file watcher lifecycle with proper cleanup on disposal\",\n    \"Integrates with FileWatcherService for centralized file monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from disk and updates the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a displayable tree item for VS Code\",\n      \"inputs\": \"InsightItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root-level items if no parent\",\n      \"inputs\": \"InsightItem or undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"loadInsights\",\n      \"desc\": \"Reads and parses the insights.json file from .shadow/docs directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers for insights.json and purpose.md to auto-refresh the view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and disposable resources when the provider is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"llmService\",\n    \"domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with a convenient, always-visible sidebar view of AI-generated architecture insights about their codebase. It solves the problem of accessing and browsing architectural documentation by presenting it in an organized tree structure that automatically updates when the AI generates new insights, eliminating the need to manually open and read documentation files.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different output formats optimized for various LLM interfaces and readability preferences.",
      "userVisibleActions": [
        "View architecture issues formatted specifically for Cursor AI with emoji-enhanced sections",
        "View architecture issues formatted for ChatGPT with conversational context",
        "View architecture issues in a compact format with minimal formatting",
        "View architecture issues in a generic format suitable for any LLM",
        "See issues grouped by severity (errors, warnings, info)",
        "Receive actionable prompts requesting help with prioritization and refactoring",
        "Get insights presented with file locations, issue descriptions, and suggested fixes"
      ],
      "developerVisibleActions": [
        "Call formatInsights() to transform raw insights into LLM-ready formatted text",
        "Select different output formats by passing format parameter (cursor, chatgpt, compact, generic)",
        "Receive markdown-formatted strings ready to paste into LLM chat interfaces",
        "Get insights automatically organized by severity level",
        "Use formatted output that includes file paths, line numbers, issue descriptions, and suggestions",
        "Leverage pre-built prompts that ask LLMs for specific help (prioritization, refactoring steps, reorganization plans)"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Main entry point that routes to appropriate formatter based on target LLM",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "Formatted string ready for LLM consumption"
        },
        {
          "name": "formatForCursor",
          "desc": "Creates Cursor AI optimized format with emojis, severity sections, and actionable prompts",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown-formatted string with emoji headers and grouped issues"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Creates ChatGPT optimized format with conversational framing and context",
          "inputs": "insights: Insight[]",
          "outputs": "Conversational markdown string suited for ChatGPT interface"
        },
        {
          "name": "formatCompact",
          "desc": "Creates minimal format with just essential information and no extra formatting",
          "inputs": "insights: Insight[]",
          "outputs": "Compact text listing of issues"
        },
        {
          "name": "formatGeneric",
          "desc": "Creates standard format that works with any LLM without special optimizations",
          "inputs": "insights: Insight[]",
          "outputs": "Generic markdown-formatted string"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats individual insight with file info, description, and suggestions for Cursor",
          "inputs": "insight: Insight",
          "outputs": "Formatted markdown block for single insight"
        }
      ],
      "dependencies": [
        "./insightGenerator"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis results and LLM interfaces by transforming technical insights into well-formatted, context-rich prompts that are optimized for different AI coding assistants. It solves the problem of presenting architecture issues in a way that maximizes the effectiveness of LLM responses by providing proper context, organization, and actionable prompts.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various LLM interfaces and readability preferences.\",\n  \"userVisibleActions\": [\n    \"View architecture issues formatted specifically for Cursor AI with emoji-enhanced sections\",\n    \"View architecture issues formatted for ChatGPT with conversational context\",\n    \"View architecture issues in a compact format with minimal formatting\",\n    \"View architecture issues in a generic format suitable for any LLM\",\n    \"See issues grouped by severity (errors, warnings, info)\",\n    \"Receive actionable prompts requesting help with prioritization and refactoring\",\n    \"Get insights presented with file locations, issue descriptions, and suggested fixes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatInsights() to transform raw insights into LLM-ready formatted text\",\n    \"Select different output formats by passing format parameter (cursor, chatgpt, compact, generic)\",\n    \"Receive markdown-formatted strings ready to paste into LLM chat interfaces\",\n    \"Get insights automatically organized by severity level\",\n    \"Use formatted output that includes file paths, line numbers, issue descriptions, and suggestions\",\n    \"Leverage pre-built prompts that ask LLMs for specific help (prioritization, refactoring steps, reorganization plans)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes to appropriate formatter based on target LLM\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string ready for LLM consumption\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI optimized format with emojis, severity sections, and actionable prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string with emoji headers and grouped issues\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT optimized format with conversational framing and context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Conversational markdown string suited for ChatGPT interface\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates minimal format with just essential information and no extra formatting\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact text listing of issues\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format that works with any LLM without special optimizations\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown-formatted string\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file info, description, and suggestions for Cursor\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown block for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis results and LLM interfaces by transforming technical insights into well-formatted, context-rich prompts that are optimized for different AI coding assistants. It solves the problem of presenting architecture issues in a way that maximizes the effectiveness of LLM responses by providing proper context, organization, and actionable prompts.\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Integrates LLM-powered code analysis features into VSCode, managing documentation generation, insights, and code analysis visualization through various tree view providers and command handlers.",
      "userVisibleActions": [
        "Generate product documentation from codebase with progress notifications",
        "View generated documentation in formatted output channel and webview",
        "Analyze codebase to extract architecture insights and patterns",
        "View insights organized in tree view with categories (Entry Points, Components, etc.)",
        "Navigate codebase through product navigator showing modules and components",
        "View analysis results in interactive viewer with file structure",
        "Search and filter analysis results and insights",
        "Jump to code locations from tree views and documentation",
        "Export documentation and insights to files",
        "Refresh analysis and documentation on demand",
        "View unit test coverage and navigate to test files",
        "See error messages when API keys are missing or invalid",
        "Receive notifications when documentation or analysis completes"
      ],
      "developerVisibleActions": [
        "Trigger analysis through command palette or tree view actions",
        "Configure LLM API keys and providers in settings",
        "Access cached analysis results to avoid redundant processing",
        "Monitor analysis progress through status bar and notifications",
        "Debug LLM interactions through logging output",
        "Access saved analysis state across sessions",
        "Handle API rate limits and errors gracefully",
        "Customize documentation formatting through settings",
        "Integrate analysis results into custom workflows",
        "Load and save analysis contexts programmatically"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Initializes LLM service, registers configuration change handlers, and loads saved analysis state",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "generateProductDocumentation",
          "desc": "Analyzes codebase and generates comprehensive product documentation using LLM",
          "inputs": "workspace folder",
          "outputs": "Promise<EnhancedProductDocumentation>"
        },
        {
          "name": "analyzeCodebase",
          "desc": "Performs deep code analysis to extract architecture, patterns, and insights",
          "inputs": "workspace folder, options",
          "outputs": "Promise<CodeAnalysis>"
        },
        {
          "name": "getInsights",
          "desc": "Retrieves LLM-generated insights from analyzed codebase",
          "inputs": "analysis context",
          "outputs": "Promise<LLMInsights>"
        },
        {
          "name": "refreshInsights",
          "desc": "Re-analyzes codebase and updates insights tree view",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "showDocumentation",
          "desc": "Displays generated documentation in formatted output channel or webview",
          "inputs": "documentation object",
          "outputs": "void"
        },
        {
          "name": "exportDocumentation",
          "desc": "Saves documentation to markdown or HTML file",
          "inputs": "documentation, format, output path",
          "outputs": "Promise<void>"
        },
        {
          "name": "loadSavedCodeAnalysis",
          "desc": "Loads previously saved analysis results from disk",
          "inputs": "workspace folder",
          "outputs": "Promise<CodeAnalysis | null>"
        },
        {
          "name": "saveAnalysisResults",
          "desc": "Persists analysis results and insights to disk for later use",
          "inputs": "analysis data, workspace folder",
          "outputs": "Promise<void>"
        },
        {
          "name": "registerCommands",
          "desc": "Registers all VSCode commands for LLM features in command palette",
          "inputs": "extension context",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "llmService",
        "insightsTreeView",
        "fileDocumentation",
        "analyzer",
        "productNavigator",
        "analysisViewer",
        "insightsViewer",
        "unitTestsNavigator",
        "logger",
        "llmStateManager",
        "analysisContextBuilder",
        "documentationFormatter",
        "analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis and user-friendly LLM-powered features in VSCode. It solves the problem of understanding large codebases by providing automated documentation generation, architectural insights extraction, and interactive navigation through analysis results. It manages the entire lifecycle of LLM-powered analysis including initialization, execution, caching, persistence, and presentation through various UI components like tree views and webviews.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered code analysis features into VSCode, managing documentation generation, insights, and code analysis visualization through various tree view providers and command handlers.\",\n  \"userVisibleActions\": [\n    \"Generate product documentation from codebase with progress notifications\",\n    \"View generated documentation in formatted output channel and webview\",\n    \"Analyze codebase to extract architecture insights and patterns\",\n    \"View insights organized in tree view with categories (Entry Points, Components, etc.)\",\n    \"Navigate codebase through product navigator showing modules and components\",\n    \"View analysis results in interactive viewer with file structure\",\n    \"Search and filter analysis results and insights\",\n    \"Jump to code locations from tree views and documentation\",\n    \"Export documentation and insights to files\",\n    \"Refresh analysis and documentation on demand\",\n    \"View unit test coverage and navigate to test files\",\n    \"See error messages when API keys are missing or invalid\",\n    \"Receive notifications when documentation or analysis completes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger analysis through command palette or tree view actions\",\n    \"Configure LLM API keys and providers in settings\",\n    \"Access cached analysis results to avoid redundant processing\",\n    \"Monitor analysis progress through status bar and notifications\",\n    \"Debug LLM interactions through logging output\",\n    \"Access saved analysis state across sessions\",\n    \"Handle API rate limits and errors gracefully\",\n    \"Customize documentation formatting through settings\",\n    \"Integrate analysis results into custom workflows\",\n    \"Load and save analysis contexts programmatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Initializes LLM service, registers configuration change handlers, and loads saved analysis state\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Analyzes codebase and generates comprehensive product documentation using LLM\",\n      \"inputs\": \"workspace folder\",\n      \"outputs\": \"Promise<EnhancedProductDocumentation>\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Performs deep code analysis to extract architecture, patterns, and insights\",\n      \"inputs\": \"workspace folder, options\",\n      \"outputs\": \"Promise<CodeAnalysis>\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Retrieves LLM-generated insights from analyzed codebase\",\n      \"inputs\": \"analysis context\",\n      \"outputs\": \"Promise<LLMInsights>\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Re-analyzes codebase and updates insights tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showDocumentation\",\n      \"desc\": \"Displays generated documentation in formatted output channel or webview\",\n      \"inputs\": \"documentation object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"exportDocumentation\",\n      \"desc\": \"Saves documentation to markdown or HTML file\",\n      \"inputs\": \"documentation, format, output path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Loads previously saved analysis results from disk\",\n      \"inputs\": \"workspace folder\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"saveAnalysisResults\",\n      \"desc\": \"Persists analysis results and insights to disk for later use\",\n      \"inputs\": \"analysis data, workspace folder\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VSCode commands for LLM features in command palette\",\n      \"inputs\": \"extension context\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"llmStateManager\",\n    \"analysisContextBuilder\",\n    \"documentationFormatter\",\n    \"analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and user-friendly LLM-powered features in VSCode. It solves the problem of understanding large codebases by providing automated documentation generation, architectural insights extraction, and interactive navigation through analysis results. It manages the entire lifecycle of LLM-powered analysis including initialization, execution, caching, persistence, and presentation through various UI components like tree views and webviews.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure LLM responses to ensure valid, parseable output for product analysis, code health assessment, and documentation generation.",
      "userVisibleActions": [
        "Receives structured analysis of product purpose and user goals",
        "Gets organized lists of code health issues with clear titles and descriptions",
        "Sees categorized architectural problems and design decisions",
        "Receives formatted proposed fixes for identified issues",
        "Gets structured documentation with sections for behaviors, functions, and dependencies"
      ],
      "developerVisibleActions": [
        "Sends codebase information to LLM and receives guaranteed JSON structure back",
        "Uses schemas to validate LLM responses match expected format",
        "Relies on schema enforcement to avoid manual parsing of LLM output",
        "Gets predictable data structures for product purpose analysis including architecture rationale and user goals",
        "Receives code health issues with required fields: title, description, relevant files, functions, and severity",
        "Obtains structured file analysis with purpose, user/developer-facing actions, key functions, and dependencies"
      ],
      "keyFunctions": [
        {
          "name": "productPurposeAnalysisSchema",
          "desc": "Schema ensuring LLM returns structured product purpose analysis",
          "inputs": "Used by LLM to structure response",
          "outputs": "Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
        },
        {
          "name": "issueItemSchema",
          "desc": "Schema defining structure for individual code health issues",
          "inputs": "Nested within other schemas",
          "outputs": "Object with title, description, relevantFiles, relevantFunctions, severity, priority"
        },
        {
          "name": "codeHealthAnalysisSchema",
          "desc": "Schema ensuring LLM returns organized list of code health problems",
          "inputs": "Used by LLM to structure code analysis response",
          "outputs": "Object with issues array containing structured problem reports"
        },
        {
          "name": "fileAnalysisSchema",
          "desc": "Schema ensuring LLM returns structured file documentation",
          "inputs": "Used by LLM to structure file analysis response",
          "outputs": "Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent"
        }
      ],
      "dependencies": [],
      "intent": "Eliminates unreliable LLM response parsing by enforcing strict JSON schemas that guarantee valid, structured output for product analysis, code health assessment, and documentation generation tasks.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure LLM responses to ensure valid, parseable output for product analysis, code health assessment, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and user goals\",\n    \"Gets organized lists of code health issues with clear titles and descriptions\",\n    \"Sees categorized architectural problems and design decisions\",\n    \"Receives formatted proposed fixes for identified issues\",\n    \"Gets structured documentation with sections for behaviors, functions, and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Sends codebase information to LLM and receives guaranteed JSON structure back\",\n    \"Uses schemas to validate LLM responses match expected format\",\n    \"Relies on schema enforcement to avoid manual parsing of LLM output\",\n    \"Gets predictable data structures for product purpose analysis including architecture rationale and user goals\",\n    \"Receives code health issues with required fields: title, description, relevant files, functions, and severity\",\n    \"Obtains structured file analysis with purpose, user/developer-facing actions, key functions, and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns structured product purpose analysis\",\n      \"inputs\": \"Used by LLM to structure response\",\n      \"outputs\": \"Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema defining structure for individual code health issues\",\n      \"inputs\": \"Nested within other schemas\",\n      \"outputs\": \"Object with title, description, relevantFiles, relevantFunctions, severity, priority\"\n    },\n    {\n      \"name\": \"codeHealthAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns organized list of code health problems\",\n      \"inputs\": \"Used by LLM to structure code analysis response\",\n      \"outputs\": \"Object with issues array containing structured problem reports\"\n    },\n    {\n      \"name\": \"fileAnalysisSchema\",\n      \"desc\": \"Schema ensuring LLM returns structured file documentation\",\n      \"inputs\": \"Used by LLM to structure file analysis response\",\n      \"outputs\": \"Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Eliminates unreliable LLM response parsing by enforcing strict JSON schemas that guarantee valid, structured output for product analysis, code health assessment, and documentation generation tasks.\"\n}\n```"
    },
    {
      "file": "src/llmService.ts",
      "role": "Core Logic",
      "purpose": "Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.",
      "userVisibleActions": [
        "Receives AI-generated explanations of what the product/codebase does",
        "Gets intelligent insights about code architecture and design patterns",
        "Views AI-generated product documentation with purpose, features, and architecture",
        "Sees automated test plans and suggestions for code improvements",
        "Receives refactoring suggestions for complex functions",
        "Gets incremental analysis updates as code changes"
      ],
      "developerVisibleActions": [
        "Calls AI providers to analyze entire codebases and generate product purpose summaries",
        "Requests AI analysis of code structure, entry points, and module relationships",
        "Generates enhanced product documentation by analyzing file summaries and module structure",
        "Creates unit test plans by analyzing code coverage and function signatures",
        "Obtains refactoring suggestions for specific functions or code sections",
        "Triggers incremental analysis for file changes without re-analyzing entire codebase",
        "Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration",
        "Handles rate limiting and retry logic for LLM API calls automatically",
        "Parses and validates LLM responses using predefined schemas",
        "Accesses detailed function metadata and code analysis results"
      ],
      "keyFunctions": [
        {
          "name": "analyzeProductPurpose",
          "desc": "Analyzes the entire codebase to determine the product's main purpose and architecture",
          "inputs": "CodeAnalysis object containing all analyzed files and their metadata",
          "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules"
        },
        {
          "name": "generateInsights",
          "desc": "Generates AI-powered insights about code quality, patterns, and potential issues",
          "inputs": "CodeAnalysis with file information and analysis context",
          "outputs": "LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions"
        },
        {
          "name": "generateEnhancedProductDocumentation",
          "desc": "Creates comprehensive product documentation by analyzing file summaries and module structure",
          "inputs": "Array of FileSummary and ModuleSummary objects",
          "outputs": "EnhancedProductDocumentation with product overview, architecture, features, and technical details"
        },
        {
          "name": "generateUnitTestPlan",
          "desc": "Analyzes code to create a test plan identifying untested functions and suggesting test cases",
          "inputs": "CodeAnalysis and list of existing test files",
          "outputs": "UnitTestPlan with prioritized list of functions to test and suggested test cases"
        },
        {
          "name": "generateRefactoringSuggestions",
          "desc": "Analyzes a specific function and provides refactoring recommendations",
          "inputs": "Function code, metadata, and surrounding context",
          "outputs": "RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps"
        },
        {
          "name": "performIncrementalAnalysis",
          "desc": "Analyzes changes to specific files without re-analyzing the entire codebase",
          "inputs": "Array of changed file paths and full code analysis",
          "outputs": "Updated analysis focusing only on changed files and their immediate dependencies"
        },
        {
          "name": "callLLM",
          "desc": "Makes authenticated API calls to configured LLM provider with rate limiting and retry logic",
          "inputs": "Prompt string, expected response schema, and optional provider override",
          "outputs": "Parsed and validated response from the LLM matching the specified schema"
        }
      ],
      "dependencies": [
        "vscode",
        "./fileDocumentation",
        "./analyzer",
        "./analysis/enhancedAnalyzer",
        "./llmSchemas",
        "./fileAccessHelper",
        "./logger",
        "./config/configurationManager",
        "./ai/providers/providerFactory",
        "./ai/llmResponseParser",
        "./ai/llmRateLimiter",
        "./ai/llmRetryHandler",
        "./domain/prompts/promptBuilder",
        "./domain/services/incrementalAnalysisService",
        "./domain/prompts/refactoringPromptBuilder",
        "./analysis/functionAnalyzer"
      ],
      "intent": "This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis and documentation generation by calling LLM providers (OpenAI/Claude) to generate intelligent insights about codebases.\",\n  \"userVisibleActions\": [\n    \"Receives AI-generated explanations of what the product/codebase does\",\n    \"Gets intelligent insights about code architecture and design patterns\",\n    \"Views AI-generated product documentation with purpose, features, and architecture\",\n    \"Sees automated test plans and suggestions for code improvements\",\n    \"Receives refactoring suggestions for complex functions\",\n    \"Gets incremental analysis updates as code changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls AI providers to analyze entire codebases and generate product purpose summaries\",\n    \"Requests AI analysis of code structure, entry points, and module relationships\",\n    \"Generates enhanced product documentation by analyzing file summaries and module structure\",\n    \"Creates unit test plans by analyzing code coverage and function signatures\",\n    \"Obtains refactoring suggestions for specific functions or code sections\",\n    \"Triggers incremental analysis for file changes without re-analyzing entire codebase\",\n    \"Switches between different LLM providers (OpenAI, Claude, Ollama) based on configuration\",\n    \"Handles rate limiting and retry logic for LLM API calls automatically\",\n    \"Parses and validates LLM responses using predefined schemas\",\n    \"Accesses detailed function metadata and code analysis results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine the product's main purpose and architecture\",\n      \"inputs\": \"CodeAnalysis object containing all analyzed files and their metadata\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, entry points, and key modules\"\n    },\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates AI-powered insights about code quality, patterns, and potential issues\",\n      \"inputs\": \"CodeAnalysis with file information and analysis context\",\n      \"outputs\": \"LLMInsights containing code quality observations, design patterns, complexity issues, and improvement suggestions\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation by analyzing file summaries and module structure\",\n      \"inputs\": \"Array of FileSummary and ModuleSummary objects\",\n      \"outputs\": \"EnhancedProductDocumentation with product overview, architecture, features, and technical details\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Analyzes code to create a test plan identifying untested functions and suggesting test cases\",\n      \"inputs\": \"CodeAnalysis and list of existing test files\",\n      \"outputs\": \"UnitTestPlan with prioritized list of functions to test and suggested test cases\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Analyzes a specific function and provides refactoring recommendations\",\n      \"inputs\": \"Function code, metadata, and surrounding context\",\n      \"outputs\": \"RefactoringSuggestions with complexity analysis, code smells, and specific refactoring steps\"\n    },\n    {\n      \"name\": \"performIncrementalAnalysis\",\n      \"desc\": \"Analyzes changes to specific files without re-analyzing the entire codebase\",\n      \"inputs\": \"Array of changed file paths and full code analysis\",\n      \"outputs\": \"Updated analysis focusing only on changed files and their immediate dependencies\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Makes authenticated API calls to configured LLM provider with rate limiting and retry logic\",\n      \"inputs\": \"Prompt string, expected response schema, and optional provider override\",\n      \"outputs\": \"Parsed and validated response from the LLM matching the specified schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent AI-powered insights. It solves the problem of understanding large codebases by leveraging LLMs to interpret raw code analysis data and generate human-readable explanations, documentation, test plans, and refactoring suggestions. It provides the core AI service layer that transforms technical code metrics into actionable insights for developers.\"\n}\n```"
    },
    {
      "file": "src/logger.ts",
      "role": "Core Logic",
      "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
      "userVisibleActions": [
        "Creates a .shadow/logs directory in the workspace root if it doesn't exist",
        "Writes log entries to a shadow-watch.log file with timestamps",
        "Logs are persistent and can be reviewed to troubleshoot extension behavior"
      ],
      "developerVisibleActions": [
        "Call SWLogger.log() to write timestamped messages to the log file",
        "Call SWLogger.section() to create visual separators in the log with section titles",
        "Logging automatically handles errors silently without crashing the extension",
        "Log files are stored at workspace-root/.shadow/logs/shadow-watch.log"
      ],
      "keyFunctions": [
        {
          "name": "log",
          "desc": "Writes a timestamped message to the shadow-watch.log file",
          "inputs": "message (string): The text to log",
          "outputs": "void (no return value)"
        },
        {
          "name": "section",
          "desc": "Creates a formatted section header in the log file with blank lines for readability",
          "inputs": "title (string): The section heading text",
          "outputs": "void (no return value)"
        },
        {
          "name": "getLogPath",
          "desc": "Determines the file path where logs should be written, creating directories if needed",
          "inputs": "none",
          "outputs": "string | null: The log file path, or null if no workspace is open"
        },
        {
          "name": "ensureDir",
          "desc": "Creates a directory and its parent directories if they don't exist",
          "inputs": "dir (string): The directory path to create",
          "outputs": "void (no return value)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "vscode"
      ],
      "intent": "This file exists to provide a centralized, reliable logging mechanism for debugging and monitoring the extension's behavior, storing logs in a predictable location within the workspace that users can access to troubleshoot issues without interfering with normal extension operation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Creates a .shadow/logs directory in the workspace root if it doesn't exist\",\n    \"Writes log entries to a shadow-watch.log file with timestamps\",\n    \"Logs are persistent and can be reviewed to troubleshoot extension behavior\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call SWLogger.log() to write timestamped messages to the log file\",\n    \"Call SWLogger.section() to create visual separators in the log with section titles\",\n    \"Logging automatically handles errors silently without crashing the extension\",\n    \"Log files are stored at workspace-root/.shadow/logs/shadow-watch.log\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message (string): The text to log\",\n      \"outputs\": \"void (no return value)\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a formatted section header in the log file with blank lines for readability\",\n      \"inputs\": \"title (string): The section heading text\",\n      \"outputs\": \"void (no return value)\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path where logs should be written, creating directories if needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null: The log file path, or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory and its parent directories if they don't exist\",\n      \"inputs\": \"dir (string): The directory path to create\",\n      \"outputs\": \"void (no return value)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, reliable logging mechanism for debugging and monitoring the extension's behavior, storing logs in a predictable location within the workspace that users can access to troubleshoot issues without interfering with normal extension operation.\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is a Visual Studio Code extension that provides AI-powered code analysis and automated documentation generation for software development teams. It analyzes your codebase to identify code quality issues, generate comprehensive documentation, and provide intelligent refactoring recommendations. The extension continuously monitors your workspace, automatically detecting problems like high complexity functions, circular dependencies, orphaned code, and missing test coverage, then presents these findings through interactive visualizations and structured reports.\\n\\nUsers interact with Shadow Watch through VS Code's command palette, sidebar views, and inline editor annotations. The extension integrates with AI providers (OpenAI or Claude) to generate intelligent insights about your codebase architecture, produce product documentation, and create automated tests. All analysis results are presented through multiple interactive views including a problem diagnostics panel, hierarchical tree views for browsing insights, and a product navigator that shows your codebase structure organized by modules and components.\\n\\nShadow Watch enables development workflows focused on code quality improvement, technical debt management, and knowledge capture. It automatically saves all analysis results with timestamps, allowing teams to track code health over time and maintain comprehensive documentation without manual effort. The extension works continuously in the background, re-analyzing code when files change and keeping all views synchronized with the current codebase state.\",\"whatItDoes\":[\"Automatically analyzes code quality and identifies issues like high complexity, large files, and circular dependencies\",\"Generates comprehensive product documentation and architecture insights using AI language models\",\"Creates interactive visualizations of code problems directly in the VS Code editor and Problems panel\",\"Provides hierarchical navigation of analysis results through multiple sidebar tree views\",\"Automatically generates unit tests for functions with AI-powered test planning and validation\",\"Detects and configures test frameworks (Jest, Mocha, Vitest, Pytest) without manual setup\",\"Exports analysis results in multiple formats optimized for AI assistants like Cursor and ChatGPT\",\"Tracks code coverage and identifies untested functions across your codebase\",\"Monitors file changes and automatically re-analyzes modified code\",\"Generates detailed refactoring recommendations with step-by-step implementation guidance\",\"Creates timestamped documentation archives to track codebase evolution over time\",\"Provides search capabilities for AI agents to explore and understand codebases\"],\"userPerspective\":{\"gui\":[\"Command palette commands for triggering workspace or file-specific analysis\",\"Interactive tree views in the sidebar showing analysis results, insights, and documentation hierarchy\",\"Visual problem indicators in the editor with color-coded severity levels\",\"Hover tooltips displaying detailed information about detected issues\",\"Click-to-navigate functionality from tree views to source code locations\",\"Status bar indicators showing analysis progress and extension state\",\"Real-time progress notifications during long-running operations with cancel buttons\",\"Problems panel integration displaying all detected code issues with jump-to-source links\",\"Webview panels for viewing detailed reports and documentation\",\"Context menus for quick access to analysis and documentation commands\"],\"cli\":[\"VS Code command palette commands like 'Shadow Watch: Analyze Workspace'\",\"Commands for generating insights, clearing cache, and switching AI providers\",\"Export commands for saving analysis results to disk in various formats\",\"Test generation commands for creating automated unit tests\",\"Commands for navigating to specific code elements and viewing details\"],\"api\":[\"Integration with OpenAI API for GPT-based code analysis and documentation generation\",\"Integration with Anthropic Claude API for alternative AI-powered analysis\",\"Extensible provider system allowing integration of additional AI services\",\"File system watching API for detecting workspace changes\",\"Analysis result storage API for persisting documentation and insights\"],\"cicd\":[\"Can be integrated into CI/CD pipelines through VS Code automation\",\"Exports analysis results that can be consumed by automated quality gates\",\"Generates machine-readable JSON reports for integration with other tools\",\"Timestamps all analysis runs for tracking quality metrics over time\"]},\"workflowIntegration\":[\"Code review preparation: Generate documentation and identify issues before submitting pull requests\",\"Technical debt management: Identify and prioritize refactoring opportunities based on complexity metrics\",\"Onboarding new team members: Provide AI-generated architecture documentation and codebase overviews\",\"Test coverage improvement: Automatically generate missing tests and validate they execute correctly\",\"Knowledge capture: Maintain up-to-date documentation that evolves with the codebase\",\"Quality monitoring: Track code health metrics across multiple analysis runs\",\"Refactoring planning: Get AI-generated step-by-step guidance for extracting complex functions\",\"Documentation maintenance: Keep product documentation synchronized with code changes\"],\"problemsSolved\":[\"Manual documentation becomes outdated quickly - Shadow Watch automatically generates and updates documentation as code changes\",\"Identifying code quality issues requires expertise - The extension automatically detects complexity, circular dependencies, and other problems\",\"Writing tests is time-consuming - AI-powered test generation creates comprehensive unit tests automatically\",\"Understanding large codebases is difficult - Interactive navigation and AI-generated insights make exploration easier\",\"Tracking code health over time requires manual effort - Timestamped analysis runs create a historical record\",\"Setting up test frameworks is complex - Automatic detection and configuration eliminates manual setup\",\"Refactoring complex code is risky - Detailed step-by-step plans reduce the chance of introducing bugs\",\"Finding relevant code quickly in large projects - Search and navigation tools help locate specific functions and modules\"],\"architecture\":\"Shadow Watch follows a modular architecture organized around core domains: analysis, documentation generation, testing automation, and user interface presentation. The analysis domain performs deep code inspection using TypeScript/JavaScript AST parsing to extract function metadata, complexity metrics, and dependency relationships. This analysis data flows through a caching layer that stores results to avoid redundant processing, then feeds into insight generators that identify code quality issues and refactoring opportunities.\\n\\nThe documentation generation domain integrates with AI language model providers through an abstraction layer that supports both OpenAI and Claude. Rate limiting, retry handling, and response parsing components ensure reliable AI interactions. Documentation requests flow through a prompt building system that constructs specialized queries for different tasks (architecture analysis, test generation, refactoring guidance), then results are formatted into structured Markdown and persisted to timestamped storage directories.\\n\\nThe user interface architecture consists of multiple coordinated views: tree view providers for hierarchical data display, diagnostics providers for inline problem annotations, webview providers for rich content display, and a navigation handler for jumping between code locations. A file watching service monitors workspace changes and triggers appropriate updates across all views, while a progress service provides consistent user feedback during long-running operations. All components communicate through a command registry that maps user actions to appropriate handlers, creating a cohesive user experience across the extension.\",\"titles\":[\"Shadow Watch Extension\",\"Code Analysis Engine\",\"AI Documentation Generator\",\"Test Automation System\",\"Architecture Insights Generator\",\"Product Documentation Generator\",\"Refactoring Recommendation Engine\",\"Code Quality Diagnostics\",\"Interactive Analysis Browser\",\"Insights Tree View\",\"Product Navigator\",\"Unit Test Navigator\",\"Static Analysis Viewer\",\"Reports Tree Provider\",\"File Watcher Service\",\"Incremental Analysis Service\",\"Test Configuration Service\",\"LLM Integration Layer\",\"Rate Limiter\",\"Retry Handler\",\"Response Parser\",\"Provider Factory\",\"Configuration Manager\",\"Navigation Handler\",\"Documentation Formatter\",\"LLM Formatter\",\"Prompt Builder\",\"Test Prompt Builder\",\"Refactoring Prompt Builder\",\"File Cache\",\"File Processor\",\"Analysis Result Repository\",\"Progress Service\",\"Test Generation Service\",\"Test Planning Service\",\"Test Setup Service\",\"Test Validation Service\",\"Test Execution Service\",\"Enhanced Code Analyzer\",\"Function Analyzer\",\"Context Builder\",\"Extension Bootstrapper\",\"Command Registry\",\"Diagnostic Provider\",\"Insight Generator\"],\"descriptions\":[{\"title\":\"Shadow Watch Extension\",\"description\":\"VS Code extension that provides comprehensive code analysis, AI-powered documentation generation, and automated testing capabilities for software development teams\",\"category\":\"feature\"},{\"title\":\"Code Analysis Engine\",\"description\":\"Deep code inspection system that parses TypeScript and JavaScript files to extract function metadata, calculate complexity metrics, map dependencies, and identify code quality issues\",\"category\":\"component\"},{\"title\":\"AI Documentation Generator\",\"description\":\"Integrates with OpenAI and Claude to automatically generate product documentation, architecture insights, and code explanations from analyzed codebases\",\"category\":\"feature\"},{\"title\":\"Test Automation System\",\"description\":\"Comprehensive testing workflow that automatically plans, generates, executes, and validates unit tests using AI analysis and multi-framework support\",\"category\":\"feature\"},{\"title\":\"Architecture Insights Generator\",\"description\":\"Produces high-level architecture documentation showing component relationships, data flows, and system organization using AI analysis\",\"category\":\"feature\"},{\"title\":\"Product Documentation Generator\",\"description\":\"Creates user-facing documentation describing what the application does, how users interact with it, and what problems it solves\",\"category\":\"feature\"},{\"title\":\"Refactoring Recommendation Engine\",\"description\":\"Analyzes complex functions and generates detailed step-by-step refactoring plans with AI-guided extraction instructions\",\"category\":\"feature\"},{\"title\":\"Code Quality Diagnostics\",\"description\":\"Visual problem indicators that appear in the editor and Problems panel showing issues like high complexity, large files, circular dependencies, and missing tests\",\"category\":\"feature\"},{\"title\":\"Interactive Analysis Browser\",\"description\":\"Sidebar tree view that displays complete analysis results organized hierarchically with click-to-navigate functionality\",\"category\":\"feature\"},{\"title\":\"Insights Tree View\",\"description\":\"Displays AI-generated insights, reports, and documentation in a hierarchical tree structure with real-time status updates\",\"category\":\"component\"},{\"title\":\"Product Navigator\",\"description\":\"Shows codebase structure organized by modules, components, and entry points with navigation capabilities\",\"category\":\"feature\"},{\"title\":\"Unit Test Navigator\",\"description\":\"Displays test coverage information and allows navigation to tested and untested functions\",\"category\":\"feature\"},{\"title\":\"Static Analysis Viewer\",\"description\":\"Shows static analysis results including file-level metrics and quality indicators\",\"category\":\"component\"},{\"title\":\"File Watcher Service\",\"description\":\"Monitors workspace for file changes and automatically triggers re-analysis when code is modified\",\"category\":\"component\"},{\"title\":\"Incremental Analysis Service\",\"description\":\"Manages iterative analysis where AI can request additional context through multiple rounds until sufficient information is gathered\",\"category\":\"component\"},{\"title\":\"Test Configuration Service\",\"description\":\"Automatically detects test frameworks in use and configures them without manual user intervention\",\"category\":\"component\"},{\"title\":\"LLM Integration Layer\",\"description\":\"Abstraction layer for integrating multiple AI providers with rate limiting, retry handling, and response parsing\",\"category\":\"component\"},{\"title\":\"Rate Limiter\",\"description\":\"Prevents exceeding API rate limits by throttling requests to AI providers\",\"category\":\"component\"},{\"title\":\"Retry Handler\",\"description\":\"Automatically retries failed AI requests with exponential backoff for transient errors\",\"category\":\"component\"},{\"title\":\"Response Parser\",\"description\":\"Extracts structured data from AI text responses into typed objects for file summaries, module summaries, and documentation\",\"category\":\"component\"},{\"title\":\"Configuration Manager\",\"description\":\"Manages all extension settings with type-safe access and automatic change detection\",\"category\":\"component\"},{\"title\":\"Navigation Handler\",\"description\":\"Handles jumping to code locations including files, functions, and API endpoints with detailed information display\",\"category\":\"component\"},{\"title\":\"Documentation Formatter\",\"description\":\"Transforms analysis and product information into well-structured Markdown documents\",\"category\":\"component\"},{\"title\":\"Prompt Builder\",\"description\":\"Constructs specialized prompts for different AI tasks including analysis, documentation, and test generation\",\"category\":\"component\"},{\"title\":\"File Cache\",\"description\":\"Caches file contents in memory to reduce disk I/O and improve performance\",\"category\":\"component\"},{\"title\":\"Analysis Result Repository\",\"description\":\"Manages saving and organizing analysis results to disk in timestamped directories\",\"category\":\"component\"},{\"title\":\"Progress Service\",\"description\":\"Displays standardized progress notifications during long-running operations with cancellation support\",\"category\":\"component\"},{\"title\":\"Test Generation Service\",\"description\":\"Generates unit tests for functions incrementally using AI with progress feedback\",\"category\":\"component\"},{\"title\":\"Test Planning Service\",\"description\":\"Analyzes code and creates prioritized test plans recommending which functions should be tested\",\"category\":\"component\"},{\"title\":\"Test Setup Service\",\"description\":\"Detects test environment and generates setup plans using AI analysis\",\"category\":\"component\"},{\"title\":\"Test Validation Service\",\"description\":\"Runs generated tests, captures failures, and automatically fixes failing tests using AI\",\"category\":\"component\"},{\"title\":\"Test Execution Service\",\"description\":\"Executes test suites across multiple frameworks and captures results\",\"category\":\"component\"},{\"title\":\"Enhanced Code Analyzer\",\"description\":\"Parses code to extract detailed function metadata including complexity, dependencies, and behavioral hints\",\"category\":\"component\"},{\"title\":\"Context Builder\",\"description\":\"Converts analysis data into formats suitable for AI consumption\",\"category\":\"component\"}],\"relevantFunctions\":[{\"name\":\"analyzeWorkspace\",\"description\":\"Performs comprehensive analysis of entire workspace, detecting issues and generating insights\",\"file\":\"src/extension.ts\",\"module\":\"Extension\"},{\"name\":\"analyzeFile\",\"description\":\"Analyzes a single file for code quality issues and complexity metrics\",\"file\":\"src/extension.ts\",\"module\":\"Extension\"},{\"name\":\"generateInsights\",\"description\":\"Creates AI-powered architecture insights and recommendations from analysis results\",\"file\":\"src/llmIntegration.ts\",\"module\":\"LLM Integration\"},{\"name\":\"generateProductDocs\",\"description\":\"Produces product documentation describing application functionality from code analysis\",\"file\":\"src/llmIntegration.ts\",\"module\":\"LLM Integration\"},{\"name\":\"generateTests\",\"description\":\"Automatically creates unit tests for functions using AI analysis\",\"file\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"module\":\"Test Generation\"},{\"name\":\"planTests\",\"description\":\"Analyzes code and recommends which functions should be tested with priorities\",\"file\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"module\":\"Test Planning\"},{\"name\":\"validateTests\",\"description\":\"Runs generated tests and automatically fixes failures using AI\",\"file\":\"src/domain/services/testing/llmTestValidationService.ts\",\"module\":\"Test Validation\"},{\"name\":\"detectTestEnvironment\",\"description\":\"Identifies test framework in use and checks configuration completeness\",\"file\":\"src/domain/services/testConfigurationService.ts\",\"module\":\"Test Configuration\"},{\"name\":\"analyzeFunction\",\"description\":\"Extracts detailed metadata from functions including complexity and dependencies\",\"file\":\"src/analysis/functionAnalyzer.ts\",\"module\":\"Function Analyzer\"},{\"name\":\"generateRefactoringPlan\",\"description\":\"Creates step-by-step refactoring instructions for complex functions\",\"file\":\"src/domain/prompts/refactoringPromptBuilder.ts\",\"module\":\"Refactoring\"},{\"name\":\"navigateToLocation\",\"description\":\"Handles navigation to specific code locations with automatic scrolling\",\"file\":\"src/domain/handlers/navigationHandler.ts\",\"module\":\"Navigation\"},{\"name\":\"formatDocumentation\",\"description\":\"Transforms raw analysis into structured Markdown documentation\",\"file\":\"src/domain/formatters/documentationFormatter.ts\",\"module\":\"Documentation Formatting\"},{\"name\":\"handleRateLimit\",\"description\":\"Manages API rate limiting to prevent exceeding provider quotas\",\"file\":\"src/ai/llmRateLimiter.ts\",\"module\":\"Rate Limiting\"},{\"name\":\"retryWithBackoff\",\"description\":\"Automatically retries failed AI requests with exponential delay\",\"file\":\"src/ai/llmRetryHandler.ts\",\"module\":\"Retry Handling\"},{\"name\":\"parseResponse\",\"description\":\"Extracts structured data from AI-generated text responses\",\"file\":\"src/ai/llmResponseParser.ts\",\"module\":\"Response Parsing\"},{\"name\":\"watchFiles\",\"description\":\"Monitors workspace for file changes and triggers re-analysis\",\"file\":\"src/domain/services/fileWatcherService.ts\",\"module\":\"File Watching\"},{\"name\":\"processIncremental\",\"description\":\"Manages iterative analysis where AI requests additional context\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\",\"module\":\"Incremental Analysis\"},{\"name\":\"executeTests\",\"description\":\"Runs test suites and captures execution results\",\"file\":\"src/domain/services/testing/testExecutionService.ts\",\"module\":\"Test Execution\"},{\"name\":\"generateInsightsFromAnalysis\",\"description\":\"Identifies code quality issues and generates actionable recommendations\",\"file\":\"src/insightGenerator.ts\",\"module\":\"Insight Generation\"},{\"name\":\"exportForLLM\",\"description\":\"Formats analysis results for consumption by AI assistants like Cursor\",\"file\":\"src/llmFormatter.ts\",\"module\":\"LLM Formatting\"}],\"relevantDataStructures\":[{\"name\":\"AnalysisResult\",\"description\":\"Complete analysis results for a workspace including file metadata, dependencies, and insights\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FileAnalysis\",\"description\":\"Analysis data for a single file including functions, complexity, and quality metrics\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FunctionInfo\",\"description\":\"Metadata about a function including signature, complexity, dependencies, and behavioral hints\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"ProductDocumentation\",\"description\":\"Structured product documentation including overview, features, user perspective, and architecture\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"ArchitectureInsight\",\"description\":\"AI-generated insight about codebase architecture, patterns, or structure\",\"type\":\"interface\",\"file\":\"src/llmIntegration.ts\"},{\"name\":\"TestPlan\",\"description\":\"Prioritized plan for testing functions with recommendations and test areas\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestResult\",\"description\":\"Results of test execution including pass/fail counts, errors, and coverage data\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestSetupPlan\",\"description\":\"Plan for configuring test environment including frameworks, dependencies, and files\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testSetupTypes.ts\"},{\"name\":\"RefactoringPlan\",\"description\":\"Step-by-step plan for refactoring complex functions with extraction instructions\",\"type\":\"interface\",\"file\":\"src/domain/prompts/refactoringPromptBuilder.ts\"},{\"name\":\"Insight\",\"description\":\"Code quality insight describing an issue, severity, and recommendation\",\"type\":\"interface\",\"file\":\"src/insightGenerator.ts\"},{\"name\":\"LLMRequest\",\"description\":\"Request configuration for AI provider including prompt, schema, and timeout\",\"type\":\"interface\",\"file\":\"src/ai/providers/ILLMProvider.ts\"},{\"name\":\"LLMResponse\",\"description\":\"Response from AI provider with generated text or structured JSON\",\"type\":\"interface\",\"file\":\"src/ai/providers/ILLMProvider.ts\"},{\"name\":\"FileRequest\",\"description\":\"Request for specific file content during incremental analysis\",\"type\":\"interface\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\"},{\"name\":\"GrepRequest\",\"description\":\"Request to search codebase for patterns during incremental analysis\",\"type\":\"interface\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\"},{\"name\":\"DiagnosticInfo\",\"description\":\"Visual problem indicator with severity, message, and location\",\"type\":\"interface\",\"file\":\"src/diagnosticsProvider.ts\"},{\"name\":\"NavigationItem\",\"description\":\"Tree view item representing navigable code element with location and metadata\",\"type\":\"class\",\"file\":\"src/productNavigator.ts\"},{\"name\":\"AnalysisTreeItem\",\"description\":\"Tree view item representing analysis result or insight with hierarchy\",\"type\":\"class\",\"file\":\"src/analysisViewer.ts\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main extension entry point that registers all commands and initializes components when VS Code activates the extension\",\"purpose\":\"Coordinates extension activation, command registration, and component initialization\",\"role\":\"Entry point and orchestrator\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"Manages all AI-powered features including documentation generation, insights creation, and analysis formatting\",\"purpose\":\"Integrates AI capabilities into the extension workflow\",\"role\":\"AI feature coordinator\"},{\"path\":\"src/llmService.ts\",\"description\":\"Core service for making AI requests, handling responses, and managing provider communication\",\"purpose\":\"Provides reliable AI request/response handling with error management\",\"role\":\"AI communication layer\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Defines data structures and interfaces for representing code analysis results throughout the system\",\"purpose\":\"Provides type definitions for analysis data\",\"role\":\"Type definitions\"},{\"path\":\"src/insightGenerator.ts\",\"description\":\"Analyzes code metrics to identify quality issues and generate actionable recommendations\",\"purpose\":\"Transforms analysis data into user-facing insights\",\"role\":\"Insight generation\"},{\"path\":\"src/analysisViewer.ts\",\"description\":\"Implements tree view for browsing complete analysis results in the sidebar\",\"purpose\":\"Provides hierarchical navigation of analysis data\",\"role\":\"UI component\"},{\"path\":\"src/insightsTreeView.ts\",\"description\":\"Implements tree view for displaying AI-generated insights and documentation\",\"purpose\":\"Shows AI-powered analysis results in navigable tree structure\",\"role\":\"UI component\"},{\"path\":\"src/productNavigator.ts\",\"description\":\"Implements tree view for navigating codebase structure organized by modules and components\",\"purpose\":\"Provides codebase exploration through hierarchical organization\",\"role\":\"UI component\"},{\"path\":\"src/diagnosticsProvider.ts\",\"description\":\"Creates and displays visual problem indicators in the editor and Problems panel\",\"purpose\":\"Shows code quality issues inline in the editor\",\"role\":\"UI component\"},{\"path\":\"src/domain/bootstrap/extensionBootstrapper.ts\",\"description\":\"Handles complete extension initialization including UI setup and command registration\",\"purpose\":\"Bootstraps all extension components during activation\",\"role\":\"Initialization\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Manages navigation to code locations and displays detailed information about code elements\",\"purpose\":\"Enables jumping to source code from tree views and listings\",\"role\":\"Navigation handler\"},{\"path\":\"src/domain/services/fileWatcherService.ts\",\"description\":\"Monitors workspace for file changes and triggers appropriate updates\",\"purpose\":\"Enables automatic re-analysis when code changes\",\"role\":\"File monitoring\"},{\"path\":\"src/domain/services/incrementalAnalysisService.ts\",\"description\":\"Manages multi-round analysis where AI requests additional context iteratively\",\"purpose\":\"Enables thorough analysis through iterative information gathering\",\"role\":\"Analysis orchestration\"},{\"path\":\"src/domain/services/testConfigurationService.ts\",\"description\":\"Automatically detects and configures test frameworks without manual setup\",\"purpose\":\"Eliminates manual test environment configuration\",\"role\":\"Test setup automation\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Generates unit tests for functions using AI with progress tracking\",\"purpose\":\"Automates test creation with AI assistance\",\"role\":\"Test generation\"},{\"path\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"description\":\"Creates prioritized test plans recommending which functions need testing\",\"purpose\":\"Guides test coverage improvement with AI recommendations\",\"role\":\"Test planning\"},{\"path\":\"src/domain/services/testing/llmTestValidationService.ts\",\"description\":\"Validates generated tests and automatically fixes failures using AI\",\"purpose\":\"Ensures generated tests actually work correctly\",\"role\":\"Test validation\"},{\"path\":\"src/domain/services/testing/testExecutionService.ts\",\"description\":\"Executes test suites across multiple frameworks and captures results\",\"purpose\":\"Runs tests and reports execution outcomes\",\"role\":\"Test execution\"},{\"path\":\"src/analysis/enhancedAnalyzer.ts\",\"description\":\"Performs deep code analysis extracting function metadata, complexity, and dependencies\",\"purpose\":\"Provides detailed code quality metrics\",\"role\":\"Code analysis\"},{\"path\":\"src/analysis/functionAnalyzer.ts\",\"description\":\"Analyzes individual functions to extract signatures, dependencies, and refactoring candidates\",\"purpose\":\"Enables function-level analysis and refactoring guidance\",\"role\":\"Function analysis\"},{\"path\":\"src/domain/prompts/promptBuilder.ts\",\"description\":\"Constructs specialized AI prompts for different analysis and documentation tasks\",\"purpose\":\"Creates effective prompts that produce useful AI responses\",\"role\":\"Prompt engineering\"},{\"path\":\"src/domain/prompts/refactoringPromptBuilder.ts\",\"description\":\"Builds detailed refactoring plans with step-by-step extraction instructions\",\"purpose\":\"Guides complex refactoring with AI-generated plans\",\"role\":\"Refactoring guidance\"},{\"path\":\"src/domain/prompts/testPrompts.ts\",\"description\":\"Creates prompts for test generation, planning, and configuration analysis\",\"purpose\":\"Enables AI-powered test automation\",\"role\":\"Test prompt engineering\"},{\"path\":\"src/domain/formatters/documentationFormatter.ts\",\"description\":\"Transforms analysis results into well-structured Markdown documentation\",\"purpose\":\"Produces readable documentation from analysis data\",\"role\":\"Documentation formatting\"},{\"path\":\"src/ai/llmRateLimiter.ts\",\"description\":\"Manages API rate limiting to prevent exceeding provider quotas\",\"purpose\":\"Ensures reliable AI operations within rate limits\",\"role\":\"Rate limiting\"},{\"path\":\"src/ai/llmRetryHandler.ts\",\"description\":\"Automatically retries failed AI requests with intelligent backoff\",\"purpose\":\"Handles transient failures without user intervention\",\"role\":\"Retry logic\"},{\"path\":\"src/ai/llmResponseParser.ts\",\"description\":\"Extracts structured data from AI-generated text responses\",\"purpose\":\"Converts AI output into usable data structures\",\"role\":\"Response parsing\"},{\"path\":\"src/ai/providers/providerFactory.ts\",\"description\":\"Creates and manages AI provider instances based on configuration\",\"purpose\":\"Enables flexible AI provider selection\",\"role\":\"Provider management\"},{\"path\":\"src/config/configurationManager.ts\",\"description\":\"Manages all extension settings with type-safe access and change detection\",\"purpose\":\"Provides centralized configuration management\",\"role\":\"Configuration\"},{\"path\":\"src/infrastructure/persistence/analysisResultRepository.ts\",\"description\":\"Saves and organizes analysis results to disk in timestamped directories\",\"purpose\":\"Maintains historical record of analysis runs\",\"role\":\"Data persistence\"},{\"path\":\"src/infrastructure/progressService.ts\",\"description\":\"Displays standardized progress notifications during long-running operations\",\"purpose\":\"Provides consistent user feedback for async operations\",\"role\":\"Progress reporting\"},{\"path\":\"src/infrastructure/fileSystem/fileCache.ts\",\"description\":\"Caches file contents in memory to reduce redundant disk reads\",\"purpose\":\"Improves performance through intelligent caching\",\"role\":\"Performance optimization\"},{\"path\":\"src/infrastructure/fileSystem/fileProcessor.ts\",\"description\":\"Provides reusable framework for parallel file processing with filtering\",\"purpose\":\"Enables efficient batch file operations\",\"role\":\"File processing\"}],\"exampleInput\":{\"description\":\"Example analysis configuration and code snippet submitted for analysis\",\"json\":\"{\\\"analysisType\\\":\\\"workspace\\\",\\\"config\\\":{\\\"analyzeOnSave\\\":true,\\\"aiProvider\\\":\\\"openai\\\",\\\"severityThreshold\\\":\\\"warning\\\",\\\"timeout\\\":300000},\\\"codeSnippet\\\":{\\\"file\\\":\\\"src/userService.ts\\\",\\\"content\\\":\\\"export class UserService {\\\\n  async getUser(id: string) {\\\\n    const user = await db.users.findOne(id);\\\\n    if (!user) throw new Error('Not found');\\\\n    return user;\\\\n  }\\\\n}\\\",\\\"language\\\":\\\"typescript\\\"}}\"},\"exampleOutput\":{\"description\":\"Example analysis result showing detected issues, insights, and documentation\",\"json\":\"{\\\"analysisId\\\":\\\"20240115-143022\\\",\\\"timestamp\\\":\\\"2024-01-15T14:30:22.000Z\\\",\\\"summary\\\":{\\\"filesAnalyzed\\\":147,\\\"functionsAnalyzed\\\":892,\\\"issuesFound\\\":23,\\\"testCoverage\\\":67.5},\\\"insights\\\":[{\\\"type\\\":\\\"complexity\\\",\\\"severity\\\":\\\"warning\\\",\\\"file\\\":\\\"src/orderProcessor.ts\\\",\\\"function\\\":\\\"processOrder\\\",\\\"message\\\":\\\"High complexity detected (15 branches)\\\",\\\"recommendation\\\":\\\"Consider extracting order validation logic into separate function\\\",\\\"line\\\":45}],\\\"documentation\\\":{\\\"overview\\\":\\\"User management system that handles authentication, authorization, and profile management\\\",\\\"features\\\":[\\\"User registration and login\\\",\\\"Role-based access control\\\",\\\"Profile editing and preferences\\\"],\\\"architecture\\\":\\\"Layered architecture with service, repository, and controller layers\\\"},\\\"refactoringRecommendations\\\":[{\\\"function\\\":\\\"processOrder\\\",\\\"priority\\\":\\\"high\\\",\\\"reason\\\":\\\"High complexity and multiple responsibilities\\\",\\\"steps\\\":[\\\"Extract validation logic\\\",\\\"Extract payment processing\\\",\\\"Extract notification logic\\\"]}],\\\"testResults\\\":{\\\"totalTests\\\":156,\\\"passed\\\":142,\\\"failed\\\":8,\\\"skipped\\\":6,\\\"coverage\\\":67.5,\\\"uncoveredFunctions\\\":[\\\"handlePaymentFailure\\\",\\\"retryOrder\\\"]}}}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-21T04:29:45.639Z",
    "generatedAtLocal": "11/20/2025, 8:29:45 PM",
    "runId": "product-docs-2025-11-21T04-13-41-053Z"
  }
}