{
  "overview": "Shadow Watch is an AI-powered VS Code extension that provides developers with comprehensive code analysis, automated documentation generation, and intelligent testing capabilities. It analyzes your entire codebase to understand its architecture, identify quality issues, and generate actionable insights—all without leaving your editor. The extension monitors your code continuously, automatically updating its analysis when you save files, and presents findings through an intuitive tree-based interface alongside your familiar VS Code panels.\n\nDevelopers interact with Shadow Watch through multiple integrated views: a sidebar navigator for browsing documentation and analysis results, a dedicated insights panel showing AI-generated recommendations, the Problems panel for diagnostics, and output channels for detailed reports. The extension connects to AI language models (OpenAI GPT or Anthropic Claude) to generate human-readable documentation, suggest refactorings, create test plans, and identify architectural improvements. All analysis results are cached locally for instant access and preserved between sessions.\n\nThe extension transforms static code analysis into actionable development guidance. It identifies circular dependencies, dead code, orphaned files, overly complex functions, and missing test coverage—then provides specific recommendations for improvement. Developers can generate comprehensive test suites with a single command, navigate directly from insights to source code locations, and maintain up-to-date product documentation as their codebase evolves.",
  "whatItDoes": [
    "Analyzes entire codebase architecture and generates AI-powered documentation describing what the application does",
    "Identifies code quality issues including circular dependencies, dead code, large files, and orphaned modules",
    "Generates comprehensive test plans and automatically creates unit tests for functions that lack coverage",
    "Monitors file changes in real-time and automatically updates analysis results when code is saved",
    "Provides AI-generated refactoring recommendations with detailed migration strategies",
    "Creates visual tree-based navigation of code structure, test coverage, and architecture insights",
    "Displays diagnostic warnings and errors in VS Code's Problems panel for quick issue identification",
    "Generates multiple documentation formats optimized for different AI chat interfaces (Cursor, ChatGPT, Claude)",
    "Maps test files to source code to identify untested functions and components",
    "Analyzes function complexity and identifies candidates for refactoring or splitting",
    "Detects entry points and visualizes code flow through the application",
    "Validates test configurations and automatically sets up testing frameworks (Jest, Mocha, Vitest, Pytest)"
  ],
  "userPerspective": {
    "gui": [
      "Browse code analysis results in a hierarchical tree view in the VS Code sidebar",
      "View AI-generated architecture insights and recommendations in a dedicated insights panel",
      "Navigate directly to source code locations by clicking on insights, issues, or analysis results",
      "See diagnostic warnings and errors displayed in VS Code's Problems panel with severity indicators",
      "Monitor analysis progress through status bar indicators and progress notifications",
      "Access detailed test execution results showing pass/fail status for each test file",
      "View comprehensive product documentation generated from codebase analysis",
      "Switch between different AI providers (OpenAI, Claude) through configuration settings",
      "Copy formatted analysis results to clipboard for sharing or pasting into AI chat interfaces",
      "Clear cached analysis data and regenerate insights on demand"
    ],
    "cli": [],
    "api": [],
    "cicd": [
      "Integrate automated code analysis into CI/CD pipelines through command-line execution",
      "Generate and validate test suites as part of automated build processes",
      "Produce documentation artifacts during deployment workflows",
      "Cache analysis results for faster subsequent pipeline runs"
    ]
  },
  "workflowIntegration": [
    "Code review workflow: Analyze changes and identify quality issues before committing",
    "Documentation workflow: Generate and update product documentation as features are developed",
    "Testing workflow: Discover untested code, create test plans, generate tests, and validate coverage",
    "Refactoring workflow: Identify complex functions, receive AI-powered refactoring guidance, and track improvements",
    "Architecture review workflow: Understand codebase structure, detect anti-patterns, and plan improvements",
    "Onboarding workflow: New developers use generated documentation to understand the codebase quickly",
    "Maintenance workflow: Continuously monitor code quality and address issues as they arise"
  ],
  "problemsSolved": [
    "Eliminates manual documentation effort by automatically generating comprehensive product and architecture docs",
    "Reduces time spent understanding unfamiliar codebases through AI-generated architecture insights",
    "Prevents circular dependency bugs by detecting them early in development",
    "Identifies dead code and orphaned files that waste maintenance effort",
    "Reduces technical debt by highlighting overly complex functions that need refactoring",
    "Improves test coverage by automatically discovering untested functions and generating test suites",
    "Saves time navigating large codebases by providing instant jumps from insights to source code",
    "Prevents API rate limit errors when using AI services through automatic throttling and retry logic",
    "Maintains documentation consistency across team members through automated generation",
    "Reduces context switching by integrating all analysis, documentation, and testing tools within VS Code"
  ],
  "architecture": "Shadow Watch is built as a VS Code extension with a modular architecture centered around AI-powered analysis capabilities. The extension initializes through a bootstrapper that orchestrates multiple independent services: file watching, code analysis, insight generation, documentation formatting, and test automation. These services communicate through a centralized configuration manager that tracks user preferences and notifies components when settings change. All analysis results flow through a caching layer that persists data to disk and reloads it instantly when workspaces reopen.\n\nThe AI integration layer abstracts multiple language model providers (OpenAI and Anthropic) behind a unified interface, enabling seamless switching between providers based on user configuration. Rate limiting and retry logic ensure reliable API interactions even under high load or temporary service disruptions. LLM responses are parsed and validated against structured schemas to extract consistent, typed data from natural language outputs. The system implements an iterative analysis workflow where the AI can request additional file contents or grep searches to progressively deepen its understanding of the codebase.\n\nThe user interface layer presents analysis results through multiple coordinated views: tree-based navigators for browsing code structure and insights, diagnostic providers for showing issues in the Problems panel, and webview panels for displaying detailed reports. Navigation handlers allow users to jump directly from any insight or result to the corresponding source code location. The testing subsystem orchestrates an end-to-end workflow from test environment detection through test generation, execution, validation, and automatic fixing of failures. All components are designed to work asynchronously with comprehensive error handling and progress feedback to maintain a responsive user experience.",
  "titles": [
    "Shadow Watch Extension",
    "Code Analysis Engine",
    "AI Documentation Generator",
    "Test Generation System",
    "Insight Generator",
    "Architecture Analyzer",
    "Dependency Tracker",
    "Test Coverage Mapper",
    "Refactoring Advisor",
    "File Watcher",
    "Diagnostics Provider",
    "Product Navigator",
    "Insights Tree View",
    "Analysis Viewer",
    "Test Configuration Service",
    "LLM Integration Layer",
    "Rate Limiter",
    "Response Parser",
    "Retry Handler",
    "Provider Factory",
    "Configuration Manager",
    "Analysis Context Builder",
    "Incremental Analysis Service",
    "Function Extraction Service",
    "Test Planning Service",
    "Test Generation Service",
    "Test Validation Service",
    "Test Execution Service",
    "Navigation Handler",
    "Documentation Formatter",
    "Progress Service",
    "File Cache",
    "File Processor",
    "Analysis Result Repository",
    "Command Registry",
    "Extension Bootstrapper"
  ],
  "descriptions": [
    {
      "title": "Code Analysis Engine",
      "description": "Performs comprehensive static analysis of source code by parsing Abstract Syntax Trees to extract metadata about functions, dependencies, complexity metrics, and code structure. Identifies entry points, maps test coverage, detects circular dependencies, and highlights potential quality issues like large files and dead code.",
      "category": "component"
    },
    {
      "title": "AI Documentation Generator",
      "description": "Leverages language models to automatically generate human-readable documentation from code analysis results. Produces product overviews, architecture descriptions, API documentation, and feature descriptions by understanding code structure and purpose through AI analysis.",
      "category": "feature"
    },
    {
      "title": "Test Generation System",
      "description": "Automates the entire testing workflow from discovering testable functions through generating unit tests, executing them, validating results, and automatically fixing failures. Intelligently prioritizes which functions need testing based on complexity and existing coverage.",
      "category": "feature"
    },
    {
      "title": "Insight Generator",
      "description": "Analyzes code structure to identify actionable insights about code quality, organization patterns, and potential improvements. Generates specific recommendations for refactoring, dependency management, test coverage improvements, and architectural enhancements.",
      "category": "component"
    },
    {
      "title": "Dependency Tracker",
      "description": "Maps relationships between code components to detect circular dependencies, identify orphaned files, and understand code flow through the application. Helps developers visualize how different parts of the codebase interact and depend on each other.",
      "category": "feature"
    },
    {
      "title": "Test Coverage Mapper",
      "description": "Links test files to their corresponding source code files to identify functions and modules that lack test coverage. Provides visibility into testing gaps and helps prioritize where new tests should be written.",
      "category": "feature"
    },
    {
      "title": "Refactoring Advisor",
      "description": "Analyzes code complexity and structure to recommend specific refactoring opportunities. Suggests extracting functions from large files, simplifying complex logic, and breaking down 'god objects' into more maintainable components.",
      "category": "feature"
    },
    {
      "title": "Product Navigator",
      "description": "Provides a tree-based interface for browsing generated product documentation, architecture insights, and analysis results. Allows developers to explore their codebase's structure and navigate directly to relevant code locations.",
      "category": "feature"
    },
    {
      "title": "Real-time File Monitoring",
      "description": "Watches for file saves and document changes throughout the workspace, automatically triggering re-analysis when code is modified. Keeps all analysis results, insights, and documentation synchronized with the latest code state.",
      "category": "feature"
    },
    {
      "title": "Multi-Provider AI Support",
      "description": "Supports multiple AI language model providers including OpenAI GPT and Anthropic Claude, allowing users to choose their preferred provider or switch between them based on needs and availability.",
      "category": "feature"
    },
    {
      "title": "Automatic Rate Limiting",
      "description": "Manages API request throttling to prevent exceeding provider rate limits, tracking quotas independently for different AI services and automatically queuing requests that would exceed limits.",
      "category": "feature"
    },
    {
      "title": "Intelligent Retry Logic",
      "description": "Handles temporary API failures with exponential backoff retry strategies, automatically recovering from transient network issues or service disruptions without user intervention.",
      "category": "feature"
    },
    {
      "title": "Iterative Code Analysis",
      "description": "Enables progressive deepening of code understanding by allowing AI to request additional file contents or grep searches during analysis, gathering context incrementally until sufficient information is available.",
      "category": "workflow"
    },
    {
      "title": "Test Environment Detection",
      "description": "Automatically identifies which testing framework is being used (Jest, Mocha, Vitest, Pytest), validates configuration, detects missing dependencies, and provides setup recommendations to ensure generated tests run successfully.",
      "category": "feature"
    },
    {
      "title": "Batch Test Generation",
      "description": "Generates unit tests in small batches to manage API costs and provide incremental progress feedback. Executes each batch immediately after generation to validate test quality and identify issues early.",
      "category": "workflow"
    },
    {
      "title": "Self-Healing Test Validation",
      "description": "Executes generated tests, detects failures, and automatically attempts to fix broken tests using AI assistance. Provides detailed error reporting and tracks retry attempts until tests pass or maximum attempts are reached.",
      "category": "feature"
    },
    {
      "title": "Multi-Format Output",
      "description": "Formats analysis results and documentation in multiple formats optimized for different AI chat interfaces (Cursor IDE, ChatGPT, Claude), making it easy to continue conversations about code in external AI tools.",
      "category": "feature"
    },
    {
      "title": "Persistent Analysis Caching",
      "description": "Stores all analysis results to disk with timestamp organization, preserving historical analysis runs and enabling instant workspace reopening without re-analysis. Maintains complete audit trail of documentation changes.",
      "category": "feature"
    },
    {
      "title": "Diagnostic Integration",
      "description": "Displays code quality issues, warnings, and recommendations directly in VS Code's Problems panel with appropriate severity levels, enabling quick issue identification and navigation to problem areas.",
      "category": "integration"
    },
    {
      "title": "Direct Code Navigation",
      "description": "Allows users to click on any insight, issue, or analysis result to jump directly to the corresponding source code location in the editor, with automatic cursor positioning and code highlighting.",
      "category": "feature"
    }
  ],
  "relevantFunctions": [
    {
      "name": "activate",
      "description": "Extension entry point that initializes all components when VS Code loads the extension, orchestrating the setup of tree views, commands, file watchers, and AI services",
      "file": "src/extension.ts"
    },
    {
      "name": "analyzeWorkspace",
      "description": "Triggers comprehensive analysis of the entire workspace, scanning all source files, extracting metadata, and generating insights about code structure and quality",
      "file": "src/extension.ts"
    },
    {
      "name": "generateProductDocs",
      "description": "Invokes AI language model to analyze codebase and generate comprehensive product documentation describing what the application does from a user perspective"
    },
    {
      "name": "extractTestableFunctions",
      "description": "Uses AI to scan source files and identify all functions, methods, and classes that should have unit tests, along with their complexity and testability characteristics",
      "file": "src/domain/services/testing/llmFunctionExtractionService.ts"
    },
    {
      "name": "generateTestPlan",
      "description": "Creates prioritized test plans by analyzing functions and determining which ones need testing, organizing them by priority level (critical, high, medium, low)",
      "file": "src/domain/services/testing/llmTestPlanningService.ts"
    },
    {
      "name": "generateTests",
      "description": "Generates unit test code for functions in small batches, immediately executes each batch, and tracks generation progress and success rates",
      "file": "src/domain/services/testing/llmTestGenerationService.ts"
    },
    {
      "name": "validateTests",
      "description": "Runs generated test files, detects failures, and automatically attempts to fix broken tests using AI assistance until they pass or max retry attempts are reached",
      "file": "src/domain/services/testing/llmTestValidationService.ts"
    },
    {
      "name": "analyzeWithLLM",
      "description": "Sends code analysis requests to configured AI provider, handling rate limiting, retries, and response parsing to extract structured insights from natural language responses",
      "file": "src/llmIntegration.ts"
    },
    {
      "name": "parseProductDocumentation",
      "description": "Extracts structured product documentation data from LLM text responses, handling both strict JSON parsing and fallback extraction when responses don't match expected format",
      "file": "src/ai/llmResponseParser.ts"
    },
    {
      "name": "checkRateLimit",
      "description": "Enforces API rate limits by tracking request counts per time window and preventing requests that would exceed provider quotas",
      "file": "src/ai/llmRateLimiter.ts"
    },
    {
      "name": "retryWithBackoff",
      "description": "Implements exponential backoff retry logic for failed API requests, automatically retrying transient errors with increasing delays between attempts",
      "file": "src/ai/llmRetryHandler.ts"
    },
    {
      "name": "navigateToCodeItem",
      "description": "Opens editor to specific file location when user clicks on analysis results, positions cursor at target line/column, and highlights relevant code range",
      "file": "src/domain/handlers/navigationHandler.ts"
    },
    {
      "name": "processIncrementalRequests",
      "description": "Handles iterative analysis by processing file read and grep search requests from AI across multiple iterations until analysis is complete",
      "file": "src/domain/services/incrementalAnalysisService.ts"
    },
    {
      "name": "detectTestFramework",
      "description": "Automatically identifies which testing framework is configured in the project by examining package.json, config files, and existing test patterns",
      "file": "src/domain/services/testConfigurationService.ts"
    },
    {
      "name": "formatDocumentation",
      "description": "Converts raw product documentation data into polished Markdown documents with consistent formatting, sections, and quality indicators",
      "file": "src/domain/formatters/documentationFormatter.ts"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "AnalysisResult",
      "description": "Comprehensive data structure containing all code analysis results including file metadata, function information, dependencies, test mappings, insights, and quality metrics",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "ProductDocumentation",
      "description": "Structured documentation describing what the application does from a user perspective, including overview, features, user interactions, workflows, and architecture",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "TestPlan",
      "description": "Organized structure containing testable functions grouped by priority level (critical, high, medium, low) with metadata about complexity and testability",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestGenerationProgress",
      "description": "Tracks progress through test generation phases including setup, planning, generation, validation, and completion with statistics on test counts and success rates",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestExecutionResult",
      "description": "Contains results from running test files including pass/fail status, execution duration, error messages with stack traces, and overall statistics",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "ArchitectureInsight",
      "description": "AI-generated recommendation about code architecture, quality, or improvements with severity level, category, and specific remediation guidance",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FunctionInfo",
      "description": "Detailed metadata about a function including name, parameters, return type, dependencies, complexity metrics, and relationships to other code",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "CodeDependency",
      "description": "Represents dependency relationships between code files or modules, used to detect circular dependencies and understand code flow",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "TestMapping",
      "description": "Links test files to their corresponding source code files to identify coverage gaps and enable test-to-source navigation",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "LLMProviderConfig",
      "description": "Configuration settings for AI language model providers including API keys, endpoints, model selection, and provider-specific parameters",
      "type": "interface",
      "file": "src/config/configurationManager.ts"
    },
    {
      "name": "TestSetupPlan",
      "description": "Details required test environment setup including framework selection, dependencies to install, configuration files to create, and mock requirements",
      "type": "interface",
      "file": "src/domain/services/testing/types/testSetupTypes.ts"
    },
    {
      "name": "FileAnalysisContext",
      "description": "Context information about analyzed files formatted for LLM consumption, including code content, metadata, and analysis results",
      "type": "interface",
      "file": "src/context/analysisContextBuilder.ts"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Main extension entry point that coordinates all functionality",
      "purpose": "Initializes extension components, registers commands, and manages extension lifecycle",
      "role": "Entry point"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "Core AI integration providing documentation generation and code analysis capabilities",
      "purpose": "Connects to AI language models to generate insights, documentation, and recommendations",
      "role": "Core service"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Defines data structures for code analysis results and metrics",
      "purpose": "Provides type definitions for representing code structure, dependencies, and quality metrics",
      "role": "Data model"
    },
    {
      "path": "src/insightGenerator.ts",
      "description": "Analyzes code to identify quality issues and improvement opportunities",
      "purpose": "Generates actionable insights about code organization, dependencies, and potential problems",
      "role": "Analysis engine"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Orchestrates automated test generation workflow",
      "purpose": "Manages end-to-end process of generating, executing, and validating unit tests",
      "role": "Core service"
    },
    {
      "path": "src/domain/services/testing/llmFunctionExtractionService.ts",
      "description": "Identifies functions that need test coverage",
      "purpose": "Uses AI to discover testable functions and assess their complexity and testability",
      "role": "Analysis service"
    },
    {
      "path": "src/ai/providers/providerFactory.ts",
      "description": "Manages AI provider instantiation and configuration",
      "purpose": "Creates and configures AI language model provider instances based on user settings",
      "role": "Factory"
    },
    {
      "path": "src/config/configurationManager.ts",
      "description": "Centralizes all extension configuration management",
      "purpose": "Provides unified access to user settings and notifies components of configuration changes",
      "role": "Configuration manager"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Handles code navigation from UI interactions",
      "purpose": "Opens files and positions cursor when users click on insights or analysis results",
      "role": "UI handler"
    },
    {
      "path": "src/domain/formatters/documentationFormatter.ts",
      "description": "Formats documentation into polished output",
      "purpose": "Converts raw documentation data into well-organized Markdown documents",
      "role": "Formatter"
    },
    {
      "path": "src/cache.ts",
      "description": "Manages persistent storage of analysis results",
      "purpose": "Caches analysis data to disk for instant workspace reopening and historical tracking",
      "role": "Storage service"
    },
    {
      "path": "src/fileWatcher.ts",
      "description": "Monitors file changes to trigger automatic re-analysis",
      "purpose": "Watches for file saves and updates analysis results when code changes",
      "role": "Event handler"
    }
  ],
  "exampleInput": {
    "description": "Example configuration object that users provide through VS Code settings to configure the extension's behavior, AI provider selection, and analysis parameters",
    "json": "{\"shadowWatch.enabled\":true,\"shadowWatch.autoAnalyze\":true,\"shadowWatch.showInlineHints\":true,\"shadowWatch.llmProvider\":\"openai\",\"shadowWatch.openai.apiKey\":\"sk-proj-...\",\"shadowWatch.openai.model\":\"gpt-4\",\"shadowWatch.openai.maxTokens\":4000,\"shadowWatch.analysisTimeout\":300000,\"shadowWatch.maxFileSize\":1048576,\"shadowWatch.maxLines\":10000,\"shadowWatch.diagnosticSeverity\":\"warning\",\"shadowWatch.outputFormat\":\"cursor\"}"
  },
  "exampleOutput": {
    "description": "Example analysis result object containing comprehensive code analysis data, insights, and documentation generated by the extension",
    "json": "{\"files\":[{\"path\":\"src/api/users.ts\",\"lines\":245,\"functions\":[{\"name\":\"createUser\",\"lineNumber\":15,\"complexity\":3,\"parameters\":[{\"name\":\"userData\",\"type\":\"UserInput\"}],\"returnType\":\"Promise<User>\"}],\"dependencies\":[\"./database\",\"./validation\"],\"hasTests\":true,\"testFile\":\"src/api/users.test.ts\"}],\"insights\":[{\"type\":\"warning\",\"severity\":\"medium\",\"category\":\"complexity\",\"title\":\"High Complexity Function\",\"description\":\"Function 'processUserData' has cyclomatic complexity of 15, consider refactoring\",\"file\":\"src/api/users.ts\",\"line\":42,\"recommendation\":\"Extract validation logic into separate functions\"}],\"dependencies\":[{\"source\":\"src/api/users.ts\",\"target\":\"src/database.ts\",\"type\":\"import\"}],\"testCoverage\":{\"totalFunctions\":127,\"testedFunctions\":98,\"coveragePercentage\":77.2,\"untestedFunctions\":[{\"name\":\"handleEdgeCase\",\"file\":\"src/utils/helpers.ts\",\"line\":156}]},\"productDocumentation\":{\"overview\":\"User management system providing authentication, profile management, and access control\",\"features\":[\"User registration and login\",\"Profile updates and password resets\",\"Role-based access control\"],\"architecture\":\"RESTful API with JWT authentication, PostgreSQL database, and Redis caching layer\"}}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Configure automated testing infrastructure for TypeScript code",
        "Enable unit test execution in a Node.js environment",
        "Support TypeScript-to-JavaScript transformation during test execution",
        "Provide isolated test environment setup and teardown"
      ],
      "summary": "This module provides the testing infrastructure configuration for the project. It sets up Jest as the testing framework with TypeScript support, enabling developers to write and execute unit tests for the codebase.\n\nThe configuration establishes a Node.js test environment and integrates TypeScript preprocessing through ts-jest, allowing tests to be written in TypeScript alongside the source code. This ensures that the testing workflow matches the development workflow and maintains type safety throughout the test suite.\n\nDevelopers can use this configuration to run automated tests, verify code behavior, and maintain code quality through test-driven development practices. The setup provides a foundation for continuous integration and automated testing pipelines.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest testing framework for TypeScript-based unit tests in a Node.js environment",
          "userVisibleActions": [
            "No direct user-visible actions - this is a testing configuration file"
          ],
          "developerVisibleActions": [
            "Developers can run Jest tests against TypeScript files in src and UnitTests directories",
            "Test files matching patterns *.test.ts, *.spec.ts, or files in __tests__ directories are automatically discovered and executed",
            "Code coverage reports are generated in text, lcov, and HTML formats in the coverage directory",
            "Tests run with a 10-second timeout per test case",
            "TypeScript files are automatically transpiled to JavaScript during test execution",
            "Mock VSCode module is available for testing VSCode extension code",
            "Source files in src directory are collected for coverage analysis, excluding test files, declaration files, and mock files"
          ],
          "keyFunctions": [],
          "dependencies": [
            "ts-jest",
            "jest",
            "typescript"
          ],
          "intent": "This file exists to configure the Jest testing framework for a TypeScript project, enabling developers to write and run unit tests with proper TypeScript support, code coverage reporting, and VSCode extension testing capabilities. It solves the problem of setting up a consistent testing environment with TypeScript compilation, module resolution, and coverage collection.",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript-based unit tests in a Node.js environment\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a testing configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can run Jest tests against TypeScript files in src and UnitTests directories\",\n    \"Test files matching patterns *.test.ts, *.spec.ts, or files in __tests__ directories are automatically discovered and executed\",\n    \"Code coverage reports are generated in text, lcov, and HTML formats in the coverage directory\",\n    \"Tests run with a 10-second timeout per test case\",\n    \"TypeScript files are automatically transpiled to JavaScript during test execution\",\n    \"Mock VSCode module is available for testing VSCode extension code\",\n    \"Source files in src directory are collected for coverage analysis, excluding test files, declaration files, and mock files\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript project, enabling developers to write and run unit tests with proper TypeScript support, code coverage reporting, and VSCode extension testing capabilities. It solves the problem of setting up a consistent testing environment with TypeScript compilation, module resolution, and coverage collection.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Automatically manages AI/LLM API rate limits to prevent exceeding provider quotas",
        "Parses unstructured LLM text responses into structured, typed data for file and module summaries",
        "Handles temporary API failures with automatic retry logic and exponential backoff",
        "Tracks rate limits independently for different AI providers (OpenAI, Claude, etc.)",
        "Extracts and formats product documentation from LLM responses with fallback mechanisms",
        "Ensures reliable AI request completion despite network issues or temporary service disruptions"
      ],
      "summary": "This module provides the reliability and safety infrastructure for AI/LLM interactions throughout the application. It ensures that all AI API requests are automatically throttled to stay within provider rate limits, preventing errors and service disruptions. When requests do fail due to temporary issues like network problems or rate limiting, the module automatically retries them with intelligent backoff strategies until they succeed or reach maximum retry attempts.\n\nThe module also handles the critical task of converting unstructured text responses from LLMs into structured, typed data that the application can use. This includes parsing file summaries, module summaries, and product documentation from natural language responses into consistent JSON formats. When strict parsing fails, fallback mechanisms extract useful information to ensure users always receive actionable results.\n\nUsers benefit from seamless, reliable AI interactions without needing to understand the underlying complexity. Rate limiting happens transparently, retries occur automatically, and LLM responses are consistently formatted regardless of how the AI model structures its output. This creates a smooth experience where AI-powered features work reliably even under challenging conditions like high traffic or API instability.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
          "userVisibleActions": [
            "API requests are automatically throttled to prevent rate limit errors",
            "Requests are blocked when rate limits are reached within the time window",
            "Different AI providers (OpenAI, Claude) have independent rate limit tracking"
          ],
          "developerVisibleActions": [
            "Developer checks if a request can be made before calling LLM APIs",
            "Developer records each request to track usage against limits",
            "Developer configures custom rate limits per provider (maxRequests, windowMs)",
            "System automatically cleans up old request history outside the time window",
            "Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute"
          ],
          "keyFunctions": [
            {
              "name": "canMakeRequest",
              "desc": "Checks if a new request is allowed based on recent request history and configured limits",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "boolean - true if request allowed, false if rate limit reached"
            },
            {
              "name": "recordRequest",
              "desc": "Records the timestamp of a request to track usage against rate limits",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "void - updates internal request history"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limit configuration for a specific provider",
              "inputs": "provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}",
              "outputs": "void - updates provider configuration"
            }
          ],
          "dependencies": [],
          "intent": "This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.",
          "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\n  \"userVisibleActions\": [\n    \"API requests are automatically throttled to prevent rate limit errors\",\n    \"Requests are blocked when rate limits are reached within the time window\",\n    \"Different AI providers (OpenAI, Claude) have independent rate limit tracking\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer checks if a request can be made before calling LLM APIs\",\n    \"Developer records each request to track usage against limits\",\n    \"Developer configures custom rate limits per provider (maxRequests, windowMs)\",\n    \"System automatically cleans up old request history outside the time window\",\n    \"Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on recent request history and configured limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean - true if request allowed, false if rate limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records the timestamp of a request to track usage against rate limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"void - updates internal request history\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific provider\",\n      \"inputs\": \"provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Parses and extracts structured information from LLM text responses into typed data structures for file summaries, module summaries, and product documentation.",
          "userVisibleActions": [
            "User receives structured file analysis from unstructured LLM text responses",
            "User gets parsed product documentation with consistent formatting",
            "User sees extracted module summaries with organized information",
            "User receives fallback text extraction when JSON parsing fails"
          ],
          "developerVisibleActions": [
            "Developer calls parseFileSummary() to convert LLM response text into FileSummary objects",
            "Developer calls parseModuleSummary() to extract module-level information from LLM output",
            "Developer calls parseProductDocumentation() to get enhanced product documentation from LLM responses",
            "Developer calls parseLLMInsights() to extract analysis insights from LLM text",
            "Developer receives structured data with fallback extraction when JSON parsing fails",
            "Parser attempts JSON extraction first, then falls back to text pattern matching",
            "Parser handles malformed or incomplete LLM responses gracefully"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into a structured FileSummary object",
              "inputs": "content (string), filePath (string), role (string)",
              "outputs": "FileSummary object with purpose, actions, functions, dependencies"
            },
            {
              "name": "parseModuleSummary",
              "desc": "Extracts module-level information from LLM response",
              "inputs": "content (string), moduleName (string)",
              "outputs": "ModuleSummary object with module details"
            },
            {
              "name": "parseProductDocumentation",
              "desc": "Parses enhanced product documentation from LLM output",
              "inputs": "content (string)",
              "outputs": "EnhancedProductDocumentation object"
            },
            {
              "name": "parseLLMInsights",
              "desc": "Extracts analysis insights and context from LLM responses",
              "inputs": "content (string)",
              "outputs": "LLMInsights object with structured analysis data"
            },
            {
              "name": "extractSection",
              "desc": "Extracts a specific named section from text content",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Extracted section text as string"
            },
            {
              "name": "extractListSection",
              "desc": "Extracts a list/array section from text content",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Array of extracted list items"
            }
          ],
          "dependencies": [
            "../fileDocumentation",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured data types required by the application. It solves the problem of reliably extracting consistent, typed information from potentially varied LLM output formats, with robust fallback mechanisms when the LLM doesn't return perfectly formatted JSON.",
          "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured information from LLM text responses into typed data structures for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"User receives structured file analysis from unstructured LLM text responses\",\n    \"User gets parsed product documentation with consistent formatting\",\n    \"User sees extracted module summaries with organized information\",\n    \"User receives fallback text extraction when JSON parsing fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls parseFileSummary() to convert LLM response text into FileSummary objects\",\n    \"Developer calls parseModuleSummary() to extract module-level information from LLM output\",\n    \"Developer calls parseProductDocumentation() to get enhanced product documentation from LLM responses\",\n    \"Developer calls parseLLMInsights() to extract analysis insights from LLM text\",\n    \"Developer receives structured data with fallback extraction when JSON parsing fails\",\n    \"Parser attempts JSON extraction first, then falls back to text pattern matching\",\n    \"Parser handles malformed or incomplete LLM responses gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a structured FileSummary object\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object with purpose, actions, functions, dependencies\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level information from LLM response\",\n      \"inputs\": \"content (string), moduleName (string)\",\n      \"outputs\": \"ModuleSummary object with module details\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Parses enhanced product documentation from LLM output\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts analysis insights and context from LLM responses\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"LLMInsights object with structured analysis data\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a specific named section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted section text as string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of extracted list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured data types required by the application. It solves the problem of reliably extracting consistent, typed information from potentially varied LLM output formats, with robust fallback mechanisms when the LLM doesn't return perfectly formatted JSON.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles automatic retries of failed AI/LLM API requests with exponential backoff when temporary errors occur",
          "userVisibleActions": [
            "AI requests automatically retry when they fail due to temporary issues like rate limits or network problems",
            "Multiple retry attempts happen transparently without user intervention",
            "Requests eventually succeed after temporary failures are resolved",
            "Requests fail with clear error after maximum retry attempts are exhausted"
          ],
          "developerVisibleActions": [
            "Wrap any LLM API call with retry logic using executeWithRetry method",
            "Configure retry behavior (max attempts, delays, backoff multiplier)",
            "Specify which error types should trigger retries via retryableErrors list",
            "Receive callbacks on each retry attempt with onRetry handler",
            "Get retry metadata (number of attempts) along with successful results",
            "Distinguish between retryable errors (rate limits, timeouts, network) and permanent errors (invalid requests)",
            "Errors classified as non-retryable are thrown immediately without retry attempts"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an async operation with automatic retry logic and exponential backoff",
              "inputs": "operation: async function to execute, options: retry configuration (maxRetries, delays, error types)",
              "outputs": "Promise resolving to operation result, or throws error after retries exhausted"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines if an error should trigger a retry based on error message and configured retryable error patterns",
              "inputs": "error: caught exception, retryableErrors: list of error patterns to match",
              "outputs": "boolean indicating if error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Provides resilience for LLM API calls by automatically handling transient failures like rate limits, network issues, and temporary service unavailability, improving reliability without requiring manual retry logic in calling code",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of failed AI/LLM API requests with exponential backoff when temporary errors occur\",\n  \"userVisibleActions\": [\n    \"AI requests automatically retry when they fail due to temporary issues like rate limits or network problems\",\n    \"Multiple retry attempts happen transparently without user intervention\",\n    \"Requests eventually succeed after temporary failures are resolved\",\n    \"Requests fail with clear error after maximum retry attempts are exhausted\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic using executeWithRetry method\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries via retryableErrors list\",\n    \"Receive callbacks on each retry attempt with onRetry handler\",\n    \"Get retry metadata (number of attempts) along with successful results\",\n    \"Distinguish between retryable errors (rate limits, timeouts, network) and permanent errors (invalid requests)\",\n    \"Errors classified as non-retryable are thrown immediately without retry attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation: async function to execute, options: retry configuration (maxRetries, delays, error types)\",\n      \"outputs\": \"Promise resolving to operation result, or throws error after retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry based on error message and configured retryable error patterns\",\n      \"inputs\": \"error: caught exception, retryableErrors: list of error patterns to match\",\n      \"outputs\": \"boolean indicating if error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API calls by automatically handling transient failures like rate limits, network issues, and temporary service unavailability, improving reliability without requiring manual retry logic in calling code\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Unified interface for interacting with multiple AI language model providers (OpenAI GPT and Anthropic Claude)",
        "Seamless switching between different AI providers based on configuration without changing workflows",
        "Structured JSON output generation from AI models using defined schemas",
        "Automatic request retry logic with exponential backoff for failed API calls",
        "Real-time streaming responses for immediate AI output display",
        "API key validation and configuration checking before processing requests",
        "Automatic extraction and parsing of JSON data from AI responses",
        "AI-suggested file and grep search requests based on analysis needs"
      ],
      "summary": "The AI Providers module serves as the abstraction layer for integrating multiple AI language model services into the application. It provides a standardized interface that allows users to interact with different AI providers (currently OpenAI's GPT models and Anthropic's Claude) transparently, without needing to understand the underlying implementation differences. The module handles provider instantiation, configuration management, and ensures consistent behavior across all supported AI services.\n\nUsers can send messages to AI models and receive intelligent text responses, generate structured JSON outputs based on predefined schemas, and benefit from automatic error handling including retry logic for transient failures. The provider factory pattern enables dynamic selection of the active AI provider based on user configuration, making it easy to switch between OpenAI and Claude depending on preferences or requirements. All AI-powered features in the application leverage this module to deliver consistent, reliable AI interactions regardless of which provider is configured.\n\nThe module emphasizes reliability and user experience through features like streaming response support for real-time output display, automatic configuration validation to catch setup issues early, and intelligent parsing of AI responses to extract structured data. This architecture ensures that as new AI providers become available, they can be integrated seamlessly without disrupting existing user workflows or requiring changes to other parts of the application.",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines the standard interface for all LLM (Large Language Model) provider implementations to ensure consistent AI integration across different providers like OpenAI and Claude.",
          "userVisibleActions": [
            "User receives AI-generated text responses to their queries",
            "User receives structured JSON data from AI models when requesting formatted output",
            "User can work with different AI providers (OpenAI, Claude, custom) transparently without changing their workflow",
            "User gets file and grep search requests suggested by the AI based on analysis needs"
          ],
          "developerVisibleActions": [
            "Developer implements this interface to add support for new LLM providers",
            "Developer checks if an AI provider is configured and ready using isConfigured()",
            "Developer sends text-based requests to AI models with customizable parameters (temperature, max tokens, model selection)",
            "Developer requests structured JSON output from AI models with optional schema validation",
            "Developer receives additional context requests (file reads, grep searches) from AI responses",
            "Developer accesses raw provider responses for debugging or advanced processing",
            "Developer identifies which provider is being used via getName()"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Verifies if the LLM provider has valid credentials and is ready to process requests",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt to the LLM and retrieves a text response with optional configuration like temperature and token limits",
              "inputs": "LLMRequestOptions (messages, model, temperature, maxTokens, systemPrompt, responseFormat)",
              "outputs": "Promise<LLMResponse> containing generated text content, finish reason, model used, and raw response"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt expecting structured JSON output, optionally validated against a schema, with additional file/grep requests",
              "inputs": "LLMRequestOptions and optional schema for validation",
              "outputs": "Promise<StructuredOutputResponse<T>> containing parsed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the identifier of the LLM provider for logging and user display",
              "inputs": "none",
              "outputs": "string with provider name"
            }
          ],
          "dependencies": [],
          "intent": "This interface exists to abstract away differences between various LLM providers (OpenAI, Claude, custom implementations), allowing the codebase to work with any AI provider through a unified API. It solves the problem of vendor lock-in and enables easy switching or addition of new AI providers without changing consuming code. It also standardizes how structured outputs and additional context requests are handled across providers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the standard interface for all LLM (Large Language Model) provider implementations to ensure consistent AI integration across different providers like OpenAI and Claude.\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON data from AI models when requesting formatted output\",\n    \"User can work with different AI providers (OpenAI, Claude, custom) transparently without changing their workflow\",\n    \"User gets file and grep search requests suggested by the AI based on analysis needs\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add support for new LLM providers\",\n    \"Developer checks if an AI provider is configured and ready using isConfigured()\",\n    \"Developer sends text-based requests to AI models with customizable parameters (temperature, max tokens, model selection)\",\n    \"Developer requests structured JSON output from AI models with optional schema validation\",\n    \"Developer receives additional context requests (file reads, grep searches) from AI responses\",\n    \"Developer accesses raw provider responses for debugging or advanced processing\",\n    \"Developer identifies which provider is being used via getName()\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Verifies if the LLM provider has valid credentials and is ready to process requests\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the LLM and retrieves a text response with optional configuration like temperature and token limits\",\n      \"inputs\": \"LLMRequestOptions (messages, model, temperature, maxTokens, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> containing generated text content, finish reason, model used, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt expecting structured JSON output, optionally validated against a schema, with additional file/grep requests\",\n      \"inputs\": \"LLMRequestOptions and optional schema for validation\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> containing parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier of the LLM provider for logging and user display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between various LLM providers (OpenAI, Claude, custom implementations), allowing the codebase to work with any AI provider through a unified API. It solves the problem of vendor lock-in and enables easy switching or addition of new AI providers without changing consuming code. It also standardizes how structured outputs and additional context requests are handled across providers.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with Anthropic's Claude AI models for sending chat requests and receiving AI-generated responses",
          "userVisibleActions": [
            "Sends messages to Claude AI and receives intelligent responses",
            "Generates structured JSON outputs from Claude based on schemas",
            "Automatically retries failed requests with exponential backoff",
            "Validates Claude API configuration before allowing requests",
            "Extracts and parses JSON from Claude's responses automatically"
          ],
          "developerVisibleActions": [
            "Configure Claude API key through configuration manager to enable the provider",
            "Send chat requests with system prompts, conversation history, and model selection",
            "Request structured outputs by providing a JSON schema and receive validated responses",
            "Check if Claude is configured and available before making requests",
            "Handle errors when API key is missing or requests fail",
            "Automatically converts OpenAI-format messages to Claude's format",
            "Receives responses with token usage information and content"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is set up and provider is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a chat completion request to Claude with messages and options",
              "inputs": "LLMRequestOptions with messages, model, maxTokens, systemPrompt",
              "outputs": "LLMResponse with content, model, and token usage"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Sends a request to Claude and ensures the response matches a provided JSON schema",
              "inputs": "LLMRequestOptions plus JSON schema definition",
              "outputs": "StructuredOutputResponse with validated JSON data and metadata"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Claude client with API key from configuration",
              "inputs": "none (reads from config)",
              "outputs": "void (initializes internal client)"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to abstract and implement the specific integration with Anthropic's Claude API, converting between the application's generic LLM interface and Claude's specific API format, handling authentication, request formatting, response parsing, and error handling for Claude-specific operations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for sending chat requests and receiving AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Sends messages to Claude AI and receives intelligent responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Automatically retries failed requests with exponential backoff\",\n    \"Validates Claude API configuration before allowing requests\",\n    \"Extracts and parses JSON from Claude's responses automatically\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through configuration manager to enable the provider\",\n    \"Send chat requests with system prompts, conversation history, and model selection\",\n    \"Request structured outputs by providing a JSON schema and receive validated responses\",\n    \"Check if Claude is configured and available before making requests\",\n    \"Handle errors when API key is missing or requests fail\",\n    \"Automatically converts OpenAI-format messages to Claude's format\",\n    \"Receives responses with token usage information and content\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to Claude with messages and options\",\n      \"inputs\": \"LLMRequestOptions with messages, model, maxTokens, systemPrompt\",\n      \"outputs\": \"LLMResponse with content, model, and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends a request to Claude and ensures the response matches a provided JSON schema\",\n      \"inputs\": \"LLMRequestOptions plus JSON schema definition\",\n      \"outputs\": \"StructuredOutputResponse with validated JSON data and metadata\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude client with API key from configuration\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"void (initializes internal client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract and implement the specific integration with Anthropic's Claude API, converting between the application's generic LLM interface and Claude's specific API format, handling authentication, request formatting, response parsing, and error handling for Claude-specific operations.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Implements the OpenAI API provider to send chat completion requests and handle structured responses using OpenAI's GPT models",
          "userVisibleActions": [
            "Sends messages to OpenAI's GPT models and receives AI-generated responses",
            "Supports structured JSON output format when requested",
            "Processes streaming responses for real-time AI output display",
            "Validates API key configuration before allowing requests",
            "Returns error messages when OpenAI API key is not configured"
          ],
          "developerVisibleActions": [
            "Provides ILLMProvider interface implementation for OpenAI",
            "Automatically initializes OpenAI client with API key from configuration manager",
            "Defaults to 'gpt-4o' model when no model is specified",
            "Sets 5-minute timeout for all OpenAI API requests",
            "Combines system prompts with conversation messages automatically",
            "Extracts and parses JSON from structured responses",
            "Handles streaming responses with token-by-token content delivery",
            "Reports finish reasons (stop, length, content_filter, etc.) from API responses"
          ],
          "keyFunctions": [
            {
              "name": "initialize",
              "desc": "Sets up OpenAI client with API key from configuration",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "isConfigured",
              "desc": "Checks if OpenAI client is ready with valid API key",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "getName",
              "desc": "Returns provider identifier",
              "inputs": "none",
              "outputs": "string 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends chat completion request to OpenAI API with messages and options",
              "inputs": "LLMRequestOptions (model, messages, systemPrompt, responseFormat)",
              "outputs": "Promise<LLMResponse> with content and finish reason"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends request expecting JSON response and parses it into structured data",
              "inputs": "LLMRequestOptions with JSON response format",
              "outputs": "Promise<StructuredOutputResponse> with parsed JSON data"
            },
            {
              "name": "sendStreamingRequest",
              "desc": "Sends streaming request and yields response tokens in real-time",
              "inputs": "LLMRequestOptions",
              "outputs": "AsyncGenerator yielding content chunks and finish reason"
            }
          ],
          "dependencies": [
            "openai",
            "configurationManager",
            "jsonExtractor",
            "ILLMProvider"
          ],
          "intent": "This file exists to integrate OpenAI's GPT models into the application by providing a standardized interface for chat completions, structured outputs, and streaming responses. It solves the problem of communicating with OpenAI's API while abstracting away provider-specific details through the ILLMProvider interface, allowing the application to easily swap AI providers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Implements the OpenAI API provider to send chat completion requests and handle structured responses using OpenAI's GPT models\",\n  \"userVisibleActions\": [\n    \"Sends messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Supports structured JSON output format when requested\",\n    \"Processes streaming responses for real-time AI output display\",\n    \"Validates API key configuration before allowing requests\",\n    \"Returns error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides ILLMProvider interface implementation for OpenAI\",\n    \"Automatically initializes OpenAI client with API key from configuration manager\",\n    \"Defaults to 'gpt-4o' model when no model is specified\",\n    \"Sets 5-minute timeout for all OpenAI API requests\",\n    \"Combines system prompts with conversation messages automatically\",\n    \"Extracts and parses JSON from structured responses\",\n    \"Handles streaming responses with token-by-token content delivery\",\n    \"Reports finish reasons (stop, length, content_filter, etc.) from API responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI client is ready with valid API key\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends chat completion request to OpenAI API with messages and options\",\n      \"inputs\": \"LLMRequestOptions (model, messages, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends request expecting JSON response and parses it into structured data\",\n      \"inputs\": \"LLMRequestOptions with JSON response format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data\"\n    },\n    {\n      \"name\": \"sendStreamingRequest\",\n      \"desc\": \"Sends streaming request and yields response tokens in real-time\",\n      \"inputs\": \"LLMRequestOptions\",\n      \"outputs\": \"AsyncGenerator yielding content chunks and finish reason\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"configurationManager\",\n    \"jsonExtractor\",\n    \"ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to integrate OpenAI's GPT models into the application by providing a standardized interface for chat completions, structured outputs, and streaming responses. It solves the problem of communicating with OpenAI's API while abstracting away provider-specific details through the ILLMProvider interface, allowing the application to easily swap AI providers.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Creates and manages AI language model provider instances (OpenAI and Anthropic/Claude) with lazy initialization and configuration checking",
          "userVisibleActions": [
            "Switches between different AI providers (OpenAI or Claude) based on configuration",
            "Uses the currently configured AI provider for all AI-powered features",
            "Gets error feedback when an unknown AI provider is selected"
          ],
          "developerVisibleActions": [
            "Retrieve a specific AI provider instance by name (openai or claude)",
            "Get the currently configured AI provider based on user settings",
            "Check if a specific AI provider is properly configured with credentials",
            "Get a list of all properly configured AI providers available for use",
            "Providers are created lazily only when first requested to save resources"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns the provider instance for the specified provider type (openai or claude)",
              "inputs": "provider: LLMProvider ('openai' | 'claude')",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the currently configured provider based on user settings",
              "inputs": "none",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks if a provider has valid configuration and credentials",
              "inputs": "provider: LLMProvider ('openai' | 'claude')",
              "outputs": "boolean indicating if provider is ready to use"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns a list of all providers that are properly configured",
              "inputs": "none",
              "outputs": "Array of configured LLMProvider names"
            }
          ],
          "dependencies": [
            "./ILLMProvider",
            "./openAIProvider",
            "./anthropicProvider",
            "../../config/configurationManager"
          ],
          "intent": "Centralizes AI provider creation and management to avoid duplicate instances, enable easy switching between providers, and provide a consistent interface for checking provider availability and configuration status",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI language model provider instances (OpenAI and Anthropic/Claude) with lazy initialization and configuration checking\",\n  \"userVisibleActions\": [\n    \"Switches between different AI providers (OpenAI or Claude) based on configuration\",\n    \"Uses the currently configured AI provider for all AI-powered features\",\n    \"Gets error feedback when an unknown AI provider is selected\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve a specific AI provider instance by name (openai or claude)\",\n    \"Get the currently configured AI provider based on user settings\",\n    \"Check if a specific AI provider is properly configured with credentials\",\n    \"Get a list of all properly configured AI providers available for use\",\n    \"Providers are created lazily only when first requested to save resources\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the provider instance for the specified provider type (openai or claude)\",\n      \"inputs\": \"provider: LLMProvider ('openai' | 'claude')\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the currently configured provider based on user settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a provider has valid configuration and credentials\",\n      \"inputs\": \"provider: LLMProvider ('openai' | 'claude')\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all providers that are properly configured\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of configured LLMProvider names\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and management to avoid duplicate instances, enable easy switching between providers, and provide a consistent interface for checking provider availability and configuration status\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Performs deep static code analysis by parsing Abstract Syntax Trees (AST) to understand code structure and behavior",
        "Extracts comprehensive function-level metadata including signatures, parameters, return types, and dependencies",
        "Analyzes code complexity metrics and identifies behavioral patterns in functions",
        "Maps relationships between functions to show what each function depends on and what depends on it",
        "Identifies conditional logic paths and provides branch coverage information",
        "Detects test-to-source code mappings to understand test coverage relationships",
        "Highlights functions in large files that may benefit from refactoring",
        "Provides insights into how functions interact with application state and external dependencies"
      ],
      "summary": "The analysis module provides comprehensive static code analysis capabilities that help users understand their codebase at a deep structural level. By parsing Abstract Syntax Trees (AST), it extracts detailed metadata about functions, their dependencies, complexity patterns, and behavioral characteristics. Users can leverage this module to gain visibility into how their code is organized, identify potential refactoring opportunities, and understand the relationships between different parts of their codebase.\n\nThe module serves two primary workflows: enhanced analysis for understanding code behavior and complexity, and function-level analysis for refactoring support. Enhanced analysis examines conditional logic branches, dependency patterns, and state interactions to provide insights into code quality and test coverage. Function analysis focuses on extracting detailed information about individual functions within large files, showing their signatures, what they depend on, and what other code depends on them. Together, these capabilities enable users to make informed decisions about code maintenance, refactoring, and quality improvements.\n\nThis module is particularly valuable for developers working with large codebases who need to understand complex function interactions, identify tightly coupled components, or plan refactoring efforts. The analysis results can inform decisions about code splitting, test coverage improvements, and architectural changes by providing clear visibility into the existing code structure and dependencies.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed metadata about functions, branches, dependencies, and behavioral patterns.",
          "userVisibleActions": [
            "Receives detailed analysis of code complexity and behavioral hints",
            "Gets insights into how functions interact with state and dependencies",
            "Views branch coverage information for conditional logic paths",
            "Sees identified test mappings between test files and source code"
          ],
          "developerVisibleActions": [
            "Analyzes TypeScript/JavaScript files using AST parsing to extract function metadata",
            "Detects branches (if/else, switch, ternary) and tracks conditional logic complexity",
            "Profiles function dependencies by tracking imports, function calls, and external references",
            "Identifies state mutations and side effects in function bodies",
            "Generates behavioral hints about function characteristics (pure, async, error-prone)",
            "Maps test files to source code functions for coverage analysis",
            "Falls back to regex-based analysis for non-TypeScript languages",
            "Extracts function content from source files based on line ranges"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes a file and extracts enhanced metadata for all functions",
              "inputs": "filePath: string, content: string, language: string, functions: FunctionInfo[]",
              "outputs": "Map<string, FunctionMetadata>"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis on TypeScript/JavaScript functions",
              "inputs": "filePath: string, content: string, func: FunctionInfo, functionContent: string",
              "outputs": "FunctionMetadata"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Fallback analysis using regex patterns for non-TypeScript languages",
              "inputs": "filePath: string, func: FunctionInfo, functionContent: string, language: string",
              "outputs": "FunctionMetadata"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the text content of a function from a file",
              "inputs": "content: string, startLine: number, endLine: number",
              "outputs": "string"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer"
          ],
          "intent": "This file exists to provide advanced static code analysis beyond basic syntax parsing. It solves the problem of understanding code behavior, complexity, and relationships by using AST parsing to detect branches, dependencies, state mutations, and behavioral patterns. This enables intelligent test generation, code quality assessment, and automated documentation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed metadata about functions, branches, dependencies, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code complexity and behavioral hints\",\n    \"Gets insights into how functions interact with state and dependencies\",\n    \"Views branch coverage information for conditional logic paths\",\n    \"Sees identified test mappings between test files and source code\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes TypeScript/JavaScript files using AST parsing to extract function metadata\",\n    \"Detects branches (if/else, switch, ternary) and tracks conditional logic complexity\",\n    \"Profiles function dependencies by tracking imports, function calls, and external references\",\n    \"Identifies state mutations and side effects in function bodies\",\n    \"Generates behavioral hints about function characteristics (pure, async, error-prone)\",\n    \"Maps test files to source code functions for coverage analysis\",\n    \"Falls back to regex-based analysis for non-TypeScript languages\",\n    \"Extracts function content from source files based on line ranges\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions\",\n      \"inputs\": \"filePath: string, content: string, language: string, functions: FunctionInfo[]\",\n      \"outputs\": \"Map<string, FunctionMetadata>\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions\",\n      \"inputs\": \"filePath: string, content: string, func: FunctionInfo, functionContent: string\",\n      \"outputs\": \"FunctionMetadata\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Fallback analysis using regex patterns for non-TypeScript languages\",\n      \"inputs\": \"filePath: string, func: FunctionInfo, functionContent: string, language: string\",\n      \"outputs\": \"FunctionMetadata\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the text content of a function from a file\",\n      \"inputs\": \"content: string, startLine: number, endLine: number\",\n      \"outputs\": \"string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced static code analysis beyond basic syntax parsing. It solves the problem of understanding code behavior, complexity, and relationships by using AST parsing to detect branches, dependencies, state mutations, and behavioral patterns. This enables intelligent test generation, code quality assessment, and automated documentation.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Extracts detailed function information from large code files to support refactoring analysis and reporting.",
          "userVisibleActions": [
            "Identifies functions in large files that may need refactoring",
            "Provides detailed function information including signatures, dependencies, and responsibilities",
            "Highlights which functions are called by other parts of the codebase (dependents)",
            "Shows what other functions or modules each function depends on"
          ],
          "developerVisibleActions": [
            "Developer runs analysis on a codebase to identify large files",
            "System automatically analyzes all functions in files exceeding a configurable line threshold (default 500 lines)",
            "Developer receives structured function analysis data for each function in large files",
            "System extracts function signatures, metadata, dependencies, and dependent relationships",
            "Developer can use this analysis to inform refactoring decisions and generate refactoring reports",
            "Analysis integrates with existing code analysis infrastructure to build comprehensive function profiles"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in large files and returns detailed function analysis data",
              "inputs": "CodeAnalysis object, optional line threshold for large files (default 500)",
              "outputs": "Array of FunctionAnalysis objects containing detailed function information"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs detailed analysis on a single function including extracting signature, dependencies, and dependent relationships",
              "inputs": "File path, function information object, code analysis object",
              "outputs": "FunctionAnalysis object or null if analysis fails"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves relative file paths to absolute paths for file system access",
              "inputs": "Relative file path, code analysis object",
              "outputs": "Absolute file path string"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to provide deep analysis of functions within large files to support automated refactoring suggestions. It solves the problem of identifying which functions in oversized files should be refactored by extracting their signatures, understanding their dependencies, and mapping their usage patterns across the codebase. This enables developers to make informed decisions about code splitting and module organization.",
          "rawContent": "```json\n{\n  \"purpose\": \"Extracts detailed function information from large code files to support refactoring analysis and reporting.\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Provides detailed function information including signatures, dependencies, and responsibilities\",\n    \"Highlights which functions are called by other parts of the codebase (dependents)\",\n    \"Shows what other functions or modules each function depends on\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer runs analysis on a codebase to identify large files\",\n    \"System automatically analyzes all functions in files exceeding a configurable line threshold (default 500 lines)\",\n    \"Developer receives structured function analysis data for each function in large files\",\n    \"System extracts function signatures, metadata, dependencies, and dependent relationships\",\n    \"Developer can use this analysis to inform refactoring decisions and generate refactoring reports\",\n    \"Analysis integrates with existing code analysis infrastructure to build comprehensive function profiles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in large files and returns detailed function analysis data\",\n      \"inputs\": \"CodeAnalysis object, optional line threshold for large files (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing detailed function information\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function including extracting signature, dependencies, and dependent relationships\",\n      \"inputs\": \"File path, function information object, code analysis object\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file system access\",\n      \"inputs\": \"Relative file path, code analysis object\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions within large files to support automated refactoring suggestions. It solves the problem of identifying which functions in oversized files should be refactored by extracting their signatures, understanding their dependencies, and mapping their usage patterns across the codebase. This enables developers to make informed decisions about code splitting and module organization.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "Automatic code analysis and architecture insights generation",
        "AI-powered product documentation generation from source code",
        "Visual tree-based browsing of code analysis results and insights",
        "Real-time diagnostic reporting in VS Code's Problems panel",
        "Intelligent caching of analysis results for instant workspace reopening",
        "File change monitoring with automatic re-analysis on save",
        "LLM-optimized code context formatting for AI chat interfaces",
        "Code quality metrics including complexity, maintainability, and risk assessment",
        "Dependency tracking and circular dependency detection",
        "Test coverage mapping and uncovered function identification",
        "Entry point detection and code flow visualization",
        "Dead code and orphaned file detection",
        "Large file and 'god object' identification",
        "File search and content exploration for iterative LLM-based analysis",
        "Multi-format output optimized for different LLM interfaces (Cursor, ChatGPT, etc.)"
      ],
      "summary": "This is the core VS Code extension module for Shadow Watch, an AI-powered code analysis and documentation tool. It provides developers with comprehensive insights into their codebase's architecture, quality, and maintainability through automated analysis and AI-generated documentation. The extension monitors code changes in real-time and automatically updates analysis results when files are saved.\n\nUsers interact with Shadow Watch through multiple VS Code interface components: a sidebar tree view for browsing analysis results, an insights panel for AI-generated recommendations, the Problems panel for diagnostics, and output channels for detailed reports. The extension analyzes code structure, tracks dependencies, identifies potential issues (circular dependencies, orphaned files, large files, dead code), and generates actionable recommendations. It also creates comprehensive product documentation by understanding the purpose and architecture of the codebase.\n\nThe module integrates deeply with LLM capabilities to provide intelligent analysis beyond simple static code inspection. Results are cached for performance and formatted for optimal consumption by various LLM interfaces. Users can navigate directly from insights to source code locations, view hierarchical breakdowns of their project structure, see test coverage gaps, and receive severity-categorized issues with specific remediation guidance. The extension supports iterative analysis workflows where users can search code, view file contents, and explore relationships between components.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view interface for browsing and exploring code analysis results in VS Code",
          "userVisibleActions": [
            "View a hierarchical tree of code analysis results in the sidebar",
            "See project statistics (file count, function count, complexity metrics)",
            "Browse analyzed files organized by directory structure",
            "Click on files to see their functions and entry points",
            "Click on functions to jump to their location in the code",
            "See file-level metrics (lines of code, complexity, function count)",
            "View entry points and their relationships",
            "See 'No analysis available' message when no analysis has been run",
            "Expand/collapse sections to drill down into analysis details"
          ],
          "developerVisibleActions": [
            "Tree view updates automatically when new analysis is available",
            "Analysis data is received from the analyzer module",
            "Tree items are organized into categories: statistics, files, functions, entry points",
            "Each tree item can be clicked to trigger navigation or reveal more details",
            "File paths are resolved and displayed relative to workspace",
            "Icons and descriptions enhance visual presentation of analysis data"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the tree view with new analysis results",
              "inputs": "CodeAnalysis object or null",
              "outputs": "void (triggers tree refresh)"
            },
            {
              "name": "refresh",
              "desc": "Forces the tree view to reload and redisplay all items",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the visual representation of a tree item",
              "inputs": "AnalysisItem element",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node (or root items if none specified)",
              "inputs": "optional AnalysisItem element",
              "outputs": "Promise of AnalysisItem array"
            },
            {
              "name": "getRootItems",
              "desc": "Generates top-level tree items (statistics, files, functions, entry points)",
              "inputs": "none",
              "outputs": "Array of AnalysisItem"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Creates tree items showing project-wide metrics",
              "inputs": "none",
              "outputs": "Array of AnalysisItem with statistics"
            },
            {
              "name": "getFilesItems",
              "desc": "Organizes analyzed files into a directory tree structure",
              "inputs": "none",
              "outputs": "Array of AnalysisItem representing files and directories"
            },
            {
              "name": "getFileDetails",
              "desc": "Shows functions and metrics for a specific file",
              "inputs": "AnalysisItem representing a file",
              "outputs": "Array of AnalysisItem with file details"
            }
          ],
          "dependencies": [
            "vscode",
            "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
            "path"
          ],
          "intent": "This file exists to provide developers with a navigable, visual representation of their codebase analysis results directly within VS Code's sidebar, making it easy to explore code structure, complexity, and relationships without leaving the editor",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for browsing and exploring code analysis results in VS Code\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"See project statistics (file count, function count, complexity metrics)\",\n    \"Browse analyzed files organized by directory structure\",\n    \"Click on files to see their functions and entry points\",\n    \"Click on functions to jump to their location in the code\",\n    \"See file-level metrics (lines of code, complexity, function count)\",\n    \"View entry points and their relationships\",\n    \"See 'No analysis available' message when no analysis has been run\",\n    \"Expand/collapse sections to drill down into analysis details\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when new analysis is available\",\n    \"Analysis data is received from the analyzer module\",\n    \"Tree items are organized into categories: statistics, files, functions, entry points\",\n    \"Each tree item can be clicked to trigger navigation or reveal more details\",\n    \"File paths are resolved and displayed relative to workspace\",\n    \"Icons and descriptions enhance visual presentation of analysis data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void (triggers tree refresh)\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces the tree view to reload and redisplay all items\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the visual representation of a tree item\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node (or root items if none specified)\",\n      \"inputs\": \"optional AnalysisItem element\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level tree items (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing project-wide metrics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem with statistics\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes analyzed files into a directory tree structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem representing files and directories\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Shows functions and metrics for a specific file\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"Array of AnalysisItem with file details\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide developers with a navigable, visual representation of their codebase analysis results directly within VS Code's sidebar, making it easy to explore code structure, complexity, and relationships without leaving the editor\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
          "userVisibleActions": [
            "View analysis of codebase structure including file counts, line counts, and function counts",
            "See identification of large files that may need refactoring",
            "View detected orphaned files that aren't imported anywhere",
            "See entry points in the codebase",
            "View duplicate code detection results",
            "See function-level risk assessments (high/medium/low)",
            "View function dependencies including database, HTTP, filesystem, and other external services",
            "See test coverage mapping showing which tests cover which source files and functions",
            "View uncovered functions that lack tests",
            "See code quality metrics including complexity scores and maintainability ratings"
          ],
          "developerVisibleActions": [
            "Import and use CodeAnalysis interface to structure analysis results",
            "Access file metadata including lines of code, functions per file, and cyclomatic complexity",
            "Query function metadata including parameters, return types, visibility, and documentation",
            "Track function branches (if/else/switch/loop/exception handling)",
            "Analyze dependencies by type (database, HTTP, filesystem, cache, etc.)",
            "Monitor state mutations (assignments, modifications, deletions)",
            "Map source files to their corresponding test files",
            "Identify untested functions and areas lacking coverage",
            "Access duplicate code groups with similarity scores",
            "Use caching mechanism to speed up repeated analyses",
            "Query import relationships between files",
            "Get entry point detection results"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main interface representing complete codebase analysis results",
              "inputs": "N/A (interface definition)",
              "outputs": "Structure containing totalFiles, totalLines, totalFunctions, largeFiles, file list, function list, imports, orphaned files, entry points, duplicates, and optional enhanced metadata"
            },
            {
              "name": "FunctionMetadata",
              "desc": "Detailed metadata about a single function including complexity, dependencies, and risk",
              "inputs": "N/A (interface definition)",
              "outputs": "Structure with symbolName, file, parameters, returnType, visibility, docstring, branches, dependencies, state mutations, risk level, and line numbers"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source code to test files and identifies coverage gaps",
              "inputs": "N/A (interface definition)",
              "outputs": "Maps from source files to test files, functions to test names, and list of uncovered functions"
            },
            {
              "name": "DuplicateGroup",
              "desc": "Groups duplicate or similar code blocks together",
              "inputs": "N/A (interface definition)",
              "outputs": "Array of duplicate instances with similarity score and total duplicate lines"
            },
            {
              "name": "QualityMetrics",
              "desc": "Provides code quality scores and ratings",
              "inputs": "N/A (interface definition)",
              "outputs": "Overall score, complexity score, maintainability rating, test coverage percentage, and documentation completeness"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache (AnalysisCache)"
          ],
          "intent": "This file exists to provide a comprehensive type system for code analysis results, enabling developers to understand codebase structure, quality, dependencies, test coverage, and potential issues. It serves as the contract between analysis tools and their consumers, ensuring consistent and structured representation of code metrics, function metadata, dependency tracking, and quality assessments.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View analysis of codebase structure including file counts, line counts, and function counts\",\n    \"See identification of large files that may need refactoring\",\n    \"View detected orphaned files that aren't imported anywhere\",\n    \"See entry points in the codebase\",\n    \"View duplicate code detection results\",\n    \"See function-level risk assessments (high/medium/low)\",\n    \"View function dependencies including database, HTTP, filesystem, and other external services\",\n    \"See test coverage mapping showing which tests cover which source files and functions\",\n    \"View uncovered functions that lack tests\",\n    \"See code quality metrics including complexity scores and maintainability ratings\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access file metadata including lines of code, functions per file, and cyclomatic complexity\",\n    \"Query function metadata including parameters, return types, visibility, and documentation\",\n    \"Track function branches (if/else/switch/loop/exception handling)\",\n    \"Analyze dependencies by type (database, HTTP, filesystem, cache, etc.)\",\n    \"Monitor state mutations (assignments, modifications, deletions)\",\n    \"Map source files to their corresponding test files\",\n    \"Identify untested functions and areas lacking coverage\",\n    \"Access duplicate code groups with similarity scores\",\n    \"Use caching mechanism to speed up repeated analyses\",\n    \"Query import relationships between files\",\n    \"Get entry point detection results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface representing complete codebase analysis results\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Structure containing totalFiles, totalLines, totalFunctions, largeFiles, file list, function list, imports, orphaned files, entry points, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function including complexity, dependencies, and risk\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Structure with symbolName, file, parameters, returnType, visibility, docstring, branches, dependencies, state mutations, risk level, and line numbers\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test files and identifies coverage gaps\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Maps from source files to test files, functions to test names, and list of uncovered functions\"\n    },\n    {\n      \"name\": \"DuplicateGroup\",\n      \"desc\": \"Groups duplicate or similar code blocks together\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Array of duplicate instances with similarity score and total duplicate lines\"\n    },\n    {\n      \"name\": \"QualityMetrics\",\n      \"desc\": \"Provides code quality scores and ratings\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Overall score, complexity score, maintainability rating, test coverage percentage, and documentation completeness\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file exists to provide a comprehensive type system for code analysis results, enabling developers to understand codebase structure, quality, dependencies, test coverage, and potential issues. It serves as the contract between analysis tools and their consumers, ensuring consistent and structured representation of code metrics, function metadata, dependency tracking, and quality assessments.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration",
          "userVisibleActions": [
            "Analysis results are loaded instantly from cache when reopening a workspace",
            "Cached analysis automatically expires after 24 hours to ensure freshness",
            "Cache is stored in a hidden .shadowwatch-cache directory"
          ],
          "developerVisibleActions": [
            "Store code analysis results to avoid re-analyzing unchanged code",
            "Retrieve previously cached analysis when workspace is reopened",
            "Clear all cached data to force fresh analysis",
            "Cache automatically invalidates after 24 hours",
            "Cache files are created in the storage path with base64-encoded workspace names"
          ],
          "keyFunctions": [
            {
              "name": "getCacheKey",
              "desc": "Generates a safe filename identifier for a workspace",
              "inputs": "workspaceRoot (string)",
              "outputs": "base64-encoded workspace path (string)"
            },
            {
              "name": "get",
              "desc": "Retrieves cached analysis data if it exists and is less than 24 hours old",
              "inputs": "workspaceRoot (string)",
              "outputs": "CodeAnalysis object or null if not found/expired"
            },
            {
              "name": "set",
              "desc": "Saves code analysis results to disk with current timestamp",
              "inputs": "workspaceRoot (string), data (CodeAnalysis)",
              "outputs": "void (Promise)"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis files from the cache directory",
              "inputs": "none",
              "outputs": "void (Promise)"
            },
            {
              "name": "ensureCacheDir",
              "desc": "Creates the cache directory if it doesn't exist",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "Improves extension performance by caching expensive code analysis operations, allowing instant results when reopening workspaces and preventing redundant analysis of unchanged code, while ensuring data freshness through automatic expiration",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration\",\n  \"userVisibleActions\": [\n    \"Analysis results are loaded instantly from cache when reopening a workspace\",\n    \"Cached analysis automatically expires after 24 hours to ensure freshness\",\n    \"Cache is stored in a hidden .shadowwatch-cache directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Store code analysis results to avoid re-analyzing unchanged code\",\n    \"Retrieve previously cached analysis when workspace is reopened\",\n    \"Clear all cached data to force fresh analysis\",\n    \"Cache automatically invalidates after 24 hours\",\n    \"Cache files are created in the storage path with base64-encoded workspace names\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier for a workspace\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"base64-encoded workspace path (string)\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis data if it exists and is less than 24 hours old\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"CodeAnalysis object or null if not found/expired\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves code analysis results to disk with current timestamp\",\n      \"inputs\": \"workspaceRoot (string), data (CodeAnalysis)\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"ensureCacheDir\",\n      \"desc\": \"Creates the cache directory if it doesn't exist\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis operations, allowing instant results when reopening workspaces and preventing redundant analysis of unchanged code, while ensuring data freshness through automatic expiration\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Manages diagnostic messages (warnings, errors, info) displayed in VS Code's Problems panel based on code insights",
          "userVisibleActions": [
            "User sees diagnostic messages appear in the Problems panel when issues are detected",
            "User sees warnings, errors, or informational messages inline in their code editor with squiggly underlines",
            "User can click on diagnostic messages to navigate to the problematic line of code",
            "User sees diagnostics organized by file in the Problems panel",
            "User sees 'Shadow Watch' as the source of diagnostic messages",
            "User sees diagnostics cleared when issues are resolved or analysis is reset"
          ],
          "developerVisibleActions": [
            "Developer triggers diagnostic updates by providing insights from code analysis",
            "Developer can update diagnostics for all files at once with a batch of insights",
            "Developer can update diagnostics for a specific file individually",
            "Developer can clear all diagnostics from the Problems panel",
            "Developer sees diagnostics automatically grouped by file path",
            "Developer controls diagnostic severity levels (error, warning, info) through insight severity",
            "Developer provides insight metadata (file path, line number, description, severity) to generate diagnostics"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Updates all diagnostics across multiple files based on provided insights",
              "inputs": "Array of Insight objects containing file paths, line numbers, and descriptions",
              "outputs": "void - displays diagnostics in VS Code Problems panel"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostics for a specific file only",
              "inputs": "VS Code URI of the file and array of Insight objects for that file",
              "outputs": "void - displays diagnostics for the specific file"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostics from the Problems panel",
              "inputs": "none",
              "outputs": "void - clears all displayed diagnostics"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts an insight into a VS Code diagnostic message with proper formatting and severity",
              "inputs": "Insight object with description, line number, and severity",
              "outputs": "VS Code Diagnostic object ready for display"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources when the diagnostics provider is no longer needed",
              "inputs": "none",
              "outputs": "void - releases diagnostic collection resources"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "This file exists to bridge between code analysis results (insights) and VS Code's native diagnostics system, translating detected issues into user-friendly messages that appear in the Problems panel and inline in the editor, making code quality issues immediately visible to developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages diagnostic messages (warnings, errors, info) displayed in VS Code's Problems panel based on code insights\",\n  \"userVisibleActions\": [\n    \"User sees diagnostic messages appear in the Problems panel when issues are detected\",\n    \"User sees warnings, errors, or informational messages inline in their code editor with squiggly underlines\",\n    \"User can click on diagnostic messages to navigate to the problematic line of code\",\n    \"User sees diagnostics organized by file in the Problems panel\",\n    \"User sees 'Shadow Watch' as the source of diagnostic messages\",\n    \"User sees diagnostics cleared when issues are resolved or analysis is reset\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers diagnostic updates by providing insights from code analysis\",\n    \"Developer can update diagnostics for all files at once with a batch of insights\",\n    \"Developer can update diagnostics for a specific file individually\",\n    \"Developer can clear all diagnostics from the Problems panel\",\n    \"Developer sees diagnostics automatically grouped by file path\",\n    \"Developer controls diagnostic severity levels (error, warning, info) through insight severity\",\n    \"Developer provides insight metadata (file path, line number, description, severity) to generate diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across multiple files based on provided insights\",\n      \"inputs\": \"Array of Insight objects containing file paths, line numbers, and descriptions\",\n      \"outputs\": \"void - displays diagnostics in VS Code Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file only\",\n      \"inputs\": \"VS Code URI of the file and array of Insight objects for that file\",\n      \"outputs\": \"void - displays diagnostics for the specific file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - clears all displayed diagnostics\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic message with proper formatting and severity\",\n      \"inputs\": \"Insight object with description, line number, and severity\",\n      \"outputs\": \"VS Code Diagnostic object ready for display\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources when the diagnostics provider is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - releases diagnostic collection resources\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge between code analysis results (insights) and VS Code's native diagnostics system, translating detected issues into user-friendly messages that appear in the Problems panel and inline in the editor, making code quality issues immediately visible to developers.\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "This is the main extension entry point that initializes and orchestrates all VSCode extension components, registers commands, and manages the extension lifecycle.",
          "userVisibleActions": [
            "Analyze code files to generate insights about architecture and dependencies",
            "View code insights in a tree view panel showing project structure",
            "Copy formatted code context to clipboard for LLM interactions",
            "Navigate to specific code locations from insights",
            "See status updates in the status bar during analysis",
            "Refresh analysis results manually",
            "Clear cached analysis data",
            "View diagnostics and warnings in the problems panel",
            "Navigate through product documentation structure",
            "Access analysis results through webview panels"
          ],
          "developerVisibleActions": [
            "Extension activates when VSCode starts or workspace is opened",
            "File watcher monitors code changes and triggers automatic re-analysis",
            "Configuration changes reload extension settings",
            "Analysis results are cached to improve performance",
            "Commands are registered and available in command palette",
            "Status bar shows current analysis state and errors",
            "Tree view updates automatically when code changes",
            "Diagnostics are published when issues are detected",
            "LLM integration formats code for external AI tools",
            "Error handling captures and displays extension failures"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Initializes the extension, bootstraps all components, registers commands, and sets up event handlers",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "void"
            },
            {
              "name": "deactivate",
              "desc": "Cleans up resources when the extension is deactivated",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Triggers full workspace analysis and updates all views with results",
              "inputs": "none (uses workspace context)",
              "outputs": "Promise<void>"
            },
            {
              "name": "handleCopyToClipboard",
              "desc": "Formats and copies selected code insights to clipboard for LLM use",
              "inputs": "treeItem: TreeItem",
              "outputs": "Promise<void>"
            },
            {
              "name": "handleNavigateToCode",
              "desc": "Opens the editor and navigates to the code location associated with an insight",
              "inputs": "treeItem: TreeItem",
              "outputs": "Promise<void>"
            },
            {
              "name": "handleRefresh",
              "desc": "Manually triggers re-analysis of the workspace and refreshes all views",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "handleClearCache",
              "desc": "Clears the analysis cache and triggers a fresh analysis",
              "inputs": "none",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler",
            "./productNavigator"
          ],
          "intent": "This file exists to serve as the central coordination point for the entire VSCode extension. It solves the problem of managing complex extension initialization, component dependencies, command registration, and lifecycle management. It ensures all extension features are properly initialized, connected, and accessible to users through VSCode's command palette, tree views, and other UI elements.",
          "rawContent": "```json\n{\n  \"purpose\": \"This is the main extension entry point that initializes and orchestrates all VSCode extension components, registers commands, and manages the extension lifecycle.\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights about architecture and dependencies\",\n    \"View code insights in a tree view panel showing project structure\",\n    \"Copy formatted code context to clipboard for LLM interactions\",\n    \"Navigate to specific code locations from insights\",\n    \"See status updates in the status bar during analysis\",\n    \"Refresh analysis results manually\",\n    \"Clear cached analysis data\",\n    \"View diagnostics and warnings in the problems panel\",\n    \"Navigate through product documentation structure\",\n    \"Access analysis results through webview panels\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or workspace is opened\",\n    \"File watcher monitors code changes and triggers automatic re-analysis\",\n    \"Configuration changes reload extension settings\",\n    \"Analysis results are cached to improve performance\",\n    \"Commands are registered and available in command palette\",\n    \"Status bar shows current analysis state and errors\",\n    \"Tree view updates automatically when code changes\",\n    \"Diagnostics are published when issues are detected\",\n    \"LLM integration formats code for external AI tools\",\n    \"Error handling captures and displays extension failures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, bootstraps all components, registers commands, and sets up event handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when the extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers full workspace analysis and updates all views with results\",\n      \"inputs\": \"none (uses workspace context)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleCopyToClipboard\",\n      \"desc\": \"Formats and copies selected code insights to clipboard for LLM use\",\n      \"inputs\": \"treeItem: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleNavigateToCode\",\n      \"desc\": \"Opens the editor and navigates to the code location associated with an insight\",\n      \"inputs\": \"treeItem: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleRefresh\",\n      \"desc\": \"Manually triggers re-analysis of the workspace and refreshes all views\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleClearCache\",\n      \"desc\": \"Clears the analysis cache and triggers a fresh analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file exists to serve as the central coordination point for the entire VSCode extension. It solves the problem of managing complex extension initialization, component dependencies, command registration, and lifecycle management. It ensures all extension features are properly initialized, connected, and accessible to users through VSCode's command palette, tree views, and other UI elements.\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and code search (grep) functionality to enable iterative analysis of codebases by LLM agents",
          "userVisibleActions": [
            "View file contents from the workspace when requested by the LLM",
            "See search results when the LLM queries for code patterns across files",
            "Receive organized file listings grouped by folders with line counts",
            "Get context around matched lines (before/after lines) in search results"
          ],
          "developerVisibleActions": [
            "Request specific files by path to analyze their contents",
            "Search for code patterns using grep with optional file type filters",
            "Limit search results to prevent overwhelming responses",
            "Receive structured data about files (path, content, line count, existence status)",
            "Get matches with line numbers and surrounding context for better understanding",
            "Process requests through a unified LLMRequest interface supporting both file and grep operations"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Organizes files into a hierarchical folder structure with metadata",
              "inputs": "Array of file objects with path, lines, and language",
              "outputs": "Formatted string showing files grouped by folders with sorting"
            },
            {
              "name": "readFile",
              "desc": "Reads and returns the contents of a specific file",
              "inputs": "FileRequest with file path and optional reason",
              "outputs": "FileResponse with content, line count, and existence status"
            },
            {
              "name": "grepFiles",
              "desc": "Searches for patterns across files with optional filtering and result limiting",
              "inputs": "GrepRequest with pattern, optional file pattern filter, max results, and reason",
              "outputs": "GrepResponse with matches including file paths, line numbers, content, and context"
            },
            {
              "name": "processRequest",
              "desc": "Routes requests to appropriate handler based on request type",
              "inputs": "LLMRequest (either FileRequest or GrepRequest)",
              "outputs": "FileResponse or GrepResponse depending on request type"
            },
            {
              "name": "formatResponse",
              "desc": "Converts response objects into human-readable formatted strings",
              "inputs": "FileResponse or GrepResponse",
              "outputs": "Formatted string presentation of the response"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to bridge the gap between LLM agents and file system access, allowing AI to iteratively explore and analyze code by requesting specific files or searching for patterns. It solves the problem of providing structured, controlled access to workspace files for LLM-driven code analysis without exposing the entire codebase at once.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and code search (grep) functionality to enable iterative analysis of codebases by LLM agents\",\n  \"userVisibleActions\": [\n    \"View file contents from the workspace when requested by the LLM\",\n    \"See search results when the LLM queries for code patterns across files\",\n    \"Receive organized file listings grouped by folders with line counts\",\n    \"Get context around matched lines (before/after lines) in search results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path to analyze their contents\",\n    \"Search for code patterns using grep with optional file type filters\",\n    \"Limit search results to prevent overwhelming responses\",\n    \"Receive structured data about files (path, content, line count, existence status)\",\n    \"Get matches with line numbers and surrounding context for better understanding\",\n    \"Process requests through a unified LLMRequest interface supporting both file and grep operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes files into a hierarchical folder structure with metadata\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files grouped by folders with sorting\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads and returns the contents of a specific file\",\n      \"inputs\": \"FileRequest with file path and optional reason\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches for patterns across files with optional filtering and result limiting\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern filter, max results, and reason\",\n      \"outputs\": \"GrepResponse with matches including file paths, line numbers, content, and context\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Routes requests to appropriate handler based on request type\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"formatResponse\",\n      \"desc\": \"Converts response objects into human-readable formatted strings\",\n      \"inputs\": \"FileResponse or GrepResponse\",\n      \"outputs\": \"Formatted string presentation of the response\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM agents and file system access, allowing AI to iteratively explore and analyze code by requesting specific files or searching for patterns. It solves the problem of providing structured, controlled access to workspace files for LLM-driven code analysis without exposing the entire codebase at once.\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces and types for organizing code documentation at file, module, and product levels",
          "userVisibleActions": [
            "No direct user-visible actions - this is a type definition file",
            "Indirectly enables structured documentation that users can browse"
          ],
          "developerVisibleActions": [
            "Import and use FileSummary interface to structure individual file documentation",
            "Import and use ModuleSummary interface to group related files into modules",
            "Import and use EnhancedProductDocumentation interface to create product-level documentation",
            "Use defined types to ensure consistent documentation structure across the codebase",
            "Reference role types (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface) when categorizing files"
          ],
          "keyFunctions": [
            {
              "name": "FileSummary",
              "desc": "Interface defining how individual file documentation should be structured",
              "inputs": "file path, role, purpose, actions, functions, dependencies, intent",
              "outputs": "Type constraint for file-level documentation objects"
            },
            {
              "name": "ModuleSummary",
              "desc": "Interface defining how module-level documentation should be structured",
              "inputs": "module path, type, capabilities, summary, files, endpoints, commands, workers",
              "outputs": "Type constraint for module-level documentation objects"
            },
            {
              "name": "EnhancedProductDocumentation",
              "desc": "Interface defining how product-level documentation should be structured",
              "inputs": "overview, user perspectives, workflows, architecture, diagrams, structured data",
              "outputs": "Type constraint for product-level documentation objects"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "This file exists to establish a consistent, hierarchical documentation structure for the entire codebase. It solves the problem of organizing code documentation at multiple levels (file, module, product) with clear separation between user-facing and developer-facing information. It enables automated documentation generation tools to produce standardized output.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and types for organizing code documentation at file, module, and product levels\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a type definition file\",\n    \"Indirectly enables structured documentation that users can browse\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use FileSummary interface to structure individual file documentation\",\n    \"Import and use ModuleSummary interface to group related files into modules\",\n    \"Import and use EnhancedProductDocumentation interface to create product-level documentation\",\n    \"Use defined types to ensure consistent documentation structure across the codebase\",\n    \"Reference role types (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface) when categorizing files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"FileSummary\",\n      \"desc\": \"Interface defining how individual file documentation should be structured\",\n      \"inputs\": \"file path, role, purpose, actions, functions, dependencies, intent\",\n      \"outputs\": \"Type constraint for file-level documentation objects\"\n    },\n    {\n      \"name\": \"ModuleSummary\",\n      \"desc\": \"Interface defining how module-level documentation should be structured\",\n      \"inputs\": \"module path, type, capabilities, summary, files, endpoints, commands, workers\",\n      \"outputs\": \"Type constraint for module-level documentation objects\"\n    },\n    {\n      \"name\": \"EnhancedProductDocumentation\",\n      \"desc\": \"Interface defining how product-level documentation should be structured\",\n      \"inputs\": \"overview, user perspectives, workflows, architecture, diagrams, structured data\",\n      \"outputs\": \"Type constraint for product-level documentation objects\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a consistent, hierarchical documentation structure for the entire codebase. It solves the problem of organizing code documentation at multiple levels (file, module, product) with clear separation between user-facing and developer-facing information. It enables automated documentation generation tools to produce standardized output.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file saves and triggers automatic code analysis when files are saved in the workspace",
          "userVisibleActions": [
            "Code is automatically analyzed when a file is saved (if 'analyze on save' is enabled)",
            "Analysis results appear in the diagnostics panel after saving a file",
            "Insights tree view updates automatically after file changes",
            "Analysis is debounced to avoid running too frequently on rapid saves"
          ],
          "developerVisibleActions": [
            "FileWatcher can be started and stopped to control automatic analysis",
            "Analysis is triggered by document save events",
            "Multiple rapid saves are debounced into a single analysis after a delay",
            "Analysis respects configuration settings (analyzeOnSave, debounceDelay)",
            "Analysis can be manually triggered on demand for specific files",
            "Service tracks analysis state to prevent concurrent analyses",
            "Errors during file watching are logged and handled gracefully"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins monitoring file saves and enables automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops monitoring file saves and disables automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "triggerAnalysis",
              "desc": "Manually initiates code analysis for a specific file",
              "inputs": "filePath (string)",
              "outputs": "Promise<void>"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save events and schedules debounced analysis",
              "inputs": "document (vscode.TextDocument)",
              "outputs": "void"
            },
            {
              "name": "scheduleAnalysis",
              "desc": "Debounces analysis requests to avoid running too frequently",
              "inputs": "filePath (string)",
              "outputs": "void"
            },
            {
              "name": "runAnalysis",
              "desc": "Executes the full analysis pipeline and updates diagnostics",
              "inputs": "filePath (string)",
              "outputs": "Promise<void>"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources and stops the file watcher",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "ConfigurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic code analysis triggered by file saves, eliminating the need for users to manually request analysis. It solves the problem of keeping code insights and diagnostics up-to-date as developers work, while preventing performance issues through debouncing and state tracking.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file saves and triggers automatic code analysis when files are saved in the workspace\",\n  \"userVisibleActions\": [\n    \"Code is automatically analyzed when a file is saved (if 'analyze on save' is enabled)\",\n    \"Analysis results appear in the diagnostics panel after saving a file\",\n    \"Insights tree view updates automatically after file changes\",\n    \"Analysis is debounced to avoid running too frequently on rapid saves\"\n  ],\n  \"developerVisibleActions\": [\n    \"FileWatcher can be started and stopped to control automatic analysis\",\n    \"Analysis is triggered by document save events\",\n    \"Multiple rapid saves are debounced into a single analysis after a delay\",\n    \"Analysis respects configuration settings (analyzeOnSave, debounceDelay)\",\n    \"Analysis can be manually triggered on demand for specific files\",\n    \"Service tracks analysis state to prevent concurrent analyses\",\n    \"Errors during file watching are logged and handled gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins monitoring file saves and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops monitoring file saves and disables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Manually initiates code analysis for a specific file\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and schedules debounced analysis\",\n      \"inputs\": \"document (vscode.TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"scheduleAnalysis\",\n      \"desc\": \"Debounces analysis requests to avoid running too frequently\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"runAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline and updates diagnostics\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources and stops the file watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic code analysis triggered by file saves, eliminating the need for users to manually request analysis. It solves the problem of keeping code insights and diagnostics up-to-date as developers work, while preventing performance issues through debouncing and state tracking.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code structure and generates actionable insights about code quality, organization, and potential issues",
          "userVisibleActions": [
            "See warnings about large files exceeding 500 lines",
            "View alerts for orphaned files with no dependencies",
            "Receive notifications about missing entry points in the project",
            "Get warnings about circular dependency patterns",
            "See alerts for 'god objects' (files with too many responsibilities)",
            "View suggestions for dead code that may be unused",
            "Receive recommendations for file organization improvements",
            "Get notified about complex functions that need refactoring"
          ],
          "developerVisibleActions": [
            "Pass CodeAnalysis object to generate insights for entire codebase",
            "Generate file-specific insights by providing file path",
            "Receive structured Insight objects with severity levels (error/warning/info)",
            "Access categorized insights with titles, descriptions, and actionable suggestions",
            "Get code snippets and line numbers for each identified issue",
            "Filter insights by category (Code Organization, Maintainability, etc.)",
            "View unique insight IDs for tracking and deduplication"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Analyzes entire codebase and returns all detected code quality issues and recommendations",
              "inputs": "CodeAnalysis object containing file and function information",
              "outputs": "Array of Insight objects with severity, category, and suggestions"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Analyzes a specific file and returns insights relevant only to that file",
              "inputs": "CodeAnalysis object and file path string",
              "outputs": "Array of Insight objects specific to the requested file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Identifies files exceeding recommended line count thresholds",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for oversized files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Finds files that have no dependencies or relationships with other files",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for isolated files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Validates presence of required entry point files in the project",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Detects potential circular dependency patterns between files",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for circular references"
            },
            {
              "name": "checkGodObjects",
              "desc": "Identifies files with excessive responsibilities or complexity",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for over-complex files"
            },
            {
              "name": "checkDeadCode",
              "desc": "Finds code that may be unused or unreachable",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for potentially dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Evaluates project structure and file placement patterns",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for organizational improvements"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Analyzes individual functions for complexity issues",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of Insight objects for complex functions"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, architectural problems, and opportunities for refactoring. It acts as the intelligence layer that interprets code metrics and patterns to provide meaningful recommendations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code structure and generates actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"See warnings about large files exceeding 500 lines\",\n    \"View alerts for orphaned files with no dependencies\",\n    \"Receive notifications about missing entry points in the project\",\n    \"Get warnings about circular dependency patterns\",\n    \"See alerts for 'god objects' (files with too many responsibilities)\",\n    \"View suggestions for dead code that may be unused\",\n    \"Receive recommendations for file organization improvements\",\n    \"Get notified about complex functions that need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Pass CodeAnalysis object to generate insights for entire codebase\",\n    \"Generate file-specific insights by providing file path\",\n    \"Receive structured Insight objects with severity levels (error/warning/info)\",\n    \"Access categorized insights with titles, descriptions, and actionable suggestions\",\n    \"Get code snippets and line numbers for each identified issue\",\n    \"Filter insights by category (Code Organization, Maintainability, etc.)\",\n    \"View unique insight IDs for tracking and deduplication\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all detected code quality issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with severity, category, and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights relevant only to that file\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that have no dependencies or relationships with other files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry point files in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular references\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with excessive responsibilities or complexity\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for over-complex files\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds code that may be unused or unreachable\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potentially dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file placement patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organizational improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes individual functions for complexity issues\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, architectural problems, and opportunities for refactoring. It acts as the intelligence layer that interprets code metrics and patterns to provide meaningful recommendations.\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VS Code that displays AI-generated insights, documentation, test results, and analysis reports for the codebase",
          "userVisibleActions": [
            "View AI-generated insights about code quality, architecture, and improvements in a tree structure",
            "See status indicators showing when documentation, insights, or tests are being generated",
            "Click on insight items to view detailed explanations and suggestions",
            "Access generated product documentation through the tree view",
            "View unit test generation status and results",
            "Open analysis reports (workspace, product, architecture, unit test) directly from the tree",
            "See timestamps showing when each report or insight was last generated",
            "Refresh the insights view to update displayed information",
            "Navigate to specific code locations by clicking on insights with file references",
            "View collapsed/expanded sections for different types of insights (product docs, insights, analysis)",
            "See progress spinners while AI is generating content",
            "Access quick actions like 'Generate Product Docs', 'Generate Insights', or 'Run Analysis' from tree items"
          ],
          "developerVisibleActions": [
            "Tree view automatically refreshes when new insights are generated",
            "Insights are organized hierarchically by category (documentation, code insights, test results, analysis)",
            "Persisted state maintains report paths and timestamps across VS Code sessions",
            "LLM service integration provides AI-generated insights and documentation",
            "Tree items have contextual commands and icons based on their type and status",
            "Report files are opened in the editor when user clicks on report items",
            "Tree supports collapsible sections with different states (idle, generating, complete)",
            "Status updates trigger automatic tree data refresh events",
            "Integration with static analysis viewer for detailed code analysis"
          ],
          "keyFunctions": [
            {
              "name": "getTreeItem",
              "desc": "Converts an insight or status item into a displayable tree item with icon, label, and command",
              "inputs": "TreeItem element",
              "outputs": "vscode.TreeItem with display properties"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for tree hierarchy - top-level sections or insights within sections",
              "inputs": "Optional parent TreeItem",
              "outputs": "Array of TreeItem children or Promise of children"
            },
            {
              "name": "updateInsights",
              "desc": "Updates the displayed insights and refreshes the tree view",
              "inputs": "Array of Insight objects",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "setProductDocsStatus",
              "desc": "Updates the status of product documentation generation (idle/generating/complete)",
              "inputs": "Status string and optional timestamp",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "setInsightsStatus",
              "desc": "Updates the status of insights generation (idle/generating/complete)",
              "inputs": "Status string and optional timestamp",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "setUnitTestStatus",
              "desc": "Updates the status of unit test generation (idle/generating/complete)",
              "inputs": "Status string and optional timestamp",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "setAnalysisStatus",
              "desc": "Updates the status of code analysis (idle/complete)",
              "inputs": "Status string and optional timestamp",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "setReportPath",
              "desc": "Sets the file path for a generated report and stores it persistently",
              "inputs": "File path string and optional timestamp",
              "outputs": "void - saves to workspace state"
            },
            {
              "name": "setWorkspaceReportPath",
              "desc": "Sets the file path for workspace analysis report",
              "inputs": "File path string and optional timestamp",
              "outputs": "void - saves to workspace state"
            },
            {
              "name": "setProductReportPath",
              "desc": "Sets the file path for product documentation report",
              "inputs": "File path string and optional timestamp",
              "outputs": "void - saves to workspace state"
            },
            {
              "name": "setArchitectureReportPath",
              "desc": "Sets the file path for architecture analysis report",
              "inputs": "File path string and optional timestamp",
              "outputs": "void - saves to workspace state"
            },
            {
              "name": "setUnitTestReportPath",
              "desc": "Sets the file path for unit test report",
              "inputs": "File path string and optional timestamp",
              "outputs": "void - saves to workspace state"
            },
            {
              "name": "refresh",
              "desc": "Manually triggers a refresh of the entire tree view",
              "inputs": "None",
              "outputs": "void - fires tree data change event"
            },
            {
              "name": "setLLMService",
              "desc": "Connects an LLM service instance to enable AI-generated insights",
              "inputs": "LLMService instance",
              "outputs": "void"
            },
            {
              "name": "setLLMInsights",
              "desc": "Updates the AI-generated insights to display in the tree",
              "inputs": "LLMInsights object",
              "outputs": "void - triggers tree refresh"
            },
            {
              "name": "loadPersistedState",
              "desc": "Restores saved report paths and timestamps from previous VS Code sessions",
              "inputs": "None",
              "outputs": "Promise<void> - validates files still exist"
            },
            {
              "name": "openReport",
              "desc": "Opens a generated report file in the VS Code editor",
              "inputs": "File path string",
              "outputs": "Promise<void> - displays document"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator",
            "./llmFormatter",
            "./llmService"
          ],
          "intent": "This file exists to provide users with a visual, organized interface to view AI-generated code insights, documentation, test results, and analysis reports within VS Code's sidebar. It solves the problem of presenting complex AI analysis results in an accessible, navigable tree structure that persists across sessions and updates in real-time as new insights are generated.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated insights, documentation, test results, and analysis reports for the codebase\",\n  \"userVisibleActions\": [\n    \"View AI-generated insights about code quality, architecture, and improvements in a tree structure\",\n    \"See status indicators showing when documentation, insights, or tests are being generated\",\n    \"Click on insight items to view detailed explanations and suggestions\",\n    \"Access generated product documentation through the tree view\",\n    \"View unit test generation status and results\",\n    \"Open analysis reports (workspace, product, architecture, unit test) directly from the tree\",\n    \"See timestamps showing when each report or insight was last generated\",\n    \"Refresh the insights view to update displayed information\",\n    \"Navigate to specific code locations by clicking on insights with file references\",\n    \"View collapsed/expanded sections for different types of insights (product docs, insights, analysis)\",\n    \"See progress spinners while AI is generating content\",\n    \"Access quick actions like 'Generate Product Docs', 'Generate Insights', or 'Run Analysis' from tree items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when new insights are generated\",\n    \"Insights are organized hierarchically by category (documentation, code insights, test results, analysis)\",\n    \"Persisted state maintains report paths and timestamps across VS Code sessions\",\n    \"LLM service integration provides AI-generated insights and documentation\",\n    \"Tree items have contextual commands and icons based on their type and status\",\n    \"Report files are opened in the editor when user clicks on report items\",\n    \"Tree supports collapsible sections with different states (idle, generating, complete)\",\n    \"Status updates trigger automatic tree data refresh events\",\n    \"Integration with static analysis viewer for detailed code analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an insight or status item into a displayable tree item with icon, label, and command\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem with display properties\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for tree hierarchy - top-level sections or insights within sections\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of TreeItem children or Promise of children\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the status of insights generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the status of unit test generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of code analysis (idle/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and stores it persistently\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setWorkspaceReportPath\",\n      \"desc\": \"Sets the file path for workspace analysis report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setProductReportPath\",\n      \"desc\": \"Sets the file path for product documentation report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setArchitectureReportPath\",\n      \"desc\": \"Sets the file path for architecture analysis report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setUnitTestReportPath\",\n      \"desc\": \"Sets the file path for unit test report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Manually triggers a refresh of the entire tree view\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void - fires tree data change event\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Connects an LLM service instance to enable AI-generated insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the AI-generated insights to display in the tree\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved report paths and timestamps from previous VS Code sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void> - validates files still exist\"\n    },\n    {\n      \"name\": \"openReport\",\n      \"desc\": \"Opens a generated report file in the VS Code editor\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"Promise<void> - displays document\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide users with a visual, organized interface to view AI-generated code insights, documentation, test results, and analysis reports within VS Code's sidebar. It solves the problem of presenting complex AI analysis results in an accessible, navigable tree structure that persists across sessions and updates in real-time as new insights are generated.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view interface for browsing and exploring AI-generated architecture insights about the codebase",
          "userVisibleActions": [
            "View AI-generated architecture insights in a tree structure in the sidebar",
            "Browse insights organized by categories (purpose, architecture, behavior, patterns, API, technical debt, security, performance, maintainability, dependencies)",
            "Click on insight items to open related files or documentation",
            "See real-time updates when insights.json or PROJECT_PURPOSE.md files change",
            "Navigate to source code locations from insight items",
            "View empty state prompts when no insights are available",
            "Refresh insights view manually via refresh command"
          ],
          "developerVisibleActions": [
            "Tree view automatically watches .shadow/insights.json for changes and refreshes",
            "Tree view watches .shadow/docs/PROJECT_PURPOSE.md for purpose changes",
            "File changes trigger automatic tree data refresh",
            "Insights data is loaded from .shadow directory structure",
            "Click handlers open files at specific line numbers when available",
            "Tree items show icons, descriptions, and tooltips based on insight types",
            "Empty directories are created automatically (.shadow, .shadow/docs)",
            "TreeItem collapsible states control expansion behavior"
          ],
          "keyFunctions": [
            {
              "name": "setInsights",
              "desc": "Updates the insights data displayed in the tree view and triggers a refresh",
              "inputs": "insights: LLMInsights object containing analysis results",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts an InsightItem into a VS Code TreeItem for display",
              "inputs": "element: InsightItem to convert",
              "outputs": "vscode.TreeItem with label, icon, tooltip, and command"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for the tree view hierarchy",
              "inputs": "element?: InsightItem (undefined for root level)",
              "outputs": "Array of InsightItem objects or empty array"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Configures automatic file watching for insights.json and PROJECT_PURPOSE.md changes",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Manually triggers a refresh of the tree view display",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "openFile",
              "desc": "Opens a file in the editor at a specific line when user clicks an insight item",
              "inputs": "filePath: string, line?: number",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "LLMInsights from ./llmService",
            "path",
            "fs",
            "FileWatcherService from ./domain/services/fileWatcherService"
          ],
          "intent": "This file exists to provide developers with an interactive, hierarchical view of AI-generated codebase insights within VS Code's sidebar. It solves the problem of making complex architecture analysis results easily browsable and navigable, with automatic updates when analysis results change, enabling developers to quickly understand code structure, patterns, and issues without manually reading through analysis files.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for browsing and exploring AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View AI-generated architecture insights in a tree structure in the sidebar\",\n    \"Browse insights organized by categories (purpose, architecture, behavior, patterns, API, technical debt, security, performance, maintainability, dependencies)\",\n    \"Click on insight items to open related files or documentation\",\n    \"See real-time updates when insights.json or PROJECT_PURPOSE.md files change\",\n    \"Navigate to source code locations from insight items\",\n    \"View empty state prompts when no insights are available\",\n    \"Refresh insights view manually via refresh command\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically watches .shadow/insights.json for changes and refreshes\",\n    \"Tree view watches .shadow/docs/PROJECT_PURPOSE.md for purpose changes\",\n    \"File changes trigger automatic tree data refresh\",\n    \"Insights data is loaded from .shadow directory structure\",\n    \"Click handlers open files at specific line numbers when available\",\n    \"Tree items show icons, descriptions, and tooltips based on insight types\",\n    \"Empty directories are created automatically (.shadow, .shadow/docs)\",\n    \"TreeItem collapsible states control expansion behavior\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data displayed in the tree view and triggers a refresh\",\n      \"inputs\": \"insights: LLMInsights object containing analysis results\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem for display\",\n      \"inputs\": \"element: InsightItem to convert\",\n      \"outputs\": \"vscode.TreeItem with label, icon, tooltip, and command\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for the tree view hierarchy\",\n      \"inputs\": \"element?: InsightItem (undefined for root level)\",\n      \"outputs\": \"Array of InsightItem objects or empty array\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Configures automatic file watching for insights.json and PROJECT_PURPOSE.md changes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Manually triggers a refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"openFile\",\n      \"desc\": \"Opens a file in the editor at a specific line when user clicks an insight item\",\n      \"inputs\": \"filePath: string, line?: number\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"LLMInsights from ./llmService\",\n    \"path\",\n    \"fs\",\n    \"FileWatcherService from ./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with an interactive, hierarchical view of AI-generated codebase insights within VS Code's sidebar. It solves the problem of making complex architecture analysis results easily browsable and navigable, with automatic updates when analysis results change, enabling developers to quickly understand code structure, patterns, and issues without manually reading through analysis files.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different output formats optimized for various LLM interfaces and human readability",
          "userVisibleActions": [
            "Receives formatted architecture issues grouped by severity (errors, warnings, info)",
            "Sees issues organized with visual indicators (🔴 for errors, ⚠️ for warnings, ℹ️ for info)",
            "Gets actionable guidance on how to address detected issues",
            "Receives output optimized for their chosen LLM interface (Cursor, ChatGPT, or generic)",
            "Sees compact summaries when requesting condensed output",
            "Views file paths and line numbers where issues occur",
            "Gets context about what each issue means and why it matters"
          ],
          "developerVisibleActions": [
            "Developer calls formatInsights() to convert raw insights into formatted text",
            "Developer specifies output format: 'cursor', 'chatgpt', 'compact', or 'generic'",
            "Developer receives formatted markdown text ready to display or send to LLM",
            "Developer gets insights grouped and sorted by severity automatically",
            "Developer sees file locations and affected code patterns in the output",
            "Developer receives actionable suggestions and next steps included in the output"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Main entry point that routes insights to the appropriate formatter based on specified format",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "Formatted string ready for display or LLM consumption"
            },
            {
              "name": "formatForCursor",
              "desc": "Formats insights specifically for Cursor IDE with severity grouping, emoji indicators, and actionable guidance",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown-formatted string optimized for Cursor"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Formats insights for ChatGPT with conversational tone and context about being a codebase analysis",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown-formatted string optimized for ChatGPT"
            },
            {
              "name": "formatCompact",
              "desc": "Formats insights in a condensed format with just essential information and counts",
              "inputs": "insights: Insight[]",
              "outputs": "Compact markdown string with summary statistics"
            },
            {
              "name": "formatGeneric",
              "desc": "Formats insights in a generic markdown format suitable for any LLM or documentation",
              "inputs": "insights: Insight[]",
              "outputs": "Generic markdown-formatted string"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats a single insight with location, message, and suggestion details for Cursor",
              "inputs": "insight: Insight",
              "outputs": "Formatted string for one insight"
            },
            {
              "name": "formatInsightForChatGPT",
              "desc": "Formats a single insight with conversational style for ChatGPT",
              "inputs": "insight: Insight",
              "outputs": "Formatted string for one insight"
            },
            {
              "name": "formatInsightGeneric",
              "desc": "Formats a single insight in a neutral, generic style",
              "inputs": "insight: Insight",
              "outputs": "Formatted string for one insight"
            }
          ],
          "dependencies": [
            "./insightGenerator (Insight type)"
          ],
          "intent": "Transforms raw code analysis data into human-readable, LLM-optimized formats that help developers understand and act on architecture issues by presenting them in the most effective way for their chosen AI assistant or documentation needs",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various LLM interfaces and human readability\",\n  \"userVisibleActions\": [\n    \"Receives formatted architecture issues grouped by severity (errors, warnings, info)\",\n    \"Sees issues organized with visual indicators (🔴 for errors, ⚠️ for warnings, ℹ️ for info)\",\n    \"Gets actionable guidance on how to address detected issues\",\n    \"Receives output optimized for their chosen LLM interface (Cursor, ChatGPT, or generic)\",\n    \"Sees compact summaries when requesting condensed output\",\n    \"Views file paths and line numbers where issues occur\",\n    \"Gets context about what each issue means and why it matters\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls formatInsights() to convert raw insights into formatted text\",\n    \"Developer specifies output format: 'cursor', 'chatgpt', 'compact', or 'generic'\",\n    \"Developer receives formatted markdown text ready to display or send to LLM\",\n    \"Developer gets insights grouped and sorted by severity automatically\",\n    \"Developer sees file locations and affected code patterns in the output\",\n    \"Developer receives actionable suggestions and next steps included in the output\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes insights to the appropriate formatter based on specified format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string ready for display or LLM consumption\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Formats insights specifically for Cursor IDE with severity grouping, emoji indicators, and actionable guidance\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string optimized for Cursor\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Formats insights for ChatGPT with conversational tone and context about being a codebase analysis\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string optimized for ChatGPT\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Formats insights in a condensed format with just essential information and counts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with summary statistics\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Formats insights in a generic markdown format suitable for any LLM or documentation\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown-formatted string\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats a single insight with location, message, and suggestion details for Cursor\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats a single insight with conversational style for ChatGPT\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats a single insight in a neutral, generic style\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator (Insight type)\"\n  ],\n  \"intent\": \"Transforms raw code analysis data into human-readable, LLM-optimized formats that help developers understand and act on architecture issues by presenting them in the most effective way for their chosen AI assistant or documentation needs\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Integrates LLM-powered features into VS Code to provide AI-driven code analysis, documentation generation, and insights for software projects",
          "userVisibleActions": [
            "View AI-generated code insights in a tree view panel",
            "Generate comprehensive product documentation from code",
            "Analyze code structure and relationships automatically",
            "View entry points and code flow visualizations",
            "Browse unit test results and coverage",
            "See AI-powered recommendations for code improvements",
            "Access formatted documentation in output channels",
            "Navigate through analyzed code components",
            "View saved analysis results from previous sessions"
          ],
          "developerVisibleActions": [
            "Initialize LLM service on extension activation",
            "Configure API keys for LLM providers",
            "Trigger code analysis on workspace or specific files",
            "Generate documentation that persists across sessions",
            "Load and display previously saved insights and analysis",
            "Refresh tree views when configuration changes",
            "Export analysis results to structured formats",
            "Handle errors and display status in output channels",
            "Integrate with multiple view providers (insights, analysis, navigation)",
            "Manage state across extension lifecycle"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Sets up the LLM service, creates output channels, and loads saved data on extension startup",
              "inputs": "none",
              "outputs": "void - initializes state manager with LLM service"
            },
            {
              "name": "analyzeCodebase",
              "desc": "Analyzes entire codebase or specific files to extract structure, dependencies, and entry points",
              "inputs": "workspace or file paths",
              "outputs": "CodeAnalysis object with discovered patterns and relationships"
            },
            {
              "name": "generateDocumentation",
              "desc": "Creates comprehensive product documentation from analyzed code using LLM",
              "inputs": "analysis context and code structure",
              "outputs": "EnhancedProductDocumentation with formatted sections"
            },
            {
              "name": "getInsights",
              "desc": "Generates AI-powered insights about code quality, architecture, and improvements",
              "inputs": "AnalysisContext with code information",
              "outputs": "LLMInsights with recommendations and observations"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists analysis results to storage for future sessions",
              "inputs": "CodeAnalysis object and workspace path",
              "outputs": "void - saves to file system"
            },
            {
              "name": "loadSavedCodeAnalysis",
              "desc": "Retrieves previously saved analysis results from storage",
              "inputs": "workspace path",
              "outputs": "CodeAnalysis object or null if not found"
            },
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms code analysis into a format suitable for LLM processing",
              "inputs": "CodeAnalysis object",
              "outputs": "AnalysisContext for LLM consumption"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "./llmService",
            "./insightsTreeView",
            "./fileDocumentation",
            "./analyzer",
            "./productNavigator",
            "./analysisViewer",
            "./insightsViewer",
            "./unitTestsNavigator",
            "./logger",
            "./state/llmStateManager",
            "./context/analysisContextBuilder",
            "./domain/formatters/documentationFormatter",
            "./infrastructure/persistence/analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis and AI-powered understanding, enabling developers to quickly comprehend large codebases through automated documentation, insights, and visualizations. It solves the problem of manually documenting and understanding complex software projects by leveraging LLM capabilities to automatically generate meaningful documentation, identify patterns, and provide actionable insights.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered features into VS Code to provide AI-driven code analysis, documentation generation, and insights for software projects\",\n  \"userVisibleActions\": [\n    \"View AI-generated code insights in a tree view panel\",\n    \"Generate comprehensive product documentation from code\",\n    \"Analyze code structure and relationships automatically\",\n    \"View entry points and code flow visualizations\",\n    \"Browse unit test results and coverage\",\n    \"See AI-powered recommendations for code improvements\",\n    \"Access formatted documentation in output channels\",\n    \"Navigate through analyzed code components\",\n    \"View saved analysis results from previous sessions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service on extension activation\",\n    \"Configure API keys for LLM providers\",\n    \"Trigger code analysis on workspace or specific files\",\n    \"Generate documentation that persists across sessions\",\n    \"Load and display previously saved insights and analysis\",\n    \"Refresh tree views when configuration changes\",\n    \"Export analysis results to structured formats\",\n    \"Handle errors and display status in output channels\",\n    \"Integrate with multiple view providers (insights, analysis, navigation)\",\n    \"Manage state across extension lifecycle\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service, creates output channels, and loads saved data on extension startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - initializes state manager with LLM service\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Analyzes entire codebase or specific files to extract structure, dependencies, and entry points\",\n      \"inputs\": \"workspace or file paths\",\n      \"outputs\": \"CodeAnalysis object with discovered patterns and relationships\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation from analyzed code using LLM\",\n      \"inputs\": \"analysis context and code structure\",\n      \"outputs\": \"EnhancedProductDocumentation with formatted sections\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Generates AI-powered insights about code quality, architecture, and improvements\",\n      \"inputs\": \"AnalysisContext with code information\",\n      \"outputs\": \"LLMInsights with recommendations and observations\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to storage for future sessions\",\n      \"inputs\": \"CodeAnalysis object and workspace path\",\n      \"outputs\": \"void - saves to file system\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis results from storage\",\n      \"inputs\": \"workspace path\",\n      \"outputs\": \"CodeAnalysis object or null if not found\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis into a format suitable for LLM processing\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"AnalysisContext for LLM consumption\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and AI-powered understanding, enabling developers to quickly comprehend large codebases through automated documentation, insights, and visualizations. It solves the problem of manually documenting and understanding complex software projects by leveraging LLM capabilities to automatically generate meaningful documentation, identify patterns, and provide actionable insights.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure LLM (Claude) responses to ensure valid, parseable outputs for product analysis, issue identification, and documentation generation.",
          "userVisibleActions": [
            "User receives structured analysis of product purpose and architecture rationale",
            "User sees categorized issues (architectural, code quality, documentation, maintenance) with clear titles and descriptions",
            "User gets actionable recommendations with specific fixes for each identified issue",
            "User receives consistent, predictable documentation formats from LLM analysis"
          ],
          "developerVisibleActions": [
            "Developer defines schema structure for product purpose analysis including design decisions and user goals",
            "Developer specifies issue schema with title, description, relevant files, functions, severity, and category fields",
            "Developer ensures LLM outputs include structured recommendations with confidence levels",
            "Developer constrains LLM responses to predefined formats using JSON Schema validation",
            "Developer guarantees parseable responses without manual text parsing or extraction"
          ],
          "keyFunctions": [
            {
              "name": "productPurposeAnalysisSchema",
              "desc": "Schema for analyzing product purpose, architecture rationale, design decisions, user goals, and contextual factors",
              "inputs": "N/A (schema definition)",
              "outputs": "JSON schema object with required fields: productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
            },
            {
              "name": "issueItemSchema",
              "desc": "Schema for individual issue items with title, description, relevant files/functions, severity, and category",
              "inputs": "N/A (schema definition)",
              "outputs": "JSON schema object defining issue structure with human-readable titles and detailed descriptions including proposed fixes"
            }
          ],
          "dependencies": [],
          "intent": "This file exists to guarantee structured, valid, and machine-parseable responses from Claude AI by defining strict JSON schemas. It eliminates the need for fragile text parsing by enforcing a contract between the LLM and the application, ensuring consistent output formats for product analysis, issue identification, and recommendations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure LLM (Claude) responses to ensure valid, parseable outputs for product analysis, issue identification, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"User receives structured analysis of product purpose and architecture rationale\",\n    \"User sees categorized issues (architectural, code quality, documentation, maintenance) with clear titles and descriptions\",\n    \"User gets actionable recommendations with specific fixes for each identified issue\",\n    \"User receives consistent, predictable documentation formats from LLM analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines schema structure for product purpose analysis including design decisions and user goals\",\n    \"Developer specifies issue schema with title, description, relevant files, functions, severity, and category fields\",\n    \"Developer ensures LLM outputs include structured recommendations with confidence levels\",\n    \"Developer constrains LLM responses to predefined formats using JSON Schema validation\",\n    \"Developer guarantees parseable responses without manual text parsing or extraction\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose, architecture rationale, design decisions, user goals, and contextual factors\",\n      \"inputs\": \"N/A (schema definition)\",\n      \"outputs\": \"JSON schema object with required fields: productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema for individual issue items with title, description, relevant files/functions, severity, and category\",\n      \"inputs\": \"N/A (schema definition)\",\n      \"outputs\": \"JSON schema object defining issue structure with human-readable titles and detailed descriptions including proposed fixes\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to guarantee structured, valid, and machine-parseable responses from Claude AI by defining strict JSON schemas. It eliminates the need for fragile text parsing by enforcing a contract between the LLM and the application, ensuring consistent output formats for product analysis, issue identification, and recommendations.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadowwatch.analyzeCode",
          "description": "Analyzes the entire codebase and generates comprehensive insights about architecture, dependencies, code quality, and potential issues"
        },
        {
          "command": "shadowwatch.copyContextToClipboard",
          "description": "Copies formatted code context and analysis results to clipboard for pasting into LLM chat interfaces"
        },
        {
          "command": "shadowwatch.refreshAnalysis",
          "description": "Manually triggers a fresh analysis of the codebase, bypassing cache"
        },
        {
          "command": "shadowwatch.clearCache",
          "description": "Clears all cached analysis results, forcing a complete re-analysis on next run"
        },
        {
          "command": "shadowwatch.generateProductDocs",
          "description": "Uses AI to generate comprehensive product documentation from source code analysis"
        },
        {
          "command": "shadowwatch.generateInsights",
          "description": "Generates AI-powered insights and recommendations about code quality, architecture, and improvements"
        },
        {
          "command": "shadowwatch.refreshInsights",
          "description": "Refreshes the insights tree view to display the latest AI-generated recommendations"
        },
        {
          "command": "shadowwatch.openAnalysisReport",
          "description": "Opens detailed analysis reports (workspace, product, architecture, or unit test reports)"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized management of all Shadow Watch extension settings",
        "Real-time configuration updates with automatic listener notification",
        "LLM provider configuration for OpenAI and Claude integrations",
        "Flexible analysis behavior customization (automatic analysis, inline hints, severity filtering)",
        "API endpoint and authentication management for external services",
        "Performance tuning through timeout and file size limit controls"
      ],
      "summary": "The config module serves as the central configuration management system for the Shadow Watch extension. It provides a unified interface for accessing and modifying all extension settings, from basic functionality toggles to advanced LLM integration parameters. The module implements a reactive architecture that automatically notifies registered listeners whenever configuration values change, ensuring all components stay synchronized with user preferences.\n\nUsers can control every aspect of Shadow Watch's behavior through this module. This includes enabling or disabling the extension entirely, configuring when and how code analysis runs (on save, manually, or continuously), and customizing the visual presentation of analysis results through inline hints and diagnostic severity filters. The module also manages critical integration settings such as LLM provider selection (OpenAI or Claude), API credentials, custom endpoints, and output format preferences.\n\nThe configuration system supports operational parameters that help users optimize Shadow Watch for their specific environment. This includes setting analysis timeouts to prevent long-running operations, defining file size and line count limits to control resource usage, and configuring retry behavior for API calls. All settings are persisted automatically and can be modified through VS Code's standard settings interface or programmatically through the configuration manager API.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all Shadow Watch extension configuration settings and notifies listeners when settings change",
          "userVisibleActions": [
            "Enable or disable the Shadow Watch extension",
            "Toggle automatic analysis when saving files",
            "Show or hide inline hints in the editor",
            "Configure which LLM provider to use (OpenAI or Claude)",
            "Set the output format for LLM analysis results",
            "Choose minimum severity level for displaying diagnostics",
            "Customize API keys and endpoints for LLM services",
            "Adjust timeout settings for analysis operations",
            "Control file size and line count limits for analysis"
          ],
          "developerVisibleActions": [
            "Access type-safe configuration properties through getter methods",
            "Register callbacks that trigger when user changes settings",
            "Validate configuration values to ensure they meet requirements",
            "Retrieve AI provider settings including API keys and model names",
            "Get analysis parameters like debounce delays and file size limits",
            "Check if specific features are enabled before executing logic",
            "Receive automatic notifications when workspace configuration changes"
          ],
          "keyFunctions": [
            {
              "name": "onConfigurationChange",
              "desc": "Registers a callback function that executes whenever configuration settings change",
              "inputs": "callback: () => void",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Unregisters a previously registered configuration change callback",
              "inputs": "callback: () => void",
              "outputs": "void"
            },
            {
              "name": "validate",
              "desc": "Checks if current configuration values are valid and returns any errors found",
              "inputs": "none",
              "outputs": "ConfigValidationResult with valid flag and error messages"
            },
            {
              "name": "enabled",
              "desc": "Returns whether the Shadow Watch extension is currently enabled",
              "inputs": "none (getter property)",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave",
              "desc": "Returns whether automatic analysis should run when files are saved",
              "inputs": "none (getter property)",
              "outputs": "boolean"
            },
            {
              "name": "llmProvider",
              "desc": "Returns the configured LLM provider (OpenAI or Claude)",
              "inputs": "none (getter property)",
              "outputs": "LLMProvider type ('openai' or 'claude')"
            },
            {
              "name": "severityThreshold",
              "desc": "Returns the minimum severity level for displaying diagnostics",
              "inputs": "none (getter property)",
              "outputs": "SeverityThreshold type ('error', 'warning', or 'info')"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to provide a centralized, type-safe way to access all Shadow Watch configuration settings, eliminating scattered configuration calls throughout the codebase and ensuring consistent access to user preferences. It solves the problem of configuration management by providing a single source of truth with automatic change detection and listener notification.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension configuration settings and notifies listeners when settings change\",\n  \"userVisibleActions\": [\n    \"Enable or disable the Shadow Watch extension\",\n    \"Toggle automatic analysis when saving files\",\n    \"Show or hide inline hints in the editor\",\n    \"Configure which LLM provider to use (OpenAI or Claude)\",\n    \"Set the output format for LLM analysis results\",\n    \"Choose minimum severity level for displaying diagnostics\",\n    \"Customize API keys and endpoints for LLM services\",\n    \"Adjust timeout settings for analysis operations\",\n    \"Control file size and line count limits for analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access type-safe configuration properties through getter methods\",\n    \"Register callbacks that trigger when user changes settings\",\n    \"Validate configuration values to ensure they meet requirements\",\n    \"Retrieve AI provider settings including API keys and model names\",\n    \"Get analysis parameters like debounce delays and file size limits\",\n    \"Check if specific features are enabled before executing logic\",\n    \"Receive automatic notifications when workspace configuration changes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function that executes whenever configuration settings change\",\n      \"inputs\": \"callback: () => void\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback: () => void\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Checks if current configuration values are valid and returns any errors found\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult with valid flag and error messages\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider\",\n      \"desc\": \"Returns the configured LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"LLMProvider type ('openai' or 'claude')\"\n    },\n    {\n      \"name\": \"severityThreshold\",\n      \"desc\": \"Returns the minimum severity level for displaying diagnostics\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"SeverityThreshold type ('error', 'warning', or 'info')\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, type-safe way to access all Shadow Watch configuration settings, eliminating scattered configuration calls throughout the codebase and ensuring consistent access to user preferences. It solves the problem of configuration management by providing a single source of truth with automatic change detection and listener notification.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Automatically converts code analysis results into LLM-ready context format",
        "Persists analysis data between sessions in workspace .shadow/docs directory",
        "Structures analyzed code information for efficient AI processing",
        "Maintains historical record of code analysis for future reference"
      ],
      "summary": "The context module serves as a bridge between code analysis output and AI language model consumption. It automatically transforms technical code analysis results into a structured format optimized for LLM processing, ensuring that insights from code scanning can be effectively utilized by AI-powered features.\n\nWhen code is analyzed, this module saves the results to the workspace's .shadow/docs directory, creating a persistent knowledge base. This allows analysis data to be reused across sessions without requiring re-analysis, improving performance and maintaining continuity. The module handles the serialization and storage of complex analysis structures, making them readily accessible for downstream AI features.\n\nUsers benefit from this module transparently - their code analysis results are automatically preserved and formatted without manual intervention. The persistent storage means that documentation, code insights, and analysis metadata remain available even after restarting the development environment, enabling consistent AI-assisted workflows throughout the development lifecycle.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis results into a context format for LLM processing and saves them to disk for future use",
          "userVisibleActions": [
            "Code analysis results are automatically saved to workspace for future reference",
            "Analysis data persists between sessions in .shadow/docs directory"
          ],
          "developerVisibleActions": [
            "Transforms raw code analysis into LLM-compatible context format",
            "Saves analysis with metadata (timestamps, version) to .shadow/docs/code-analysis.json",
            "Creates necessary directories (.shadow/docs) if they don't exist",
            "Handles workspace validation before saving"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms CodeAnalysis object into AnalysisContext format suitable for LLM consumption",
              "inputs": "CodeAnalysis object containing files, imports, entry points, and metrics",
              "outputs": "AnalysisContext object with reformatted data structure"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to disk with metadata for future use",
              "inputs": "CodeAnalysis object to save",
              "outputs": "void (creates code-analysis.json file in workspace)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between code analysis results and LLM processing by transforming data into the appropriate format and ensuring analysis results are persisted across sessions, allowing the extension to reuse previous analysis work without re-scanning the codebase",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a context format for LLM processing and saves them to disk for future use\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to workspace for future reference\",\n    \"Analysis data persists between sessions in .shadow/docs directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transforms raw code analysis into LLM-compatible context format\",\n    \"Saves analysis with metadata (timestamps, version) to .shadow/docs/code-analysis.json\",\n    \"Creates necessary directories (.shadow/docs) if they don't exist\",\n    \"Handles workspace validation before saving\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis object into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and metrics\",\n      \"outputs\": \"AnalysisContext object with reformatted data structure\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk with metadata for future use\",\n      \"inputs\": \"CodeAnalysis object to save\",\n      \"outputs\": \"void (creates code-analysis.json file in workspace)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM processing by transforming data into the appropriate format and ensuring analysis results are persisted across sessions, allowing the extension to reuse previous analysis work without re-scanning the codebase\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Initialize and configure all extension components on VS Code startup",
        "Register and manage all user-triggered commands for code analysis and insights",
        "Coordinate workspace and file-level code analysis workflows",
        "Manage insight data operations including viewing, copying, and clearing",
        "Switch between multiple LLM providers (OpenAI, Anthropic, etc.)",
        "Display analysis results in tree views, status bar, and diagnostics panel",
        "Provide navigation to code locations from insights and analysis results",
        "Manage extension lifecycle including activation, updates, and cleanup"
      ],
      "summary": "This module serves as the foundation for the VS Code extension, handling initialization and command registration. When the extension activates, it orchestrates the setup of all components including tree views for insights, status bar indicators, diagnostic panels, and file watchers. It ensures that all extension features are properly initialized and ready for user interaction.\n\nThe module registers a comprehensive set of commands that allow users to perform code analysis at workspace or file level, manage insights through copy and clear operations, switch between different LLM providers, and navigate to specific code locations. Users can trigger analysis, view results in multiple formats (tree views, diagnostics, reports), and interact with the extension through both UI elements and command palette entries.\n\nThe bootstrap process manages the complete lifecycle of extension components, ensuring proper dependency injection, event handling, and cleanup. It coordinates between analysis engines, storage systems, UI components, and external LLM services to provide a seamless user experience for code analysis and insight generation.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers all VS Code commands that users and the extension can trigger for code analysis, insight management, and LLM provider operations",
          "userVisibleActions": [
            "Analyze entire workspace for code insights",
            "Analyze currently open file",
            "Copy all insights to clipboard",
            "Copy insights for specific file",
            "Copy individual insight to clipboard",
            "Clear cached analysis data",
            "Clear all extension data",
            "Open extension settings",
            "Open latest analysis report",
            "Open latest unit test report",
            "Switch between LLM providers (OpenAI, Anthropic, etc.)",
            "Copy menu structure to clipboard",
            "View LLM provider connection status",
            "Navigate to product item in codebase",
            "Navigate to analysis item location",
            "View detailed information for product items",
            "View detailed information for insights",
            "View detailed information for unit test items"
          ],
          "developerVisibleActions": [
            "Provides centralized command registration for the extension",
            "Defines command handler interface for type safety",
            "Wires up VS Code command IDs to handler functions",
            "Manages dependencies between commands and extension components",
            "Separates command registration logic from main extension activation",
            "Enables command handlers to access analyzer, cache, tree views, and LLM integration",
            "Registers commands with VS Code's command palette and UI elements"
          ],
          "keyFunctions": [
            {
              "name": "CommandRegistry.register",
              "desc": "Registers all VS Code commands with their handlers",
              "inputs": "context: vscode.ExtensionContext, components: ExtensionComponents",
              "outputs": "void (registers commands as side effect)"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "This file exists to centralize and organize all command registration logic for the VS Code extension, separating it from the main activation flow to improve maintainability and provide a clear registry of all user-triggered actions and their implementations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands that users and the extension can trigger for code analysis, insight management, and LLM provider operations\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View LLM provider connection status\",\n    \"Navigate to product item in codebase\",\n    \"Navigate to analysis item location\",\n    \"View detailed information for product items\",\n    \"View detailed information for insights\",\n    \"View detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized command registration for the extension\",\n    \"Defines command handler interface for type safety\",\n    \"Wires up VS Code command IDs to handler functions\",\n    \"Manages dependencies between commands and extension components\",\n    \"Separates command registration logic from main extension activation\",\n    \"Enables command handlers to access analyzer, cache, tree views, and LLM integration\",\n    \"Registers commands with VS Code's command palette and UI elements\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CommandRegistry.register\",\n      \"desc\": \"Registers all VS Code commands with their handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext, components: ExtensionComponents\",\n      \"outputs\": \"void (registers commands as side effect)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file exists to centralize and organize all command registration logic for the VS Code extension, separating it from the main activation flow to improve maintainability and provide a clear registry of all user-triggered actions and their implementations.\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Initializes and orchestrates all VS Code extension components when the extension activates, managing their lifecycle and dependencies",
          "userVisibleActions": [
            "Extension components are initialized and ready when VS Code starts",
            "Status bar shows extension activity status",
            "Tree views populate with code insights, analysis results, reports, and test information",
            "Diagnostics appear in the Problems panel for code issues",
            "File changes trigger automatic analysis updates",
            "Reports viewer displays analysis reports",
            "Product navigation view becomes available",
            "Unit tests navigator shows test structure"
          ],
          "developerVisibleActions": [
            "Extension activation initializes all required components in correct order",
            "Components are registered with VS Code's extension context",
            "Event handlers and watchers are set up for file changes",
            "Cache system is initialized for performance optimization",
            "LLM integration services are connected and ready",
            "Configuration manager provides access to extension settings",
            "Error handling system is established for debugging",
            "Multiple tree view providers are registered for different data types",
            "Disposables are tracked for proper cleanup on deactivation"
          ],
          "keyFunctions": [
            {
              "name": "bootstrap",
              "desc": "Initializes all extension components and registers them with VS Code",
              "inputs": "vscode.ExtensionContext",
              "outputs": "ExtensionComponents object containing all initialized services"
            },
            {
              "name": "createComponents",
              "desc": "Instantiates all core services like analyzer, insight generator, formatters, and providers",
              "inputs": "context",
              "outputs": "Complete set of extension component instances"
            },
            {
              "name": "registerTreeViews",
              "desc": "Registers all tree view providers with VS Code UI",
              "inputs": "context, components",
              "outputs": "Registered tree views for insights, analysis, reports, and tests"
            },
            {
              "name": "setupFileWatching",
              "desc": "Configures automatic file monitoring and change detection",
              "inputs": "components",
              "outputs": "Active file watcher with event handlers"
            },
            {
              "name": "initializeCache",
              "desc": "Sets up the analysis cache system for storing results",
              "inputs": "none",
              "outputs": "Initialized cache instance"
            }
          ],
          "dependencies": [
            "vscode",
            "../../analyzer",
            "../../insightGenerator",
            "../../llmFormatter",
            "../../fileWatcher",
            "../../insightsTreeView",
            "../../diagnosticsProvider",
            "../../cache",
            "../../llmIntegration",
            "../../productNavigator",
            "../../analysisViewer",
            "../../insightsViewer",
            "../../staticAnalysisViewer",
            "../../unitTestsNavigator",
            "../../config/configurationManager",
            "../../utils/errorHandler",
            "../../domain/services/fileWatcherService",
            "../../ui/reportsViewer",
            "../../reportsTreeProvider",
            "../../state/llmStateManager"
          ],
          "intent": "This file exists to separate the complex initialization logic from the main extension entry point, ensuring all components are created in the correct order with proper dependencies, making the extension activation process maintainable, testable, and reducing coupling between the activation trigger and component setup",
          "rawContent": "```json\n{\n  \"purpose\": \"Initializes and orchestrates all VS Code extension components when the extension activates, managing their lifecycle and dependencies\",\n  \"userVisibleActions\": [\n    \"Extension components are initialized and ready when VS Code starts\",\n    \"Status bar shows extension activity status\",\n    \"Tree views populate with code insights, analysis results, reports, and test information\",\n    \"Diagnostics appear in the Problems panel for code issues\",\n    \"File changes trigger automatic analysis updates\",\n    \"Reports viewer displays analysis reports\",\n    \"Product navigation view becomes available\",\n    \"Unit tests navigator shows test structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activation initializes all required components in correct order\",\n    \"Components are registered with VS Code's extension context\",\n    \"Event handlers and watchers are set up for file changes\",\n    \"Cache system is initialized for performance optimization\",\n    \"LLM integration services are connected and ready\",\n    \"Configuration manager provides access to extension settings\",\n    \"Error handling system is established for debugging\",\n    \"Multiple tree view providers are registered for different data types\",\n    \"Disposables are tracked for proper cleanup on deactivation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Initializes all extension components and registers them with VS Code\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object containing all initialized services\"\n    },\n    {\n      \"name\": \"createComponents\",\n      \"desc\": \"Instantiates all core services like analyzer, insight generator, formatters, and providers\",\n      \"inputs\": \"context\",\n      \"outputs\": \"Complete set of extension component instances\"\n    },\n    {\n      \"name\": \"registerTreeViews\",\n      \"desc\": \"Registers all tree view providers with VS Code UI\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"Registered tree views for insights, analysis, reports, and tests\"\n    },\n    {\n      \"name\": \"setupFileWatching\",\n      \"desc\": \"Configures automatic file monitoring and change detection\",\n      \"inputs\": \"components\",\n      \"outputs\": \"Active file watcher with event handlers\"\n    },\n    {\n      \"name\": \"initializeCache\",\n      \"desc\": \"Sets up the analysis cache system for storing results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Initialized cache instance\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer\",\n    \"../../insightGenerator\",\n    \"../../llmFormatter\",\n    \"../../fileWatcher\",\n    \"../../insightsTreeView\",\n    \"../../diagnosticsProvider\",\n    \"../../cache\",\n    \"../../llmIntegration\",\n    \"../../productNavigator\",\n    \"../../analysisViewer\",\n    \"../../insightsViewer\",\n    \"../../staticAnalysisViewer\",\n    \"../../unitTestsNavigator\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler\",\n    \"../../domain/services/fileWatcherService\",\n    \"../../ui/reportsViewer\",\n    \"../../reportsTreeProvider\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to separate the complex initialization logic from the main extension entry point, ensuring all components are created in the correct order with proper dependencies, making the extension activation process maintainable, testable, and reducing coupling between the activation trigger and component setup\"\n}\n```"
        }
      ],
      "commands": [
        {
          "command": "analyze-workspace",
          "description": "Analyze entire workspace to generate code insights across all files"
        },
        {
          "command": "analyze-file",
          "description": "Analyze the currently open file for code insights"
        },
        {
          "command": "copy-all-insights",
          "description": "Copy all generated insights to clipboard"
        },
        {
          "command": "copy-file-insights",
          "description": "Copy insights for a specific file to clipboard"
        },
        {
          "command": "copy-insight",
          "description": "Copy an individual insight item to clipboard"
        },
        {
          "command": "clear-cache",
          "description": "Clear cached analysis data to force fresh analysis"
        },
        {
          "command": "clear-all-data",
          "description": "Clear all extension data including insights and cached results"
        },
        {
          "command": "open-settings",
          "description": "Open extension configuration settings"
        },
        {
          "command": "open-analysis-report",
          "description": "Open the latest analysis report in a viewer"
        },
        {
          "command": "open-unit-test-report",
          "description": "Open the latest unit test report"
        },
        {
          "command": "switch-llm-provider",
          "description": "Switch between different LLM providers (OpenAI, Anthropic, etc.)"
        },
        {
          "command": "copy-menu-structure",
          "description": "Copy the menu structure to clipboard"
        },
        {
          "command": "view-llm-status",
          "description": "View connection status and details for the active LLM provider"
        },
        {
          "command": "navigate-to-product-item",
          "description": "Navigate to a product item's location in the codebase"
        },
        {
          "command": "navigate-to-analysis-item",
          "description": "Navigate to the code location associated with an analysis item"
        },
        {
          "command": "view-product-item-details",
          "description": "View detailed information about a selected product item"
        },
        {
          "command": "view-insight-details",
          "description": "View detailed information about a specific insight"
        },
        {
          "command": "view-unit-test-details",
          "description": "View detailed information about a unit test item"
        }
      ]
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Format product documentation into structured Markdown documents with consistent organization",
        "Generate comprehensive documentation sections including overview, features, and user perspectives",
        "Organize features by user roles (GUI, CLI, API) and categorize them by functional domains",
        "Structure behavior descriptions using the who/what/when/where/why/how framework",
        "Present LLM-generated insights about technical architecture, patterns, and implementation details",
        "Display quality metrics including confidence scores and accuracy ratings for documentation",
        "Format dependency information and integration point details in readable formats",
        "Add metadata such as generation timestamps to track documentation freshness"
      ],
      "summary": "The formatters module provides documentation formatting capabilities that transform raw product documentation and LLM-generated insights into polished, user-ready Markdown documents. It takes structured documentation data and applies consistent formatting rules to create organized, readable documentation with clear sections for different audiences (GUI users, CLI users, API developers).\n\nUsers interact with this module when they view product documentation in their development environment. The module automatically formats documentation to include a product overview, categorized feature lists organized by user type and functional domain, detailed behavior descriptions following a structured framework, and technical insights generated by LLMs. Each document includes quality indicators like confidence scores and accuracy ratings, helping users assess the reliability of the information.\n\nThe module supports documentation workflows by ensuring consistent presentation across different products and documentation types. It organizes complex technical information into scannable sections, groups related features together, and presents dependencies and integration points in a clear format. Generated timestamps help users understand when the documentation was last updated, supporting documentation maintenance and review processes.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and LLM insights into structured Markdown documents for user consumption",
          "userVisibleActions": [
            "View formatted product documentation with overview, features, and user perspectives",
            "See organized sections for GUI, CLI, and API user interactions",
            "Read categorized features grouped by user roles and domains",
            "Access behavior descriptions organized by who/what/when/where/why/how",
            "View LLM-generated insights about technical architecture and patterns",
            "See quality scores and confidence ratings for documentation accuracy",
            "Read dependency information and integration points",
            "Access generated timestamps showing when documentation was created"
          ],
          "developerVisibleActions": [
            "Call formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects into Markdown strings",
            "Call formatInsightsAsMarkdown() to convert LLM analysis results into readable documentation",
            "Receive Markdown output with consistent heading hierarchy and formatting",
            "Get documentation with automatic timestamp injection (both UTC and local)",
            "Obtain structured sections for overview, features, user perspectives, behaviors, and insights",
            "Receive formatted lists with proper bullet points and indentation",
            "Get quality metrics and confidence scores embedded in the output",
            "Access formatted dependency trees and architecture patterns"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation object into formatted Markdown document with all sections",
              "inputs": "EnhancedProductDocumentation object containing overview, features, perspectives, behaviors",
              "outputs": "Formatted Markdown string with sections for overview, features, user perspectives, behaviors, and quality scores"
            },
            {
              "name": "formatInsightsAsMarkdown",
              "desc": "Converts LLM-generated insights into formatted Markdown document with architecture and patterns",
              "inputs": "LLMInsights object containing technical patterns, dependencies, and quality metrics",
              "outputs": "Formatted Markdown string with sections for technical architecture, patterns, dependencies, and confidence ratings"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "This file exists to separate documentation formatting concerns from LLM integration logic, providing a clean, reusable way to convert structured documentation objects into human-readable Markdown format with consistent styling and organization",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and LLM insights into structured Markdown documents for user consumption\",\n  \"userVisibleActions\": [\n    \"View formatted product documentation with overview, features, and user perspectives\",\n    \"See organized sections for GUI, CLI, and API user interactions\",\n    \"Read categorized features grouped by user roles and domains\",\n    \"Access behavior descriptions organized by who/what/when/where/why/how\",\n    \"View LLM-generated insights about technical architecture and patterns\",\n    \"See quality scores and confidence ratings for documentation accuracy\",\n    \"Read dependency information and integration points\",\n    \"Access generated timestamps showing when documentation was created\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects into Markdown strings\",\n    \"Call formatInsightsAsMarkdown() to convert LLM analysis results into readable documentation\",\n    \"Receive Markdown output with consistent heading hierarchy and formatting\",\n    \"Get documentation with automatic timestamp injection (both UTC and local)\",\n    \"Obtain structured sections for overview, features, user perspectives, behaviors, and insights\",\n    \"Receive formatted lists with proper bullet points and indentation\",\n    \"Get quality metrics and confidence scores embedded in the output\",\n    \"Access formatted dependency trees and architecture patterns\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown document with all sections\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, perspectives, behaviors\",\n      \"outputs\": \"Formatted Markdown string with sections for overview, features, user perspectives, behaviors, and quality scores\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into formatted Markdown document with architecture and patterns\",\n      \"inputs\": \"LLMInsights object containing technical patterns, dependencies, and quality metrics\",\n      \"outputs\": \"Formatted Markdown string with sections for technical architecture, patterns, dependencies, and confidence ratings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting concerns from LLM integration logic, providing a clean, reusable way to convert structured documentation objects into human-readable Markdown format with consistent styling and organization\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate to specific files in the editor when clicking items in the product navigator or analysis viewer",
        "Jump directly to functions, methods, and other code elements with automatic cursor positioning",
        "Navigate to API endpoints and automatically highlight their location in the source code",
        "Display detailed information about code items in a dedicated webview panel",
        "Reveal and highlight specific code ranges when interacting with analysis results",
        "Open external links in the system's default browser",
        "Provide user feedback through error messages when navigation targets cannot be found"
      ],
      "summary": "This module provides comprehensive navigation capabilities that enable users to seamlessly move between different parts of their codebase directly from the product navigator and analysis viewer interfaces. When users interact with code items displayed in these views, the module handles opening the appropriate files in the editor and positioning the cursor at the exact location of interest.\n\nThe navigation system supports multiple types of code elements including files, functions, methods, and API endpoints. It automatically highlights the relevant code sections to help users quickly orient themselves in the file. When detailed information is needed, the module can display comprehensive details about code items in a dedicated webview panel, providing context without requiring users to search through files manually.\n\nThe module also handles edge cases gracefully by displaying informative error messages when files cannot be opened or navigation targets cannot be found. Additionally, it supports opening external links in the user's default browser, making it easy to access related documentation or resources referenced in the code analysis.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation to files, functions, endpoints, and other code items in the editor when user clicks items in the product navigator or analysis viewer.",
          "userVisibleActions": [
            "Opens files in the editor when clicking on file items in the navigator",
            "Jumps to specific functions or methods in files with cursor positioned at the function location",
            "Navigates to API endpoints and highlights their location in the code",
            "Shows error messages when files cannot be opened or found",
            "Displays detailed information about code items (functions, endpoints, etc.) in a webview panel",
            "Reveals and highlights specific code ranges when clicking on analysis items",
            "Opens external links in the default browser when clicked"
          ],
          "developerVisibleActions": [
            "Provides methods to programmatically navigate to ProductNavItem objects (files, functions, endpoints)",
            "Provides methods to navigate to AnalysisItem objects from analysis results",
            "Handles both absolute and relative file paths relative to workspace root",
            "Searches for function definitions by name within opened documents",
            "Creates and manages webview panels for displaying detailed item information",
            "Converts file paths to VS Code URI format for opening documents",
            "Handles navigation for different item types: files, functions, endpoints, entry points",
            "Provides link handling for external URLs in webview content"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to a product navigation item (file or function) and opens it in the editor",
              "inputs": "ProductNavItem (type: file/function/navigate, data with file path and optional function name)",
              "outputs": "Promise<void>"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to an analysis item and reveals it in the editor with highlighting",
              "inputs": "AnalysisItem (with file path, line number, and column information)",
              "outputs": "Promise<void>"
            },
            {
              "name": "showItemDetails",
              "desc": "Displays detailed information about a code item in a webview panel",
              "inputs": "ProductNavItem or AnalysisItem (with metadata like name, type, description, file location)",
              "outputs": "void"
            },
            {
              "name": "navigateToEntryPoint",
              "desc": "Navigates to an entry point (function, endpoint, etc.) and positions cursor at its location",
              "inputs": "EntryPoint (with file path, line number, column, and name)",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "ProductNavItem from productNavigator",
            "AnalysisItem from analysisViewer",
            "EntryPoint from analyzer"
          ],
          "intent": "This file exists to centralize all navigation logic in one place, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to files, functions, and other code items regardless of where the navigation request originates.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code items in the editor when user clicks items in the product navigator or analysis viewer.\",\n  \"userVisibleActions\": [\n    \"Opens files in the editor when clicking on file items in the navigator\",\n    \"Jumps to specific functions or methods in files with cursor positioned at the function location\",\n    \"Navigates to API endpoints and highlights their location in the code\",\n    \"Shows error messages when files cannot be opened or found\",\n    \"Displays detailed information about code items (functions, endpoints, etc.) in a webview panel\",\n    \"Reveals and highlights specific code ranges when clicking on analysis items\",\n    \"Opens external links in the default browser when clicked\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides methods to programmatically navigate to ProductNavItem objects (files, functions, endpoints)\",\n    \"Provides methods to navigate to AnalysisItem objects from analysis results\",\n    \"Handles both absolute and relative file paths relative to workspace root\",\n    \"Searches for function definitions by name within opened documents\",\n    \"Creates and manages webview panels for displaying detailed item information\",\n    \"Converts file paths to VS Code URI format for opening documents\",\n    \"Handles navigation for different item types: files, functions, endpoints, entry points\",\n    \"Provides link handling for external URLs in webview content\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file or function) and opens it in the editor\",\n      \"inputs\": \"ProductNavItem (type: file/function/navigate, data with file path and optional function name)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item and reveals it in the editor with highlighting\",\n      \"inputs\": \"AnalysisItem (with file path, line number, and column information)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a code item in a webview panel\",\n      \"inputs\": \"ProductNavItem or AnalysisItem (with metadata like name, type, description, file location)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point (function, endpoint, etc.) and positions cursor at its location\",\n      \"inputs\": \"EntryPoint (with file path, line number, column, and name)\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic in one place, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to files, functions, and other code items regardless of where the navigation request originates.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Generates structured prompts for AI-powered code analysis and documentation",
        "Creates prompts for extracting testable functions and methods from source code",
        "Builds prompts for comprehensive project architecture analysis",
        "Generates prompts for automated test plan creation and test code generation",
        "Produces prompts for code refactoring recommendations with migration plans",
        "Constructs prompts for module and file-level documentation generation"
      ],
      "summary": "The prompts module serves as the AI prompt engineering layer for the application, generating specialized instruction templates that guide language models to perform various code analysis, documentation, and testing tasks. It provides a collection of prompt builders that create structured, consistent instructions for LLMs to analyze codebases, extract information, and generate outputs like documentation, test plans, and refactoring recommendations.\n\nThis module enables users to leverage AI capabilities across multiple workflows including project documentation generation, test strategy development, code refactoring guidance, and automated test implementation. Each prompt builder is designed to ensure the LLM receives clear, contextual instructions that produce actionable results. The module handles the complexity of translating user intentions into effective AI prompts, managing token budgets, and structuring inputs for optimal LLM performance.\n\nThe prompt builders work together to support end-to-end workflows: from analyzing project architecture and documenting code structure, to identifying testable components and generating comprehensive test suites, to recommending refactoring strategies with detailed migration steps. This creates a cohesive AI-assisted development experience where users can generate high-quality documentation, testing artifacts, and improvement recommendations through natural language interactions with the codebase.",
      "files": [
        {
          "file": "src/domain/prompts/functionExtractionPrompt.ts",
          "role": "Core Logic",
          "purpose": "Builds a prompt template for LLM-based extraction of testable functions, methods, and classes from source code files, replacing regex-based extraction that incorrectly captured control flow keywords.",
          "userVisibleActions": [
            "N/A - Internal prompt generation utility with no direct user interface"
          ],
          "developerVisibleActions": [
            "Developer calls buildFunctionExtractionPrompt() with an array of source files to analyze",
            "Receives a formatted prompt string that can be sent to an LLM for code analysis",
            "Can specify maximum functions to extract per file via maxFunctionsPerFile parameter",
            "System automatically truncates files over 10,000 characters to prevent token limit issues",
            "System includes file paths, languages, and formatted source code in the prompt",
            "System instructs LLM to extract functions/methods/classes while excluding control flow statements",
            "System requests structured output including name, file path, line numbers, complexity, dependencies, and visibility for each extracted item"
          ],
          "keyFunctions": [
            {
              "name": "buildFunctionExtractionPrompt",
              "desc": "Constructs an LLM prompt for extracting testable code elements from source files with specific rules to avoid control flow keywords",
              "inputs": "files (array of objects with path, content, language), maxFunctionsPerFile (optional number, default 50)",
              "outputs": "Formatted prompt string containing instructions and source code for LLM analysis"
            }
          ],
          "dependencies": [],
          "intent": "This file exists to solve the problem of accurately extracting testable functions from source code by using LLM-based analysis instead of regex patterns. It addresses the specific issue where regex incorrectly captured control flow keywords (if, for, while, etc.) as functions. The prompt template ensures the LLM understands what constitutes a valid testable function versus control flow statements, enabling more accurate test generation workflows.",
          "rawContent": "```json\n{\n  \"purpose\": \"Builds a prompt template for LLM-based extraction of testable functions, methods, and classes from source code files, replacing regex-based extraction that incorrectly captured control flow keywords.\",\n  \"userVisibleActions\": [\n    \"N/A - Internal prompt generation utility with no direct user interface\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildFunctionExtractionPrompt() with an array of source files to analyze\",\n    \"Receives a formatted prompt string that can be sent to an LLM for code analysis\",\n    \"Can specify maximum functions to extract per file via maxFunctionsPerFile parameter\",\n    \"System automatically truncates files over 10,000 characters to prevent token limit issues\",\n    \"System includes file paths, languages, and formatted source code in the prompt\",\n    \"System instructs LLM to extract functions/methods/classes while excluding control flow statements\",\n    \"System requests structured output including name, file path, line numbers, complexity, dependencies, and visibility for each extracted item\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildFunctionExtractionPrompt\",\n      \"desc\": \"Constructs an LLM prompt for extracting testable code elements from source files with specific rules to avoid control flow keywords\",\n      \"inputs\": \"files (array of objects with path, content, language), maxFunctionsPerFile (optional number, default 50)\",\n      \"outputs\": \"Formatted prompt string containing instructions and source code for LLM analysis\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to solve the problem of accurately extracting testable functions from source code by using LLM-based analysis instead of regex patterns. It addresses the specific issue where regex incorrectly captured control flow keywords (if, for, while, etc.) as functions. The prompt template ensures the LLM understands what constitutes a valid testable function versus control flow statements, enabling more accurate test generation workflows.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Constructs structured prompts for AI/LLM analysis tasks across the entire codebase, ensuring consistent and effective communication with language models.",
          "userVisibleActions": [
            "Analyzes project architecture and generates comprehensive documentation",
            "Creates product-level documentation from codebase analysis",
            "Generates test plans for code files with coverage recommendations",
            "Produces test code based on defined test scenarios",
            "Documents individual files with user-facing behavior descriptions",
            "Summarizes code modules and their relationships"
          ],
          "developerVisibleActions": [
            "Provides centralized prompt generation for all LLM analysis operations",
            "Builds architecture analysis prompts with codebase context and product documentation",
            "Constructs product documentation prompts from analysis context",
            "Creates file-specific analysis prompts with role-based categorization",
            "Generates module rollup prompts for aggregating file summaries",
            "Builds test planning prompts with existing test awareness and function metadata",
            "Produces test code generation prompts with source code and test framework details",
            "Eliminates prompt duplication across different analysis services",
            "Supports multiple programming languages and test frameworks"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Constructs a prompt for analyzing overall system architecture",
              "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
              "outputs": "string prompt for LLM consumption"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Creates a prompt for generating product-level documentation",
              "inputs": "context (AnalysisContext)",
              "outputs": "string prompt for documentation generation"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Generates a prompt for understanding the product's core purpose",
              "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
              "outputs": "string prompt for purpose analysis"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Creates a prompt for analyzing individual code files",
              "inputs": "file (FileInfo), content (string), role (string)",
              "outputs": "string prompt for file analysis"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Constructs a prompt for aggregating multiple file summaries into module documentation",
              "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
              "outputs": "string prompt for module summary"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Builds a comprehensive prompt for product-wide documentation",
              "inputs": "fileSummaries, moduleSummaries, analysis (CodeAnalysis), fileAccessHelper",
              "outputs": "string prompt for product documentation"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Creates a prompt for generating test plans for specific files",
              "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
              "outputs": "string prompt for test planning"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Generates a prompt for creating actual test code from test plans",
              "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
              "outputs": "string prompt for test code generation"
            }
          ],
          "dependencies": [
            "../../llmService",
            "../../analyzer",
            "../../fileDocumentation",
            "../../fileAccessHelper"
          ],
          "intent": "This file exists to eliminate duplication and ensure consistency across all AI/LLM interactions by centralizing prompt construction logic. It solves the problem of scattered, inconsistent prompt generation throughout the codebase, making it easier to maintain and improve how the system communicates with language models for analysis, documentation, and test generation tasks.",
          "rawContent": "```json\n{\n  \"purpose\": \"Constructs structured prompts for AI/LLM analysis tasks across the entire codebase, ensuring consistent and effective communication with language models.\",\n  \"userVisibleActions\": [\n    \"Analyzes project architecture and generates comprehensive documentation\",\n    \"Creates product-level documentation from codebase analysis\",\n    \"Generates test plans for code files with coverage recommendations\",\n    \"Produces test code based on defined test scenarios\",\n    \"Documents individual files with user-facing behavior descriptions\",\n    \"Summarizes code modules and their relationships\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized prompt generation for all LLM analysis operations\",\n    \"Builds architecture analysis prompts with codebase context and product documentation\",\n    \"Constructs product documentation prompts from analysis context\",\n    \"Creates file-specific analysis prompts with role-based categorization\",\n    \"Generates module rollup prompts for aggregating file summaries\",\n    \"Builds test planning prompts with existing test awareness and function metadata\",\n    \"Produces test code generation prompts with source code and test framework details\",\n    \"Eliminates prompt duplication across different analysis services\",\n    \"Supports multiple programming languages and test frameworks\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing overall system architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"string prompt for LLM consumption\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates a prompt for generating product-level documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"string prompt for documentation generation\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Generates a prompt for understanding the product's core purpose\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"string prompt for purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates a prompt for analyzing individual code files\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"string prompt for file analysis\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs a prompt for aggregating multiple file summaries into module documentation\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"string prompt for module summary\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Builds a comprehensive prompt for product-wide documentation\",\n      \"inputs\": \"fileSummaries, moduleSummaries, analysis (CodeAnalysis), fileAccessHelper\",\n      \"outputs\": \"string prompt for product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates a prompt for generating test plans for specific files\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"string prompt for test planning\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates a prompt for creating actual test code from test plans\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"string prompt for test code generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and ensure consistency across all AI/LLM interactions by centralizing prompt construction logic. It solves the problem of scattered, inconsistent prompt generation throughout the codebase, making it easier to maintain and improve how the system communicates with language models for analysis, documentation, and test generation tasks.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Generates AI prompts that instruct an LLM to create detailed code refactoring plans with function extraction recommendations.",
          "userVisibleActions": [
            "Receives detailed refactoring recommendations for improving code organization",
            "Gets step-by-step migration plans for extracting functions to new files",
            "Views before/after code examples showing proposed refactoring changes",
            "Sees analysis of function dependencies and which code calls what"
          ],
          "developerVisibleActions": [
            "Builds comprehensive prompts that guide LLMs to generate refactoring reports",
            "Includes code analysis data, product documentation, and architecture insights in prompts",
            "Generates prompts that request function extraction plans with dependencies and migration steps",
            "Provides function-level analysis including responsibilities, dependencies, and dependents",
            "Creates prompts requesting before/after code examples for refactoring changes"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Creates a comprehensive prompt for generating detailed refactoring recommendations",
              "inputs": "context (analysis settings), codeAnalysis (parsed code structure), productDocs (optional documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)",
              "outputs": "String prompt for LLM to generate refactoring report"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Constructs the foundational prompt section with project context and code analysis",
              "inputs": "context, codeAnalysis, productDocs, architectureInsights",
              "outputs": "String containing base prompt instructions"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Adds detailed function analysis information to the prompt",
              "inputs": "functionAnalyses (array of function metadata)",
              "outputs": "String section describing function responsibilities and relationships"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Specifies requirements for LLM to generate function extraction plans",
              "inputs": "None",
              "outputs": "String section with extraction planning instructions"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
            "../../llmService (AnalysisContext, LLMInsights)",
            "../../fileDocumentation (EnhancedProductDocumentation)"
          ],
          "intent": "This file exists to translate code analysis results into structured prompts that guide AI models to generate actionable refactoring recommendations. It solves the problem of getting useful, detailed refactoring suggestions by carefully crafting prompts that include function dependencies, extraction plans, and migration steps rather than generic improvement advice.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates AI prompts that instruct an LLM to create detailed code refactoring plans with function extraction recommendations.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations for improving code organization\",\n    \"Gets step-by-step migration plans for extracting functions to new files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Sees analysis of function dependencies and which code calls what\"\n  ],\n  \"developerVisibleActions\": [\n    \"Builds comprehensive prompts that guide LLMs to generate refactoring reports\",\n    \"Includes code analysis data, product documentation, and architecture insights in prompts\",\n    \"Generates prompts that request function extraction plans with dependencies and migration steps\",\n    \"Provides function-level analysis including responsibilities, dependencies, and dependents\",\n    \"Creates prompts requesting before/after code examples for refactoring changes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for generating detailed refactoring recommendations\",\n      \"inputs\": \"context (analysis settings), codeAnalysis (parsed code structure), productDocs (optional documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)\",\n      \"outputs\": \"String prompt for LLM to generate refactoring report\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational prompt section with project context and code analysis\",\n      \"inputs\": \"context, codeAnalysis, productDocs, architectureInsights\",\n      \"outputs\": \"String containing base prompt instructions\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function analysis information to the prompt\",\n      \"inputs\": \"functionAnalyses (array of function metadata)\",\n      \"outputs\": \"String section describing function responsibilities and relationships\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Specifies requirements for LLM to generate function extraction plans\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String section with extraction planning instructions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to translate code analysis results into structured prompts that guide AI models to generate actionable refactoring recommendations. It solves the problem of getting useful, detailed refactoring suggestions by carefully crafting prompts that include function dependencies, extraction plans, and migration steps rather than generic improvement advice.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides prompt builders that generate structured instructions for an LLM to analyze codebases and create test plans, configurations, and test implementations.",
          "userVisibleActions": [
            "Automatically analyzes the project structure and suggests appropriate testing frameworks",
            "Generates prioritized test plans based on code complexity and risk",
            "Creates test implementations for specific functions",
            "Provides test setup recommendations including dependencies and configurations"
          ],
          "developerVisibleActions": [
            "Call buildSetupPrompt() with workspace info to get LLM prompt for test configuration recommendations",
            "Call buildPlanningPrompt() with code analysis to get LLM prompt for test strategy and prioritization",
            "Call buildImplementationPrompt() with function details to get LLM prompt for generating actual test code",
            "Receive structured JSON responses from LLM containing test plans, configurations, and code",
            "Prompts guide LLM to consider code complexity, dependencies, edge cases, and testing best practices"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Creates a prompt asking LLM to analyze codebase structure and recommend optimal test setup",
              "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
              "outputs": "Formatted prompt string requesting JSON response with language, framework, dependencies, and config files"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Creates a prompt asking LLM to generate a prioritized test plan based on code analysis",
              "inputs": "context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any",
              "outputs": "Formatted prompt string requesting JSON response with priority levels, coverage targets, and testing strategy"
            },
            {
              "name": "buildImplementationPrompt",
              "desc": "Creates a prompt asking LLM to generate actual test code for a specific function",
              "inputs": "testableFunction: TestableFunction, setupInfo: any, contextualInfo?: any",
              "outputs": "Formatted prompt string requesting complete test implementation with setup, assertions, and edge cases"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis type)",
            "../services/testing/types/testPlanTypes (TestableFunction type)"
          ],
          "intent": "This file exists to standardize how the system communicates with LLMs for test generation tasks. It encapsulates the complex prompt engineering needed to get high-quality, structured test recommendations and implementations from language models, ensuring consistent formatting and comprehensive coverage of testing concerns.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt builders that generate structured instructions for an LLM to analyze codebases and create test plans, configurations, and test implementations.\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes the project structure and suggests appropriate testing frameworks\",\n    \"Generates prioritized test plans based on code complexity and risk\",\n    \"Creates test implementations for specific functions\",\n    \"Provides test setup recommendations including dependencies and configurations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace info to get LLM prompt for test configuration recommendations\",\n    \"Call buildPlanningPrompt() with code analysis to get LLM prompt for test strategy and prioritization\",\n    \"Call buildImplementationPrompt() with function details to get LLM prompt for generating actual test code\",\n    \"Receive structured JSON responses from LLM containing test plans, configurations, and code\",\n    \"Prompts guide LLM to consider code complexity, dependencies, edge cases, and testing best practices\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to analyze codebase structure and recommend optimal test setup\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"Formatted prompt string requesting JSON response with language, framework, dependencies, and config files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to generate a prioritized test plan based on code analysis\",\n      \"inputs\": \"context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"Formatted prompt string requesting JSON response with priority levels, coverage targets, and testing strategy\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to generate actual test code for a specific function\",\n      \"inputs\": \"testableFunction: TestableFunction, setupInfo: any, contextualInfo?: any\",\n      \"outputs\": \"Formatted prompt string requesting complete test implementation with setup, assertions, and edge cases\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis type)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction type)\"\n  ],\n  \"intent\": \"This file exists to standardize how the system communicates with LLMs for test generation tasks. It encapsulates the complex prompt engineering needed to get high-quality, structured test recommendations and implementations from language models, ensuring consistent formatting and comprehensive coverage of testing concerns.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatic file system monitoring and change detection across the extension",
        "Iterative AI-powered code analysis that automatically gathers required context",
        "Intelligent test framework detection and configuration validation",
        "Real-time synchronization of views and data when files are modified",
        "Automatic detection of missing test dependencies and configuration issues",
        "Progressive analysis that reads additional files and searches code as needed"
      ],
      "summary": "The services module provides core automated workflows that enhance the user experience by eliminating manual configuration and monitoring tasks. It includes a file watcher service that automatically detects changes to files in the workspace, ensuring that all views and analysis results stay synchronized with the latest file system state without requiring manual refreshes. The incremental analysis service powers intelligent code understanding by iteratively requesting additional context, reading relevant files, and performing grep searches until sufficient information is gathered for analysis tasks.\n\nThe test configuration service automatically detects which testing framework is being used (Jest, Mocha, Vitest, or Pytest) and validates that the environment is properly configured to run generated tests. It identifies missing dependencies, checks for required configuration files, and provides actionable recommendations to fix any setup issues. Together, these services create a seamless experience where file changes are automatically tracked, code analysis progressively deepens its understanding, and test generation works reliably without manual environment setup.\n\nThese services work behind the scenes to support user-facing features like test generation, code analysis, and file-based insights. Users benefit from automatic updates when files change, intelligent analysis that knows when to gather more information, and test generation that adapts to their specific testing setup without requiring configuration knowledge.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides a centralized service for monitoring file system changes and document saves across the extension, eliminating duplication of file watching logic.",
          "userVisibleActions": [
            "Files are automatically monitored for changes when opened or created",
            "Updates occur automatically when files are saved, modified, or deleted",
            "File system changes trigger automatic refreshes of views and data",
            "Changes to specific file patterns (like product files or insights) are detected in real-time"
          ],
          "developerVisibleActions": [
            "Register file watchers for specific patterns (e.g., '**/*.md', '**/*.json')",
            "Subscribe to file creation, modification, and deletion events",
            "Register handlers for document save events",
            "Ignore specific file patterns when watching (e.g., '.git/**', 'node_modules/**')",
            "Clean up watchers automatically when handlers are disposed",
            "Receive structured FileChangeEvent objects with URI and event type",
            "Watch multiple patterns with separate handlers for each",
            "Debounce file change events to prevent excessive handler calls"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Registers a handler to be called when files matching a pattern are created, changed, or deleted",
              "inputs": "id (string), pattern (glob or RelativePattern), handler (callback function), options (ignore patterns, event types to watch)",
              "outputs": "Disposable object to stop watching"
            },
            {
              "name": "onDidSaveTextDocument",
              "desc": "Registers a handler to be called when any text document is saved",
              "inputs": "handler (callback function receiving TextDocument)",
              "outputs": "Disposable object to unregister the handler"
            },
            {
              "name": "unwatch",
              "desc": "Removes a specific handler from watching file changes",
              "inputs": "id (string), pattern (glob or RelativePattern)",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all watchers and handlers when the service is no longer needed",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getPatternKey",
              "desc": "Generates a unique key for a file pattern to avoid duplicate watchers",
              "inputs": "pattern (string or RelativePattern)",
              "outputs": "string key"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to consolidate file watching functionality that was previously duplicated across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file monitoring behavior and prevents resource waste from multiple watchers monitoring the same files. It provides a single, reliable service that other components can use to react to file system changes without implementing their own watching logic.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes and document saves across the extension, eliminating duplication of file watching logic.\",\n  \"userVisibleActions\": [\n    \"Files are automatically monitored for changes when opened or created\",\n    \"Updates occur automatically when files are saved, modified, or deleted\",\n    \"File system changes trigger automatic refreshes of views and data\",\n    \"Changes to specific file patterns (like product files or insights) are detected in real-time\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers for specific patterns (e.g., '**/*.md', '**/*.json')\",\n    \"Subscribe to file creation, modification, and deletion events\",\n    \"Register handlers for document save events\",\n    \"Ignore specific file patterns when watching (e.g., '.git/**', 'node_modules/**')\",\n    \"Clean up watchers automatically when handlers are disposed\",\n    \"Receive structured FileChangeEvent objects with URI and event type\",\n    \"Watch multiple patterns with separate handlers for each\",\n    \"Debounce file change events to prevent excessive handler calls\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a handler to be called when files matching a pattern are created, changed, or deleted\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern), handler (callback function), options (ignore patterns, event types to watch)\",\n      \"outputs\": \"Disposable object to stop watching\"\n    },\n    {\n      \"name\": \"onDidSaveTextDocument\",\n      \"desc\": \"Registers a handler to be called when any text document is saved\",\n      \"inputs\": \"handler (callback function receiving TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific handler from watching file changes\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers when the service is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to avoid duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate file watching functionality that was previously duplicated across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file monitoring behavior and prevents resource waste from multiple watchers monitoring the same files. It provides a single, reliable service that other components can use to react to file system changes without implementing their own watching logic.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative LLM analysis by processing file read and grep search requests across multiple analysis iterations until completion or max iterations reached",
          "userVisibleActions": [
            "System performs multiple analysis passes to gather required information",
            "Additional files are read automatically when analysis needs more context",
            "Grep searches execute to find code patterns requested during analysis",
            "Analysis stops after maximum iterations or when no more information needed",
            "Progress shown as iteration count advances through analysis process"
          ],
          "developerVisibleActions": [
            "Configure maximum number of analysis iterations allowed",
            "Provide callbacks to track iteration start and completion events",
            "Receive structured results containing analysis outcome, iteration count, and all file/grep requests made",
            "Access conversation history with assistant and user messages accumulated across iterations",
            "Handle file read and grep search requests automatically limited to 5 per iteration",
            "Use async iterator pattern for incremental analysis instead of while loops"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes LLM-requested file reads and grep searches, formatting results for next iteration",
              "inputs": "requests: LLMRequest[], currentResult: any, messages: conversation history array",
              "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
            },
            {
              "name": "Constructor",
              "desc": "Initializes service with file access helper for reading files and running searches",
              "inputs": "fileAccessHelper: FileAccessHelper",
              "outputs": "IncrementalAnalysisService instance"
            }
          ],
          "dependencies": [
            "../../fileAccessHelper (FileAccessHelper, LLMRequest types)"
          ],
          "intent": "Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a reusable, testable service that handles the common pattern of: analyze → request files/searches → gather info → re-analyze → repeat until done",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file read and grep search requests across multiple analysis iterations until completion or max iterations reached\",\n  \"userVisibleActions\": [\n    \"System performs multiple analysis passes to gather required information\",\n    \"Additional files are read automatically when analysis needs more context\",\n    \"Grep searches execute to find code patterns requested during analysis\",\n    \"Analysis stops after maximum iterations or when no more information needed\",\n    \"Progress shown as iteration count advances through analysis process\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum number of analysis iterations allowed\",\n    \"Provide callbacks to track iteration start and completion events\",\n    \"Receive structured results containing analysis outcome, iteration count, and all file/grep requests made\",\n    \"Access conversation history with assistant and user messages accumulated across iterations\",\n    \"Handle file read and grep search requests automatically limited to 5 per iteration\",\n    \"Use async iterator pattern for incremental analysis instead of while loops\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, formatting results for next iteration\",\n      \"inputs\": \"requests: LLMRequest[], currentResult: any, messages: conversation history array\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"Constructor\",\n      \"desc\": \"Initializes service with file access helper for reading files and running searches\",\n      \"inputs\": \"fileAccessHelper: FileAccessHelper\",\n      \"outputs\": \"IncrementalAnalysisService instance\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileAccessHelper (FileAccessHelper, LLMRequest types)\"\n  ],\n  \"intent\": \"Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a reusable, testable service that handles the common pattern of: analyze → request files/searches → gather info → re-analyze → repeat until done\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects and configures test framework settings to ensure generated tests work without manual user setup",
          "userVisibleActions": [
            "Automatically detects which test framework (Jest, Mocha, Vitest, Pytest) is being used in the project",
            "Identifies missing test dependencies and provides setup recommendations",
            "Validates that test configuration files exist and are properly configured",
            "Reports whether the test environment is ready to run generated tests",
            "Suggests specific setup actions needed to fix configuration issues"
          ],
          "developerVisibleActions": [
            "Scans workspace root for package.json to identify test framework from scripts and dependencies",
            "Checks for framework-specific configuration files (jest.config.js, .mocharc, vitest.config.ts, pytest.ini)",
            "Detects TypeScript setup and verifies TypeScript-specific test dependencies (ts-jest, @jest/globals)",
            "Analyzes installed dependencies versus required dependencies for the detected framework",
            "Returns structured status report with framework type, configuration state, and required actions",
            "Provides list of missing dependencies that need to be installed",
            "Determines if manual setup steps are required before tests can run"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Scans project to identify test framework and configuration completeness",
              "inputs": "workspaceRoot (string path to project root)",
              "outputs": "TestConfigStatus object with framework type, configuration status, missing dependencies, and setup actions"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "SWLogger"
          ],
          "intent": "Eliminates manual test configuration burden by automatically detecting what test framework is used, what's missing, and what setup is needed, ensuring generated tests can run immediately without user intervention or troubleshooting",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects and configures test framework settings to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework (Jest, Mocha, Vitest, Pytest) is being used in the project\",\n    \"Identifies missing test dependencies and provides setup recommendations\",\n    \"Validates that test configuration files exist and are properly configured\",\n    \"Reports whether the test environment is ready to run generated tests\",\n    \"Suggests specific setup actions needed to fix configuration issues\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace root for package.json to identify test framework from scripts and dependencies\",\n    \"Checks for framework-specific configuration files (jest.config.js, .mocharc, vitest.config.ts, pytest.ini)\",\n    \"Detects TypeScript setup and verifies TypeScript-specific test dependencies (ts-jest, @jest/globals)\",\n    \"Analyzes installed dependencies versus required dependencies for the detected framework\",\n    \"Returns structured status report with framework type, configuration state, and required actions\",\n    \"Provides list of missing dependencies that need to be installed\",\n    \"Determines if manual setup steps are required before tests can run\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Scans project to identify test framework and configuration completeness\",\n      \"inputs\": \"workspaceRoot (string path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration status, missing dependencies, and setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration burden by automatically detecting what test framework is used, what's missing, and what setup is needed, ensuring generated tests can run immediately without user intervention or troubleshooting\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automated discovery and analysis of testable functions across the workspace",
        "AI-powered test generation with automatic execution and validation",
        "Intelligent test planning and prioritization based on code complexity",
        "Automatic test environment setup and configuration",
        "Self-healing test validation with automatic failure detection and fixing",
        "Comprehensive test execution with detailed pass/fail reporting"
      ],
      "summary": "The testing services module provides an end-to-end AI-powered testing workflow that automates the entire process from test environment setup to test generation, execution, and validation. Users can leverage LLM-based analysis to discover testable functions in their codebase, assess their complexity and testability characteristics, and receive prioritized recommendations for which functions need testing coverage.\n\nThe module handles the complete testing lifecycle automatically: it detects the programming language and testing framework, sets up the necessary test infrastructure including directories and dependencies, generates unit tests in batches for selected functions, executes them immediately, and validates the results. When tests fail, the system automatically attempts to fix them using AI assistance, providing progress feedback throughout each stage.\n\nUsers benefit from intelligent analysis that identifies functions requiring mocks, rates complexity levels, and avoids false positives in testability assessments. The workflow provides continuous feedback showing batch processing status, test generation progress, execution results with pass/fail counts, and detailed error information when issues occur. This comprehensive automation reduces manual testing effort while improving test coverage quality.",
      "files": [
        {
          "file": "src/domain/services/testing/llmFunctionExtractionService.ts",
          "role": "Core Logic",
          "purpose": "Extracts testable functions from workspace code files using an LLM to identify function metadata, complexity, and testability characteristics.",
          "userVisibleActions": [
            "Automated analysis of code files to identify functions that can be tested",
            "Assessment of function testability (low/medium/high) with explanations",
            "Detection of functions that require mocking due to external dependencies",
            "Complexity rating (low/medium/high) assigned to each discovered function",
            "Progress feedback showing batch processing status during analysis"
          ],
          "developerVisibleActions": [
            "Call extractFunctionsFromWorkspace() to analyze multiple code files in batches",
            "Call extractFunctionsFromSingleFile() to analyze a single file in isolation",
            "Receive structured function metadata including name, location, parameters, return types, and dependencies",
            "Configure batch size (maxFilesPerBatch) to control token usage and API limits",
            "Get detailed extraction results with total function count and files analyzed",
            "Access logging output showing processing progress and any extraction errors"
          ],
          "keyFunctions": [
            {
              "name": "extractFunctionsFromWorkspace",
              "desc": "Analyzes all code files in workspace to extract function metadata using LLM in configurable batches",
              "inputs": "workspaceRoot path, array of code file paths, llmService instance, optional maxFilesPerBatch",
              "outputs": "Array of ExtractedFunction objects with metadata about each discovered function"
            },
            {
              "name": "extractFunctionsFromSingleFile",
              "desc": "Analyzes a single code file to extract all functions and their metadata using LLM",
              "inputs": "File path, file content, llmService instance",
              "outputs": "Array of ExtractedFunction objects from the analyzed file"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "CodeAnalysis",
            "buildFunctionExtractionPrompt",
            "buildSingleFileExtractionPrompt",
            "SWLogger"
          ],
          "intent": "Replaces regex-based function extraction with LLM-powered analysis to accurately identify testable functions while avoiding false positives from control flow keywords (if, while, for, etc.). Enables intelligent test generation by providing rich metadata about each function including complexity, dependencies, API calls, and testability assessment.",
          "rawContent": "```json\n{\n  \"purpose\": \"Extracts testable functions from workspace code files using an LLM to identify function metadata, complexity, and testability characteristics.\",\n  \"userVisibleActions\": [\n    \"Automated analysis of code files to identify functions that can be tested\",\n    \"Assessment of function testability (low/medium/high) with explanations\",\n    \"Detection of functions that require mocking due to external dependencies\",\n    \"Complexity rating (low/medium/high) assigned to each discovered function\",\n    \"Progress feedback showing batch processing status during analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call extractFunctionsFromWorkspace() to analyze multiple code files in batches\",\n    \"Call extractFunctionsFromSingleFile() to analyze a single file in isolation\",\n    \"Receive structured function metadata including name, location, parameters, return types, and dependencies\",\n    \"Configure batch size (maxFilesPerBatch) to control token usage and API limits\",\n    \"Get detailed extraction results with total function count and files analyzed\",\n    \"Access logging output showing processing progress and any extraction errors\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"extractFunctionsFromWorkspace\",\n      \"desc\": \"Analyzes all code files in workspace to extract function metadata using LLM in configurable batches\",\n      \"inputs\": \"workspaceRoot path, array of code file paths, llmService instance, optional maxFilesPerBatch\",\n      \"outputs\": \"Array of ExtractedFunction objects with metadata about each discovered function\"\n    },\n    {\n      \"name\": \"extractFunctionsFromSingleFile\",\n      \"desc\": \"Analyzes a single code file to extract all functions and their metadata using LLM\",\n      \"inputs\": \"File path, file content, llmService instance\",\n      \"outputs\": \"Array of ExtractedFunction objects from the analyzed file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"CodeAnalysis\",\n    \"buildFunctionExtractionPrompt\",\n    \"buildSingleFileExtractionPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Replaces regex-based function extraction with LLM-powered analysis to accurately identify testable functions while avoiding false positives from control flow keywords (if, while, for, etc.). Enables intelligent test generation by providing rich metadata about each function including complexity, dependencies, API calls, and testability assessment.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates unit tests for code functions in small batches using an LLM service, executing them and tracking generation state",
          "userVisibleActions": [
            "Tests are generated automatically for selected functions in the workspace",
            "Progress updates show which function is being processed and how many are complete",
            "Generated tests are saved to the test directory and can be executed immediately",
            "Test execution results show pass/fail status and coverage information",
            "Failed test generation attempts are reported with error messages"
          ],
          "developerVisibleActions": [
            "Developer triggers test generation for a batch of functions from their codebase",
            "Service reads the source code of each function to understand its behavior",
            "LLM generates test code based on the function's implementation and context",
            "Generated tests are written to the file system in the test directory",
            "Tests are automatically executed to verify they work correctly",
            "Service tracks which functions have tests generated, which passed, and which failed",
            "Developer receives a map of results showing success/failure for each function",
            "Existing mock files are detected and included in the generation context"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for multiple functions in a batch, processing them sequentially",
              "inputs": "Array of TestableFunction objects, workspace root path, LLM service instance, optional progress callback",
              "outputs": "Map of function names to TestGenerationResult objects containing success/failure status"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Reads and extracts the source code for a specific function from the file system",
              "inputs": "TestableFunction object, workspace root path",
              "outputs": "String containing the function's source code"
            },
            {
              "name": "extractFileContext",
              "desc": "Extracts import/export context from the source file to provide additional context for test generation",
              "inputs": "File path, workspace root path",
              "outputs": "String containing file context information"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestableFunction",
            "TestGenerationState",
            "TestGenerationResult",
            "buildGenerationPrompt",
            "TestExecutionService",
            "SWLogger"
          ],
          "intent": "This file exists to automate the tedious process of writing unit tests by leveraging LLM capabilities to generate tests incrementally in manageable batches, ensuring each function has proper test coverage without overwhelming the system or developer with too many tests at once.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions in small batches using an LLM service, executing them and tracking generation state\",\n  \"userVisibleActions\": [\n    \"Tests are generated automatically for selected functions in the workspace\",\n    \"Progress updates show which function is being processed and how many are complete\",\n    \"Generated tests are saved to the test directory and can be executed immediately\",\n    \"Test execution results show pass/fail status and coverage information\",\n    \"Failed test generation attempts are reported with error messages\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for a batch of functions from their codebase\",\n    \"Service reads the source code of each function to understand its behavior\",\n    \"LLM generates test code based on the function's implementation and context\",\n    \"Generated tests are written to the file system in the test directory\",\n    \"Tests are automatically executed to verify they work correctly\",\n    \"Service tracks which functions have tests generated, which passed, and which failed\",\n    \"Developer receives a map of results showing success/failure for each function\",\n    \"Existing mock files are detected and included in the generation context\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, processing them sequentially\",\n      \"inputs\": \"Array of TestableFunction objects, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects containing success/failure status\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Reads and extracts the source code for a specific function from the file system\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"String containing the function's source code\"\n    },\n    {\n      \"name\": \"extractFileContext\",\n      \"desc\": \"Extracts import/export context from the source file to provide additional context for test generation\",\n      \"inputs\": \"File path, workspace root path\",\n      \"outputs\": \"String containing file context information\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the tedious process of writing unit tests by leveraging LLM capabilities to generate tests incrementally in manageable batches, ensuring each function has proper test coverage without overwhelming the system or developer with too many tests at once.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Creates prioritized test plans by analyzing code functions and determining which ones need testing using LLM-based analysis.",
          "userVisibleActions": [
            "Receives an AI-generated test plan that prioritizes which functions in the codebase need testing",
            "Gets test plans based on intelligent analysis of function complexity and importance",
            "Benefits from improved test coverage recommendations that avoid false positives from control flow keywords"
          ],
          "developerVisibleActions": [
            "Calls analyzeFunctions to extract testable functions from workspace code files using LLM analysis",
            "Receives structured test plan data with function metadata (name, file, lines, complexity, parameters, return type)",
            "Uses LLM service to intelligently identify actual functions versus control flow statements",
            "Accesses legacy regex-based function extraction as fallback (deprecated)",
            "Gets functions converted to test plan format ready for prioritization"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts and analyzes testable functions from workspace code files using LLM instead of regex to avoid capturing control flow keywords",
              "inputs": "workspaceRoot (string), codeFiles (string array), llmService (LLM service instance)",
              "outputs": "Array of function metadata objects in test plan format"
            },
            {
              "name": "analyzeFunctionsLegacy",
              "desc": "Deprecated regex-based function extraction that incorrectly captured control flow keywords like for, if, switch",
              "inputs": "codeAnalysis (code analysis object)",
              "outputs": "Array of function metadata objects"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "testPlanTypes",
            "testPrompts",
            "CodeAnalysis",
            "SWLogger",
            "LLMFunctionExtractionService"
          ],
          "intent": "This file solves the problem of accurately identifying which functions in a codebase should be tested by using LLM analysis to distinguish real functions from control flow statements (for, if, switch), replacing unreliable regex-based extraction that created false positives. It enables intelligent test planning by providing structured function metadata that can be prioritized for test generation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates prioritized test plans by analyzing code functions and determining which ones need testing using LLM-based analysis.\",\n  \"userVisibleActions\": [\n    \"Receives an AI-generated test plan that prioritizes which functions in the codebase need testing\",\n    \"Gets test plans based on intelligent analysis of function complexity and importance\",\n    \"Benefits from improved test coverage recommendations that avoid false positives from control flow keywords\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions to extract testable functions from workspace code files using LLM analysis\",\n    \"Receives structured test plan data with function metadata (name, file, lines, complexity, parameters, return type)\",\n    \"Uses LLM service to intelligently identify actual functions versus control flow statements\",\n    \"Accesses legacy regex-based function extraction as fallback (deprecated)\",\n    \"Gets functions converted to test plan format ready for prioritization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and analyzes testable functions from workspace code files using LLM instead of regex to avoid capturing control flow keywords\",\n      \"inputs\": \"workspaceRoot (string), codeFiles (string array), llmService (LLM service instance)\",\n      \"outputs\": \"Array of function metadata objects in test plan format\"\n    },\n    {\n      \"name\": \"analyzeFunctionsLegacy\",\n      \"desc\": \"Deprecated regex-based function extraction that incorrectly captured control flow keywords like for, if, switch\",\n      \"inputs\": \"codeAnalysis (code analysis object)\",\n      \"outputs\": \"Array of function metadata objects\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"testPlanTypes\",\n    \"testPrompts\",\n    \"CodeAnalysis\",\n    \"SWLogger\",\n    \"LLMFunctionExtractionService\"\n  ],\n  \"intent\": \"This file solves the problem of accurately identifying which functions in a codebase should be tested by using LLM analysis to distinguish real functions from control flow statements (for, if, switch), replacing unreliable regex-based extraction that created false positives. It enables intelligent test planning by providing structured function metadata that can be prioritized for test generation.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Detects test environment configuration and generates automated test setup plans using LLM analysis.",
          "userVisibleActions": [
            "Automatically detects the programming language and testing framework in the workspace",
            "Identifies existing test infrastructure (package.json, jest config, test directories)",
            "Generates a test setup plan with configuration recommendations",
            "Creates missing test directories and configuration files",
            "Installs required testing dependencies automatically",
            "Provides feedback on setup progress and results"
          ],
          "developerVisibleActions": [
            "Scans workspace to identify TypeScript, JavaScript, Python, Java, or C++ projects",
            "Detects testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)",
            "Analyzes package.json and configuration files to understand existing setup",
            "Generates LLM prompts to create customized test configurations",
            "Executes setup commands (npm install, directory creation, file generation)",
            "Returns structured setup results with success/failure status"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Analyzes workspace to identify programming language, testing framework, and existing configuration",
              "inputs": "workspaceRoot (string path)",
              "outputs": "TestEnvironment object with language, framework, and configuration details"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively scans directory to collect all files for language detection",
              "inputs": "dirPath (string), fileList (optional array)",
              "outputs": "Array of file paths"
            },
            {
              "name": "generateSetupPlan",
              "desc": "Creates an LLM-based test setup plan based on detected environment",
              "inputs": "environment (TestEnvironment), llmService",
              "outputs": "TestSetupPlan with configuration steps and recommendations"
            },
            {
              "name": "executeSetupPlan",
              "desc": "Runs the generated setup plan by creating files and installing dependencies",
              "inputs": "plan (TestSetupPlan), workspaceRoot (string)",
              "outputs": "SetupExecutionResult with success status and messages"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "testSetupTypes",
            "testPrompts",
            "SWLogger"
          ],
          "intent": "This service exists to eliminate manual test environment setup by automatically detecting the project type and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, create test directories, and install dependencies by using LLM intelligence to understand the project structure and generate appropriate setup steps.",
          "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates automated test setup plans using LLM analysis.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language and testing framework in the workspace\",\n    \"Identifies existing test infrastructure (package.json, jest config, test directories)\",\n    \"Generates a test setup plan with configuration recommendations\",\n    \"Creates missing test directories and configuration files\",\n    \"Installs required testing dependencies automatically\",\n    \"Provides feedback on setup progress and results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace to identify TypeScript, JavaScript, Python, Java, or C++ projects\",\n    \"Detects testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)\",\n    \"Analyzes package.json and configuration files to understand existing setup\",\n    \"Generates LLM prompts to create customized test configurations\",\n    \"Executes setup commands (npm install, directory creation, file generation)\",\n    \"Returns structured setup results with success/failure status\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to identify programming language, testing framework, and existing configuration\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"TestEnvironment object with language, framework, and configuration details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans directory to collect all files for language detection\",\n      \"inputs\": \"dirPath (string), fileList (optional array)\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"generateSetupPlan\",\n      \"desc\": \"Creates an LLM-based test setup plan based on detected environment\",\n      \"inputs\": \"environment (TestEnvironment), llmService\",\n      \"outputs\": \"TestSetupPlan with configuration steps and recommendations\"\n    },\n    {\n      \"name\": \"executeSetupPlan\",\n      \"desc\": \"Runs the generated setup plan by creating files and installing dependencies\",\n      \"inputs\": \"plan (TestSetupPlan), workspaceRoot (string)\",\n      \"outputs\": \"SetupExecutionResult with success status and messages\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to eliminate manual test environment setup by automatically detecting the project type and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, create test directories, and install dependencies by using LLM intelligence to understand the project structure and generate appropriate setup steps.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates test files by running them, detecting failures, and automatically fixing broken tests using LLM assistance",
          "userVisibleActions": [
            "Tests are automatically executed and results are reported (passed/failed counts)",
            "Failing tests are identified and reported with error details",
            "Tests are automatically fixed when failures are detected",
            "Progress updates show which attempt is being made to fix a test (e.g., 'attempt 2/3')",
            "Final success or failure status is reported after fix attempts"
          ],
          "developerVisibleActions": [
            "Developer triggers test validation for a workspace or specific test file",
            "System runs Jest tests and captures execution results",
            "System reads failing test code and generates LLM prompts to fix issues",
            "System applies LLM-suggested fixes by updating test files",
            "System re-runs tests to verify fixes worked",
            "Developer receives structured test reports with pass/fail statistics",
            "System logs all validation and fix attempts for debugging"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or a specific test file and returns results with pass/fail statistics",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Array of TestExecutionResult objects with passed/failed/error counts"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to automatically fix a failing test by using LLM to analyze errors and suggest corrections",
              "inputs": "testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)",
              "outputs": "Object with success status, number of attempts made, and optional final error message"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "TestExecutionResult",
            "TestReport",
            "TestReportSummary",
            "buildFixPrompt",
            "SWLogger"
          ],
          "intent": "This file exists to automate the test validation workflow by running tests, detecting failures, and using AI to automatically fix broken tests instead of requiring manual developer intervention. It solves the problem of time-consuming manual test debugging and repair by leveraging LLM capabilities to understand test failures and generate fixes.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates test files by running them, detecting failures, and automatically fixing broken tests using LLM assistance\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed and results are reported (passed/failed counts)\",\n    \"Failing tests are identified and reported with error details\",\n    \"Tests are automatically fixed when failures are detected\",\n    \"Progress updates show which attempt is being made to fix a test (e.g., 'attempt 2/3')\",\n    \"Final success or failure status is reported after fix attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test validation for a workspace or specific test file\",\n    \"System runs Jest tests and captures execution results\",\n    \"System reads failing test code and generates LLM prompts to fix issues\",\n    \"System applies LLM-suggested fixes by updating test files\",\n    \"System re-runs tests to verify fixes worked\",\n    \"Developer receives structured test reports with pass/fail statistics\",\n    \"System logs all validation and fix attempts for debugging\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns results with pass/fail statistics\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Array of TestExecutionResult objects with passed/failed/error counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test by using LLM to analyze errors and suggest corrections\",\n      \"inputs\": \"testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)\",\n      \"outputs\": \"Object with success status, number of attempts made, and optional final error message\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation workflow by running tests, detecting failures, and using AI to automatically fix broken tests instead of requiring manual developer intervention. It solves the problem of time-consuming manual test debugging and repair by leveraging LLM capabilities to understand test failures and generate fixes.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes Jest tests and captures their results, providing detailed test execution information including passes, failures, and errors.",
          "userVisibleActions": [
            "Run all tests in the workspace",
            "Run tests for a specific test file",
            "View test execution results with pass/fail counts",
            "See detailed error messages and stack traces when tests fail",
            "Get notified when test execution times out or fails to run",
            "View test execution duration"
          ],
          "developerVisibleActions": [
            "Execute Jest tests programmatically via Node.js child process",
            "Parse Jest JSON output to extract test results",
            "Handle test execution errors and timeouts gracefully",
            "Capture both stdout and stderr from test execution",
            "Convert raw Jest output into structured TestExecutionResult objects",
            "Process individual test suite results with detailed pass/fail/error breakdowns",
            "Extract error details including test names, messages, and stack traces"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Executes Jest tests for a specific file or all tests in the workspace",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> containing test results with status, counts, and error details"
            },
            {
              "name": "parseJestOutput",
              "desc": "Parses Jest JSON output from stdout/stderr into structured test result objects",
              "inputs": "stdout (string), stderr (string)",
              "outputs": "TestExecutionResult[] array with parsed test data"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "This file exists to provide a reliable interface for running Jest tests within a VS Code extension or development environment, handling the complexity of executing external test commands, parsing their output, and converting it into a structured format that can be displayed to users or processed by other services. It solves the problem of bridging between Jest's command-line interface and the application's need for structured test execution data.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes Jest tests and captures their results, providing detailed test execution information including passes, failures, and errors.\",\n  \"userVisibleActions\": [\n    \"Run all tests in the workspace\",\n    \"Run tests for a specific test file\",\n    \"View test execution results with pass/fail counts\",\n    \"See detailed error messages and stack traces when tests fail\",\n    \"Get notified when test execution times out or fails to run\",\n    \"View test execution duration\"\n  ],\n  \"developerVisibleActions\": [\n    \"Execute Jest tests programmatically via Node.js child process\",\n    \"Parse Jest JSON output to extract test results\",\n    \"Handle test execution errors and timeouts gracefully\",\n    \"Capture both stdout and stderr from test execution\",\n    \"Convert raw Jest output into structured TestExecutionResult objects\",\n    \"Process individual test suite results with detailed pass/fail/error breakdowns\",\n    \"Extract error details including test names, messages, and stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests for a specific file or all tests in the workspace\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test results with status, counts, and error details\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output from stdout/stderr into structured test result objects\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] array with parsed test data\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This file exists to provide a reliable interface for running Jest tests within a VS Code extension or development environment, handling the complexity of executing external test commands, parsing their output, and converting it into a structured format that can be displayed to users or processed by other services. It solves the problem of bridging between Jest's command-line interface and the application's need for structured test execution data.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Define and track comprehensive test plan structures with function organization and priority grouping",
        "Monitor test generation progress through multiple phases (setup, planning, generation, validation, completion)",
        "Track test execution results with detailed pass/fail statistics and error reporting",
        "Configure test environment setup including framework selection, dependency management, and mock requirements",
        "Validate test quality with recommendations and detailed error diagnostics",
        "Organize testable functions with metadata including file paths, complexity, and priority levels"
      ],
      "summary": "This module provides TypeScript type definitions that structure the entire test generation and execution lifecycle. Users can view and track test plans that organize functions by priority, monitor progress as tests move through setup, planning, generation, and validation phases, and see detailed statistics on test coverage including counts of total, testable, generated, and validated functions.\n\nThe module enables users to receive comprehensive test execution results including pass/fail status for each test file, execution duration, error messages with stack traces, and overall test statistics. Users can access test reports that provide pass rates, file-level statistics, and actionable recommendations for improving test quality. The module also supports test environment configuration, allowing users to see what dependencies need to be installed, which configuration files will be created, and what mock requirements are needed for proper test execution.\n\nThrough these type definitions, users gain visibility into test failures with detailed error messages and retry attempt tracking, enabling them to diagnose and fix issues efficiently. The structured approach to test organization helps users understand which functions are being tested, their relative priority, and the overall health of their test suite through comprehensive reporting and progress tracking.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces for structuring test plans, tracking test generation progress, and organizing testable functions with their metadata.",
          "userVisibleActions": [
            "Views test plan showing total and testable function counts",
            "Sees functions organized into priority groups",
            "Tracks test generation progress through phases (setup, planning, generation, validation, complete)",
            "Monitors number of functions generated and validated",
            "Reviews test failures with error messages and retry attempts"
          ],
          "developerVisibleActions": [
            "Accesses structured test plan data with strategy and function groupings",
            "Uses TestPlan interface to organize functions by priority groups",
            "Tracks test generation workflow through TestGenerationState phases",
            "Retrieves function metadata including complexity, dependencies, and mocking requirements",
            "Monitors current batch of functions being processed",
            "Accesses failure records with function names, errors, and attempt counts"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides type safety and structured data contracts for the test planning and generation service, ensuring consistent representation of test plans, function metadata, generation progress tracking, and failure handling across the testing domain.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for structuring test plans, tracking test generation progress, and organizing testable functions with their metadata.\",\n  \"userVisibleActions\": [\n    \"Views test plan showing total and testable function counts\",\n    \"Sees functions organized into priority groups\",\n    \"Tracks test generation progress through phases (setup, planning, generation, validation, complete)\",\n    \"Monitors number of functions generated and validated\",\n    \"Reviews test failures with error messages and retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Accesses structured test plan data with strategy and function groupings\",\n    \"Uses TestPlan interface to organize functions by priority groups\",\n    \"Tracks test generation workflow through TestGenerationState phases\",\n    \"Retrieves function metadata including complexity, dependencies, and mocking requirements\",\n    \"Monitors current batch of functions being processed\",\n    \"Accesses failure records with function names, errors, and attempt counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structured data contracts for the test planning and generation service, ensuring consistent representation of test plans, function metadata, generation progress tracking, and failure handling across the testing domain.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type structures for test generation, validation, execution results, and reporting in a testing framework",
          "userVisibleActions": [
            "View test execution status (pass, fail, or error) for each test file",
            "See number of tests passed, failed, and encountered errors",
            "Review test execution duration and overall test statistics",
            "Access detailed error messages and stack traces for failing tests",
            "View test report summary with pass rates and file statistics",
            "Read recommendations for improving test quality"
          ],
          "developerVisibleActions": [
            "Import type definitions to structure test generation results with file paths, imports, mocks, and test code",
            "Use MockStatement type to document mock statements with explanations",
            "Access TestValidationResult to get validation status and fixed code suggestions",
            "Retrieve TestExecutionResult for detailed test run metrics and error information",
            "Generate TestReport with summary statistics and execution results",
            "Include setup and teardown code in test generation output",
            "Track remaining issues after validation attempts"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a standardized type system for the entire test generation and validation workflow, ensuring consistent data structures across test creation, execution, validation, and reporting phases, enabling type-safe communication between testing components",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type structures for test generation, validation, execution results, and reporting in a testing framework\",\n  \"userVisibleActions\": [\n    \"View test execution status (pass, fail, or error) for each test file\",\n    \"See number of tests passed, failed, and encountered errors\",\n    \"Review test execution duration and overall test statistics\",\n    \"Access detailed error messages and stack traces for failing tests\",\n    \"View test report summary with pass rates and file statistics\",\n    \"Read recommendations for improving test quality\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import type definitions to structure test generation results with file paths, imports, mocks, and test code\",\n    \"Use MockStatement type to document mock statements with explanations\",\n    \"Access TestValidationResult to get validation status and fixed code suggestions\",\n    \"Retrieve TestExecutionResult for detailed test run metrics and error information\",\n    \"Generate TestReport with summary statistics and execution results\",\n    \"Include setup and teardown code in test generation output\",\n    \"Track remaining issues after validation attempts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for the entire test generation and validation workflow, ensuring consistent data structures across test creation, execution, validation, and reporting phases, enabling type-safe communication between testing components\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test setup and execution functionality, including test plans, dependencies, configuration files, and environment detection.",
          "userVisibleActions": [
            "User receives structured information about test setup plans including framework and dependencies",
            "User sees results of test setup execution with created files and installed dependencies",
            "User receives feedback on test environment status including missing dependencies",
            "User gets notified about mock requirements needed for testing"
          ],
          "developerVisibleActions": [
            "Developer uses TestSetupPlan interface to structure test configuration data including framework, dependencies, and mock requirements",
            "Developer uses TestEnvironment interface to detect existing test infrastructure and identify gaps",
            "Developer uses SetupExecutionResult interface to report success/failure of test setup operations",
            "Developer specifies configuration files with paths and content through ConfigFile interface",
            "Developer tracks which dependencies are dev dependencies through Dependency interface"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to provide type safety and structure for the test setup service, ensuring consistent data shapes when planning, executing, and reporting on automated test environment configuration. It solves the problem of maintaining contract definitions between components that analyze project structure, generate test configurations, and execute setup operations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup and execution functionality, including test plans, dependencies, configuration files, and environment detection.\",\n  \"userVisibleActions\": [\n    \"User receives structured information about test setup plans including framework and dependencies\",\n    \"User sees results of test setup execution with created files and installed dependencies\",\n    \"User receives feedback on test environment status including missing dependencies\",\n    \"User gets notified about mock requirements needed for testing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan interface to structure test configuration data including framework, dependencies, and mock requirements\",\n    \"Developer uses TestEnvironment interface to detect existing test infrastructure and identify gaps\",\n    \"Developer uses SetupExecutionResult interface to report success/failure of test setup operations\",\n    \"Developer specifies configuration files with paths and content through ConfigFile interface\",\n    \"Developer tracks which dependencies are dev dependencies through Dependency interface\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide type safety and structure for the test setup service, ensuring consistent data shapes when planning, executing, and reporting on automated test environment configuration. It solves the problem of maintaining contract definitions between components that analyze project structure, generate test configurations, and execute setup operations.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Optimizes file system operations through intelligent caching to reduce redundant file reads",
        "Processes multiple files in parallel with automatic filtering of common non-source directories",
        "Automatically updates cached content when files are modified externally",
        "Provides consistent error handling across all file processing operations",
        "Improves extension responsiveness when accessing project files repeatedly"
      ],
      "summary": "This module provides optimized file system operations for the VS Code extension, focusing on performance and efficiency. It implements a caching layer that stores file contents in memory, significantly reducing disk I/O when the extension needs to access the same files multiple times during operations like code analysis, documentation generation, or project scanning.\n\nThe module handles bulk file processing with intelligent defaults, automatically excluding common directories that typically don't contain source code (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea). Files are processed in parallel for maximum throughput, making operations on large codebases faster and more responsive.\n\nUsers benefit from faster extension performance without any configuration required. The cache automatically invalidates when files change, ensuring data stays fresh. Whether the extension is analyzing code, generating documentation, or scanning project structure, these file system utilities work behind the scenes to deliver a smooth, responsive experience.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Optimizes file system operations by caching file contents to reduce redundant file reads and improve performance across the extension",
          "userVisibleActions": [
            "Faster file operations when accessing the same files multiple times",
            "Improved responsiveness when extension reads project files",
            "Automatic updates when files are modified externally"
          ],
          "developerVisibleActions": [
            "Retrieve cached file contents instead of reading from disk repeatedly",
            "Automatic cache invalidation when files change on disk",
            "Access cache statistics to monitor performance (hits, misses, evictions)",
            "Configure cache size limits and time-to-live settings",
            "Clear cache manually or invalidate specific files",
            "Monitor memory usage through cache size tracking"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "invalidate",
              "desc": "Removes a specific file from the cache, forcing next access to read from disk",
              "inputs": "filePath: string",
              "outputs": "void"
            },
            {
              "name": "clear",
              "desc": "Empties the entire cache and resets statistics",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getStats",
              "desc": "Returns cache performance metrics including hits, misses, evictions, and size",
              "inputs": "none",
              "outputs": "CacheStats object"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources including file system watcher and cache contents",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "This file exists to improve extension performance by preventing repeated disk reads of the same files. It solves the problem of slow file system operations causing UI lag by caching frequently accessed files, automatically invalidating the cache when files change, and using an LRU eviction policy to manage memory efficiently.",
          "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant file reads and improve performance across the extension\",\n  \"userVisibleActions\": [\n    \"Faster file operations when accessing the same files multiple times\",\n    \"Improved responsiveness when extension reads project files\",\n    \"Automatic updates when files are modified externally\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve cached file contents instead of reading from disk repeatedly\",\n    \"Automatic cache invalidation when files change on disk\",\n    \"Access cache statistics to monitor performance (hits, misses, evictions)\",\n    \"Configure cache size limits and time-to-live settings\",\n    \"Clear cache manually or invalidate specific files\",\n    \"Monitor memory usage through cache size tracking\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing next access to read from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Empties the entire cache and resets statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, evictions, and size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources including file system watcher and cache contents\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by preventing repeated disk reads of the same files. It solves the problem of slow file system operations causing UI lag by caching frequently accessed files, automatically invalidating the cache when files change, and using an LRU eviction policy to manage memory efficiently.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Provides a reusable file processing system that filters, reads, and processes multiple files in parallel with consistent error handling.",
          "userVisibleActions": [
            "Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing",
            "Multiple files are processed simultaneously for faster performance"
          ],
          "developerVisibleActions": [
            "Developer provides a list of file paths and a processing function to batch process files",
            "Developer can customize which files to process by providing a custom filter implementation",
            "Developer can customize how files are read by providing a custom reader implementation",
            "Files are automatically filtered to skip non-source directories before processing",
            "File content is read and passed to the developer's processing function",
            "All file processing errors are caught and handled through the ErrorHandler system",
            "Processing results are returned as an array in the same order as input files"
          ],
          "keyFunctions": [
            {
              "name": "shouldProcess",
              "desc": "Determines whether a file should be processed based on its path",
              "inputs": "filePath: string",
              "outputs": "boolean indicating if file should be processed"
            },
            {
              "name": "readFile",
              "desc": "Reads a file and returns its content as a string",
              "inputs": "filePath: string",
              "outputs": "Promise<string> with file content"
            },
            {
              "name": "processFiles",
              "desc": "Processes multiple files in parallel by filtering, reading, and applying a custom processor function",
              "inputs": "files: string[], processor: (content: string, filePath: string) => Promise<T>, context?: ErrorContext",
              "outputs": "Promise<T[]> with processed results for each file"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "ErrorHandler",
            "ErrorContext"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns across the codebase by providing a single, reusable, and testable file processing system. It solves the problem of inconsistent file filtering, error handling, and parallel processing logic that would otherwise be scattered throughout the application.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a reusable file processing system that filters, reads, and processes multiple files in parallel with consistent error handling.\",\n  \"userVisibleActions\": [\n    \"Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing\",\n    \"Multiple files are processed simultaneously for faster performance\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides a list of file paths and a processing function to batch process files\",\n    \"Developer can customize which files to process by providing a custom filter implementation\",\n    \"Developer can customize how files are read by providing a custom reader implementation\",\n    \"Files are automatically filtered to skip non-source directories before processing\",\n    \"File content is read and passed to the developer's processing function\",\n    \"All file processing errors are caught and handled through the ErrorHandler system\",\n    \"Processing results are returned as an array in the same order as input files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines whether a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file and returns its content as a string\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> with file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel by filtering, reading, and applying a custom processor function\",\n      \"inputs\": \"files: string[], processor: (content: string, filePath: string) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> with processed results for each file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"ErrorHandler\",\n    \"ErrorContext\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase by providing a single, reusable, and testable file processing system. It solves the problem of inconsistent file filtering, error handling, and parallel processing logic that would otherwise be scattered throughout the application.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Automatically persists all analysis results to disk with timestamped organization",
        "Stores product documentation in organized run folders within .shadow/docs directory",
        "Maintains historical tracking of architecture insights with timestamps",
        "Creates and manages summary documents in dedicated .shadow/summary directory",
        "Preserves complete analysis history through timestamped folder structure"
      ],
      "summary": "This module provides persistent storage capabilities for all codebase analysis results. It automatically saves analysis outputs to the local filesystem, organizing them into structured directories within the .shadow folder. Each analysis run creates a new timestamped folder, ensuring that historical results are preserved and easily accessible.\n\nThe module handles multiple types of documentation artifacts including product documentation, architecture insights, and summary documents. All results are stored with timestamps, allowing users to track how their codebase documentation evolves over time. The organized folder structure makes it easy to locate specific analysis runs and compare results across different points in time.\n\nUsers benefit from automatic persistence without manual intervention - every analysis automatically generates and saves results to predictable locations. The timestamped storage ensures that no previous analysis is overwritten, providing a complete audit trail of documentation changes and architectural evolution.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages saving and retrieving analysis results like product documentation, architecture insights, and summaries to disk with timestamped storage.",
          "userVisibleActions": [
            "Analysis results are automatically saved to .shadow/docs folder with timestamps",
            "Product documentation is generated and stored in organized run folders",
            "Architecture insights are saved with timestamps for historical tracking",
            "Summary documents are created in the .shadow/summary directory",
            "Each analysis run creates a new timestamped folder to preserve history"
          ],
          "developerVisibleActions": [
            "Initialize product documentation runs to create storage directories",
            "Initialize architecture insights runs to create separate storage locations",
            "Save individual product documentation for specific files",
            "Save architecture insights for the entire codebase",
            "Save summary documents with aggregated analysis results",
            "Retrieve the most recent product documentation for a file",
            "Retrieve the most recent architecture insights",
            "Access all product documentation from the current run",
            "Get the current run directory path for organizing outputs",
            "Finalize runs to complete the analysis session"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Creates a new timestamped run for storing product documentation",
              "inputs": "workspaceRoot: string",
              "outputs": "runDir path as string"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Creates a new timestamped run for storing architecture insights",
              "inputs": "workspaceRoot: string",
              "outputs": "runDir path as string"
            },
            {
              "name": "saveProductDocumentation",
              "desc": "Saves product documentation for a specific file to the current run folder",
              "inputs": "filePath: string, documentation: EnhancedProductDocumentation, workspaceRoot: string",
              "outputs": "void"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Saves architecture insights to the current run folder",
              "inputs": "insights: LLMInsights, workspaceRoot: string",
              "outputs": "void"
            },
            {
              "name": "saveSummaryDocument",
              "desc": "Saves a summary document combining all documentation and insights",
              "inputs": "summary content and metadata, workspaceRoot: string",
              "outputs": "void"
            },
            {
              "name": "getLatestProductDocumentation",
              "desc": "Retrieves the most recent product documentation for a given file",
              "inputs": "filePath: string, workspaceRoot: string",
              "outputs": "EnhancedProductDocumentation or null"
            },
            {
              "name": "getLatestArchitectureInsights",
              "desc": "Retrieves the most recent architecture insights",
              "inputs": "workspaceRoot: string",
              "outputs": "LLMInsights or null"
            },
            {
              "name": "getAllProductDocsFromCurrentRun",
              "desc": "Gets all product documentation saved in the current run",
              "inputs": "none",
              "outputs": "Map of file paths to documentation"
            },
            {
              "name": "getCurrentRunDir",
              "desc": "Returns the directory path for the current product docs run",
              "inputs": "none",
              "outputs": "runDir path as string or null"
            },
            {
              "name": "finalizeProductDocsRun",
              "desc": "Completes the current product documentation run session",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "finalizeArchitectureInsightsRun",
              "desc": "Completes the current architecture insights run session",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "EnhancedProductDocumentation from fileDocumentation",
            "LLMInsights from llmService",
            "DocumentationFormatter from domain/formatters",
            "createTimestampedStorage from storage/incrementalStorage"
          ],
          "intent": "Separates data persistence logic from business logic by providing a dedicated repository for managing analysis results storage, enabling historical tracking of documentation and insights through timestamped runs, and organizing outputs in a structured directory hierarchy.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages saving and retrieving analysis results like product documentation, architecture insights, and summaries to disk with timestamped storage.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to .shadow/docs folder with timestamps\",\n    \"Product documentation is generated and stored in organized run folders\",\n    \"Architecture insights are saved with timestamps for historical tracking\",\n    \"Summary documents are created in the .shadow/summary directory\",\n    \"Each analysis run creates a new timestamped folder to preserve history\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to create storage directories\",\n    \"Initialize architecture insights runs to create separate storage locations\",\n    \"Save individual product documentation for specific files\",\n    \"Save architecture insights for the entire codebase\",\n    \"Save summary documents with aggregated analysis results\",\n    \"Retrieve the most recent product documentation for a file\",\n    \"Retrieve the most recent architecture insights\",\n    \"Access all product documentation from the current run\",\n    \"Get the current run directory path for organizing outputs\",\n    \"Finalize runs to complete the analysis session\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped run for storing product documentation\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"runDir path as string\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped run for storing architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"runDir path as string\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves product documentation for a specific file to the current run folder\",\n      \"inputs\": \"filePath: string, documentation: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights to the current run folder\",\n      \"inputs\": \"insights: LLMInsights, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummaryDocument\",\n      \"desc\": \"Saves a summary document combining all documentation and insights\",\n      \"inputs\": \"summary content and metadata, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getLatestProductDocumentation\",\n      \"desc\": \"Retrieves the most recent product documentation for a given file\",\n      \"inputs\": \"filePath: string, workspaceRoot: string\",\n      \"outputs\": \"EnhancedProductDocumentation or null\"\n    },\n    {\n      \"name\": \"getLatestArchitectureInsights\",\n      \"desc\": \"Retrieves the most recent architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"LLMInsights or null\"\n    },\n    {\n      \"name\": \"getAllProductDocsFromCurrentRun\",\n      \"desc\": \"Gets all product documentation saved in the current run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Map of file paths to documentation\"\n    },\n    {\n      \"name\": \"getCurrentRunDir\",\n      \"desc\": \"Returns the directory path for the current product docs run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path as string or null\"\n    },\n    {\n      \"name\": \"finalizeProductDocsRun\",\n      \"desc\": \"Completes the current product documentation run session\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeArchitectureInsightsRun\",\n      \"desc\": \"Completes the current architecture insights run session\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"EnhancedProductDocumentation from fileDocumentation\",\n    \"LLMInsights from llmService\",\n    \"DocumentationFormatter from domain/formatters\",\n    \"createTimestampedStorage from storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates data persistence logic from business logic by providing a dedicated repository for managing analysis results storage, enabling historical tracking of documentation and insights through timestamped runs, and organizing outputs in a structured directory hierarchy.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display progress notifications for long-running operations with customizable titles and messages",
        "Show progress indicators in multiple locations (notification area, status bar, etc.)",
        "Allow users to cancel ongoing operations through progress notification controls",
        "Provide standardized progress feedback across all extension operations",
        "Track operation status and communicate progress updates to users in real-time"
      ],
      "summary": "The infrastructure module provides a centralized progress service that manages how users are informed about ongoing operations throughout the extension. It creates a consistent user experience by displaying progress notifications with clear titles and messages whenever the extension performs time-consuming tasks.\n\nUsers interact with this module passively through visual feedback and actively when they choose to cancel operations. When any long-running task begins—such as file processing, API calls, or complex computations—the progress service automatically shows a notification that keeps users informed about what's happening. These notifications can appear in various locations within the VS Code interface, including the notification area and status bar.\n\nThe primary workflow involves the extension initiating an operation, the progress service displaying a notification with relevant status information, and users either waiting for completion or choosing to cancel via the notification's cancel button. This standardized approach ensures users always know when the extension is working and provides them with control over cancellable operations.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a standardized service for displaying progress notifications and status indicators throughout the extension.",
          "userVisibleActions": [
            "See progress notifications with titles and messages during long-running operations",
            "Cancel ongoing operations using the cancel button in progress notifications",
            "View progress indicators in different locations (notification area, status bar, etc.)"
          ],
          "developerVisibleActions": [
            "Wrap any async operation with progress reporting using a simple API",
            "Report incremental progress updates with custom messages during task execution",
            "Configure progress notifications as cancellable or non-cancellable",
            "Choose where progress indicators appear (notification, window, status bar)",
            "Access cancellation tokens to check if user cancelled the operation",
            "Use either a simple string title or full options object for flexibility"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying a progress notification to the user",
              "inputs": "options (title, cancellable flag, location) and async task function with reporter",
              "outputs": "The result of the executed task"
            },
            {
              "name": "report",
              "desc": "Updates the progress message shown to the user during task execution",
              "inputs": "message string and optional increment percentage",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "Eliminates boilerplate code for progress reporting by wrapping VSCode's progress API with a consistent, reusable service that ensures all long-running operations provide user feedback in a standardized way.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications and status indicators throughout the extension.\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during long-running operations\",\n    \"Cancel ongoing operations using the cancel button in progress notifications\",\n    \"View progress indicators in different locations (notification area, status bar, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any async operation with progress reporting using a simple API\",\n    \"Report incremental progress updates with custom messages during task execution\",\n    \"Configure progress notifications as cancellable or non-cancellable\",\n    \"Choose where progress indicators appear (notification, window, status bar)\",\n    \"Access cancellation tokens to check if user cancelled the operation\",\n    \"Use either a simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function with reporter\",\n      \"outputs\": \"The result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress message shown to the user during task execution\",\n      \"inputs\": \"message string and optional increment percentage\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Eliminates boilerplate code for progress reporting by wrapping VSCode's progress API with a consistent, reusable service that ensures all long-running operations provide user feedback in a standardized way.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest testing framework for TypeScript-based unit tests in a Node.js environment",
      "userVisibleActions": [
        "No direct user-visible actions - this is a testing configuration file"
      ],
      "developerVisibleActions": [
        "Developers can run Jest tests against TypeScript files in src and UnitTests directories",
        "Test files matching patterns *.test.ts, *.spec.ts, or files in __tests__ directories are automatically discovered and executed",
        "Code coverage reports are generated in text, lcov, and HTML formats in the coverage directory",
        "Tests run with a 10-second timeout per test case",
        "TypeScript files are automatically transpiled to JavaScript during test execution",
        "Mock VSCode module is available for testing VSCode extension code",
        "Source files in src directory are collected for coverage analysis, excluding test files, declaration files, and mock files"
      ],
      "keyFunctions": [],
      "dependencies": [
        "ts-jest",
        "jest",
        "typescript"
      ],
      "intent": "This file exists to configure the Jest testing framework for a TypeScript project, enabling developers to write and run unit tests with proper TypeScript support, code coverage reporting, and VSCode extension testing capabilities. It solves the problem of setting up a consistent testing environment with TypeScript compilation, module resolution, and coverage collection.",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript-based unit tests in a Node.js environment\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a testing configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can run Jest tests against TypeScript files in src and UnitTests directories\",\n    \"Test files matching patterns *.test.ts, *.spec.ts, or files in __tests__ directories are automatically discovered and executed\",\n    \"Code coverage reports are generated in text, lcov, and HTML formats in the coverage directory\",\n    \"Tests run with a 10-second timeout per test case\",\n    \"TypeScript files are automatically transpiled to JavaScript during test execution\",\n    \"Mock VSCode module is available for testing VSCode extension code\",\n    \"Source files in src directory are collected for coverage analysis, excluding test files, declaration files, and mock files\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript project, enabling developers to write and run unit tests with proper TypeScript support, code coverage reporting, and VSCode extension testing capabilities. It solves the problem of setting up a consistent testing environment with TypeScript compilation, module resolution, and coverage collection.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
      "userVisibleActions": [
        "API requests are automatically throttled to prevent rate limit errors",
        "Requests are blocked when rate limits are reached within the time window",
        "Different AI providers (OpenAI, Claude) have independent rate limit tracking"
      ],
      "developerVisibleActions": [
        "Developer checks if a request can be made before calling LLM APIs",
        "Developer records each request to track usage against limits",
        "Developer configures custom rate limits per provider (maxRequests, windowMs)",
        "System automatically cleans up old request history outside the time window",
        "Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute"
      ],
      "keyFunctions": [
        {
          "name": "canMakeRequest",
          "desc": "Checks if a new request is allowed based on recent request history and configured limits",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "boolean - true if request allowed, false if rate limit reached"
        },
        {
          "name": "recordRequest",
          "desc": "Records the timestamp of a request to track usage against rate limits",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "void - updates internal request history"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limit configuration for a specific provider",
          "inputs": "provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}",
          "outputs": "void - updates provider configuration"
        }
      ],
      "dependencies": [],
      "intent": "This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.",
      "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\n  \"userVisibleActions\": [\n    \"API requests are automatically throttled to prevent rate limit errors\",\n    \"Requests are blocked when rate limits are reached within the time window\",\n    \"Different AI providers (OpenAI, Claude) have independent rate limit tracking\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer checks if a request can be made before calling LLM APIs\",\n    \"Developer records each request to track usage against limits\",\n    \"Developer configures custom rate limits per provider (maxRequests, windowMs)\",\n    \"System automatically cleans up old request history outside the time window\",\n    \"Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on recent request history and configured limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean - true if request allowed, false if rate limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records the timestamp of a request to track usage against rate limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"void - updates internal request history\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific provider\",\n      \"inputs\": \"provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Parses and extracts structured information from LLM text responses into typed data structures for file summaries, module summaries, and product documentation.",
      "userVisibleActions": [
        "User receives structured file analysis from unstructured LLM text responses",
        "User gets parsed product documentation with consistent formatting",
        "User sees extracted module summaries with organized information",
        "User receives fallback text extraction when JSON parsing fails"
      ],
      "developerVisibleActions": [
        "Developer calls parseFileSummary() to convert LLM response text into FileSummary objects",
        "Developer calls parseModuleSummary() to extract module-level information from LLM output",
        "Developer calls parseProductDocumentation() to get enhanced product documentation from LLM responses",
        "Developer calls parseLLMInsights() to extract analysis insights from LLM text",
        "Developer receives structured data with fallback extraction when JSON parsing fails",
        "Parser attempts JSON extraction first, then falls back to text pattern matching",
        "Parser handles malformed or incomplete LLM responses gracefully"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into a structured FileSummary object",
          "inputs": "content (string), filePath (string), role (string)",
          "outputs": "FileSummary object with purpose, actions, functions, dependencies"
        },
        {
          "name": "parseModuleSummary",
          "desc": "Extracts module-level information from LLM response",
          "inputs": "content (string), moduleName (string)",
          "outputs": "ModuleSummary object with module details"
        },
        {
          "name": "parseProductDocumentation",
          "desc": "Parses enhanced product documentation from LLM output",
          "inputs": "content (string)",
          "outputs": "EnhancedProductDocumentation object"
        },
        {
          "name": "parseLLMInsights",
          "desc": "Extracts analysis insights and context from LLM responses",
          "inputs": "content (string)",
          "outputs": "LLMInsights object with structured analysis data"
        },
        {
          "name": "extractSection",
          "desc": "Extracts a specific named section from text content",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Extracted section text as string"
        },
        {
          "name": "extractListSection",
          "desc": "Extracts a list/array section from text content",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Array of extracted list items"
        }
      ],
      "dependencies": [
        "../fileDocumentation",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured data types required by the application. It solves the problem of reliably extracting consistent, typed information from potentially varied LLM output formats, with robust fallback mechanisms when the LLM doesn't return perfectly formatted JSON.",
      "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured information from LLM text responses into typed data structures for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"User receives structured file analysis from unstructured LLM text responses\",\n    \"User gets parsed product documentation with consistent formatting\",\n    \"User sees extracted module summaries with organized information\",\n    \"User receives fallback text extraction when JSON parsing fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls parseFileSummary() to convert LLM response text into FileSummary objects\",\n    \"Developer calls parseModuleSummary() to extract module-level information from LLM output\",\n    \"Developer calls parseProductDocumentation() to get enhanced product documentation from LLM responses\",\n    \"Developer calls parseLLMInsights() to extract analysis insights from LLM text\",\n    \"Developer receives structured data with fallback extraction when JSON parsing fails\",\n    \"Parser attempts JSON extraction first, then falls back to text pattern matching\",\n    \"Parser handles malformed or incomplete LLM responses gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a structured FileSummary object\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object with purpose, actions, functions, dependencies\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level information from LLM response\",\n      \"inputs\": \"content (string), moduleName (string)\",\n      \"outputs\": \"ModuleSummary object with module details\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Parses enhanced product documentation from LLM output\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Extracts analysis insights and context from LLM responses\",\n      \"inputs\": \"content (string)\",\n      \"outputs\": \"LLMInsights object with structured analysis data\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a specific named section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted section text as string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array section from text content\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of extracted list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured data types required by the application. It solves the problem of reliably extracting consistent, typed information from potentially varied LLM output formats, with robust fallback mechanisms when the LLM doesn't return perfectly formatted JSON.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles automatic retries of failed AI/LLM API requests with exponential backoff when temporary errors occur",
      "userVisibleActions": [
        "AI requests automatically retry when they fail due to temporary issues like rate limits or network problems",
        "Multiple retry attempts happen transparently without user intervention",
        "Requests eventually succeed after temporary failures are resolved",
        "Requests fail with clear error after maximum retry attempts are exhausted"
      ],
      "developerVisibleActions": [
        "Wrap any LLM API call with retry logic using executeWithRetry method",
        "Configure retry behavior (max attempts, delays, backoff multiplier)",
        "Specify which error types should trigger retries via retryableErrors list",
        "Receive callbacks on each retry attempt with onRetry handler",
        "Get retry metadata (number of attempts) along with successful results",
        "Distinguish between retryable errors (rate limits, timeouts, network) and permanent errors (invalid requests)",
        "Errors classified as non-retryable are thrown immediately without retry attempts"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an async operation with automatic retry logic and exponential backoff",
          "inputs": "operation: async function to execute, options: retry configuration (maxRetries, delays, error types)",
          "outputs": "Promise resolving to operation result, or throws error after retries exhausted"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines if an error should trigger a retry based on error message and configured retryable error patterns",
          "inputs": "error: caught exception, retryableErrors: list of error patterns to match",
          "outputs": "boolean indicating if error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Provides resilience for LLM API calls by automatically handling transient failures like rate limits, network issues, and temporary service unavailability, improving reliability without requiring manual retry logic in calling code",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retries of failed AI/LLM API requests with exponential backoff when temporary errors occur\",\n  \"userVisibleActions\": [\n    \"AI requests automatically retry when they fail due to temporary issues like rate limits or network problems\",\n    \"Multiple retry attempts happen transparently without user intervention\",\n    \"Requests eventually succeed after temporary failures are resolved\",\n    \"Requests fail with clear error after maximum retry attempts are exhausted\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic using executeWithRetry method\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries via retryableErrors list\",\n    \"Receive callbacks on each retry attempt with onRetry handler\",\n    \"Get retry metadata (number of attempts) along with successful results\",\n    \"Distinguish between retryable errors (rate limits, timeouts, network) and permanent errors (invalid requests)\",\n    \"Errors classified as non-retryable are thrown immediately without retry attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic and exponential backoff\",\n      \"inputs\": \"operation: async function to execute, options: retry configuration (maxRetries, delays, error types)\",\n      \"outputs\": \"Promise resolving to operation result, or throws error after retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry based on error message and configured retryable error patterns\",\n      \"inputs\": \"error: caught exception, retryableErrors: list of error patterns to match\",\n      \"outputs\": \"boolean indicating if error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API calls by automatically handling transient failures like rate limits, network issues, and temporary service unavailability, improving reliability without requiring manual retry logic in calling code\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines the standard interface for all LLM (Large Language Model) provider implementations to ensure consistent AI integration across different providers like OpenAI and Claude.",
      "userVisibleActions": [
        "User receives AI-generated text responses to their queries",
        "User receives structured JSON data from AI models when requesting formatted output",
        "User can work with different AI providers (OpenAI, Claude, custom) transparently without changing their workflow",
        "User gets file and grep search requests suggested by the AI based on analysis needs"
      ],
      "developerVisibleActions": [
        "Developer implements this interface to add support for new LLM providers",
        "Developer checks if an AI provider is configured and ready using isConfigured()",
        "Developer sends text-based requests to AI models with customizable parameters (temperature, max tokens, model selection)",
        "Developer requests structured JSON output from AI models with optional schema validation",
        "Developer receives additional context requests (file reads, grep searches) from AI responses",
        "Developer accesses raw provider responses for debugging or advanced processing",
        "Developer identifies which provider is being used via getName()"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Verifies if the LLM provider has valid credentials and is ready to process requests",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt to the LLM and retrieves a text response with optional configuration like temperature and token limits",
          "inputs": "LLMRequestOptions (messages, model, temperature, maxTokens, systemPrompt, responseFormat)",
          "outputs": "Promise<LLMResponse> containing generated text content, finish reason, model used, and raw response"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt expecting structured JSON output, optionally validated against a schema, with additional file/grep requests",
          "inputs": "LLMRequestOptions and optional schema for validation",
          "outputs": "Promise<StructuredOutputResponse<T>> containing parsed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the identifier of the LLM provider for logging and user display",
          "inputs": "none",
          "outputs": "string with provider name"
        }
      ],
      "dependencies": [],
      "intent": "This interface exists to abstract away differences between various LLM providers (OpenAI, Claude, custom implementations), allowing the codebase to work with any AI provider through a unified API. It solves the problem of vendor lock-in and enables easy switching or addition of new AI providers without changing consuming code. It also standardizes how structured outputs and additional context requests are handled across providers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the standard interface for all LLM (Large Language Model) provider implementations to ensure consistent AI integration across different providers like OpenAI and Claude.\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON data from AI models when requesting formatted output\",\n    \"User can work with different AI providers (OpenAI, Claude, custom) transparently without changing their workflow\",\n    \"User gets file and grep search requests suggested by the AI based on analysis needs\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add support for new LLM providers\",\n    \"Developer checks if an AI provider is configured and ready using isConfigured()\",\n    \"Developer sends text-based requests to AI models with customizable parameters (temperature, max tokens, model selection)\",\n    \"Developer requests structured JSON output from AI models with optional schema validation\",\n    \"Developer receives additional context requests (file reads, grep searches) from AI responses\",\n    \"Developer accesses raw provider responses for debugging or advanced processing\",\n    \"Developer identifies which provider is being used via getName()\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Verifies if the LLM provider has valid credentials and is ready to process requests\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the LLM and retrieves a text response with optional configuration like temperature and token limits\",\n      \"inputs\": \"LLMRequestOptions (messages, model, temperature, maxTokens, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> containing generated text content, finish reason, model used, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt expecting structured JSON output, optionally validated against a schema, with additional file/grep requests\",\n      \"inputs\": \"LLMRequestOptions and optional schema for validation\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> containing parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier of the LLM provider for logging and user display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between various LLM providers (OpenAI, Claude, custom implementations), allowing the codebase to work with any AI provider through a unified API. It solves the problem of vendor lock-in and enables easy switching or addition of new AI providers without changing consuming code. It also standardizes how structured outputs and additional context requests are handled across providers.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with Anthropic's Claude AI models for sending chat requests and receiving AI-generated responses",
      "userVisibleActions": [
        "Sends messages to Claude AI and receives intelligent responses",
        "Generates structured JSON outputs from Claude based on schemas",
        "Automatically retries failed requests with exponential backoff",
        "Validates Claude API configuration before allowing requests",
        "Extracts and parses JSON from Claude's responses automatically"
      ],
      "developerVisibleActions": [
        "Configure Claude API key through configuration manager to enable the provider",
        "Send chat requests with system prompts, conversation history, and model selection",
        "Request structured outputs by providing a JSON schema and receive validated responses",
        "Check if Claude is configured and available before making requests",
        "Handle errors when API key is missing or requests fail",
        "Automatically converts OpenAI-format messages to Claude's format",
        "Receives responses with token usage information and content"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is set up and provider is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a chat completion request to Claude with messages and options",
          "inputs": "LLMRequestOptions with messages, model, maxTokens, systemPrompt",
          "outputs": "LLMResponse with content, model, and token usage"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Sends a request to Claude and ensures the response matches a provided JSON schema",
          "inputs": "LLMRequestOptions plus JSON schema definition",
          "outputs": "StructuredOutputResponse with validated JSON data and metadata"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Claude client with API key from configuration",
          "inputs": "none (reads from config)",
          "outputs": "void (initializes internal client)"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to abstract and implement the specific integration with Anthropic's Claude API, converting between the application's generic LLM interface and Claude's specific API format, handling authentication, request formatting, response parsing, and error handling for Claude-specific operations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for sending chat requests and receiving AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Sends messages to Claude AI and receives intelligent responses\",\n    \"Generates structured JSON outputs from Claude based on schemas\",\n    \"Automatically retries failed requests with exponential backoff\",\n    \"Validates Claude API configuration before allowing requests\",\n    \"Extracts and parses JSON from Claude's responses automatically\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure Claude API key through configuration manager to enable the provider\",\n    \"Send chat requests with system prompts, conversation history, and model selection\",\n    \"Request structured outputs by providing a JSON schema and receive validated responses\",\n    \"Check if Claude is configured and available before making requests\",\n    \"Handle errors when API key is missing or requests fail\",\n    \"Automatically converts OpenAI-format messages to Claude's format\",\n    \"Receives responses with token usage information and content\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to Claude with messages and options\",\n      \"inputs\": \"LLMRequestOptions with messages, model, maxTokens, systemPrompt\",\n      \"outputs\": \"LLMResponse with content, model, and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends a request to Claude and ensures the response matches a provided JSON schema\",\n      \"inputs\": \"LLMRequestOptions plus JSON schema definition\",\n      \"outputs\": \"StructuredOutputResponse with validated JSON data and metadata\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude client with API key from configuration\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"void (initializes internal client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract and implement the specific integration with Anthropic's Claude API, converting between the application's generic LLM interface and Claude's specific API format, handling authentication, request formatting, response parsing, and error handling for Claude-specific operations.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Implements the OpenAI API provider to send chat completion requests and handle structured responses using OpenAI's GPT models",
      "userVisibleActions": [
        "Sends messages to OpenAI's GPT models and receives AI-generated responses",
        "Supports structured JSON output format when requested",
        "Processes streaming responses for real-time AI output display",
        "Validates API key configuration before allowing requests",
        "Returns error messages when OpenAI API key is not configured"
      ],
      "developerVisibleActions": [
        "Provides ILLMProvider interface implementation for OpenAI",
        "Automatically initializes OpenAI client with API key from configuration manager",
        "Defaults to 'gpt-4o' model when no model is specified",
        "Sets 5-minute timeout for all OpenAI API requests",
        "Combines system prompts with conversation messages automatically",
        "Extracts and parses JSON from structured responses",
        "Handles streaming responses with token-by-token content delivery",
        "Reports finish reasons (stop, length, content_filter, etc.) from API responses"
      ],
      "keyFunctions": [
        {
          "name": "initialize",
          "desc": "Sets up OpenAI client with API key from configuration",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "isConfigured",
          "desc": "Checks if OpenAI client is ready with valid API key",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "getName",
          "desc": "Returns provider identifier",
          "inputs": "none",
          "outputs": "string 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends chat completion request to OpenAI API with messages and options",
          "inputs": "LLMRequestOptions (model, messages, systemPrompt, responseFormat)",
          "outputs": "Promise<LLMResponse> with content and finish reason"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends request expecting JSON response and parses it into structured data",
          "inputs": "LLMRequestOptions with JSON response format",
          "outputs": "Promise<StructuredOutputResponse> with parsed JSON data"
        },
        {
          "name": "sendStreamingRequest",
          "desc": "Sends streaming request and yields response tokens in real-time",
          "inputs": "LLMRequestOptions",
          "outputs": "AsyncGenerator yielding content chunks and finish reason"
        }
      ],
      "dependencies": [
        "openai",
        "configurationManager",
        "jsonExtractor",
        "ILLMProvider"
      ],
      "intent": "This file exists to integrate OpenAI's GPT models into the application by providing a standardized interface for chat completions, structured outputs, and streaming responses. It solves the problem of communicating with OpenAI's API while abstracting away provider-specific details through the ILLMProvider interface, allowing the application to easily swap AI providers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Implements the OpenAI API provider to send chat completion requests and handle structured responses using OpenAI's GPT models\",\n  \"userVisibleActions\": [\n    \"Sends messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Supports structured JSON output format when requested\",\n    \"Processes streaming responses for real-time AI output display\",\n    \"Validates API key configuration before allowing requests\",\n    \"Returns error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides ILLMProvider interface implementation for OpenAI\",\n    \"Automatically initializes OpenAI client with API key from configuration manager\",\n    \"Defaults to 'gpt-4o' model when no model is specified\",\n    \"Sets 5-minute timeout for all OpenAI API requests\",\n    \"Combines system prompts with conversation messages automatically\",\n    \"Extracts and parses JSON from structured responses\",\n    \"Handles streaming responses with token-by-token content delivery\",\n    \"Reports finish reasons (stop, length, content_filter, etc.) from API responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI client is ready with valid API key\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends chat completion request to OpenAI API with messages and options\",\n      \"inputs\": \"LLMRequestOptions (model, messages, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends request expecting JSON response and parses it into structured data\",\n      \"inputs\": \"LLMRequestOptions with JSON response format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data\"\n    },\n    {\n      \"name\": \"sendStreamingRequest\",\n      \"desc\": \"Sends streaming request and yields response tokens in real-time\",\n      \"inputs\": \"LLMRequestOptions\",\n      \"outputs\": \"AsyncGenerator yielding content chunks and finish reason\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"configurationManager\",\n    \"jsonExtractor\",\n    \"ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to integrate OpenAI's GPT models into the application by providing a standardized interface for chat completions, structured outputs, and streaming responses. It solves the problem of communicating with OpenAI's API while abstracting away provider-specific details through the ILLMProvider interface, allowing the application to easily swap AI providers.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Creates and manages AI language model provider instances (OpenAI and Anthropic/Claude) with lazy initialization and configuration checking",
      "userVisibleActions": [
        "Switches between different AI providers (OpenAI or Claude) based on configuration",
        "Uses the currently configured AI provider for all AI-powered features",
        "Gets error feedback when an unknown AI provider is selected"
      ],
      "developerVisibleActions": [
        "Retrieve a specific AI provider instance by name (openai or claude)",
        "Get the currently configured AI provider based on user settings",
        "Check if a specific AI provider is properly configured with credentials",
        "Get a list of all properly configured AI providers available for use",
        "Providers are created lazily only when first requested to save resources"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns the provider instance for the specified provider type (openai or claude)",
          "inputs": "provider: LLMProvider ('openai' | 'claude')",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the currently configured provider based on user settings",
          "inputs": "none",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks if a provider has valid configuration and credentials",
          "inputs": "provider: LLMProvider ('openai' | 'claude')",
          "outputs": "boolean indicating if provider is ready to use"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns a list of all providers that are properly configured",
          "inputs": "none",
          "outputs": "Array of configured LLMProvider names"
        }
      ],
      "dependencies": [
        "./ILLMProvider",
        "./openAIProvider",
        "./anthropicProvider",
        "../../config/configurationManager"
      ],
      "intent": "Centralizes AI provider creation and management to avoid duplicate instances, enable easy switching between providers, and provide a consistent interface for checking provider availability and configuration status",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI language model provider instances (OpenAI and Anthropic/Claude) with lazy initialization and configuration checking\",\n  \"userVisibleActions\": [\n    \"Switches between different AI providers (OpenAI or Claude) based on configuration\",\n    \"Uses the currently configured AI provider for all AI-powered features\",\n    \"Gets error feedback when an unknown AI provider is selected\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve a specific AI provider instance by name (openai or claude)\",\n    \"Get the currently configured AI provider based on user settings\",\n    \"Check if a specific AI provider is properly configured with credentials\",\n    \"Get a list of all properly configured AI providers available for use\",\n    \"Providers are created lazily only when first requested to save resources\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the provider instance for the specified provider type (openai or claude)\",\n      \"inputs\": \"provider: LLMProvider ('openai' | 'claude')\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the currently configured provider based on user settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a provider has valid configuration and credentials\",\n      \"inputs\": \"provider: LLMProvider ('openai' | 'claude')\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all providers that are properly configured\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of configured LLMProvider names\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Centralizes AI provider creation and management to avoid duplicate instances, enable easy switching between providers, and provide a consistent interface for checking provider availability and configuration status\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed metadata about functions, branches, dependencies, and behavioral patterns.",
      "userVisibleActions": [
        "Receives detailed analysis of code complexity and behavioral hints",
        "Gets insights into how functions interact with state and dependencies",
        "Views branch coverage information for conditional logic paths",
        "Sees identified test mappings between test files and source code"
      ],
      "developerVisibleActions": [
        "Analyzes TypeScript/JavaScript files using AST parsing to extract function metadata",
        "Detects branches (if/else, switch, ternary) and tracks conditional logic complexity",
        "Profiles function dependencies by tracking imports, function calls, and external references",
        "Identifies state mutations and side effects in function bodies",
        "Generates behavioral hints about function characteristics (pure, async, error-prone)",
        "Maps test files to source code functions for coverage analysis",
        "Falls back to regex-based analysis for non-TypeScript languages",
        "Extracts function content from source files based on line ranges"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes a file and extracts enhanced metadata for all functions",
          "inputs": "filePath: string, content: string, language: string, functions: FunctionInfo[]",
          "outputs": "Map<string, FunctionMetadata>"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis on TypeScript/JavaScript functions",
          "inputs": "filePath: string, content: string, func: FunctionInfo, functionContent: string",
          "outputs": "FunctionMetadata"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Fallback analysis using regex patterns for non-TypeScript languages",
          "inputs": "filePath: string, func: FunctionInfo, functionContent: string, language: string",
          "outputs": "FunctionMetadata"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the text content of a function from a file",
          "inputs": "content: string, startLine: number, endLine: number",
          "outputs": "string"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer"
      ],
      "intent": "This file exists to provide advanced static code analysis beyond basic syntax parsing. It solves the problem of understanding code behavior, complexity, and relationships by using AST parsing to detect branches, dependencies, state mutations, and behavioral patterns. This enables intelligent test generation, code quality assessment, and automated documentation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing Abstract Syntax Trees (AST) to extract detailed metadata about functions, branches, dependencies, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code complexity and behavioral hints\",\n    \"Gets insights into how functions interact with state and dependencies\",\n    \"Views branch coverage information for conditional logic paths\",\n    \"Sees identified test mappings between test files and source code\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes TypeScript/JavaScript files using AST parsing to extract function metadata\",\n    \"Detects branches (if/else, switch, ternary) and tracks conditional logic complexity\",\n    \"Profiles function dependencies by tracking imports, function calls, and external references\",\n    \"Identifies state mutations and side effects in function bodies\",\n    \"Generates behavioral hints about function characteristics (pure, async, error-prone)\",\n    \"Maps test files to source code functions for coverage analysis\",\n    \"Falls back to regex-based analysis for non-TypeScript languages\",\n    \"Extracts function content from source files based on line ranges\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions\",\n      \"inputs\": \"filePath: string, content: string, language: string, functions: FunctionInfo[]\",\n      \"outputs\": \"Map<string, FunctionMetadata>\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions\",\n      \"inputs\": \"filePath: string, content: string, func: FunctionInfo, functionContent: string\",\n      \"outputs\": \"FunctionMetadata\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Fallback analysis using regex patterns for non-TypeScript languages\",\n      \"inputs\": \"filePath: string, func: FunctionInfo, functionContent: string, language: string\",\n      \"outputs\": \"FunctionMetadata\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the text content of a function from a file\",\n      \"inputs\": \"content: string, startLine: number, endLine: number\",\n      \"outputs\": \"string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced static code analysis beyond basic syntax parsing. It solves the problem of understanding code behavior, complexity, and relationships by using AST parsing to detect branches, dependencies, state mutations, and behavioral patterns. This enables intelligent test generation, code quality assessment, and automated documentation.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Extracts detailed function information from large code files to support refactoring analysis and reporting.",
      "userVisibleActions": [
        "Identifies functions in large files that may need refactoring",
        "Provides detailed function information including signatures, dependencies, and responsibilities",
        "Highlights which functions are called by other parts of the codebase (dependents)",
        "Shows what other functions or modules each function depends on"
      ],
      "developerVisibleActions": [
        "Developer runs analysis on a codebase to identify large files",
        "System automatically analyzes all functions in files exceeding a configurable line threshold (default 500 lines)",
        "Developer receives structured function analysis data for each function in large files",
        "System extracts function signatures, metadata, dependencies, and dependent relationships",
        "Developer can use this analysis to inform refactoring decisions and generate refactoring reports",
        "Analysis integrates with existing code analysis infrastructure to build comprehensive function profiles"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in large files and returns detailed function analysis data",
          "inputs": "CodeAnalysis object, optional line threshold for large files (default 500)",
          "outputs": "Array of FunctionAnalysis objects containing detailed function information"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs detailed analysis on a single function including extracting signature, dependencies, and dependent relationships",
          "inputs": "File path, function information object, code analysis object",
          "outputs": "FunctionAnalysis object or null if analysis fails"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves relative file paths to absolute paths for file system access",
          "inputs": "Relative file path, code analysis object",
          "outputs": "Absolute file path string"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to provide deep analysis of functions within large files to support automated refactoring suggestions. It solves the problem of identifying which functions in oversized files should be refactored by extracting their signatures, understanding their dependencies, and mapping their usage patterns across the codebase. This enables developers to make informed decisions about code splitting and module organization.",
      "rawContent": "```json\n{\n  \"purpose\": \"Extracts detailed function information from large code files to support refactoring analysis and reporting.\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Provides detailed function information including signatures, dependencies, and responsibilities\",\n    \"Highlights which functions are called by other parts of the codebase (dependents)\",\n    \"Shows what other functions or modules each function depends on\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer runs analysis on a codebase to identify large files\",\n    \"System automatically analyzes all functions in files exceeding a configurable line threshold (default 500 lines)\",\n    \"Developer receives structured function analysis data for each function in large files\",\n    \"System extracts function signatures, metadata, dependencies, and dependent relationships\",\n    \"Developer can use this analysis to inform refactoring decisions and generate refactoring reports\",\n    \"Analysis integrates with existing code analysis infrastructure to build comprehensive function profiles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in large files and returns detailed function analysis data\",\n      \"inputs\": \"CodeAnalysis object, optional line threshold for large files (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing detailed function information\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function including extracting signature, dependencies, and dependent relationships\",\n      \"inputs\": \"File path, function information object, code analysis object\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths for file system access\",\n      \"inputs\": \"Relative file path, code analysis object\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions within large files to support automated refactoring suggestions. It solves the problem of identifying which functions in oversized files should be refactored by extracting their signatures, understanding their dependencies, and mapping their usage patterns across the codebase. This enables developers to make informed decisions about code splitting and module organization.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view interface for browsing and exploring code analysis results in VS Code",
      "userVisibleActions": [
        "View a hierarchical tree of code analysis results in the sidebar",
        "See project statistics (file count, function count, complexity metrics)",
        "Browse analyzed files organized by directory structure",
        "Click on files to see their functions and entry points",
        "Click on functions to jump to their location in the code",
        "See file-level metrics (lines of code, complexity, function count)",
        "View entry points and their relationships",
        "See 'No analysis available' message when no analysis has been run",
        "Expand/collapse sections to drill down into analysis details"
      ],
      "developerVisibleActions": [
        "Tree view updates automatically when new analysis is available",
        "Analysis data is received from the analyzer module",
        "Tree items are organized into categories: statistics, files, functions, entry points",
        "Each tree item can be clicked to trigger navigation or reveal more details",
        "File paths are resolved and displayed relative to workspace",
        "Icons and descriptions enhance visual presentation of analysis data"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the tree view with new analysis results",
          "inputs": "CodeAnalysis object or null",
          "outputs": "void (triggers tree refresh)"
        },
        {
          "name": "refresh",
          "desc": "Forces the tree view to reload and redisplay all items",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the visual representation of a tree item",
          "inputs": "AnalysisItem element",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node (or root items if none specified)",
          "inputs": "optional AnalysisItem element",
          "outputs": "Promise of AnalysisItem array"
        },
        {
          "name": "getRootItems",
          "desc": "Generates top-level tree items (statistics, files, functions, entry points)",
          "inputs": "none",
          "outputs": "Array of AnalysisItem"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Creates tree items showing project-wide metrics",
          "inputs": "none",
          "outputs": "Array of AnalysisItem with statistics"
        },
        {
          "name": "getFilesItems",
          "desc": "Organizes analyzed files into a directory tree structure",
          "inputs": "none",
          "outputs": "Array of AnalysisItem representing files and directories"
        },
        {
          "name": "getFileDetails",
          "desc": "Shows functions and metrics for a specific file",
          "inputs": "AnalysisItem representing a file",
          "outputs": "Array of AnalysisItem with file details"
        }
      ],
      "dependencies": [
        "vscode",
        "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
        "path"
      ],
      "intent": "This file exists to provide developers with a navigable, visual representation of their codebase analysis results directly within VS Code's sidebar, making it easy to explore code structure, complexity, and relationships without leaving the editor",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for browsing and exploring code analysis results in VS Code\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"See project statistics (file count, function count, complexity metrics)\",\n    \"Browse analyzed files organized by directory structure\",\n    \"Click on files to see their functions and entry points\",\n    \"Click on functions to jump to their location in the code\",\n    \"See file-level metrics (lines of code, complexity, function count)\",\n    \"View entry points and their relationships\",\n    \"See 'No analysis available' message when no analysis has been run\",\n    \"Expand/collapse sections to drill down into analysis details\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when new analysis is available\",\n    \"Analysis data is received from the analyzer module\",\n    \"Tree items are organized into categories: statistics, files, functions, entry points\",\n    \"Each tree item can be clicked to trigger navigation or reveal more details\",\n    \"File paths are resolved and displayed relative to workspace\",\n    \"Icons and descriptions enhance visual presentation of analysis data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void (triggers tree refresh)\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Forces the tree view to reload and redisplay all items\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the visual representation of a tree item\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node (or root items if none specified)\",\n      \"inputs\": \"optional AnalysisItem element\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level tree items (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing project-wide metrics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem with statistics\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes analyzed files into a directory tree structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem representing files and directories\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Shows functions and metrics for a specific file\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"Array of AnalysisItem with file details\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide developers with a navigable, visual representation of their codebase analysis results directly within VS Code's sidebar, making it easy to explore code structure, complexity, and relationships without leaving the editor\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
      "userVisibleActions": [
        "View analysis of codebase structure including file counts, line counts, and function counts",
        "See identification of large files that may need refactoring",
        "View detected orphaned files that aren't imported anywhere",
        "See entry points in the codebase",
        "View duplicate code detection results",
        "See function-level risk assessments (high/medium/low)",
        "View function dependencies including database, HTTP, filesystem, and other external services",
        "See test coverage mapping showing which tests cover which source files and functions",
        "View uncovered functions that lack tests",
        "See code quality metrics including complexity scores and maintainability ratings"
      ],
      "developerVisibleActions": [
        "Import and use CodeAnalysis interface to structure analysis results",
        "Access file metadata including lines of code, functions per file, and cyclomatic complexity",
        "Query function metadata including parameters, return types, visibility, and documentation",
        "Track function branches (if/else/switch/loop/exception handling)",
        "Analyze dependencies by type (database, HTTP, filesystem, cache, etc.)",
        "Monitor state mutations (assignments, modifications, deletions)",
        "Map source files to their corresponding test files",
        "Identify untested functions and areas lacking coverage",
        "Access duplicate code groups with similarity scores",
        "Use caching mechanism to speed up repeated analyses",
        "Query import relationships between files",
        "Get entry point detection results"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main interface representing complete codebase analysis results",
          "inputs": "N/A (interface definition)",
          "outputs": "Structure containing totalFiles, totalLines, totalFunctions, largeFiles, file list, function list, imports, orphaned files, entry points, duplicates, and optional enhanced metadata"
        },
        {
          "name": "FunctionMetadata",
          "desc": "Detailed metadata about a single function including complexity, dependencies, and risk",
          "inputs": "N/A (interface definition)",
          "outputs": "Structure with symbolName, file, parameters, returnType, visibility, docstring, branches, dependencies, state mutations, risk level, and line numbers"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source code to test files and identifies coverage gaps",
          "inputs": "N/A (interface definition)",
          "outputs": "Maps from source files to test files, functions to test names, and list of uncovered functions"
        },
        {
          "name": "DuplicateGroup",
          "desc": "Groups duplicate or similar code blocks together",
          "inputs": "N/A (interface definition)",
          "outputs": "Array of duplicate instances with similarity score and total duplicate lines"
        },
        {
          "name": "QualityMetrics",
          "desc": "Provides code quality scores and ratings",
          "inputs": "N/A (interface definition)",
          "outputs": "Overall score, complexity score, maintainability rating, test coverage percentage, and documentation completeness"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache (AnalysisCache)"
      ],
      "intent": "This file exists to provide a comprehensive type system for code analysis results, enabling developers to understand codebase structure, quality, dependencies, test coverage, and potential issues. It serves as the contract between analysis tools and their consumers, ensuring consistent and structured representation of code metrics, function metadata, dependency tracking, and quality assessments.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View analysis of codebase structure including file counts, line counts, and function counts\",\n    \"See identification of large files that may need refactoring\",\n    \"View detected orphaned files that aren't imported anywhere\",\n    \"See entry points in the codebase\",\n    \"View duplicate code detection results\",\n    \"See function-level risk assessments (high/medium/low)\",\n    \"View function dependencies including database, HTTP, filesystem, and other external services\",\n    \"See test coverage mapping showing which tests cover which source files and functions\",\n    \"View uncovered functions that lack tests\",\n    \"See code quality metrics including complexity scores and maintainability ratings\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access file metadata including lines of code, functions per file, and cyclomatic complexity\",\n    \"Query function metadata including parameters, return types, visibility, and documentation\",\n    \"Track function branches (if/else/switch/loop/exception handling)\",\n    \"Analyze dependencies by type (database, HTTP, filesystem, cache, etc.)\",\n    \"Monitor state mutations (assignments, modifications, deletions)\",\n    \"Map source files to their corresponding test files\",\n    \"Identify untested functions and areas lacking coverage\",\n    \"Access duplicate code groups with similarity scores\",\n    \"Use caching mechanism to speed up repeated analyses\",\n    \"Query import relationships between files\",\n    \"Get entry point detection results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface representing complete codebase analysis results\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Structure containing totalFiles, totalLines, totalFunctions, largeFiles, file list, function list, imports, orphaned files, entry points, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function including complexity, dependencies, and risk\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Structure with symbolName, file, parameters, returnType, visibility, docstring, branches, dependencies, state mutations, risk level, and line numbers\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test files and identifies coverage gaps\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Maps from source files to test files, functions to test names, and list of uncovered functions\"\n    },\n    {\n      \"name\": \"DuplicateGroup\",\n      \"desc\": \"Groups duplicate or similar code blocks together\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Array of duplicate instances with similarity score and total duplicate lines\"\n    },\n    {\n      \"name\": \"QualityMetrics\",\n      \"desc\": \"Provides code quality scores and ratings\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Overall score, complexity score, maintainability rating, test coverage percentage, and documentation completeness\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache (AnalysisCache)\"\n  ],\n  \"intent\": \"This file exists to provide a comprehensive type system for code analysis results, enabling developers to understand codebase structure, quality, dependencies, test coverage, and potential issues. It serves as the contract between analysis tools and their consumers, ensuring consistent and structured representation of code metrics, function metadata, dependency tracking, and quality assessments.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration",
      "userVisibleActions": [
        "Analysis results are loaded instantly from cache when reopening a workspace",
        "Cached analysis automatically expires after 24 hours to ensure freshness",
        "Cache is stored in a hidden .shadowwatch-cache directory"
      ],
      "developerVisibleActions": [
        "Store code analysis results to avoid re-analyzing unchanged code",
        "Retrieve previously cached analysis when workspace is reopened",
        "Clear all cached data to force fresh analysis",
        "Cache automatically invalidates after 24 hours",
        "Cache files are created in the storage path with base64-encoded workspace names"
      ],
      "keyFunctions": [
        {
          "name": "getCacheKey",
          "desc": "Generates a safe filename identifier for a workspace",
          "inputs": "workspaceRoot (string)",
          "outputs": "base64-encoded workspace path (string)"
        },
        {
          "name": "get",
          "desc": "Retrieves cached analysis data if it exists and is less than 24 hours old",
          "inputs": "workspaceRoot (string)",
          "outputs": "CodeAnalysis object or null if not found/expired"
        },
        {
          "name": "set",
          "desc": "Saves code analysis results to disk with current timestamp",
          "inputs": "workspaceRoot (string), data (CodeAnalysis)",
          "outputs": "void (Promise)"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis files from the cache directory",
          "inputs": "none",
          "outputs": "void (Promise)"
        },
        {
          "name": "ensureCacheDir",
          "desc": "Creates the cache directory if it doesn't exist",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "Improves extension performance by caching expensive code analysis operations, allowing instant results when reopening workspaces and preventing redundant analysis of unchanged code, while ensuring data freshness through automatic expiration",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration\",\n  \"userVisibleActions\": [\n    \"Analysis results are loaded instantly from cache when reopening a workspace\",\n    \"Cached analysis automatically expires after 24 hours to ensure freshness\",\n    \"Cache is stored in a hidden .shadowwatch-cache directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Store code analysis results to avoid re-analyzing unchanged code\",\n    \"Retrieve previously cached analysis when workspace is reopened\",\n    \"Clear all cached data to force fresh analysis\",\n    \"Cache automatically invalidates after 24 hours\",\n    \"Cache files are created in the storage path with base64-encoded workspace names\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier for a workspace\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"base64-encoded workspace path (string)\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis data if it exists and is less than 24 hours old\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"CodeAnalysis object or null if not found/expired\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves code analysis results to disk with current timestamp\",\n      \"inputs\": \"workspaceRoot (string), data (CodeAnalysis)\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (Promise)\"\n    },\n    {\n      \"name\": \"ensureCacheDir\",\n      \"desc\": \"Creates the cache directory if it doesn't exist\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis operations, allowing instant results when reopening workspaces and preventing redundant analysis of unchanged code, while ensuring data freshness through automatic expiration\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all Shadow Watch extension configuration settings and notifies listeners when settings change",
      "userVisibleActions": [
        "Enable or disable the Shadow Watch extension",
        "Toggle automatic analysis when saving files",
        "Show or hide inline hints in the editor",
        "Configure which LLM provider to use (OpenAI or Claude)",
        "Set the output format for LLM analysis results",
        "Choose minimum severity level for displaying diagnostics",
        "Customize API keys and endpoints for LLM services",
        "Adjust timeout settings for analysis operations",
        "Control file size and line count limits for analysis"
      ],
      "developerVisibleActions": [
        "Access type-safe configuration properties through getter methods",
        "Register callbacks that trigger when user changes settings",
        "Validate configuration values to ensure they meet requirements",
        "Retrieve AI provider settings including API keys and model names",
        "Get analysis parameters like debounce delays and file size limits",
        "Check if specific features are enabled before executing logic",
        "Receive automatic notifications when workspace configuration changes"
      ],
      "keyFunctions": [
        {
          "name": "onConfigurationChange",
          "desc": "Registers a callback function that executes whenever configuration settings change",
          "inputs": "callback: () => void",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Unregisters a previously registered configuration change callback",
          "inputs": "callback: () => void",
          "outputs": "void"
        },
        {
          "name": "validate",
          "desc": "Checks if current configuration values are valid and returns any errors found",
          "inputs": "none",
          "outputs": "ConfigValidationResult with valid flag and error messages"
        },
        {
          "name": "enabled",
          "desc": "Returns whether the Shadow Watch extension is currently enabled",
          "inputs": "none (getter property)",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave",
          "desc": "Returns whether automatic analysis should run when files are saved",
          "inputs": "none (getter property)",
          "outputs": "boolean"
        },
        {
          "name": "llmProvider",
          "desc": "Returns the configured LLM provider (OpenAI or Claude)",
          "inputs": "none (getter property)",
          "outputs": "LLMProvider type ('openai' or 'claude')"
        },
        {
          "name": "severityThreshold",
          "desc": "Returns the minimum severity level for displaying diagnostics",
          "inputs": "none (getter property)",
          "outputs": "SeverityThreshold type ('error', 'warning', or 'info')"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to provide a centralized, type-safe way to access all Shadow Watch configuration settings, eliminating scattered configuration calls throughout the codebase and ensuring consistent access to user preferences. It solves the problem of configuration management by providing a single source of truth with automatic change detection and listener notification.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension configuration settings and notifies listeners when settings change\",\n  \"userVisibleActions\": [\n    \"Enable or disable the Shadow Watch extension\",\n    \"Toggle automatic analysis when saving files\",\n    \"Show or hide inline hints in the editor\",\n    \"Configure which LLM provider to use (OpenAI or Claude)\",\n    \"Set the output format for LLM analysis results\",\n    \"Choose minimum severity level for displaying diagnostics\",\n    \"Customize API keys and endpoints for LLM services\",\n    \"Adjust timeout settings for analysis operations\",\n    \"Control file size and line count limits for analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access type-safe configuration properties through getter methods\",\n    \"Register callbacks that trigger when user changes settings\",\n    \"Validate configuration values to ensure they meet requirements\",\n    \"Retrieve AI provider settings including API keys and model names\",\n    \"Get analysis parameters like debounce delays and file size limits\",\n    \"Check if specific features are enabled before executing logic\",\n    \"Receive automatic notifications when workspace configuration changes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function that executes whenever configuration settings change\",\n      \"inputs\": \"callback: () => void\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback: () => void\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Checks if current configuration values are valid and returns any errors found\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult with valid flag and error messages\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider\",\n      \"desc\": \"Returns the configured LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"LLMProvider type ('openai' or 'claude')\"\n    },\n    {\n      \"name\": \"severityThreshold\",\n      \"desc\": \"Returns the minimum severity level for displaying diagnostics\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"SeverityThreshold type ('error', 'warning', or 'info')\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a centralized, type-safe way to access all Shadow Watch configuration settings, eliminating scattered configuration calls throughout the codebase and ensuring consistent access to user preferences. It solves the problem of configuration management by providing a single source of truth with automatic change detection and listener notification.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis results into a context format for LLM processing and saves them to disk for future use",
      "userVisibleActions": [
        "Code analysis results are automatically saved to workspace for future reference",
        "Analysis data persists between sessions in .shadow/docs directory"
      ],
      "developerVisibleActions": [
        "Transforms raw code analysis into LLM-compatible context format",
        "Saves analysis with metadata (timestamps, version) to .shadow/docs/code-analysis.json",
        "Creates necessary directories (.shadow/docs) if they don't exist",
        "Handles workspace validation before saving"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms CodeAnalysis object into AnalysisContext format suitable for LLM consumption",
          "inputs": "CodeAnalysis object containing files, imports, entry points, and metrics",
          "outputs": "AnalysisContext object with reformatted data structure"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to disk with metadata for future use",
          "inputs": "CodeAnalysis object to save",
          "outputs": "void (creates code-analysis.json file in workspace)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between code analysis results and LLM processing by transforming data into the appropriate format and ensuring analysis results are persisted across sessions, allowing the extension to reuse previous analysis work without re-scanning the codebase",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a context format for LLM processing and saves them to disk for future use\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to workspace for future reference\",\n    \"Analysis data persists between sessions in .shadow/docs directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transforms raw code analysis into LLM-compatible context format\",\n    \"Saves analysis with metadata (timestamps, version) to .shadow/docs/code-analysis.json\",\n    \"Creates necessary directories (.shadow/docs) if they don't exist\",\n    \"Handles workspace validation before saving\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis object into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and metrics\",\n      \"outputs\": \"AnalysisContext object with reformatted data structure\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk with metadata for future use\",\n      \"inputs\": \"CodeAnalysis object to save\",\n      \"outputs\": \"void (creates code-analysis.json file in workspace)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM processing by transforming data into the appropriate format and ensuring analysis results are persisted across sessions, allowing the extension to reuse previous analysis work without re-scanning the codebase\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Manages diagnostic messages (warnings, errors, info) displayed in VS Code's Problems panel based on code insights",
      "userVisibleActions": [
        "User sees diagnostic messages appear in the Problems panel when issues are detected",
        "User sees warnings, errors, or informational messages inline in their code editor with squiggly underlines",
        "User can click on diagnostic messages to navigate to the problematic line of code",
        "User sees diagnostics organized by file in the Problems panel",
        "User sees 'Shadow Watch' as the source of diagnostic messages",
        "User sees diagnostics cleared when issues are resolved or analysis is reset"
      ],
      "developerVisibleActions": [
        "Developer triggers diagnostic updates by providing insights from code analysis",
        "Developer can update diagnostics for all files at once with a batch of insights",
        "Developer can update diagnostics for a specific file individually",
        "Developer can clear all diagnostics from the Problems panel",
        "Developer sees diagnostics automatically grouped by file path",
        "Developer controls diagnostic severity levels (error, warning, info) through insight severity",
        "Developer provides insight metadata (file path, line number, description, severity) to generate diagnostics"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Updates all diagnostics across multiple files based on provided insights",
          "inputs": "Array of Insight objects containing file paths, line numbers, and descriptions",
          "outputs": "void - displays diagnostics in VS Code Problems panel"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostics for a specific file only",
          "inputs": "VS Code URI of the file and array of Insight objects for that file",
          "outputs": "void - displays diagnostics for the specific file"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostics from the Problems panel",
          "inputs": "none",
          "outputs": "void - clears all displayed diagnostics"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts an insight into a VS Code diagnostic message with proper formatting and severity",
          "inputs": "Insight object with description, line number, and severity",
          "outputs": "VS Code Diagnostic object ready for display"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources when the diagnostics provider is no longer needed",
          "inputs": "none",
          "outputs": "void - releases diagnostic collection resources"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "This file exists to bridge between code analysis results (insights) and VS Code's native diagnostics system, translating detected issues into user-friendly messages that appear in the Problems panel and inline in the editor, making code quality issues immediately visible to developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages diagnostic messages (warnings, errors, info) displayed in VS Code's Problems panel based on code insights\",\n  \"userVisibleActions\": [\n    \"User sees diagnostic messages appear in the Problems panel when issues are detected\",\n    \"User sees warnings, errors, or informational messages inline in their code editor with squiggly underlines\",\n    \"User can click on diagnostic messages to navigate to the problematic line of code\",\n    \"User sees diagnostics organized by file in the Problems panel\",\n    \"User sees 'Shadow Watch' as the source of diagnostic messages\",\n    \"User sees diagnostics cleared when issues are resolved or analysis is reset\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers diagnostic updates by providing insights from code analysis\",\n    \"Developer can update diagnostics for all files at once with a batch of insights\",\n    \"Developer can update diagnostics for a specific file individually\",\n    \"Developer can clear all diagnostics from the Problems panel\",\n    \"Developer sees diagnostics automatically grouped by file path\",\n    \"Developer controls diagnostic severity levels (error, warning, info) through insight severity\",\n    \"Developer provides insight metadata (file path, line number, description, severity) to generate diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across multiple files based on provided insights\",\n      \"inputs\": \"Array of Insight objects containing file paths, line numbers, and descriptions\",\n      \"outputs\": \"void - displays diagnostics in VS Code Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file only\",\n      \"inputs\": \"VS Code URI of the file and array of Insight objects for that file\",\n      \"outputs\": \"void - displays diagnostics for the specific file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - clears all displayed diagnostics\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic message with proper formatting and severity\",\n      \"inputs\": \"Insight object with description, line number, and severity\",\n      \"outputs\": \"VS Code Diagnostic object ready for display\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources when the diagnostics provider is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - releases diagnostic collection resources\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge between code analysis results (insights) and VS Code's native diagnostics system, translating detected issues into user-friendly messages that appear in the Problems panel and inline in the editor, making code quality issues immediately visible to developers.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers all VS Code commands that users and the extension can trigger for code analysis, insight management, and LLM provider operations",
      "userVisibleActions": [
        "Analyze entire workspace for code insights",
        "Analyze currently open file",
        "Copy all insights to clipboard",
        "Copy insights for specific file",
        "Copy individual insight to clipboard",
        "Clear cached analysis data",
        "Clear all extension data",
        "Open extension settings",
        "Open latest analysis report",
        "Open latest unit test report",
        "Switch between LLM providers (OpenAI, Anthropic, etc.)",
        "Copy menu structure to clipboard",
        "View LLM provider connection status",
        "Navigate to product item in codebase",
        "Navigate to analysis item location",
        "View detailed information for product items",
        "View detailed information for insights",
        "View detailed information for unit test items"
      ],
      "developerVisibleActions": [
        "Provides centralized command registration for the extension",
        "Defines command handler interface for type safety",
        "Wires up VS Code command IDs to handler functions",
        "Manages dependencies between commands and extension components",
        "Separates command registration logic from main extension activation",
        "Enables command handlers to access analyzer, cache, tree views, and LLM integration",
        "Registers commands with VS Code's command palette and UI elements"
      ],
      "keyFunctions": [
        {
          "name": "CommandRegistry.register",
          "desc": "Registers all VS Code commands with their handlers",
          "inputs": "context: vscode.ExtensionContext, components: ExtensionComponents",
          "outputs": "void (registers commands as side effect)"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "This file exists to centralize and organize all command registration logic for the VS Code extension, separating it from the main activation flow to improve maintainability and provide a clear registry of all user-triggered actions and their implementations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands that users and the extension can trigger for code analysis, insight management, and LLM provider operations\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View LLM provider connection status\",\n    \"Navigate to product item in codebase\",\n    \"Navigate to analysis item location\",\n    \"View detailed information for product items\",\n    \"View detailed information for insights\",\n    \"View detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized command registration for the extension\",\n    \"Defines command handler interface for type safety\",\n    \"Wires up VS Code command IDs to handler functions\",\n    \"Manages dependencies between commands and extension components\",\n    \"Separates command registration logic from main extension activation\",\n    \"Enables command handlers to access analyzer, cache, tree views, and LLM integration\",\n    \"Registers commands with VS Code's command palette and UI elements\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CommandRegistry.register\",\n      \"desc\": \"Registers all VS Code commands with their handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext, components: ExtensionComponents\",\n      \"outputs\": \"void (registers commands as side effect)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file exists to centralize and organize all command registration logic for the VS Code extension, separating it from the main activation flow to improve maintainability and provide a clear registry of all user-triggered actions and their implementations.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Initializes and orchestrates all VS Code extension components when the extension activates, managing their lifecycle and dependencies",
      "userVisibleActions": [
        "Extension components are initialized and ready when VS Code starts",
        "Status bar shows extension activity status",
        "Tree views populate with code insights, analysis results, reports, and test information",
        "Diagnostics appear in the Problems panel for code issues",
        "File changes trigger automatic analysis updates",
        "Reports viewer displays analysis reports",
        "Product navigation view becomes available",
        "Unit tests navigator shows test structure"
      ],
      "developerVisibleActions": [
        "Extension activation initializes all required components in correct order",
        "Components are registered with VS Code's extension context",
        "Event handlers and watchers are set up for file changes",
        "Cache system is initialized for performance optimization",
        "LLM integration services are connected and ready",
        "Configuration manager provides access to extension settings",
        "Error handling system is established for debugging",
        "Multiple tree view providers are registered for different data types",
        "Disposables are tracked for proper cleanup on deactivation"
      ],
      "keyFunctions": [
        {
          "name": "bootstrap",
          "desc": "Initializes all extension components and registers them with VS Code",
          "inputs": "vscode.ExtensionContext",
          "outputs": "ExtensionComponents object containing all initialized services"
        },
        {
          "name": "createComponents",
          "desc": "Instantiates all core services like analyzer, insight generator, formatters, and providers",
          "inputs": "context",
          "outputs": "Complete set of extension component instances"
        },
        {
          "name": "registerTreeViews",
          "desc": "Registers all tree view providers with VS Code UI",
          "inputs": "context, components",
          "outputs": "Registered tree views for insights, analysis, reports, and tests"
        },
        {
          "name": "setupFileWatching",
          "desc": "Configures automatic file monitoring and change detection",
          "inputs": "components",
          "outputs": "Active file watcher with event handlers"
        },
        {
          "name": "initializeCache",
          "desc": "Sets up the analysis cache system for storing results",
          "inputs": "none",
          "outputs": "Initialized cache instance"
        }
      ],
      "dependencies": [
        "vscode",
        "../../analyzer",
        "../../insightGenerator",
        "../../llmFormatter",
        "../../fileWatcher",
        "../../insightsTreeView",
        "../../diagnosticsProvider",
        "../../cache",
        "../../llmIntegration",
        "../../productNavigator",
        "../../analysisViewer",
        "../../insightsViewer",
        "../../staticAnalysisViewer",
        "../../unitTestsNavigator",
        "../../config/configurationManager",
        "../../utils/errorHandler",
        "../../domain/services/fileWatcherService",
        "../../ui/reportsViewer",
        "../../reportsTreeProvider",
        "../../state/llmStateManager"
      ],
      "intent": "This file exists to separate the complex initialization logic from the main extension entry point, ensuring all components are created in the correct order with proper dependencies, making the extension activation process maintainable, testable, and reducing coupling between the activation trigger and component setup",
      "rawContent": "```json\n{\n  \"purpose\": \"Initializes and orchestrates all VS Code extension components when the extension activates, managing their lifecycle and dependencies\",\n  \"userVisibleActions\": [\n    \"Extension components are initialized and ready when VS Code starts\",\n    \"Status bar shows extension activity status\",\n    \"Tree views populate with code insights, analysis results, reports, and test information\",\n    \"Diagnostics appear in the Problems panel for code issues\",\n    \"File changes trigger automatic analysis updates\",\n    \"Reports viewer displays analysis reports\",\n    \"Product navigation view becomes available\",\n    \"Unit tests navigator shows test structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activation initializes all required components in correct order\",\n    \"Components are registered with VS Code's extension context\",\n    \"Event handlers and watchers are set up for file changes\",\n    \"Cache system is initialized for performance optimization\",\n    \"LLM integration services are connected and ready\",\n    \"Configuration manager provides access to extension settings\",\n    \"Error handling system is established for debugging\",\n    \"Multiple tree view providers are registered for different data types\",\n    \"Disposables are tracked for proper cleanup on deactivation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Initializes all extension components and registers them with VS Code\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object containing all initialized services\"\n    },\n    {\n      \"name\": \"createComponents\",\n      \"desc\": \"Instantiates all core services like analyzer, insight generator, formatters, and providers\",\n      \"inputs\": \"context\",\n      \"outputs\": \"Complete set of extension component instances\"\n    },\n    {\n      \"name\": \"registerTreeViews\",\n      \"desc\": \"Registers all tree view providers with VS Code UI\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"Registered tree views for insights, analysis, reports, and tests\"\n    },\n    {\n      \"name\": \"setupFileWatching\",\n      \"desc\": \"Configures automatic file monitoring and change detection\",\n      \"inputs\": \"components\",\n      \"outputs\": \"Active file watcher with event handlers\"\n    },\n    {\n      \"name\": \"initializeCache\",\n      \"desc\": \"Sets up the analysis cache system for storing results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Initialized cache instance\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer\",\n    \"../../insightGenerator\",\n    \"../../llmFormatter\",\n    \"../../fileWatcher\",\n    \"../../insightsTreeView\",\n    \"../../diagnosticsProvider\",\n    \"../../cache\",\n    \"../../llmIntegration\",\n    \"../../productNavigator\",\n    \"../../analysisViewer\",\n    \"../../insightsViewer\",\n    \"../../staticAnalysisViewer\",\n    \"../../unitTestsNavigator\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler\",\n    \"../../domain/services/fileWatcherService\",\n    \"../../ui/reportsViewer\",\n    \"../../reportsTreeProvider\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to separate the complex initialization logic from the main extension entry point, ensuring all components are created in the correct order with proper dependencies, making the extension activation process maintainable, testable, and reducing coupling between the activation trigger and component setup\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and LLM insights into structured Markdown documents for user consumption",
      "userVisibleActions": [
        "View formatted product documentation with overview, features, and user perspectives",
        "See organized sections for GUI, CLI, and API user interactions",
        "Read categorized features grouped by user roles and domains",
        "Access behavior descriptions organized by who/what/when/where/why/how",
        "View LLM-generated insights about technical architecture and patterns",
        "See quality scores and confidence ratings for documentation accuracy",
        "Read dependency information and integration points",
        "Access generated timestamps showing when documentation was created"
      ],
      "developerVisibleActions": [
        "Call formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects into Markdown strings",
        "Call formatInsightsAsMarkdown() to convert LLM analysis results into readable documentation",
        "Receive Markdown output with consistent heading hierarchy and formatting",
        "Get documentation with automatic timestamp injection (both UTC and local)",
        "Obtain structured sections for overview, features, user perspectives, behaviors, and insights",
        "Receive formatted lists with proper bullet points and indentation",
        "Get quality metrics and confidence scores embedded in the output",
        "Access formatted dependency trees and architecture patterns"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation object into formatted Markdown document with all sections",
          "inputs": "EnhancedProductDocumentation object containing overview, features, perspectives, behaviors",
          "outputs": "Formatted Markdown string with sections for overview, features, user perspectives, behaviors, and quality scores"
        },
        {
          "name": "formatInsightsAsMarkdown",
          "desc": "Converts LLM-generated insights into formatted Markdown document with architecture and patterns",
          "inputs": "LLMInsights object containing technical patterns, dependencies, and quality metrics",
          "outputs": "Formatted Markdown string with sections for technical architecture, patterns, dependencies, and confidence ratings"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "This file exists to separate documentation formatting concerns from LLM integration logic, providing a clean, reusable way to convert structured documentation objects into human-readable Markdown format with consistent styling and organization",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and LLM insights into structured Markdown documents for user consumption\",\n  \"userVisibleActions\": [\n    \"View formatted product documentation with overview, features, and user perspectives\",\n    \"See organized sections for GUI, CLI, and API user interactions\",\n    \"Read categorized features grouped by user roles and domains\",\n    \"Access behavior descriptions organized by who/what/when/where/why/how\",\n    \"View LLM-generated insights about technical architecture and patterns\",\n    \"See quality scores and confidence ratings for documentation accuracy\",\n    \"Read dependency information and integration points\",\n    \"Access generated timestamps showing when documentation was created\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert EnhancedProductDocumentation objects into Markdown strings\",\n    \"Call formatInsightsAsMarkdown() to convert LLM analysis results into readable documentation\",\n    \"Receive Markdown output with consistent heading hierarchy and formatting\",\n    \"Get documentation with automatic timestamp injection (both UTC and local)\",\n    \"Obtain structured sections for overview, features, user perspectives, behaviors, and insights\",\n    \"Receive formatted lists with proper bullet points and indentation\",\n    \"Get quality metrics and confidence scores embedded in the output\",\n    \"Access formatted dependency trees and architecture patterns\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown document with all sections\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, perspectives, behaviors\",\n      \"outputs\": \"Formatted Markdown string with sections for overview, features, user perspectives, behaviors, and quality scores\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into formatted Markdown document with architecture and patterns\",\n      \"inputs\": \"LLMInsights object containing technical patterns, dependencies, and quality metrics\",\n      \"outputs\": \"Formatted Markdown string with sections for technical architecture, patterns, dependencies, and confidence ratings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting concerns from LLM integration logic, providing a clean, reusable way to convert structured documentation objects into human-readable Markdown format with consistent styling and organization\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation to files, functions, endpoints, and other code items in the editor when user clicks items in the product navigator or analysis viewer.",
      "userVisibleActions": [
        "Opens files in the editor when clicking on file items in the navigator",
        "Jumps to specific functions or methods in files with cursor positioned at the function location",
        "Navigates to API endpoints and highlights their location in the code",
        "Shows error messages when files cannot be opened or found",
        "Displays detailed information about code items (functions, endpoints, etc.) in a webview panel",
        "Reveals and highlights specific code ranges when clicking on analysis items",
        "Opens external links in the default browser when clicked"
      ],
      "developerVisibleActions": [
        "Provides methods to programmatically navigate to ProductNavItem objects (files, functions, endpoints)",
        "Provides methods to navigate to AnalysisItem objects from analysis results",
        "Handles both absolute and relative file paths relative to workspace root",
        "Searches for function definitions by name within opened documents",
        "Creates and manages webview panels for displaying detailed item information",
        "Converts file paths to VS Code URI format for opening documents",
        "Handles navigation for different item types: files, functions, endpoints, entry points",
        "Provides link handling for external URLs in webview content"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to a product navigation item (file or function) and opens it in the editor",
          "inputs": "ProductNavItem (type: file/function/navigate, data with file path and optional function name)",
          "outputs": "Promise<void>"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to an analysis item and reveals it in the editor with highlighting",
          "inputs": "AnalysisItem (with file path, line number, and column information)",
          "outputs": "Promise<void>"
        },
        {
          "name": "showItemDetails",
          "desc": "Displays detailed information about a code item in a webview panel",
          "inputs": "ProductNavItem or AnalysisItem (with metadata like name, type, description, file location)",
          "outputs": "void"
        },
        {
          "name": "navigateToEntryPoint",
          "desc": "Navigates to an entry point (function, endpoint, etc.) and positions cursor at its location",
          "inputs": "EntryPoint (with file path, line number, column, and name)",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "ProductNavItem from productNavigator",
        "AnalysisItem from analysisViewer",
        "EntryPoint from analyzer"
      ],
      "intent": "This file exists to centralize all navigation logic in one place, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to files, functions, and other code items regardless of where the navigation request originates.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code items in the editor when user clicks items in the product navigator or analysis viewer.\",\n  \"userVisibleActions\": [\n    \"Opens files in the editor when clicking on file items in the navigator\",\n    \"Jumps to specific functions or methods in files with cursor positioned at the function location\",\n    \"Navigates to API endpoints and highlights their location in the code\",\n    \"Shows error messages when files cannot be opened or found\",\n    \"Displays detailed information about code items (functions, endpoints, etc.) in a webview panel\",\n    \"Reveals and highlights specific code ranges when clicking on analysis items\",\n    \"Opens external links in the default browser when clicked\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides methods to programmatically navigate to ProductNavItem objects (files, functions, endpoints)\",\n    \"Provides methods to navigate to AnalysisItem objects from analysis results\",\n    \"Handles both absolute and relative file paths relative to workspace root\",\n    \"Searches for function definitions by name within opened documents\",\n    \"Creates and manages webview panels for displaying detailed item information\",\n    \"Converts file paths to VS Code URI format for opening documents\",\n    \"Handles navigation for different item types: files, functions, endpoints, entry points\",\n    \"Provides link handling for external URLs in webview content\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file or function) and opens it in the editor\",\n      \"inputs\": \"ProductNavItem (type: file/function/navigate, data with file path and optional function name)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis item and reveals it in the editor with highlighting\",\n      \"inputs\": \"AnalysisItem (with file path, line number, and column information)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a code item in a webview panel\",\n      \"inputs\": \"ProductNavItem or AnalysisItem (with metadata like name, type, description, file location)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point (function, endpoint, etc.) and positions cursor at its location\",\n      \"inputs\": \"EntryPoint (with file path, line number, column, and name)\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic in one place, separating concerns from the main extension file. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual code in the editor, providing a consistent way to jump to files, functions, and other code items regardless of where the navigation request originates.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/functionExtractionPrompt.ts",
      "role": "Core Logic",
      "purpose": "Builds a prompt template for LLM-based extraction of testable functions, methods, and classes from source code files, replacing regex-based extraction that incorrectly captured control flow keywords.",
      "userVisibleActions": [
        "N/A - Internal prompt generation utility with no direct user interface"
      ],
      "developerVisibleActions": [
        "Developer calls buildFunctionExtractionPrompt() with an array of source files to analyze",
        "Receives a formatted prompt string that can be sent to an LLM for code analysis",
        "Can specify maximum functions to extract per file via maxFunctionsPerFile parameter",
        "System automatically truncates files over 10,000 characters to prevent token limit issues",
        "System includes file paths, languages, and formatted source code in the prompt",
        "System instructs LLM to extract functions/methods/classes while excluding control flow statements",
        "System requests structured output including name, file path, line numbers, complexity, dependencies, and visibility for each extracted item"
      ],
      "keyFunctions": [
        {
          "name": "buildFunctionExtractionPrompt",
          "desc": "Constructs an LLM prompt for extracting testable code elements from source files with specific rules to avoid control flow keywords",
          "inputs": "files (array of objects with path, content, language), maxFunctionsPerFile (optional number, default 50)",
          "outputs": "Formatted prompt string containing instructions and source code for LLM analysis"
        }
      ],
      "dependencies": [],
      "intent": "This file exists to solve the problem of accurately extracting testable functions from source code by using LLM-based analysis instead of regex patterns. It addresses the specific issue where regex incorrectly captured control flow keywords (if, for, while, etc.) as functions. The prompt template ensures the LLM understands what constitutes a valid testable function versus control flow statements, enabling more accurate test generation workflows.",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds a prompt template for LLM-based extraction of testable functions, methods, and classes from source code files, replacing regex-based extraction that incorrectly captured control flow keywords.\",\n  \"userVisibleActions\": [\n    \"N/A - Internal prompt generation utility with no direct user interface\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls buildFunctionExtractionPrompt() with an array of source files to analyze\",\n    \"Receives a formatted prompt string that can be sent to an LLM for code analysis\",\n    \"Can specify maximum functions to extract per file via maxFunctionsPerFile parameter\",\n    \"System automatically truncates files over 10,000 characters to prevent token limit issues\",\n    \"System includes file paths, languages, and formatted source code in the prompt\",\n    \"System instructs LLM to extract functions/methods/classes while excluding control flow statements\",\n    \"System requests structured output including name, file path, line numbers, complexity, dependencies, and visibility for each extracted item\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildFunctionExtractionPrompt\",\n      \"desc\": \"Constructs an LLM prompt for extracting testable code elements from source files with specific rules to avoid control flow keywords\",\n      \"inputs\": \"files (array of objects with path, content, language), maxFunctionsPerFile (optional number, default 50)\",\n      \"outputs\": \"Formatted prompt string containing instructions and source code for LLM analysis\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to solve the problem of accurately extracting testable functions from source code by using LLM-based analysis instead of regex patterns. It addresses the specific issue where regex incorrectly captured control flow keywords (if, for, while, etc.) as functions. The prompt template ensures the LLM understands what constitutes a valid testable function versus control flow statements, enabling more accurate test generation workflows.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Constructs structured prompts for AI/LLM analysis tasks across the entire codebase, ensuring consistent and effective communication with language models.",
      "userVisibleActions": [
        "Analyzes project architecture and generates comprehensive documentation",
        "Creates product-level documentation from codebase analysis",
        "Generates test plans for code files with coverage recommendations",
        "Produces test code based on defined test scenarios",
        "Documents individual files with user-facing behavior descriptions",
        "Summarizes code modules and their relationships"
      ],
      "developerVisibleActions": [
        "Provides centralized prompt generation for all LLM analysis operations",
        "Builds architecture analysis prompts with codebase context and product documentation",
        "Constructs product documentation prompts from analysis context",
        "Creates file-specific analysis prompts with role-based categorization",
        "Generates module rollup prompts for aggregating file summaries",
        "Builds test planning prompts with existing test awareness and function metadata",
        "Produces test code generation prompts with source code and test framework details",
        "Eliminates prompt duplication across different analysis services",
        "Supports multiple programming languages and test frameworks"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Constructs a prompt for analyzing overall system architecture",
          "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
          "outputs": "string prompt for LLM consumption"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Creates a prompt for generating product-level documentation",
          "inputs": "context (AnalysisContext)",
          "outputs": "string prompt for documentation generation"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Generates a prompt for understanding the product's core purpose",
          "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
          "outputs": "string prompt for purpose analysis"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Creates a prompt for analyzing individual code files",
          "inputs": "file (FileInfo), content (string), role (string)",
          "outputs": "string prompt for file analysis"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Constructs a prompt for aggregating multiple file summaries into module documentation",
          "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
          "outputs": "string prompt for module summary"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Builds a comprehensive prompt for product-wide documentation",
          "inputs": "fileSummaries, moduleSummaries, analysis (CodeAnalysis), fileAccessHelper",
          "outputs": "string prompt for product documentation"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Creates a prompt for generating test plans for specific files",
          "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
          "outputs": "string prompt for test planning"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Generates a prompt for creating actual test code from test plans",
          "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
          "outputs": "string prompt for test code generation"
        }
      ],
      "dependencies": [
        "../../llmService",
        "../../analyzer",
        "../../fileDocumentation",
        "../../fileAccessHelper"
      ],
      "intent": "This file exists to eliminate duplication and ensure consistency across all AI/LLM interactions by centralizing prompt construction logic. It solves the problem of scattered, inconsistent prompt generation throughout the codebase, making it easier to maintain and improve how the system communicates with language models for analysis, documentation, and test generation tasks.",
      "rawContent": "```json\n{\n  \"purpose\": \"Constructs structured prompts for AI/LLM analysis tasks across the entire codebase, ensuring consistent and effective communication with language models.\",\n  \"userVisibleActions\": [\n    \"Analyzes project architecture and generates comprehensive documentation\",\n    \"Creates product-level documentation from codebase analysis\",\n    \"Generates test plans for code files with coverage recommendations\",\n    \"Produces test code based on defined test scenarios\",\n    \"Documents individual files with user-facing behavior descriptions\",\n    \"Summarizes code modules and their relationships\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized prompt generation for all LLM analysis operations\",\n    \"Builds architecture analysis prompts with codebase context and product documentation\",\n    \"Constructs product documentation prompts from analysis context\",\n    \"Creates file-specific analysis prompts with role-based categorization\",\n    \"Generates module rollup prompts for aggregating file summaries\",\n    \"Builds test planning prompts with existing test awareness and function metadata\",\n    \"Produces test code generation prompts with source code and test framework details\",\n    \"Eliminates prompt duplication across different analysis services\",\n    \"Supports multiple programming languages and test frameworks\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a prompt for analyzing overall system architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"string prompt for LLM consumption\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates a prompt for generating product-level documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"string prompt for documentation generation\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Generates a prompt for understanding the product's core purpose\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"string prompt for purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates a prompt for analyzing individual code files\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"string prompt for file analysis\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs a prompt for aggregating multiple file summaries into module documentation\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"string prompt for module summary\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Builds a comprehensive prompt for product-wide documentation\",\n      \"inputs\": \"fileSummaries, moduleSummaries, analysis (CodeAnalysis), fileAccessHelper\",\n      \"outputs\": \"string prompt for product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates a prompt for generating test plans for specific files\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"string prompt for test planning\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates a prompt for creating actual test code from test plans\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"string prompt for test code generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and ensure consistency across all AI/LLM interactions by centralizing prompt construction logic. It solves the problem of scattered, inconsistent prompt generation throughout the codebase, making it easier to maintain and improve how the system communicates with language models for analysis, documentation, and test generation tasks.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Generates AI prompts that instruct an LLM to create detailed code refactoring plans with function extraction recommendations.",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations for improving code organization",
        "Gets step-by-step migration plans for extracting functions to new files",
        "Views before/after code examples showing proposed refactoring changes",
        "Sees analysis of function dependencies and which code calls what"
      ],
      "developerVisibleActions": [
        "Builds comprehensive prompts that guide LLMs to generate refactoring reports",
        "Includes code analysis data, product documentation, and architecture insights in prompts",
        "Generates prompts that request function extraction plans with dependencies and migration steps",
        "Provides function-level analysis including responsibilities, dependencies, and dependents",
        "Creates prompts requesting before/after code examples for refactoring changes"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Creates a comprehensive prompt for generating detailed refactoring recommendations",
          "inputs": "context (analysis settings), codeAnalysis (parsed code structure), productDocs (optional documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)",
          "outputs": "String prompt for LLM to generate refactoring report"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Constructs the foundational prompt section with project context and code analysis",
          "inputs": "context, codeAnalysis, productDocs, architectureInsights",
          "outputs": "String containing base prompt instructions"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Adds detailed function analysis information to the prompt",
          "inputs": "functionAnalyses (array of function metadata)",
          "outputs": "String section describing function responsibilities and relationships"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Specifies requirements for LLM to generate function extraction plans",
          "inputs": "None",
          "outputs": "String section with extraction planning instructions"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to translate code analysis results into structured prompts that guide AI models to generate actionable refactoring recommendations. It solves the problem of getting useful, detailed refactoring suggestions by carefully crafting prompts that include function dependencies, extraction plans, and migration steps rather than generic improvement advice.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates AI prompts that instruct an LLM to create detailed code refactoring plans with function extraction recommendations.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations for improving code organization\",\n    \"Gets step-by-step migration plans for extracting functions to new files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Sees analysis of function dependencies and which code calls what\"\n  ],\n  \"developerVisibleActions\": [\n    \"Builds comprehensive prompts that guide LLMs to generate refactoring reports\",\n    \"Includes code analysis data, product documentation, and architecture insights in prompts\",\n    \"Generates prompts that request function extraction plans with dependencies and migration steps\",\n    \"Provides function-level analysis including responsibilities, dependencies, and dependents\",\n    \"Creates prompts requesting before/after code examples for refactoring changes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for generating detailed refactoring recommendations\",\n      \"inputs\": \"context (analysis settings), codeAnalysis (parsed code structure), productDocs (optional documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)\",\n      \"outputs\": \"String prompt for LLM to generate refactoring report\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational prompt section with project context and code analysis\",\n      \"inputs\": \"context, codeAnalysis, productDocs, architectureInsights\",\n      \"outputs\": \"String containing base prompt instructions\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function analysis information to the prompt\",\n      \"inputs\": \"functionAnalyses (array of function metadata)\",\n      \"outputs\": \"String section describing function responsibilities and relationships\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Specifies requirements for LLM to generate function extraction plans\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String section with extraction planning instructions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to translate code analysis results into structured prompts that guide AI models to generate actionable refactoring recommendations. It solves the problem of getting useful, detailed refactoring suggestions by carefully crafting prompts that include function dependencies, extraction plans, and migration steps rather than generic improvement advice.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt builders that generate structured instructions for an LLM to analyze codebases and create test plans, configurations, and test implementations.",
      "userVisibleActions": [
        "Automatically analyzes the project structure and suggests appropriate testing frameworks",
        "Generates prioritized test plans based on code complexity and risk",
        "Creates test implementations for specific functions",
        "Provides test setup recommendations including dependencies and configurations"
      ],
      "developerVisibleActions": [
        "Call buildSetupPrompt() with workspace info to get LLM prompt for test configuration recommendations",
        "Call buildPlanningPrompt() with code analysis to get LLM prompt for test strategy and prioritization",
        "Call buildImplementationPrompt() with function details to get LLM prompt for generating actual test code",
        "Receive structured JSON responses from LLM containing test plans, configurations, and code",
        "Prompts guide LLM to consider code complexity, dependencies, edge cases, and testing best practices"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates a prompt asking LLM to analyze codebase structure and recommend optimal test setup",
          "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
          "outputs": "Formatted prompt string requesting JSON response with language, framework, dependencies, and config files"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates a prompt asking LLM to generate a prioritized test plan based on code analysis",
          "inputs": "context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any",
          "outputs": "Formatted prompt string requesting JSON response with priority levels, coverage targets, and testing strategy"
        },
        {
          "name": "buildImplementationPrompt",
          "desc": "Creates a prompt asking LLM to generate actual test code for a specific function",
          "inputs": "testableFunction: TestableFunction, setupInfo: any, contextualInfo?: any",
          "outputs": "Formatted prompt string requesting complete test implementation with setup, assertions, and edge cases"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis type)",
        "../services/testing/types/testPlanTypes (TestableFunction type)"
      ],
      "intent": "This file exists to standardize how the system communicates with LLMs for test generation tasks. It encapsulates the complex prompt engineering needed to get high-quality, structured test recommendations and implementations from language models, ensuring consistent formatting and comprehensive coverage of testing concerns.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt builders that generate structured instructions for an LLM to analyze codebases and create test plans, configurations, and test implementations.\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes the project structure and suggests appropriate testing frameworks\",\n    \"Generates prioritized test plans based on code complexity and risk\",\n    \"Creates test implementations for specific functions\",\n    \"Provides test setup recommendations including dependencies and configurations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace info to get LLM prompt for test configuration recommendations\",\n    \"Call buildPlanningPrompt() with code analysis to get LLM prompt for test strategy and prioritization\",\n    \"Call buildImplementationPrompt() with function details to get LLM prompt for generating actual test code\",\n    \"Receive structured JSON responses from LLM containing test plans, configurations, and code\",\n    \"Prompts guide LLM to consider code complexity, dependencies, edge cases, and testing best practices\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to analyze codebase structure and recommend optimal test setup\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"Formatted prompt string requesting JSON response with language, framework, dependencies, and config files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to generate a prioritized test plan based on code analysis\",\n      \"inputs\": \"context: CodeAnalysis, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"Formatted prompt string requesting JSON response with priority levels, coverage targets, and testing strategy\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Creates a prompt asking LLM to generate actual test code for a specific function\",\n      \"inputs\": \"testableFunction: TestableFunction, setupInfo: any, contextualInfo?: any\",\n      \"outputs\": \"Formatted prompt string requesting complete test implementation with setup, assertions, and edge cases\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis type)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction type)\"\n  ],\n  \"intent\": \"This file exists to standardize how the system communicates with LLMs for test generation tasks. It encapsulates the complex prompt engineering needed to get high-quality, structured test recommendations and implementations from language models, ensuring consistent formatting and comprehensive coverage of testing concerns.\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides a centralized service for monitoring file system changes and document saves across the extension, eliminating duplication of file watching logic.",
      "userVisibleActions": [
        "Files are automatically monitored for changes when opened or created",
        "Updates occur automatically when files are saved, modified, or deleted",
        "File system changes trigger automatic refreshes of views and data",
        "Changes to specific file patterns (like product files or insights) are detected in real-time"
      ],
      "developerVisibleActions": [
        "Register file watchers for specific patterns (e.g., '**/*.md', '**/*.json')",
        "Subscribe to file creation, modification, and deletion events",
        "Register handlers for document save events",
        "Ignore specific file patterns when watching (e.g., '.git/**', 'node_modules/**')",
        "Clean up watchers automatically when handlers are disposed",
        "Receive structured FileChangeEvent objects with URI and event type",
        "Watch multiple patterns with separate handlers for each",
        "Debounce file change events to prevent excessive handler calls"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Registers a handler to be called when files matching a pattern are created, changed, or deleted",
          "inputs": "id (string), pattern (glob or RelativePattern), handler (callback function), options (ignore patterns, event types to watch)",
          "outputs": "Disposable object to stop watching"
        },
        {
          "name": "onDidSaveTextDocument",
          "desc": "Registers a handler to be called when any text document is saved",
          "inputs": "handler (callback function receiving TextDocument)",
          "outputs": "Disposable object to unregister the handler"
        },
        {
          "name": "unwatch",
          "desc": "Removes a specific handler from watching file changes",
          "inputs": "id (string), pattern (glob or RelativePattern)",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all watchers and handlers when the service is no longer needed",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getPatternKey",
          "desc": "Generates a unique key for a file pattern to avoid duplicate watchers",
          "inputs": "pattern (string or RelativePattern)",
          "outputs": "string key"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to consolidate file watching functionality that was previously duplicated across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file monitoring behavior and prevents resource waste from multiple watchers monitoring the same files. It provides a single, reliable service that other components can use to react to file system changes without implementing their own watching logic.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes and document saves across the extension, eliminating duplication of file watching logic.\",\n  \"userVisibleActions\": [\n    \"Files are automatically monitored for changes when opened or created\",\n    \"Updates occur automatically when files are saved, modified, or deleted\",\n    \"File system changes trigger automatic refreshes of views and data\",\n    \"Changes to specific file patterns (like product files or insights) are detected in real-time\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers for specific patterns (e.g., '**/*.md', '**/*.json')\",\n    \"Subscribe to file creation, modification, and deletion events\",\n    \"Register handlers for document save events\",\n    \"Ignore specific file patterns when watching (e.g., '.git/**', 'node_modules/**')\",\n    \"Clean up watchers automatically when handlers are disposed\",\n    \"Receive structured FileChangeEvent objects with URI and event type\",\n    \"Watch multiple patterns with separate handlers for each\",\n    \"Debounce file change events to prevent excessive handler calls\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a handler to be called when files matching a pattern are created, changed, or deleted\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern), handler (callback function), options (ignore patterns, event types to watch)\",\n      \"outputs\": \"Disposable object to stop watching\"\n    },\n    {\n      \"name\": \"onDidSaveTextDocument\",\n      \"desc\": \"Registers a handler to be called when any text document is saved\",\n      \"inputs\": \"handler (callback function receiving TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific handler from watching file changes\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers when the service is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to avoid duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate file watching functionality that was previously duplicated across multiple components (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file monitoring behavior and prevents resource waste from multiple watchers monitoring the same files. It provides a single, reliable service that other components can use to react to file system changes without implementing their own watching logic.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative LLM analysis by processing file read and grep search requests across multiple analysis iterations until completion or max iterations reached",
      "userVisibleActions": [
        "System performs multiple analysis passes to gather required information",
        "Additional files are read automatically when analysis needs more context",
        "Grep searches execute to find code patterns requested during analysis",
        "Analysis stops after maximum iterations or when no more information needed",
        "Progress shown as iteration count advances through analysis process"
      ],
      "developerVisibleActions": [
        "Configure maximum number of analysis iterations allowed",
        "Provide callbacks to track iteration start and completion events",
        "Receive structured results containing analysis outcome, iteration count, and all file/grep requests made",
        "Access conversation history with assistant and user messages accumulated across iterations",
        "Handle file read and grep search requests automatically limited to 5 per iteration",
        "Use async iterator pattern for incremental analysis instead of while loops"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes LLM-requested file reads and grep searches, formatting results for next iteration",
          "inputs": "requests: LLMRequest[], currentResult: any, messages: conversation history array",
          "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
        },
        {
          "name": "Constructor",
          "desc": "Initializes service with file access helper for reading files and running searches",
          "inputs": "fileAccessHelper: FileAccessHelper",
          "outputs": "IncrementalAnalysisService instance"
        }
      ],
      "dependencies": [
        "../../fileAccessHelper (FileAccessHelper, LLMRequest types)"
      ],
      "intent": "Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a reusable, testable service that handles the common pattern of: analyze → request files/searches → gather info → re-analyze → repeat until done",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file read and grep search requests across multiple analysis iterations until completion or max iterations reached\",\n  \"userVisibleActions\": [\n    \"System performs multiple analysis passes to gather required information\",\n    \"Additional files are read automatically when analysis needs more context\",\n    \"Grep searches execute to find code patterns requested during analysis\",\n    \"Analysis stops after maximum iterations or when no more information needed\",\n    \"Progress shown as iteration count advances through analysis process\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum number of analysis iterations allowed\",\n    \"Provide callbacks to track iteration start and completion events\",\n    \"Receive structured results containing analysis outcome, iteration count, and all file/grep requests made\",\n    \"Access conversation history with assistant and user messages accumulated across iterations\",\n    \"Handle file read and grep search requests automatically limited to 5 per iteration\",\n    \"Use async iterator pattern for incremental analysis instead of while loops\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, formatting results for next iteration\",\n      \"inputs\": \"requests: LLMRequest[], currentResult: any, messages: conversation history array\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"Constructor\",\n      \"desc\": \"Initializes service with file access helper for reading files and running searches\",\n      \"inputs\": \"fileAccessHelper: FileAccessHelper\",\n      \"outputs\": \"IncrementalAnalysisService instance\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileAccessHelper (FileAccessHelper, LLMRequest types)\"\n  ],\n  \"intent\": \"Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a reusable, testable service that handles the common pattern of: analyze → request files/searches → gather info → re-analyze → repeat until done\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects and configures test framework settings to ensure generated tests work without manual user setup",
      "userVisibleActions": [
        "Automatically detects which test framework (Jest, Mocha, Vitest, Pytest) is being used in the project",
        "Identifies missing test dependencies and provides setup recommendations",
        "Validates that test configuration files exist and are properly configured",
        "Reports whether the test environment is ready to run generated tests",
        "Suggests specific setup actions needed to fix configuration issues"
      ],
      "developerVisibleActions": [
        "Scans workspace root for package.json to identify test framework from scripts and dependencies",
        "Checks for framework-specific configuration files (jest.config.js, .mocharc, vitest.config.ts, pytest.ini)",
        "Detects TypeScript setup and verifies TypeScript-specific test dependencies (ts-jest, @jest/globals)",
        "Analyzes installed dependencies versus required dependencies for the detected framework",
        "Returns structured status report with framework type, configuration state, and required actions",
        "Provides list of missing dependencies that need to be installed",
        "Determines if manual setup steps are required before tests can run"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Scans project to identify test framework and configuration completeness",
          "inputs": "workspaceRoot (string path to project root)",
          "outputs": "TestConfigStatus object with framework type, configuration status, missing dependencies, and setup actions"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "SWLogger"
      ],
      "intent": "Eliminates manual test configuration burden by automatically detecting what test framework is used, what's missing, and what setup is needed, ensuring generated tests can run immediately without user intervention or troubleshooting",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects and configures test framework settings to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework (Jest, Mocha, Vitest, Pytest) is being used in the project\",\n    \"Identifies missing test dependencies and provides setup recommendations\",\n    \"Validates that test configuration files exist and are properly configured\",\n    \"Reports whether the test environment is ready to run generated tests\",\n    \"Suggests specific setup actions needed to fix configuration issues\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace root for package.json to identify test framework from scripts and dependencies\",\n    \"Checks for framework-specific configuration files (jest.config.js, .mocharc, vitest.config.ts, pytest.ini)\",\n    \"Detects TypeScript setup and verifies TypeScript-specific test dependencies (ts-jest, @jest/globals)\",\n    \"Analyzes installed dependencies versus required dependencies for the detected framework\",\n    \"Returns structured status report with framework type, configuration state, and required actions\",\n    \"Provides list of missing dependencies that need to be installed\",\n    \"Determines if manual setup steps are required before tests can run\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Scans project to identify test framework and configuration completeness\",\n      \"inputs\": \"workspaceRoot (string path to project root)\",\n      \"outputs\": \"TestConfigStatus object with framework type, configuration status, missing dependencies, and setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration burden by automatically detecting what test framework is used, what's missing, and what setup is needed, ensuring generated tests can run immediately without user intervention or troubleshooting\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmFunctionExtractionService.ts",
      "role": "Core Logic",
      "purpose": "Extracts testable functions from workspace code files using an LLM to identify function metadata, complexity, and testability characteristics.",
      "userVisibleActions": [
        "Automated analysis of code files to identify functions that can be tested",
        "Assessment of function testability (low/medium/high) with explanations",
        "Detection of functions that require mocking due to external dependencies",
        "Complexity rating (low/medium/high) assigned to each discovered function",
        "Progress feedback showing batch processing status during analysis"
      ],
      "developerVisibleActions": [
        "Call extractFunctionsFromWorkspace() to analyze multiple code files in batches",
        "Call extractFunctionsFromSingleFile() to analyze a single file in isolation",
        "Receive structured function metadata including name, location, parameters, return types, and dependencies",
        "Configure batch size (maxFilesPerBatch) to control token usage and API limits",
        "Get detailed extraction results with total function count and files analyzed",
        "Access logging output showing processing progress and any extraction errors"
      ],
      "keyFunctions": [
        {
          "name": "extractFunctionsFromWorkspace",
          "desc": "Analyzes all code files in workspace to extract function metadata using LLM in configurable batches",
          "inputs": "workspaceRoot path, array of code file paths, llmService instance, optional maxFilesPerBatch",
          "outputs": "Array of ExtractedFunction objects with metadata about each discovered function"
        },
        {
          "name": "extractFunctionsFromSingleFile",
          "desc": "Analyzes a single code file to extract all functions and their metadata using LLM",
          "inputs": "File path, file content, llmService instance",
          "outputs": "Array of ExtractedFunction objects from the analyzed file"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "CodeAnalysis",
        "buildFunctionExtractionPrompt",
        "buildSingleFileExtractionPrompt",
        "SWLogger"
      ],
      "intent": "Replaces regex-based function extraction with LLM-powered analysis to accurately identify testable functions while avoiding false positives from control flow keywords (if, while, for, etc.). Enables intelligent test generation by providing rich metadata about each function including complexity, dependencies, API calls, and testability assessment.",
      "rawContent": "```json\n{\n  \"purpose\": \"Extracts testable functions from workspace code files using an LLM to identify function metadata, complexity, and testability characteristics.\",\n  \"userVisibleActions\": [\n    \"Automated analysis of code files to identify functions that can be tested\",\n    \"Assessment of function testability (low/medium/high) with explanations\",\n    \"Detection of functions that require mocking due to external dependencies\",\n    \"Complexity rating (low/medium/high) assigned to each discovered function\",\n    \"Progress feedback showing batch processing status during analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call extractFunctionsFromWorkspace() to analyze multiple code files in batches\",\n    \"Call extractFunctionsFromSingleFile() to analyze a single file in isolation\",\n    \"Receive structured function metadata including name, location, parameters, return types, and dependencies\",\n    \"Configure batch size (maxFilesPerBatch) to control token usage and API limits\",\n    \"Get detailed extraction results with total function count and files analyzed\",\n    \"Access logging output showing processing progress and any extraction errors\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"extractFunctionsFromWorkspace\",\n      \"desc\": \"Analyzes all code files in workspace to extract function metadata using LLM in configurable batches\",\n      \"inputs\": \"workspaceRoot path, array of code file paths, llmService instance, optional maxFilesPerBatch\",\n      \"outputs\": \"Array of ExtractedFunction objects with metadata about each discovered function\"\n    },\n    {\n      \"name\": \"extractFunctionsFromSingleFile\",\n      \"desc\": \"Analyzes a single code file to extract all functions and their metadata using LLM\",\n      \"inputs\": \"File path, file content, llmService instance\",\n      \"outputs\": \"Array of ExtractedFunction objects from the analyzed file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"CodeAnalysis\",\n    \"buildFunctionExtractionPrompt\",\n    \"buildSingleFileExtractionPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Replaces regex-based function extraction with LLM-powered analysis to accurately identify testable functions while avoiding false positives from control flow keywords (if, while, for, etc.). Enables intelligent test generation by providing rich metadata about each function including complexity, dependencies, API calls, and testability assessment.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates unit tests for code functions in small batches using an LLM service, executing them and tracking generation state",
      "userVisibleActions": [
        "Tests are generated automatically for selected functions in the workspace",
        "Progress updates show which function is being processed and how many are complete",
        "Generated tests are saved to the test directory and can be executed immediately",
        "Test execution results show pass/fail status and coverage information",
        "Failed test generation attempts are reported with error messages"
      ],
      "developerVisibleActions": [
        "Developer triggers test generation for a batch of functions from their codebase",
        "Service reads the source code of each function to understand its behavior",
        "LLM generates test code based on the function's implementation and context",
        "Generated tests are written to the file system in the test directory",
        "Tests are automatically executed to verify they work correctly",
        "Service tracks which functions have tests generated, which passed, and which failed",
        "Developer receives a map of results showing success/failure for each function",
        "Existing mock files are detected and included in the generation context"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for multiple functions in a batch, processing them sequentially",
          "inputs": "Array of TestableFunction objects, workspace root path, LLM service instance, optional progress callback",
          "outputs": "Map of function names to TestGenerationResult objects containing success/failure status"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Reads and extracts the source code for a specific function from the file system",
          "inputs": "TestableFunction object, workspace root path",
          "outputs": "String containing the function's source code"
        },
        {
          "name": "extractFileContext",
          "desc": "Extracts import/export context from the source file to provide additional context for test generation",
          "inputs": "File path, workspace root path",
          "outputs": "String containing file context information"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestableFunction",
        "TestGenerationState",
        "TestGenerationResult",
        "buildGenerationPrompt",
        "TestExecutionService",
        "SWLogger"
      ],
      "intent": "This file exists to automate the tedious process of writing unit tests by leveraging LLM capabilities to generate tests incrementally in manageable batches, ensuring each function has proper test coverage without overwhelming the system or developer with too many tests at once.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions in small batches using an LLM service, executing them and tracking generation state\",\n  \"userVisibleActions\": [\n    \"Tests are generated automatically for selected functions in the workspace\",\n    \"Progress updates show which function is being processed and how many are complete\",\n    \"Generated tests are saved to the test directory and can be executed immediately\",\n    \"Test execution results show pass/fail status and coverage information\",\n    \"Failed test generation attempts are reported with error messages\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for a batch of functions from their codebase\",\n    \"Service reads the source code of each function to understand its behavior\",\n    \"LLM generates test code based on the function's implementation and context\",\n    \"Generated tests are written to the file system in the test directory\",\n    \"Tests are automatically executed to verify they work correctly\",\n    \"Service tracks which functions have tests generated, which passed, and which failed\",\n    \"Developer receives a map of results showing success/failure for each function\",\n    \"Existing mock files are detected and included in the generation context\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, processing them sequentially\",\n      \"inputs\": \"Array of TestableFunction objects, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects containing success/failure status\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Reads and extracts the source code for a specific function from the file system\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"String containing the function's source code\"\n    },\n    {\n      \"name\": \"extractFileContext\",\n      \"desc\": \"Extracts import/export context from the source file to provide additional context for test generation\",\n      \"inputs\": \"File path, workspace root path\",\n      \"outputs\": \"String containing file context information\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the tedious process of writing unit tests by leveraging LLM capabilities to generate tests incrementally in manageable batches, ensuring each function has proper test coverage without overwhelming the system or developer with too many tests at once.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Creates prioritized test plans by analyzing code functions and determining which ones need testing using LLM-based analysis.",
      "userVisibleActions": [
        "Receives an AI-generated test plan that prioritizes which functions in the codebase need testing",
        "Gets test plans based on intelligent analysis of function complexity and importance",
        "Benefits from improved test coverage recommendations that avoid false positives from control flow keywords"
      ],
      "developerVisibleActions": [
        "Calls analyzeFunctions to extract testable functions from workspace code files using LLM analysis",
        "Receives structured test plan data with function metadata (name, file, lines, complexity, parameters, return type)",
        "Uses LLM service to intelligently identify actual functions versus control flow statements",
        "Accesses legacy regex-based function extraction as fallback (deprecated)",
        "Gets functions converted to test plan format ready for prioritization"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts and analyzes testable functions from workspace code files using LLM instead of regex to avoid capturing control flow keywords",
          "inputs": "workspaceRoot (string), codeFiles (string array), llmService (LLM service instance)",
          "outputs": "Array of function metadata objects in test plan format"
        },
        {
          "name": "analyzeFunctionsLegacy",
          "desc": "Deprecated regex-based function extraction that incorrectly captured control flow keywords like for, if, switch",
          "inputs": "codeAnalysis (code analysis object)",
          "outputs": "Array of function metadata objects"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "testPlanTypes",
        "testPrompts",
        "CodeAnalysis",
        "SWLogger",
        "LLMFunctionExtractionService"
      ],
      "intent": "This file solves the problem of accurately identifying which functions in a codebase should be tested by using LLM analysis to distinguish real functions from control flow statements (for, if, switch), replacing unreliable regex-based extraction that created false positives. It enables intelligent test planning by providing structured function metadata that can be prioritized for test generation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates prioritized test plans by analyzing code functions and determining which ones need testing using LLM-based analysis.\",\n  \"userVisibleActions\": [\n    \"Receives an AI-generated test plan that prioritizes which functions in the codebase need testing\",\n    \"Gets test plans based on intelligent analysis of function complexity and importance\",\n    \"Benefits from improved test coverage recommendations that avoid false positives from control flow keywords\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions to extract testable functions from workspace code files using LLM analysis\",\n    \"Receives structured test plan data with function metadata (name, file, lines, complexity, parameters, return type)\",\n    \"Uses LLM service to intelligently identify actual functions versus control flow statements\",\n    \"Accesses legacy regex-based function extraction as fallback (deprecated)\",\n    \"Gets functions converted to test plan format ready for prioritization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and analyzes testable functions from workspace code files using LLM instead of regex to avoid capturing control flow keywords\",\n      \"inputs\": \"workspaceRoot (string), codeFiles (string array), llmService (LLM service instance)\",\n      \"outputs\": \"Array of function metadata objects in test plan format\"\n    },\n    {\n      \"name\": \"analyzeFunctionsLegacy\",\n      \"desc\": \"Deprecated regex-based function extraction that incorrectly captured control flow keywords like for, if, switch\",\n      \"inputs\": \"codeAnalysis (code analysis object)\",\n      \"outputs\": \"Array of function metadata objects\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"testPlanTypes\",\n    \"testPrompts\",\n    \"CodeAnalysis\",\n    \"SWLogger\",\n    \"LLMFunctionExtractionService\"\n  ],\n  \"intent\": \"This file solves the problem of accurately identifying which functions in a codebase should be tested by using LLM analysis to distinguish real functions from control flow statements (for, if, switch), replacing unreliable regex-based extraction that created false positives. It enables intelligent test planning by providing structured function metadata that can be prioritized for test generation.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Detects test environment configuration and generates automated test setup plans using LLM analysis.",
      "userVisibleActions": [
        "Automatically detects the programming language and testing framework in the workspace",
        "Identifies existing test infrastructure (package.json, jest config, test directories)",
        "Generates a test setup plan with configuration recommendations",
        "Creates missing test directories and configuration files",
        "Installs required testing dependencies automatically",
        "Provides feedback on setup progress and results"
      ],
      "developerVisibleActions": [
        "Scans workspace to identify TypeScript, JavaScript, Python, Java, or C++ projects",
        "Detects testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)",
        "Analyzes package.json and configuration files to understand existing setup",
        "Generates LLM prompts to create customized test configurations",
        "Executes setup commands (npm install, directory creation, file generation)",
        "Returns structured setup results with success/failure status"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Analyzes workspace to identify programming language, testing framework, and existing configuration",
          "inputs": "workspaceRoot (string path)",
          "outputs": "TestEnvironment object with language, framework, and configuration details"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively scans directory to collect all files for language detection",
          "inputs": "dirPath (string), fileList (optional array)",
          "outputs": "Array of file paths"
        },
        {
          "name": "generateSetupPlan",
          "desc": "Creates an LLM-based test setup plan based on detected environment",
          "inputs": "environment (TestEnvironment), llmService",
          "outputs": "TestSetupPlan with configuration steps and recommendations"
        },
        {
          "name": "executeSetupPlan",
          "desc": "Runs the generated setup plan by creating files and installing dependencies",
          "inputs": "plan (TestSetupPlan), workspaceRoot (string)",
          "outputs": "SetupExecutionResult with success status and messages"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "testSetupTypes",
        "testPrompts",
        "SWLogger"
      ],
      "intent": "This service exists to eliminate manual test environment setup by automatically detecting the project type and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, create test directories, and install dependencies by using LLM intelligence to understand the project structure and generate appropriate setup steps.",
      "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates automated test setup plans using LLM analysis.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the programming language and testing framework in the workspace\",\n    \"Identifies existing test infrastructure (package.json, jest config, test directories)\",\n    \"Generates a test setup plan with configuration recommendations\",\n    \"Creates missing test directories and configuration files\",\n    \"Installs required testing dependencies automatically\",\n    \"Provides feedback on setup progress and results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace to identify TypeScript, JavaScript, Python, Java, or C++ projects\",\n    \"Detects testing frameworks (Jest, Mocha, pytest, JUnit, Google Test)\",\n    \"Analyzes package.json and configuration files to understand existing setup\",\n    \"Generates LLM prompts to create customized test configurations\",\n    \"Executes setup commands (npm install, directory creation, file generation)\",\n    \"Returns structured setup results with success/failure status\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to identify programming language, testing framework, and existing configuration\",\n      \"inputs\": \"workspaceRoot (string path)\",\n      \"outputs\": \"TestEnvironment object with language, framework, and configuration details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans directory to collect all files for language detection\",\n      \"inputs\": \"dirPath (string), fileList (optional array)\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"generateSetupPlan\",\n      \"desc\": \"Creates an LLM-based test setup plan based on detected environment\",\n      \"inputs\": \"environment (TestEnvironment), llmService\",\n      \"outputs\": \"TestSetupPlan with configuration steps and recommendations\"\n    },\n    {\n      \"name\": \"executeSetupPlan\",\n      \"desc\": \"Runs the generated setup plan by creating files and installing dependencies\",\n      \"inputs\": \"plan (TestSetupPlan), workspaceRoot (string)\",\n      \"outputs\": \"SetupExecutionResult with success status and messages\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to eliminate manual test environment setup by automatically detecting the project type and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, create test directories, and install dependencies by using LLM intelligence to understand the project structure and generate appropriate setup steps.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates test files by running them, detecting failures, and automatically fixing broken tests using LLM assistance",
      "userVisibleActions": [
        "Tests are automatically executed and results are reported (passed/failed counts)",
        "Failing tests are identified and reported with error details",
        "Tests are automatically fixed when failures are detected",
        "Progress updates show which attempt is being made to fix a test (e.g., 'attempt 2/3')",
        "Final success or failure status is reported after fix attempts"
      ],
      "developerVisibleActions": [
        "Developer triggers test validation for a workspace or specific test file",
        "System runs Jest tests and captures execution results",
        "System reads failing test code and generates LLM prompts to fix issues",
        "System applies LLM-suggested fixes by updating test files",
        "System re-runs tests to verify fixes worked",
        "Developer receives structured test reports with pass/fail statistics",
        "System logs all validation and fix attempts for debugging"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or a specific test file and returns results with pass/fail statistics",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Array of TestExecutionResult objects with passed/failed/error counts"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to automatically fix a failing test by using LLM to analyze errors and suggest corrections",
          "inputs": "testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)",
          "outputs": "Object with success status, number of attempts made, and optional final error message"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "TestExecutionResult",
        "TestReport",
        "TestReportSummary",
        "buildFixPrompt",
        "SWLogger"
      ],
      "intent": "This file exists to automate the test validation workflow by running tests, detecting failures, and using AI to automatically fix broken tests instead of requiring manual developer intervention. It solves the problem of time-consuming manual test debugging and repair by leveraging LLM capabilities to understand test failures and generate fixes.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates test files by running them, detecting failures, and automatically fixing broken tests using LLM assistance\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed and results are reported (passed/failed counts)\",\n    \"Failing tests are identified and reported with error details\",\n    \"Tests are automatically fixed when failures are detected\",\n    \"Progress updates show which attempt is being made to fix a test (e.g., 'attempt 2/3')\",\n    \"Final success or failure status is reported after fix attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test validation for a workspace or specific test file\",\n    \"System runs Jest tests and captures execution results\",\n    \"System reads failing test code and generates LLM prompts to fix issues\",\n    \"System applies LLM-suggested fixes by updating test files\",\n    \"System re-runs tests to verify fixes worked\",\n    \"Developer receives structured test reports with pass/fail statistics\",\n    \"System logs all validation and fix attempts for debugging\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns results with pass/fail statistics\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Array of TestExecutionResult objects with passed/failed/error counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test by using LLM to analyze errors and suggest corrections\",\n      \"inputs\": \"testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)\",\n      \"outputs\": \"Object with success status, number of attempts made, and optional final error message\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult\",\n    \"TestReport\",\n    \"TestReportSummary\",\n    \"buildFixPrompt\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation workflow by running tests, detecting failures, and using AI to automatically fix broken tests instead of requiring manual developer intervention. It solves the problem of time-consuming manual test debugging and repair by leveraging LLM capabilities to understand test failures and generate fixes.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes Jest tests and captures their results, providing detailed test execution information including passes, failures, and errors.",
      "userVisibleActions": [
        "Run all tests in the workspace",
        "Run tests for a specific test file",
        "View test execution results with pass/fail counts",
        "See detailed error messages and stack traces when tests fail",
        "Get notified when test execution times out or fails to run",
        "View test execution duration"
      ],
      "developerVisibleActions": [
        "Execute Jest tests programmatically via Node.js child process",
        "Parse Jest JSON output to extract test results",
        "Handle test execution errors and timeouts gracefully",
        "Capture both stdout and stderr from test execution",
        "Convert raw Jest output into structured TestExecutionResult objects",
        "Process individual test suite results with detailed pass/fail/error breakdowns",
        "Extract error details including test names, messages, and stack traces"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Executes Jest tests for a specific file or all tests in the workspace",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> containing test results with status, counts, and error details"
        },
        {
          "name": "parseJestOutput",
          "desc": "Parses Jest JSON output from stdout/stderr into structured test result objects",
          "inputs": "stdout (string), stderr (string)",
          "outputs": "TestExecutionResult[] array with parsed test data"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "This file exists to provide a reliable interface for running Jest tests within a VS Code extension or development environment, handling the complexity of executing external test commands, parsing their output, and converting it into a structured format that can be displayed to users or processed by other services. It solves the problem of bridging between Jest's command-line interface and the application's need for structured test execution data.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes Jest tests and captures their results, providing detailed test execution information including passes, failures, and errors.\",\n  \"userVisibleActions\": [\n    \"Run all tests in the workspace\",\n    \"Run tests for a specific test file\",\n    \"View test execution results with pass/fail counts\",\n    \"See detailed error messages and stack traces when tests fail\",\n    \"Get notified when test execution times out or fails to run\",\n    \"View test execution duration\"\n  ],\n  \"developerVisibleActions\": [\n    \"Execute Jest tests programmatically via Node.js child process\",\n    \"Parse Jest JSON output to extract test results\",\n    \"Handle test execution errors and timeouts gracefully\",\n    \"Capture both stdout and stderr from test execution\",\n    \"Convert raw Jest output into structured TestExecutionResult objects\",\n    \"Process individual test suite results with detailed pass/fail/error breakdowns\",\n    \"Extract error details including test names, messages, and stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests for a specific file or all tests in the workspace\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test results with status, counts, and error details\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output from stdout/stderr into structured test result objects\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] array with parsed test data\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This file exists to provide a reliable interface for running Jest tests within a VS Code extension or development environment, handling the complexity of executing external test commands, parsing their output, and converting it into a structured format that can be displayed to users or processed by other services. It solves the problem of bridging between Jest's command-line interface and the application's need for structured test execution data.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces for structuring test plans, tracking test generation progress, and organizing testable functions with their metadata.",
      "userVisibleActions": [
        "Views test plan showing total and testable function counts",
        "Sees functions organized into priority groups",
        "Tracks test generation progress through phases (setup, planning, generation, validation, complete)",
        "Monitors number of functions generated and validated",
        "Reviews test failures with error messages and retry attempts"
      ],
      "developerVisibleActions": [
        "Accesses structured test plan data with strategy and function groupings",
        "Uses TestPlan interface to organize functions by priority groups",
        "Tracks test generation workflow through TestGenerationState phases",
        "Retrieves function metadata including complexity, dependencies, and mocking requirements",
        "Monitors current batch of functions being processed",
        "Accesses failure records with function names, errors, and attempt counts"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides type safety and structured data contracts for the test planning and generation service, ensuring consistent representation of test plans, function metadata, generation progress tracking, and failure handling across the testing domain.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for structuring test plans, tracking test generation progress, and organizing testable functions with their metadata.\",\n  \"userVisibleActions\": [\n    \"Views test plan showing total and testable function counts\",\n    \"Sees functions organized into priority groups\",\n    \"Tracks test generation progress through phases (setup, planning, generation, validation, complete)\",\n    \"Monitors number of functions generated and validated\",\n    \"Reviews test failures with error messages and retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Accesses structured test plan data with strategy and function groupings\",\n    \"Uses TestPlan interface to organize functions by priority groups\",\n    \"Tracks test generation workflow through TestGenerationState phases\",\n    \"Retrieves function metadata including complexity, dependencies, and mocking requirements\",\n    \"Monitors current batch of functions being processed\",\n    \"Accesses failure records with function names, errors, and attempt counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structured data contracts for the test planning and generation service, ensuring consistent representation of test plans, function metadata, generation progress tracking, and failure handling across the testing domain.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type structures for test generation, validation, execution results, and reporting in a testing framework",
      "userVisibleActions": [
        "View test execution status (pass, fail, or error) for each test file",
        "See number of tests passed, failed, and encountered errors",
        "Review test execution duration and overall test statistics",
        "Access detailed error messages and stack traces for failing tests",
        "View test report summary with pass rates and file statistics",
        "Read recommendations for improving test quality"
      ],
      "developerVisibleActions": [
        "Import type definitions to structure test generation results with file paths, imports, mocks, and test code",
        "Use MockStatement type to document mock statements with explanations",
        "Access TestValidationResult to get validation status and fixed code suggestions",
        "Retrieve TestExecutionResult for detailed test run metrics and error information",
        "Generate TestReport with summary statistics and execution results",
        "Include setup and teardown code in test generation output",
        "Track remaining issues after validation attempts"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a standardized type system for the entire test generation and validation workflow, ensuring consistent data structures across test creation, execution, validation, and reporting phases, enabling type-safe communication between testing components",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type structures for test generation, validation, execution results, and reporting in a testing framework\",\n  \"userVisibleActions\": [\n    \"View test execution status (pass, fail, or error) for each test file\",\n    \"See number of tests passed, failed, and encountered errors\",\n    \"Review test execution duration and overall test statistics\",\n    \"Access detailed error messages and stack traces for failing tests\",\n    \"View test report summary with pass rates and file statistics\",\n    \"Read recommendations for improving test quality\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import type definitions to structure test generation results with file paths, imports, mocks, and test code\",\n    \"Use MockStatement type to document mock statements with explanations\",\n    \"Access TestValidationResult to get validation status and fixed code suggestions\",\n    \"Retrieve TestExecutionResult for detailed test run metrics and error information\",\n    \"Generate TestReport with summary statistics and execution results\",\n    \"Include setup and teardown code in test generation output\",\n    \"Track remaining issues after validation attempts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for the entire test generation and validation workflow, ensuring consistent data structures across test creation, execution, validation, and reporting phases, enabling type-safe communication between testing components\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test setup and execution functionality, including test plans, dependencies, configuration files, and environment detection.",
      "userVisibleActions": [
        "User receives structured information about test setup plans including framework and dependencies",
        "User sees results of test setup execution with created files and installed dependencies",
        "User receives feedback on test environment status including missing dependencies",
        "User gets notified about mock requirements needed for testing"
      ],
      "developerVisibleActions": [
        "Developer uses TestSetupPlan interface to structure test configuration data including framework, dependencies, and mock requirements",
        "Developer uses TestEnvironment interface to detect existing test infrastructure and identify gaps",
        "Developer uses SetupExecutionResult interface to report success/failure of test setup operations",
        "Developer specifies configuration files with paths and content through ConfigFile interface",
        "Developer tracks which dependencies are dev dependencies through Dependency interface"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to provide type safety and structure for the test setup service, ensuring consistent data shapes when planning, executing, and reporting on automated test environment configuration. It solves the problem of maintaining contract definitions between components that analyze project structure, generate test configurations, and execute setup operations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup and execution functionality, including test plans, dependencies, configuration files, and environment detection.\",\n  \"userVisibleActions\": [\n    \"User receives structured information about test setup plans including framework and dependencies\",\n    \"User sees results of test setup execution with created files and installed dependencies\",\n    \"User receives feedback on test environment status including missing dependencies\",\n    \"User gets notified about mock requirements needed for testing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan interface to structure test configuration data including framework, dependencies, and mock requirements\",\n    \"Developer uses TestEnvironment interface to detect existing test infrastructure and identify gaps\",\n    \"Developer uses SetupExecutionResult interface to report success/failure of test setup operations\",\n    \"Developer specifies configuration files with paths and content through ConfigFile interface\",\n    \"Developer tracks which dependencies are dev dependencies through Dependency interface\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide type safety and structure for the test setup service, ensuring consistent data shapes when planning, executing, and reporting on automated test environment configuration. It solves the problem of maintaining contract definitions between components that analyze project structure, generate test configurations, and execute setup operations.\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "This is the main extension entry point that initializes and orchestrates all VSCode extension components, registers commands, and manages the extension lifecycle.",
      "userVisibleActions": [
        "Analyze code files to generate insights about architecture and dependencies",
        "View code insights in a tree view panel showing project structure",
        "Copy formatted code context to clipboard for LLM interactions",
        "Navigate to specific code locations from insights",
        "See status updates in the status bar during analysis",
        "Refresh analysis results manually",
        "Clear cached analysis data",
        "View diagnostics and warnings in the problems panel",
        "Navigate through product documentation structure",
        "Access analysis results through webview panels"
      ],
      "developerVisibleActions": [
        "Extension activates when VSCode starts or workspace is opened",
        "File watcher monitors code changes and triggers automatic re-analysis",
        "Configuration changes reload extension settings",
        "Analysis results are cached to improve performance",
        "Commands are registered and available in command palette",
        "Status bar shows current analysis state and errors",
        "Tree view updates automatically when code changes",
        "Diagnostics are published when issues are detected",
        "LLM integration formats code for external AI tools",
        "Error handling captures and displays extension failures"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Initializes the extension, bootstraps all components, registers commands, and sets up event handlers",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "void"
        },
        {
          "name": "deactivate",
          "desc": "Cleans up resources when the extension is deactivated",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Triggers full workspace analysis and updates all views with results",
          "inputs": "none (uses workspace context)",
          "outputs": "Promise<void>"
        },
        {
          "name": "handleCopyToClipboard",
          "desc": "Formats and copies selected code insights to clipboard for LLM use",
          "inputs": "treeItem: TreeItem",
          "outputs": "Promise<void>"
        },
        {
          "name": "handleNavigateToCode",
          "desc": "Opens the editor and navigates to the code location associated with an insight",
          "inputs": "treeItem: TreeItem",
          "outputs": "Promise<void>"
        },
        {
          "name": "handleRefresh",
          "desc": "Manually triggers re-analysis of the workspace and refreshes all views",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "handleClearCache",
          "desc": "Clears the analysis cache and triggers a fresh analysis",
          "inputs": "none",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler",
        "./productNavigator"
      ],
      "intent": "This file exists to serve as the central coordination point for the entire VSCode extension. It solves the problem of managing complex extension initialization, component dependencies, command registration, and lifecycle management. It ensures all extension features are properly initialized, connected, and accessible to users through VSCode's command palette, tree views, and other UI elements.",
      "rawContent": "```json\n{\n  \"purpose\": \"This is the main extension entry point that initializes and orchestrates all VSCode extension components, registers commands, and manages the extension lifecycle.\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights about architecture and dependencies\",\n    \"View code insights in a tree view panel showing project structure\",\n    \"Copy formatted code context to clipboard for LLM interactions\",\n    \"Navigate to specific code locations from insights\",\n    \"See status updates in the status bar during analysis\",\n    \"Refresh analysis results manually\",\n    \"Clear cached analysis data\",\n    \"View diagnostics and warnings in the problems panel\",\n    \"Navigate through product documentation structure\",\n    \"Access analysis results through webview panels\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or workspace is opened\",\n    \"File watcher monitors code changes and triggers automatic re-analysis\",\n    \"Configuration changes reload extension settings\",\n    \"Analysis results are cached to improve performance\",\n    \"Commands are registered and available in command palette\",\n    \"Status bar shows current analysis state and errors\",\n    \"Tree view updates automatically when code changes\",\n    \"Diagnostics are published when issues are detected\",\n    \"LLM integration formats code for external AI tools\",\n    \"Error handling captures and displays extension failures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, bootstraps all components, registers commands, and sets up event handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when the extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers full workspace analysis and updates all views with results\",\n      \"inputs\": \"none (uses workspace context)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleCopyToClipboard\",\n      \"desc\": \"Formats and copies selected code insights to clipboard for LLM use\",\n      \"inputs\": \"treeItem: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleNavigateToCode\",\n      \"desc\": \"Opens the editor and navigates to the code location associated with an insight\",\n      \"inputs\": \"treeItem: TreeItem\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleRefresh\",\n      \"desc\": \"Manually triggers re-analysis of the workspace and refreshes all views\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"handleClearCache\",\n      \"desc\": \"Clears the analysis cache and triggers a fresh analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file exists to serve as the central coordination point for the entire VSCode extension. It solves the problem of managing complex extension initialization, component dependencies, command registration, and lifecycle management. It ensures all extension features are properly initialized, connected, and accessible to users through VSCode's command palette, tree views, and other UI elements.\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and code search (grep) functionality to enable iterative analysis of codebases by LLM agents",
      "userVisibleActions": [
        "View file contents from the workspace when requested by the LLM",
        "See search results when the LLM queries for code patterns across files",
        "Receive organized file listings grouped by folders with line counts",
        "Get context around matched lines (before/after lines) in search results"
      ],
      "developerVisibleActions": [
        "Request specific files by path to analyze their contents",
        "Search for code patterns using grep with optional file type filters",
        "Limit search results to prevent overwhelming responses",
        "Receive structured data about files (path, content, line count, existence status)",
        "Get matches with line numbers and surrounding context for better understanding",
        "Process requests through a unified LLMRequest interface supporting both file and grep operations"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Organizes files into a hierarchical folder structure with metadata",
          "inputs": "Array of file objects with path, lines, and language",
          "outputs": "Formatted string showing files grouped by folders with sorting"
        },
        {
          "name": "readFile",
          "desc": "Reads and returns the contents of a specific file",
          "inputs": "FileRequest with file path and optional reason",
          "outputs": "FileResponse with content, line count, and existence status"
        },
        {
          "name": "grepFiles",
          "desc": "Searches for patterns across files with optional filtering and result limiting",
          "inputs": "GrepRequest with pattern, optional file pattern filter, max results, and reason",
          "outputs": "GrepResponse with matches including file paths, line numbers, content, and context"
        },
        {
          "name": "processRequest",
          "desc": "Routes requests to appropriate handler based on request type",
          "inputs": "LLMRequest (either FileRequest or GrepRequest)",
          "outputs": "FileResponse or GrepResponse depending on request type"
        },
        {
          "name": "formatResponse",
          "desc": "Converts response objects into human-readable formatted strings",
          "inputs": "FileResponse or GrepResponse",
          "outputs": "Formatted string presentation of the response"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to bridge the gap between LLM agents and file system access, allowing AI to iteratively explore and analyze code by requesting specific files or searching for patterns. It solves the problem of providing structured, controlled access to workspace files for LLM-driven code analysis without exposing the entire codebase at once.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and code search (grep) functionality to enable iterative analysis of codebases by LLM agents\",\n  \"userVisibleActions\": [\n    \"View file contents from the workspace when requested by the LLM\",\n    \"See search results when the LLM queries for code patterns across files\",\n    \"Receive organized file listings grouped by folders with line counts\",\n    \"Get context around matched lines (before/after lines) in search results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path to analyze their contents\",\n    \"Search for code patterns using grep with optional file type filters\",\n    \"Limit search results to prevent overwhelming responses\",\n    \"Receive structured data about files (path, content, line count, existence status)\",\n    \"Get matches with line numbers and surrounding context for better understanding\",\n    \"Process requests through a unified LLMRequest interface supporting both file and grep operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes files into a hierarchical folder structure with metadata\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files grouped by folders with sorting\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads and returns the contents of a specific file\",\n      \"inputs\": \"FileRequest with file path and optional reason\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches for patterns across files with optional filtering and result limiting\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern filter, max results, and reason\",\n      \"outputs\": \"GrepResponse with matches including file paths, line numbers, content, and context\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Routes requests to appropriate handler based on request type\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"formatResponse\",\n      \"desc\": \"Converts response objects into human-readable formatted strings\",\n      \"inputs\": \"FileResponse or GrepResponse\",\n      \"outputs\": \"Formatted string presentation of the response\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM agents and file system access, allowing AI to iteratively explore and analyze code by requesting specific files or searching for patterns. It solves the problem of providing structured, controlled access to workspace files for LLM-driven code analysis without exposing the entire codebase at once.\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces and types for organizing code documentation at file, module, and product levels",
      "userVisibleActions": [
        "No direct user-visible actions - this is a type definition file",
        "Indirectly enables structured documentation that users can browse"
      ],
      "developerVisibleActions": [
        "Import and use FileSummary interface to structure individual file documentation",
        "Import and use ModuleSummary interface to group related files into modules",
        "Import and use EnhancedProductDocumentation interface to create product-level documentation",
        "Use defined types to ensure consistent documentation structure across the codebase",
        "Reference role types (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface) when categorizing files"
      ],
      "keyFunctions": [
        {
          "name": "FileSummary",
          "desc": "Interface defining how individual file documentation should be structured",
          "inputs": "file path, role, purpose, actions, functions, dependencies, intent",
          "outputs": "Type constraint for file-level documentation objects"
        },
        {
          "name": "ModuleSummary",
          "desc": "Interface defining how module-level documentation should be structured",
          "inputs": "module path, type, capabilities, summary, files, endpoints, commands, workers",
          "outputs": "Type constraint for module-level documentation objects"
        },
        {
          "name": "EnhancedProductDocumentation",
          "desc": "Interface defining how product-level documentation should be structured",
          "inputs": "overview, user perspectives, workflows, architecture, diagrams, structured data",
          "outputs": "Type constraint for product-level documentation objects"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "This file exists to establish a consistent, hierarchical documentation structure for the entire codebase. It solves the problem of organizing code documentation at multiple levels (file, module, product) with clear separation between user-facing and developer-facing information. It enables automated documentation generation tools to produce standardized output.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and types for organizing code documentation at file, module, and product levels\",\n  \"userVisibleActions\": [\n    \"No direct user-visible actions - this is a type definition file\",\n    \"Indirectly enables structured documentation that users can browse\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use FileSummary interface to structure individual file documentation\",\n    \"Import and use ModuleSummary interface to group related files into modules\",\n    \"Import and use EnhancedProductDocumentation interface to create product-level documentation\",\n    \"Use defined types to ensure consistent documentation structure across the codebase\",\n    \"Reference role types (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface) when categorizing files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"FileSummary\",\n      \"desc\": \"Interface defining how individual file documentation should be structured\",\n      \"inputs\": \"file path, role, purpose, actions, functions, dependencies, intent\",\n      \"outputs\": \"Type constraint for file-level documentation objects\"\n    },\n    {\n      \"name\": \"ModuleSummary\",\n      \"desc\": \"Interface defining how module-level documentation should be structured\",\n      \"inputs\": \"module path, type, capabilities, summary, files, endpoints, commands, workers\",\n      \"outputs\": \"Type constraint for module-level documentation objects\"\n    },\n    {\n      \"name\": \"EnhancedProductDocumentation\",\n      \"desc\": \"Interface defining how product-level documentation should be structured\",\n      \"inputs\": \"overview, user perspectives, workflows, architecture, diagrams, structured data\",\n      \"outputs\": \"Type constraint for product-level documentation objects\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to establish a consistent, hierarchical documentation structure for the entire codebase. It solves the problem of organizing code documentation at multiple levels (file, module, product) with clear separation between user-facing and developer-facing information. It enables automated documentation generation tools to produce standardized output.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file saves and triggers automatic code analysis when files are saved in the workspace",
      "userVisibleActions": [
        "Code is automatically analyzed when a file is saved (if 'analyze on save' is enabled)",
        "Analysis results appear in the diagnostics panel after saving a file",
        "Insights tree view updates automatically after file changes",
        "Analysis is debounced to avoid running too frequently on rapid saves"
      ],
      "developerVisibleActions": [
        "FileWatcher can be started and stopped to control automatic analysis",
        "Analysis is triggered by document save events",
        "Multiple rapid saves are debounced into a single analysis after a delay",
        "Analysis respects configuration settings (analyzeOnSave, debounceDelay)",
        "Analysis can be manually triggered on demand for specific files",
        "Service tracks analysis state to prevent concurrent analyses",
        "Errors during file watching are logged and handled gracefully"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins monitoring file saves and enables automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops monitoring file saves and disables automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "triggerAnalysis",
          "desc": "Manually initiates code analysis for a specific file",
          "inputs": "filePath (string)",
          "outputs": "Promise<void>"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save events and schedules debounced analysis",
          "inputs": "document (vscode.TextDocument)",
          "outputs": "void"
        },
        {
          "name": "scheduleAnalysis",
          "desc": "Debounces analysis requests to avoid running too frequently",
          "inputs": "filePath (string)",
          "outputs": "void"
        },
        {
          "name": "runAnalysis",
          "desc": "Executes the full analysis pipeline and updates diagnostics",
          "inputs": "filePath (string)",
          "outputs": "Promise<void>"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources and stops the file watcher",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "ConfigurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic code analysis triggered by file saves, eliminating the need for users to manually request analysis. It solves the problem of keeping code insights and diagnostics up-to-date as developers work, while preventing performance issues through debouncing and state tracking.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file saves and triggers automatic code analysis when files are saved in the workspace\",\n  \"userVisibleActions\": [\n    \"Code is automatically analyzed when a file is saved (if 'analyze on save' is enabled)\",\n    \"Analysis results appear in the diagnostics panel after saving a file\",\n    \"Insights tree view updates automatically after file changes\",\n    \"Analysis is debounced to avoid running too frequently on rapid saves\"\n  ],\n  \"developerVisibleActions\": [\n    \"FileWatcher can be started and stopped to control automatic analysis\",\n    \"Analysis is triggered by document save events\",\n    \"Multiple rapid saves are debounced into a single analysis after a delay\",\n    \"Analysis respects configuration settings (analyzeOnSave, debounceDelay)\",\n    \"Analysis can be manually triggered on demand for specific files\",\n    \"Service tracks analysis state to prevent concurrent analyses\",\n    \"Errors during file watching are logged and handled gracefully\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins monitoring file saves and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops monitoring file saves and disables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Manually initiates code analysis for a specific file\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and schedules debounced analysis\",\n      \"inputs\": \"document (vscode.TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"scheduleAnalysis\",\n      \"desc\": \"Debounces analysis requests to avoid running too frequently\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"runAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline and updates diagnostics\",\n      \"inputs\": \"filePath (string)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources and stops the file watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic code analysis triggered by file saves, eliminating the need for users to manually request analysis. It solves the problem of keeping code insights and diagnostics up-to-date as developers work, while preventing performance issues through debouncing and state tracking.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Optimizes file system operations by caching file contents to reduce redundant file reads and improve performance across the extension",
      "userVisibleActions": [
        "Faster file operations when accessing the same files multiple times",
        "Improved responsiveness when extension reads project files",
        "Automatic updates when files are modified externally"
      ],
      "developerVisibleActions": [
        "Retrieve cached file contents instead of reading from disk repeatedly",
        "Automatic cache invalidation when files change on disk",
        "Access cache statistics to monitor performance (hits, misses, evictions)",
        "Configure cache size limits and time-to-live settings",
        "Clear cache manually or invalidate specific files",
        "Monitor memory usage through cache size tracking"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "invalidate",
          "desc": "Removes a specific file from the cache, forcing next access to read from disk",
          "inputs": "filePath: string",
          "outputs": "void"
        },
        {
          "name": "clear",
          "desc": "Empties the entire cache and resets statistics",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getStats",
          "desc": "Returns cache performance metrics including hits, misses, evictions, and size",
          "inputs": "none",
          "outputs": "CacheStats object"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources including file system watcher and cache contents",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "This file exists to improve extension performance by preventing repeated disk reads of the same files. It solves the problem of slow file system operations causing UI lag by caching frequently accessed files, automatically invalidating the cache when files change, and using an LRU eviction policy to manage memory efficiently.",
      "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant file reads and improve performance across the extension\",\n  \"userVisibleActions\": [\n    \"Faster file operations when accessing the same files multiple times\",\n    \"Improved responsiveness when extension reads project files\",\n    \"Automatic updates when files are modified externally\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve cached file contents instead of reading from disk repeatedly\",\n    \"Automatic cache invalidation when files change on disk\",\n    \"Access cache statistics to monitor performance (hits, misses, evictions)\",\n    \"Configure cache size limits and time-to-live settings\",\n    \"Clear cache manually or invalidate specific files\",\n    \"Monitor memory usage through cache size tracking\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing next access to read from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Empties the entire cache and resets statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, evictions, and size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources including file system watcher and cache contents\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by preventing repeated disk reads of the same files. It solves the problem of slow file system operations causing UI lag by caching frequently accessed files, automatically invalidating the cache when files change, and using an LRU eviction policy to manage memory efficiently.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Provides a reusable file processing system that filters, reads, and processes multiple files in parallel with consistent error handling.",
      "userVisibleActions": [
        "Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing",
        "Multiple files are processed simultaneously for faster performance"
      ],
      "developerVisibleActions": [
        "Developer provides a list of file paths and a processing function to batch process files",
        "Developer can customize which files to process by providing a custom filter implementation",
        "Developer can customize how files are read by providing a custom reader implementation",
        "Files are automatically filtered to skip non-source directories before processing",
        "File content is read and passed to the developer's processing function",
        "All file processing errors are caught and handled through the ErrorHandler system",
        "Processing results are returned as an array in the same order as input files"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines whether a file should be processed based on its path",
          "inputs": "filePath: string",
          "outputs": "boolean indicating if file should be processed"
        },
        {
          "name": "readFile",
          "desc": "Reads a file and returns its content as a string",
          "inputs": "filePath: string",
          "outputs": "Promise<string> with file content"
        },
        {
          "name": "processFiles",
          "desc": "Processes multiple files in parallel by filtering, reading, and applying a custom processor function",
          "inputs": "files: string[], processor: (content: string, filePath: string) => Promise<T>, context?: ErrorContext",
          "outputs": "Promise<T[]> with processed results for each file"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "ErrorHandler",
        "ErrorContext"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns across the codebase by providing a single, reusable, and testable file processing system. It solves the problem of inconsistent file filtering, error handling, and parallel processing logic that would otherwise be scattered throughout the application.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a reusable file processing system that filters, reads, and processes multiple files in parallel with consistent error handling.\",\n  \"userVisibleActions\": [\n    \"Files in common directories like node_modules, .git, dist, build, .shadow, coverage, .vscode, and .idea are automatically skipped during processing\",\n    \"Multiple files are processed simultaneously for faster performance\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides a list of file paths and a processing function to batch process files\",\n    \"Developer can customize which files to process by providing a custom filter implementation\",\n    \"Developer can customize how files are read by providing a custom reader implementation\",\n    \"Files are automatically filtered to skip non-source directories before processing\",\n    \"File content is read and passed to the developer's processing function\",\n    \"All file processing errors are caught and handled through the ErrorHandler system\",\n    \"Processing results are returned as an array in the same order as input files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines whether a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file and returns its content as a string\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> with file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel by filtering, reading, and applying a custom processor function\",\n      \"inputs\": \"files: string[], processor: (content: string, filePath: string) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> with processed results for each file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"ErrorHandler\",\n    \"ErrorContext\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase by providing a single, reusable, and testable file processing system. It solves the problem of inconsistent file filtering, error handling, and parallel processing logic that would otherwise be scattered throughout the application.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages saving and retrieving analysis results like product documentation, architecture insights, and summaries to disk with timestamped storage.",
      "userVisibleActions": [
        "Analysis results are automatically saved to .shadow/docs folder with timestamps",
        "Product documentation is generated and stored in organized run folders",
        "Architecture insights are saved with timestamps for historical tracking",
        "Summary documents are created in the .shadow/summary directory",
        "Each analysis run creates a new timestamped folder to preserve history"
      ],
      "developerVisibleActions": [
        "Initialize product documentation runs to create storage directories",
        "Initialize architecture insights runs to create separate storage locations",
        "Save individual product documentation for specific files",
        "Save architecture insights for the entire codebase",
        "Save summary documents with aggregated analysis results",
        "Retrieve the most recent product documentation for a file",
        "Retrieve the most recent architecture insights",
        "Access all product documentation from the current run",
        "Get the current run directory path for organizing outputs",
        "Finalize runs to complete the analysis session"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Creates a new timestamped run for storing product documentation",
          "inputs": "workspaceRoot: string",
          "outputs": "runDir path as string"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Creates a new timestamped run for storing architecture insights",
          "inputs": "workspaceRoot: string",
          "outputs": "runDir path as string"
        },
        {
          "name": "saveProductDocumentation",
          "desc": "Saves product documentation for a specific file to the current run folder",
          "inputs": "filePath: string, documentation: EnhancedProductDocumentation, workspaceRoot: string",
          "outputs": "void"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Saves architecture insights to the current run folder",
          "inputs": "insights: LLMInsights, workspaceRoot: string",
          "outputs": "void"
        },
        {
          "name": "saveSummaryDocument",
          "desc": "Saves a summary document combining all documentation and insights",
          "inputs": "summary content and metadata, workspaceRoot: string",
          "outputs": "void"
        },
        {
          "name": "getLatestProductDocumentation",
          "desc": "Retrieves the most recent product documentation for a given file",
          "inputs": "filePath: string, workspaceRoot: string",
          "outputs": "EnhancedProductDocumentation or null"
        },
        {
          "name": "getLatestArchitectureInsights",
          "desc": "Retrieves the most recent architecture insights",
          "inputs": "workspaceRoot: string",
          "outputs": "LLMInsights or null"
        },
        {
          "name": "getAllProductDocsFromCurrentRun",
          "desc": "Gets all product documentation saved in the current run",
          "inputs": "none",
          "outputs": "Map of file paths to documentation"
        },
        {
          "name": "getCurrentRunDir",
          "desc": "Returns the directory path for the current product docs run",
          "inputs": "none",
          "outputs": "runDir path as string or null"
        },
        {
          "name": "finalizeProductDocsRun",
          "desc": "Completes the current product documentation run session",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "finalizeArchitectureInsightsRun",
          "desc": "Completes the current architecture insights run session",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "EnhancedProductDocumentation from fileDocumentation",
        "LLMInsights from llmService",
        "DocumentationFormatter from domain/formatters",
        "createTimestampedStorage from storage/incrementalStorage"
      ],
      "intent": "Separates data persistence logic from business logic by providing a dedicated repository for managing analysis results storage, enabling historical tracking of documentation and insights through timestamped runs, and organizing outputs in a structured directory hierarchy.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages saving and retrieving analysis results like product documentation, architecture insights, and summaries to disk with timestamped storage.\",\n  \"userVisibleActions\": [\n    \"Analysis results are automatically saved to .shadow/docs folder with timestamps\",\n    \"Product documentation is generated and stored in organized run folders\",\n    \"Architecture insights are saved with timestamps for historical tracking\",\n    \"Summary documents are created in the .shadow/summary directory\",\n    \"Each analysis run creates a new timestamped folder to preserve history\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to create storage directories\",\n    \"Initialize architecture insights runs to create separate storage locations\",\n    \"Save individual product documentation for specific files\",\n    \"Save architecture insights for the entire codebase\",\n    \"Save summary documents with aggregated analysis results\",\n    \"Retrieve the most recent product documentation for a file\",\n    \"Retrieve the most recent architecture insights\",\n    \"Access all product documentation from the current run\",\n    \"Get the current run directory path for organizing outputs\",\n    \"Finalize runs to complete the analysis session\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped run for storing product documentation\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"runDir path as string\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped run for storing architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"runDir path as string\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves product documentation for a specific file to the current run folder\",\n      \"inputs\": \"filePath: string, documentation: EnhancedProductDocumentation, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights to the current run folder\",\n      \"inputs\": \"insights: LLMInsights, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummaryDocument\",\n      \"desc\": \"Saves a summary document combining all documentation and insights\",\n      \"inputs\": \"summary content and metadata, workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getLatestProductDocumentation\",\n      \"desc\": \"Retrieves the most recent product documentation for a given file\",\n      \"inputs\": \"filePath: string, workspaceRoot: string\",\n      \"outputs\": \"EnhancedProductDocumentation or null\"\n    },\n    {\n      \"name\": \"getLatestArchitectureInsights\",\n      \"desc\": \"Retrieves the most recent architecture insights\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"LLMInsights or null\"\n    },\n    {\n      \"name\": \"getAllProductDocsFromCurrentRun\",\n      \"desc\": \"Gets all product documentation saved in the current run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Map of file paths to documentation\"\n    },\n    {\n      \"name\": \"getCurrentRunDir\",\n      \"desc\": \"Returns the directory path for the current product docs run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path as string or null\"\n    },\n    {\n      \"name\": \"finalizeProductDocsRun\",\n      \"desc\": \"Completes the current product documentation run session\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeArchitectureInsightsRun\",\n      \"desc\": \"Completes the current architecture insights run session\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"EnhancedProductDocumentation from fileDocumentation\",\n    \"LLMInsights from llmService\",\n    \"DocumentationFormatter from domain/formatters\",\n    \"createTimestampedStorage from storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates data persistence logic from business logic by providing a dedicated repository for managing analysis results storage, enabling historical tracking of documentation and insights through timestamped runs, and organizing outputs in a structured directory hierarchy.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a standardized service for displaying progress notifications and status indicators throughout the extension.",
      "userVisibleActions": [
        "See progress notifications with titles and messages during long-running operations",
        "Cancel ongoing operations using the cancel button in progress notifications",
        "View progress indicators in different locations (notification area, status bar, etc.)"
      ],
      "developerVisibleActions": [
        "Wrap any async operation with progress reporting using a simple API",
        "Report incremental progress updates with custom messages during task execution",
        "Configure progress notifications as cancellable or non-cancellable",
        "Choose where progress indicators appear (notification, window, status bar)",
        "Access cancellation tokens to check if user cancelled the operation",
        "Use either a simple string title or full options object for flexibility"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying a progress notification to the user",
          "inputs": "options (title, cancellable flag, location) and async task function with reporter",
          "outputs": "The result of the executed task"
        },
        {
          "name": "report",
          "desc": "Updates the progress message shown to the user during task execution",
          "inputs": "message string and optional increment percentage",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "Eliminates boilerplate code for progress reporting by wrapping VSCode's progress API with a consistent, reusable service that ensures all long-running operations provide user feedback in a standardized way.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications and status indicators throughout the extension.\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during long-running operations\",\n    \"Cancel ongoing operations using the cancel button in progress notifications\",\n    \"View progress indicators in different locations (notification area, status bar, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any async operation with progress reporting using a simple API\",\n    \"Report incremental progress updates with custom messages during task execution\",\n    \"Configure progress notifications as cancellable or non-cancellable\",\n    \"Choose where progress indicators appear (notification, window, status bar)\",\n    \"Access cancellation tokens to check if user cancelled the operation\",\n    \"Use either a simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function with reporter\",\n      \"outputs\": \"The result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress message shown to the user during task execution\",\n      \"inputs\": \"message string and optional increment percentage\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Eliminates boilerplate code for progress reporting by wrapping VSCode's progress API with a consistent, reusable service that ensures all long-running operations provide user feedback in a standardized way.\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code structure and generates actionable insights about code quality, organization, and potential issues",
      "userVisibleActions": [
        "See warnings about large files exceeding 500 lines",
        "View alerts for orphaned files with no dependencies",
        "Receive notifications about missing entry points in the project",
        "Get warnings about circular dependency patterns",
        "See alerts for 'god objects' (files with too many responsibilities)",
        "View suggestions for dead code that may be unused",
        "Receive recommendations for file organization improvements",
        "Get notified about complex functions that need refactoring"
      ],
      "developerVisibleActions": [
        "Pass CodeAnalysis object to generate insights for entire codebase",
        "Generate file-specific insights by providing file path",
        "Receive structured Insight objects with severity levels (error/warning/info)",
        "Access categorized insights with titles, descriptions, and actionable suggestions",
        "Get code snippets and line numbers for each identified issue",
        "Filter insights by category (Code Organization, Maintainability, etc.)",
        "View unique insight IDs for tracking and deduplication"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Analyzes entire codebase and returns all detected code quality issues and recommendations",
          "inputs": "CodeAnalysis object containing file and function information",
          "outputs": "Array of Insight objects with severity, category, and suggestions"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Analyzes a specific file and returns insights relevant only to that file",
          "inputs": "CodeAnalysis object and file path string",
          "outputs": "Array of Insight objects specific to the requested file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Identifies files exceeding recommended line count thresholds",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for oversized files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Finds files that have no dependencies or relationships with other files",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for isolated files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Validates presence of required entry point files in the project",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Detects potential circular dependency patterns between files",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for circular references"
        },
        {
          "name": "checkGodObjects",
          "desc": "Identifies files with excessive responsibilities or complexity",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for over-complex files"
        },
        {
          "name": "checkDeadCode",
          "desc": "Finds code that may be unused or unreachable",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for potentially dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Evaluates project structure and file placement patterns",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for organizational improvements"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Analyzes individual functions for complexity issues",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of Insight objects for complex functions"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, architectural problems, and opportunities for refactoring. It acts as the intelligence layer that interprets code metrics and patterns to provide meaningful recommendations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code structure and generates actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"See warnings about large files exceeding 500 lines\",\n    \"View alerts for orphaned files with no dependencies\",\n    \"Receive notifications about missing entry points in the project\",\n    \"Get warnings about circular dependency patterns\",\n    \"See alerts for 'god objects' (files with too many responsibilities)\",\n    \"View suggestions for dead code that may be unused\",\n    \"Receive recommendations for file organization improvements\",\n    \"Get notified about complex functions that need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Pass CodeAnalysis object to generate insights for entire codebase\",\n    \"Generate file-specific insights by providing file path\",\n    \"Receive structured Insight objects with severity levels (error/warning/info)\",\n    \"Access categorized insights with titles, descriptions, and actionable suggestions\",\n    \"Get code snippets and line numbers for each identified issue\",\n    \"Filter insights by category (Code Organization, Maintainability, etc.)\",\n    \"View unique insight IDs for tracking and deduplication\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all detected code quality issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with severity, category, and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights relevant only to that file\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to the requested file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Finds files that have no dependencies or relationships with other files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry point files in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular references\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with excessive responsibilities or complexity\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for over-complex files\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Finds code that may be unused or unreachable\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potentially dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file placement patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organizational improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes individual functions for complexity issues\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, architectural problems, and opportunities for refactoring. It acts as the intelligence layer that interprets code metrics and patterns to provide meaningful recommendations.\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VS Code that displays AI-generated insights, documentation, test results, and analysis reports for the codebase",
      "userVisibleActions": [
        "View AI-generated insights about code quality, architecture, and improvements in a tree structure",
        "See status indicators showing when documentation, insights, or tests are being generated",
        "Click on insight items to view detailed explanations and suggestions",
        "Access generated product documentation through the tree view",
        "View unit test generation status and results",
        "Open analysis reports (workspace, product, architecture, unit test) directly from the tree",
        "See timestamps showing when each report or insight was last generated",
        "Refresh the insights view to update displayed information",
        "Navigate to specific code locations by clicking on insights with file references",
        "View collapsed/expanded sections for different types of insights (product docs, insights, analysis)",
        "See progress spinners while AI is generating content",
        "Access quick actions like 'Generate Product Docs', 'Generate Insights', or 'Run Analysis' from tree items"
      ],
      "developerVisibleActions": [
        "Tree view automatically refreshes when new insights are generated",
        "Insights are organized hierarchically by category (documentation, code insights, test results, analysis)",
        "Persisted state maintains report paths and timestamps across VS Code sessions",
        "LLM service integration provides AI-generated insights and documentation",
        "Tree items have contextual commands and icons based on their type and status",
        "Report files are opened in the editor when user clicks on report items",
        "Tree supports collapsible sections with different states (idle, generating, complete)",
        "Status updates trigger automatic tree data refresh events",
        "Integration with static analysis viewer for detailed code analysis"
      ],
      "keyFunctions": [
        {
          "name": "getTreeItem",
          "desc": "Converts an insight or status item into a displayable tree item with icon, label, and command",
          "inputs": "TreeItem element",
          "outputs": "vscode.TreeItem with display properties"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for tree hierarchy - top-level sections or insights within sections",
          "inputs": "Optional parent TreeItem",
          "outputs": "Array of TreeItem children or Promise of children"
        },
        {
          "name": "updateInsights",
          "desc": "Updates the displayed insights and refreshes the tree view",
          "inputs": "Array of Insight objects",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "setProductDocsStatus",
          "desc": "Updates the status of product documentation generation (idle/generating/complete)",
          "inputs": "Status string and optional timestamp",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "setInsightsStatus",
          "desc": "Updates the status of insights generation (idle/generating/complete)",
          "inputs": "Status string and optional timestamp",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "setUnitTestStatus",
          "desc": "Updates the status of unit test generation (idle/generating/complete)",
          "inputs": "Status string and optional timestamp",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "setAnalysisStatus",
          "desc": "Updates the status of code analysis (idle/complete)",
          "inputs": "Status string and optional timestamp",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "setReportPath",
          "desc": "Sets the file path for a generated report and stores it persistently",
          "inputs": "File path string and optional timestamp",
          "outputs": "void - saves to workspace state"
        },
        {
          "name": "setWorkspaceReportPath",
          "desc": "Sets the file path for workspace analysis report",
          "inputs": "File path string and optional timestamp",
          "outputs": "void - saves to workspace state"
        },
        {
          "name": "setProductReportPath",
          "desc": "Sets the file path for product documentation report",
          "inputs": "File path string and optional timestamp",
          "outputs": "void - saves to workspace state"
        },
        {
          "name": "setArchitectureReportPath",
          "desc": "Sets the file path for architecture analysis report",
          "inputs": "File path string and optional timestamp",
          "outputs": "void - saves to workspace state"
        },
        {
          "name": "setUnitTestReportPath",
          "desc": "Sets the file path for unit test report",
          "inputs": "File path string and optional timestamp",
          "outputs": "void - saves to workspace state"
        },
        {
          "name": "refresh",
          "desc": "Manually triggers a refresh of the entire tree view",
          "inputs": "None",
          "outputs": "void - fires tree data change event"
        },
        {
          "name": "setLLMService",
          "desc": "Connects an LLM service instance to enable AI-generated insights",
          "inputs": "LLMService instance",
          "outputs": "void"
        },
        {
          "name": "setLLMInsights",
          "desc": "Updates the AI-generated insights to display in the tree",
          "inputs": "LLMInsights object",
          "outputs": "void - triggers tree refresh"
        },
        {
          "name": "loadPersistedState",
          "desc": "Restores saved report paths and timestamps from previous VS Code sessions",
          "inputs": "None",
          "outputs": "Promise<void> - validates files still exist"
        },
        {
          "name": "openReport",
          "desc": "Opens a generated report file in the VS Code editor",
          "inputs": "File path string",
          "outputs": "Promise<void> - displays document"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator",
        "./llmFormatter",
        "./llmService"
      ],
      "intent": "This file exists to provide users with a visual, organized interface to view AI-generated code insights, documentation, test results, and analysis reports within VS Code's sidebar. It solves the problem of presenting complex AI analysis results in an accessible, navigable tree structure that persists across sessions and updates in real-time as new insights are generated.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays AI-generated insights, documentation, test results, and analysis reports for the codebase\",\n  \"userVisibleActions\": [\n    \"View AI-generated insights about code quality, architecture, and improvements in a tree structure\",\n    \"See status indicators showing when documentation, insights, or tests are being generated\",\n    \"Click on insight items to view detailed explanations and suggestions\",\n    \"Access generated product documentation through the tree view\",\n    \"View unit test generation status and results\",\n    \"Open analysis reports (workspace, product, architecture, unit test) directly from the tree\",\n    \"See timestamps showing when each report or insight was last generated\",\n    \"Refresh the insights view to update displayed information\",\n    \"Navigate to specific code locations by clicking on insights with file references\",\n    \"View collapsed/expanded sections for different types of insights (product docs, insights, analysis)\",\n    \"See progress spinners while AI is generating content\",\n    \"Access quick actions like 'Generate Product Docs', 'Generate Insights', or 'Run Analysis' from tree items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when new insights are generated\",\n    \"Insights are organized hierarchically by category (documentation, code insights, test results, analysis)\",\n    \"Persisted state maintains report paths and timestamps across VS Code sessions\",\n    \"LLM service integration provides AI-generated insights and documentation\",\n    \"Tree items have contextual commands and icons based on their type and status\",\n    \"Report files are opened in the editor when user clicks on report items\",\n    \"Tree supports collapsible sections with different states (idle, generating, complete)\",\n    \"Status updates trigger automatic tree data refresh events\",\n    \"Integration with static analysis viewer for detailed code analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an insight or status item into a displayable tree item with icon, label, and command\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem with display properties\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for tree hierarchy - top-level sections or insights within sections\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of TreeItem children or Promise of children\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the status of insights generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the status of unit test generation (idle/generating/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of code analysis (idle/complete)\",\n      \"inputs\": \"Status string and optional timestamp\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and stores it persistently\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setWorkspaceReportPath\",\n      \"desc\": \"Sets the file path for workspace analysis report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setProductReportPath\",\n      \"desc\": \"Sets the file path for product documentation report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setArchitectureReportPath\",\n      \"desc\": \"Sets the file path for architecture analysis report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"setUnitTestReportPath\",\n      \"desc\": \"Sets the file path for unit test report\",\n      \"inputs\": \"File path string and optional timestamp\",\n      \"outputs\": \"void - saves to workspace state\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Manually triggers a refresh of the entire tree view\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void - fires tree data change event\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Connects an LLM service instance to enable AI-generated insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the AI-generated insights to display in the tree\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void - triggers tree refresh\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved report paths and timestamps from previous VS Code sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void> - validates files still exist\"\n    },\n    {\n      \"name\": \"openReport\",\n      \"desc\": \"Opens a generated report file in the VS Code editor\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"Promise<void> - displays document\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide users with a visual, organized interface to view AI-generated code insights, documentation, test results, and analysis reports within VS Code's sidebar. It solves the problem of presenting complex AI analysis results in an accessible, navigable tree structure that persists across sessions and updates in real-time as new insights are generated.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view interface for browsing and exploring AI-generated architecture insights about the codebase",
      "userVisibleActions": [
        "View AI-generated architecture insights in a tree structure in the sidebar",
        "Browse insights organized by categories (purpose, architecture, behavior, patterns, API, technical debt, security, performance, maintainability, dependencies)",
        "Click on insight items to open related files or documentation",
        "See real-time updates when insights.json or PROJECT_PURPOSE.md files change",
        "Navigate to source code locations from insight items",
        "View empty state prompts when no insights are available",
        "Refresh insights view manually via refresh command"
      ],
      "developerVisibleActions": [
        "Tree view automatically watches .shadow/insights.json for changes and refreshes",
        "Tree view watches .shadow/docs/PROJECT_PURPOSE.md for purpose changes",
        "File changes trigger automatic tree data refresh",
        "Insights data is loaded from .shadow directory structure",
        "Click handlers open files at specific line numbers when available",
        "Tree items show icons, descriptions, and tooltips based on insight types",
        "Empty directories are created automatically (.shadow, .shadow/docs)",
        "TreeItem collapsible states control expansion behavior"
      ],
      "keyFunctions": [
        {
          "name": "setInsights",
          "desc": "Updates the insights data displayed in the tree view and triggers a refresh",
          "inputs": "insights: LLMInsights object containing analysis results",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts an InsightItem into a VS Code TreeItem for display",
          "inputs": "element: InsightItem to convert",
          "outputs": "vscode.TreeItem with label, icon, tooltip, and command"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for the tree view hierarchy",
          "inputs": "element?: InsightItem (undefined for root level)",
          "outputs": "Array of InsightItem objects or empty array"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Configures automatic file watching for insights.json and PROJECT_PURPOSE.md changes",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Manually triggers a refresh of the tree view display",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "openFile",
          "desc": "Opens a file in the editor at a specific line when user clicks an insight item",
          "inputs": "filePath: string, line?: number",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "LLMInsights from ./llmService",
        "path",
        "fs",
        "FileWatcherService from ./domain/services/fileWatcherService"
      ],
      "intent": "This file exists to provide developers with an interactive, hierarchical view of AI-generated codebase insights within VS Code's sidebar. It solves the problem of making complex architecture analysis results easily browsable and navigable, with automatic updates when analysis results change, enabling developers to quickly understand code structure, patterns, and issues without manually reading through analysis files.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for browsing and exploring AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View AI-generated architecture insights in a tree structure in the sidebar\",\n    \"Browse insights organized by categories (purpose, architecture, behavior, patterns, API, technical debt, security, performance, maintainability, dependencies)\",\n    \"Click on insight items to open related files or documentation\",\n    \"See real-time updates when insights.json or PROJECT_PURPOSE.md files change\",\n    \"Navigate to source code locations from insight items\",\n    \"View empty state prompts when no insights are available\",\n    \"Refresh insights view manually via refresh command\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically watches .shadow/insights.json for changes and refreshes\",\n    \"Tree view watches .shadow/docs/PROJECT_PURPOSE.md for purpose changes\",\n    \"File changes trigger automatic tree data refresh\",\n    \"Insights data is loaded from .shadow directory structure\",\n    \"Click handlers open files at specific line numbers when available\",\n    \"Tree items show icons, descriptions, and tooltips based on insight types\",\n    \"Empty directories are created automatically (.shadow, .shadow/docs)\",\n    \"TreeItem collapsible states control expansion behavior\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data displayed in the tree view and triggers a refresh\",\n      \"inputs\": \"insights: LLMInsights object containing analysis results\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem for display\",\n      \"inputs\": \"element: InsightItem to convert\",\n      \"outputs\": \"vscode.TreeItem with label, icon, tooltip, and command\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for the tree view hierarchy\",\n      \"inputs\": \"element?: InsightItem (undefined for root level)\",\n      \"outputs\": \"Array of InsightItem objects or empty array\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Configures automatic file watching for insights.json and PROJECT_PURPOSE.md changes\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Manually triggers a refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"openFile\",\n      \"desc\": \"Opens a file in the editor at a specific line when user clicks an insight item\",\n      \"inputs\": \"filePath: string, line?: number\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"LLMInsights from ./llmService\",\n    \"path\",\n    \"fs\",\n    \"FileWatcherService from ./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with an interactive, hierarchical view of AI-generated codebase insights within VS Code's sidebar. It solves the problem of making complex architecture analysis results easily browsable and navigable, with automatic updates when analysis results change, enabling developers to quickly understand code structure, patterns, and issues without manually reading through analysis files.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different output formats optimized for various LLM interfaces and human readability",
      "userVisibleActions": [
        "Receives formatted architecture issues grouped by severity (errors, warnings, info)",
        "Sees issues organized with visual indicators (🔴 for errors, ⚠️ for warnings, ℹ️ for info)",
        "Gets actionable guidance on how to address detected issues",
        "Receives output optimized for their chosen LLM interface (Cursor, ChatGPT, or generic)",
        "Sees compact summaries when requesting condensed output",
        "Views file paths and line numbers where issues occur",
        "Gets context about what each issue means and why it matters"
      ],
      "developerVisibleActions": [
        "Developer calls formatInsights() to convert raw insights into formatted text",
        "Developer specifies output format: 'cursor', 'chatgpt', 'compact', or 'generic'",
        "Developer receives formatted markdown text ready to display or send to LLM",
        "Developer gets insights grouped and sorted by severity automatically",
        "Developer sees file locations and affected code patterns in the output",
        "Developer receives actionable suggestions and next steps included in the output"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Main entry point that routes insights to the appropriate formatter based on specified format",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "Formatted string ready for display or LLM consumption"
        },
        {
          "name": "formatForCursor",
          "desc": "Formats insights specifically for Cursor IDE with severity grouping, emoji indicators, and actionable guidance",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown-formatted string optimized for Cursor"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Formats insights for ChatGPT with conversational tone and context about being a codebase analysis",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown-formatted string optimized for ChatGPT"
        },
        {
          "name": "formatCompact",
          "desc": "Formats insights in a condensed format with just essential information and counts",
          "inputs": "insights: Insight[]",
          "outputs": "Compact markdown string with summary statistics"
        },
        {
          "name": "formatGeneric",
          "desc": "Formats insights in a generic markdown format suitable for any LLM or documentation",
          "inputs": "insights: Insight[]",
          "outputs": "Generic markdown-formatted string"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats a single insight with location, message, and suggestion details for Cursor",
          "inputs": "insight: Insight",
          "outputs": "Formatted string for one insight"
        },
        {
          "name": "formatInsightForChatGPT",
          "desc": "Formats a single insight with conversational style for ChatGPT",
          "inputs": "insight: Insight",
          "outputs": "Formatted string for one insight"
        },
        {
          "name": "formatInsightGeneric",
          "desc": "Formats a single insight in a neutral, generic style",
          "inputs": "insight: Insight",
          "outputs": "Formatted string for one insight"
        }
      ],
      "dependencies": [
        "./insightGenerator (Insight type)"
      ],
      "intent": "Transforms raw code analysis data into human-readable, LLM-optimized formats that help developers understand and act on architecture issues by presenting them in the most effective way for their chosen AI assistant or documentation needs",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various LLM interfaces and human readability\",\n  \"userVisibleActions\": [\n    \"Receives formatted architecture issues grouped by severity (errors, warnings, info)\",\n    \"Sees issues organized with visual indicators (🔴 for errors, ⚠️ for warnings, ℹ️ for info)\",\n    \"Gets actionable guidance on how to address detected issues\",\n    \"Receives output optimized for their chosen LLM interface (Cursor, ChatGPT, or generic)\",\n    \"Sees compact summaries when requesting condensed output\",\n    \"Views file paths and line numbers where issues occur\",\n    \"Gets context about what each issue means and why it matters\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls formatInsights() to convert raw insights into formatted text\",\n    \"Developer specifies output format: 'cursor', 'chatgpt', 'compact', or 'generic'\",\n    \"Developer receives formatted markdown text ready to display or send to LLM\",\n    \"Developer gets insights grouped and sorted by severity automatically\",\n    \"Developer sees file locations and affected code patterns in the output\",\n    \"Developer receives actionable suggestions and next steps included in the output\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes insights to the appropriate formatter based on specified format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string ready for display or LLM consumption\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Formats insights specifically for Cursor IDE with severity grouping, emoji indicators, and actionable guidance\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string optimized for Cursor\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Formats insights for ChatGPT with conversational tone and context about being a codebase analysis\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown-formatted string optimized for ChatGPT\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Formats insights in a condensed format with just essential information and counts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with summary statistics\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Formats insights in a generic markdown format suitable for any LLM or documentation\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown-formatted string\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats a single insight with location, message, and suggestion details for Cursor\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats a single insight with conversational style for ChatGPT\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats a single insight in a neutral, generic style\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for one insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator (Insight type)\"\n  ],\n  \"intent\": \"Transforms raw code analysis data into human-readable, LLM-optimized formats that help developers understand and act on architecture issues by presenting them in the most effective way for their chosen AI assistant or documentation needs\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Integrates LLM-powered features into VS Code to provide AI-driven code analysis, documentation generation, and insights for software projects",
      "userVisibleActions": [
        "View AI-generated code insights in a tree view panel",
        "Generate comprehensive product documentation from code",
        "Analyze code structure and relationships automatically",
        "View entry points and code flow visualizations",
        "Browse unit test results and coverage",
        "See AI-powered recommendations for code improvements",
        "Access formatted documentation in output channels",
        "Navigate through analyzed code components",
        "View saved analysis results from previous sessions"
      ],
      "developerVisibleActions": [
        "Initialize LLM service on extension activation",
        "Configure API keys for LLM providers",
        "Trigger code analysis on workspace or specific files",
        "Generate documentation that persists across sessions",
        "Load and display previously saved insights and analysis",
        "Refresh tree views when configuration changes",
        "Export analysis results to structured formats",
        "Handle errors and display status in output channels",
        "Integrate with multiple view providers (insights, analysis, navigation)",
        "Manage state across extension lifecycle"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Sets up the LLM service, creates output channels, and loads saved data on extension startup",
          "inputs": "none",
          "outputs": "void - initializes state manager with LLM service"
        },
        {
          "name": "analyzeCodebase",
          "desc": "Analyzes entire codebase or specific files to extract structure, dependencies, and entry points",
          "inputs": "workspace or file paths",
          "outputs": "CodeAnalysis object with discovered patterns and relationships"
        },
        {
          "name": "generateDocumentation",
          "desc": "Creates comprehensive product documentation from analyzed code using LLM",
          "inputs": "analysis context and code structure",
          "outputs": "EnhancedProductDocumentation with formatted sections"
        },
        {
          "name": "getInsights",
          "desc": "Generates AI-powered insights about code quality, architecture, and improvements",
          "inputs": "AnalysisContext with code information",
          "outputs": "LLMInsights with recommendations and observations"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists analysis results to storage for future sessions",
          "inputs": "CodeAnalysis object and workspace path",
          "outputs": "void - saves to file system"
        },
        {
          "name": "loadSavedCodeAnalysis",
          "desc": "Retrieves previously saved analysis results from storage",
          "inputs": "workspace path",
          "outputs": "CodeAnalysis object or null if not found"
        },
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms code analysis into a format suitable for LLM processing",
          "inputs": "CodeAnalysis object",
          "outputs": "AnalysisContext for LLM consumption"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "./llmService",
        "./insightsTreeView",
        "./fileDocumentation",
        "./analyzer",
        "./productNavigator",
        "./analysisViewer",
        "./insightsViewer",
        "./unitTestsNavigator",
        "./logger",
        "./state/llmStateManager",
        "./context/analysisContextBuilder",
        "./domain/formatters/documentationFormatter",
        "./infrastructure/persistence/analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis and AI-powered understanding, enabling developers to quickly comprehend large codebases through automated documentation, insights, and visualizations. It solves the problem of manually documenting and understanding complex software projects by leveraging LLM capabilities to automatically generate meaningful documentation, identify patterns, and provide actionable insights.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered features into VS Code to provide AI-driven code analysis, documentation generation, and insights for software projects\",\n  \"userVisibleActions\": [\n    \"View AI-generated code insights in a tree view panel\",\n    \"Generate comprehensive product documentation from code\",\n    \"Analyze code structure and relationships automatically\",\n    \"View entry points and code flow visualizations\",\n    \"Browse unit test results and coverage\",\n    \"See AI-powered recommendations for code improvements\",\n    \"Access formatted documentation in output channels\",\n    \"Navigate through analyzed code components\",\n    \"View saved analysis results from previous sessions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service on extension activation\",\n    \"Configure API keys for LLM providers\",\n    \"Trigger code analysis on workspace or specific files\",\n    \"Generate documentation that persists across sessions\",\n    \"Load and display previously saved insights and analysis\",\n    \"Refresh tree views when configuration changes\",\n    \"Export analysis results to structured formats\",\n    \"Handle errors and display status in output channels\",\n    \"Integrate with multiple view providers (insights, analysis, navigation)\",\n    \"Manage state across extension lifecycle\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service, creates output channels, and loads saved data on extension startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - initializes state manager with LLM service\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Analyzes entire codebase or specific files to extract structure, dependencies, and entry points\",\n      \"inputs\": \"workspace or file paths\",\n      \"outputs\": \"CodeAnalysis object with discovered patterns and relationships\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation from analyzed code using LLM\",\n      \"inputs\": \"analysis context and code structure\",\n      \"outputs\": \"EnhancedProductDocumentation with formatted sections\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Generates AI-powered insights about code quality, architecture, and improvements\",\n      \"inputs\": \"AnalysisContext with code information\",\n      \"outputs\": \"LLMInsights with recommendations and observations\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to storage for future sessions\",\n      \"inputs\": \"CodeAnalysis object and workspace path\",\n      \"outputs\": \"void - saves to file system\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis results from storage\",\n      \"inputs\": \"workspace path\",\n      \"outputs\": \"CodeAnalysis object or null if not found\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis into a format suitable for LLM processing\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"AnalysisContext for LLM consumption\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and AI-powered understanding, enabling developers to quickly comprehend large codebases through automated documentation, insights, and visualizations. It solves the problem of manually documenting and understanding complex software projects by leveraging LLM capabilities to automatically generate meaningful documentation, identify patterns, and provide actionable insights.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure LLM (Claude) responses to ensure valid, parseable outputs for product analysis, issue identification, and documentation generation.",
      "userVisibleActions": [
        "User receives structured analysis of product purpose and architecture rationale",
        "User sees categorized issues (architectural, code quality, documentation, maintenance) with clear titles and descriptions",
        "User gets actionable recommendations with specific fixes for each identified issue",
        "User receives consistent, predictable documentation formats from LLM analysis"
      ],
      "developerVisibleActions": [
        "Developer defines schema structure for product purpose analysis including design decisions and user goals",
        "Developer specifies issue schema with title, description, relevant files, functions, severity, and category fields",
        "Developer ensures LLM outputs include structured recommendations with confidence levels",
        "Developer constrains LLM responses to predefined formats using JSON Schema validation",
        "Developer guarantees parseable responses without manual text parsing or extraction"
      ],
      "keyFunctions": [
        {
          "name": "productPurposeAnalysisSchema",
          "desc": "Schema for analyzing product purpose, architecture rationale, design decisions, user goals, and contextual factors",
          "inputs": "N/A (schema definition)",
          "outputs": "JSON schema object with required fields: productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
        },
        {
          "name": "issueItemSchema",
          "desc": "Schema for individual issue items with title, description, relevant files/functions, severity, and category",
          "inputs": "N/A (schema definition)",
          "outputs": "JSON schema object defining issue structure with human-readable titles and detailed descriptions including proposed fixes"
        }
      ],
      "dependencies": [],
      "intent": "This file exists to guarantee structured, valid, and machine-parseable responses from Claude AI by defining strict JSON schemas. It eliminates the need for fragile text parsing by enforcing a contract between the LLM and the application, ensuring consistent output formats for product analysis, issue identification, and recommendations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure LLM (Claude) responses to ensure valid, parseable outputs for product analysis, issue identification, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"User receives structured analysis of product purpose and architecture rationale\",\n    \"User sees categorized issues (architectural, code quality, documentation, maintenance) with clear titles and descriptions\",\n    \"User gets actionable recommendations with specific fixes for each identified issue\",\n    \"User receives consistent, predictable documentation formats from LLM analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines schema structure for product purpose analysis including design decisions and user goals\",\n    \"Developer specifies issue schema with title, description, relevant files, functions, severity, and category fields\",\n    \"Developer ensures LLM outputs include structured recommendations with confidence levels\",\n    \"Developer constrains LLM responses to predefined formats using JSON Schema validation\",\n    \"Developer guarantees parseable responses without manual text parsing or extraction\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose, architecture rationale, design decisions, user goals, and contextual factors\",\n      \"inputs\": \"N/A (schema definition)\",\n      \"outputs\": \"JSON schema object with required fields: productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema for individual issue items with title, description, relevant files/functions, severity, and category\",\n      \"inputs\": \"N/A (schema definition)\",\n      \"outputs\": \"JSON schema object defining issue structure with human-readable titles and detailed descriptions including proposed fixes\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to guarantee structured, valid, and machine-parseable responses from Claude AI by defining strict JSON schemas. It eliminates the need for fragile text parsing by enforcing a contract between the LLM and the application, ensuring consistent output formats for product analysis, issue identification, and recommendations.\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is an AI-powered VS Code extension that provides developers with comprehensive code analysis, automated documentation generation, and intelligent testing capabilities. It analyzes your entire codebase to understand its architecture, identify quality issues, and generate actionable insights—all without leaving your editor. The extension monitors your code continuously, automatically updating its analysis when you save files, and presents findings through an intuitive tree-based interface alongside your familiar VS Code panels.\\n\\nDevelopers interact with Shadow Watch through multiple integrated views: a sidebar navigator for browsing documentation and analysis results, a dedicated insights panel showing AI-generated recommendations, the Problems panel for diagnostics, and output channels for detailed reports. The extension connects to AI language models (OpenAI GPT or Anthropic Claude) to generate human-readable documentation, suggest refactorings, create test plans, and identify architectural improvements. All analysis results are cached locally for instant access and preserved between sessions.\\n\\nThe extension transforms static code analysis into actionable development guidance. It identifies circular dependencies, dead code, orphaned files, overly complex functions, and missing test coverage—then provides specific recommendations for improvement. Developers can generate comprehensive test suites with a single command, navigate directly from insights to source code locations, and maintain up-to-date product documentation as their codebase evolves.\",\"whatItDoes\":[\"Analyzes entire codebase architecture and generates AI-powered documentation describing what the application does\",\"Identifies code quality issues including circular dependencies, dead code, large files, and orphaned modules\",\"Generates comprehensive test plans and automatically creates unit tests for functions that lack coverage\",\"Monitors file changes in real-time and automatically updates analysis results when code is saved\",\"Provides AI-generated refactoring recommendations with detailed migration strategies\",\"Creates visual tree-based navigation of code structure, test coverage, and architecture insights\",\"Displays diagnostic warnings and errors in VS Code's Problems panel for quick issue identification\",\"Generates multiple documentation formats optimized for different AI chat interfaces (Cursor, ChatGPT, Claude)\",\"Maps test files to source code to identify untested functions and components\",\"Analyzes function complexity and identifies candidates for refactoring or splitting\",\"Detects entry points and visualizes code flow through the application\",\"Validates test configurations and automatically sets up testing frameworks (Jest, Mocha, Vitest, Pytest)\"],\"userPerspective\":{\"gui\":[\"Browse code analysis results in a hierarchical tree view in the VS Code sidebar\",\"View AI-generated architecture insights and recommendations in a dedicated insights panel\",\"Navigate directly to source code locations by clicking on insights, issues, or analysis results\",\"See diagnostic warnings and errors displayed in VS Code's Problems panel with severity indicators\",\"Monitor analysis progress through status bar indicators and progress notifications\",\"Access detailed test execution results showing pass/fail status for each test file\",\"View comprehensive product documentation generated from codebase analysis\",\"Switch between different AI providers (OpenAI, Claude) through configuration settings\",\"Copy formatted analysis results to clipboard for sharing or pasting into AI chat interfaces\",\"Clear cached analysis data and regenerate insights on demand\"],\"cli\":[],\"api\":[],\"cicd\":[\"Integrate automated code analysis into CI/CD pipelines through command-line execution\",\"Generate and validate test suites as part of automated build processes\",\"Produce documentation artifacts during deployment workflows\",\"Cache analysis results for faster subsequent pipeline runs\"]},\"workflowIntegration\":[\"Code review workflow: Analyze changes and identify quality issues before committing\",\"Documentation workflow: Generate and update product documentation as features are developed\",\"Testing workflow: Discover untested code, create test plans, generate tests, and validate coverage\",\"Refactoring workflow: Identify complex functions, receive AI-powered refactoring guidance, and track improvements\",\"Architecture review workflow: Understand codebase structure, detect anti-patterns, and plan improvements\",\"Onboarding workflow: New developers use generated documentation to understand the codebase quickly\",\"Maintenance workflow: Continuously monitor code quality and address issues as they arise\"],\"problemsSolved\":[\"Eliminates manual documentation effort by automatically generating comprehensive product and architecture docs\",\"Reduces time spent understanding unfamiliar codebases through AI-generated architecture insights\",\"Prevents circular dependency bugs by detecting them early in development\",\"Identifies dead code and orphaned files that waste maintenance effort\",\"Reduces technical debt by highlighting overly complex functions that need refactoring\",\"Improves test coverage by automatically discovering untested functions and generating test suites\",\"Saves time navigating large codebases by providing instant jumps from insights to source code\",\"Prevents API rate limit errors when using AI services through automatic throttling and retry logic\",\"Maintains documentation consistency across team members through automated generation\",\"Reduces context switching by integrating all analysis, documentation, and testing tools within VS Code\"],\"architecture\":\"Shadow Watch is built as a VS Code extension with a modular architecture centered around AI-powered analysis capabilities. The extension initializes through a bootstrapper that orchestrates multiple independent services: file watching, code analysis, insight generation, documentation formatting, and test automation. These services communicate through a centralized configuration manager that tracks user preferences and notifies components when settings change. All analysis results flow through a caching layer that persists data to disk and reloads it instantly when workspaces reopen.\\n\\nThe AI integration layer abstracts multiple language model providers (OpenAI and Anthropic) behind a unified interface, enabling seamless switching between providers based on user configuration. Rate limiting and retry logic ensure reliable API interactions even under high load or temporary service disruptions. LLM responses are parsed and validated against structured schemas to extract consistent, typed data from natural language outputs. The system implements an iterative analysis workflow where the AI can request additional file contents or grep searches to progressively deepen its understanding of the codebase.\\n\\nThe user interface layer presents analysis results through multiple coordinated views: tree-based navigators for browsing code structure and insights, diagnostic providers for showing issues in the Problems panel, and webview panels for displaying detailed reports. Navigation handlers allow users to jump directly from any insight or result to the corresponding source code location. The testing subsystem orchestrates an end-to-end workflow from test environment detection through test generation, execution, validation, and automatic fixing of failures. All components are designed to work asynchronously with comprehensive error handling and progress feedback to maintain a responsive user experience.\",\"titles\":[\"Shadow Watch Extension\",\"Code Analysis Engine\",\"AI Documentation Generator\",\"Test Generation System\",\"Insight Generator\",\"Architecture Analyzer\",\"Dependency Tracker\",\"Test Coverage Mapper\",\"Refactoring Advisor\",\"File Watcher\",\"Diagnostics Provider\",\"Product Navigator\",\"Insights Tree View\",\"Analysis Viewer\",\"Test Configuration Service\",\"LLM Integration Layer\",\"Rate Limiter\",\"Response Parser\",\"Retry Handler\",\"Provider Factory\",\"Configuration Manager\",\"Analysis Context Builder\",\"Incremental Analysis Service\",\"Function Extraction Service\",\"Test Planning Service\",\"Test Generation Service\",\"Test Validation Service\",\"Test Execution Service\",\"Navigation Handler\",\"Documentation Formatter\",\"Progress Service\",\"File Cache\",\"File Processor\",\"Analysis Result Repository\",\"Command Registry\",\"Extension Bootstrapper\"],\"descriptions\":[{\"title\":\"Code Analysis Engine\",\"description\":\"Performs comprehensive static analysis of source code by parsing Abstract Syntax Trees to extract metadata about functions, dependencies, complexity metrics, and code structure. Identifies entry points, maps test coverage, detects circular dependencies, and highlights potential quality issues like large files and dead code.\",\"category\":\"component\"},{\"title\":\"AI Documentation Generator\",\"description\":\"Leverages language models to automatically generate human-readable documentation from code analysis results. Produces product overviews, architecture descriptions, API documentation, and feature descriptions by understanding code structure and purpose through AI analysis.\",\"category\":\"feature\"},{\"title\":\"Test Generation System\",\"description\":\"Automates the entire testing workflow from discovering testable functions through generating unit tests, executing them, validating results, and automatically fixing failures. Intelligently prioritizes which functions need testing based on complexity and existing coverage.\",\"category\":\"feature\"},{\"title\":\"Insight Generator\",\"description\":\"Analyzes code structure to identify actionable insights about code quality, organization patterns, and potential improvements. Generates specific recommendations for refactoring, dependency management, test coverage improvements, and architectural enhancements.\",\"category\":\"component\"},{\"title\":\"Dependency Tracker\",\"description\":\"Maps relationships between code components to detect circular dependencies, identify orphaned files, and understand code flow through the application. Helps developers visualize how different parts of the codebase interact and depend on each other.\",\"category\":\"feature\"},{\"title\":\"Test Coverage Mapper\",\"description\":\"Links test files to their corresponding source code files to identify functions and modules that lack test coverage. Provides visibility into testing gaps and helps prioritize where new tests should be written.\",\"category\":\"feature\"},{\"title\":\"Refactoring Advisor\",\"description\":\"Analyzes code complexity and structure to recommend specific refactoring opportunities. Suggests extracting functions from large files, simplifying complex logic, and breaking down 'god objects' into more maintainable components.\",\"category\":\"feature\"},{\"title\":\"Product Navigator\",\"description\":\"Provides a tree-based interface for browsing generated product documentation, architecture insights, and analysis results. Allows developers to explore their codebase's structure and navigate directly to relevant code locations.\",\"category\":\"feature\"},{\"title\":\"Real-time File Monitoring\",\"description\":\"Watches for file saves and document changes throughout the workspace, automatically triggering re-analysis when code is modified. Keeps all analysis results, insights, and documentation synchronized with the latest code state.\",\"category\":\"feature\"},{\"title\":\"Multi-Provider AI Support\",\"description\":\"Supports multiple AI language model providers including OpenAI GPT and Anthropic Claude, allowing users to choose their preferred provider or switch between them based on needs and availability.\",\"category\":\"feature\"},{\"title\":\"Automatic Rate Limiting\",\"description\":\"Manages API request throttling to prevent exceeding provider rate limits, tracking quotas independently for different AI services and automatically queuing requests that would exceed limits.\",\"category\":\"feature\"},{\"title\":\"Intelligent Retry Logic\",\"description\":\"Handles temporary API failures with exponential backoff retry strategies, automatically recovering from transient network issues or service disruptions without user intervention.\",\"category\":\"feature\"},{\"title\":\"Iterative Code Analysis\",\"description\":\"Enables progressive deepening of code understanding by allowing AI to request additional file contents or grep searches during analysis, gathering context incrementally until sufficient information is available.\",\"category\":\"workflow\"},{\"title\":\"Test Environment Detection\",\"description\":\"Automatically identifies which testing framework is being used (Jest, Mocha, Vitest, Pytest), validates configuration, detects missing dependencies, and provides setup recommendations to ensure generated tests run successfully.\",\"category\":\"feature\"},{\"title\":\"Batch Test Generation\",\"description\":\"Generates unit tests in small batches to manage API costs and provide incremental progress feedback. Executes each batch immediately after generation to validate test quality and identify issues early.\",\"category\":\"workflow\"},{\"title\":\"Self-Healing Test Validation\",\"description\":\"Executes generated tests, detects failures, and automatically attempts to fix broken tests using AI assistance. Provides detailed error reporting and tracks retry attempts until tests pass or maximum attempts are reached.\",\"category\":\"feature\"},{\"title\":\"Multi-Format Output\",\"description\":\"Formats analysis results and documentation in multiple formats optimized for different AI chat interfaces (Cursor IDE, ChatGPT, Claude), making it easy to continue conversations about code in external AI tools.\",\"category\":\"feature\"},{\"title\":\"Persistent Analysis Caching\",\"description\":\"Stores all analysis results to disk with timestamp organization, preserving historical analysis runs and enabling instant workspace reopening without re-analysis. Maintains complete audit trail of documentation changes.\",\"category\":\"feature\"},{\"title\":\"Diagnostic Integration\",\"description\":\"Displays code quality issues, warnings, and recommendations directly in VS Code's Problems panel with appropriate severity levels, enabling quick issue identification and navigation to problem areas.\",\"category\":\"integration\"},{\"title\":\"Direct Code Navigation\",\"description\":\"Allows users to click on any insight, issue, or analysis result to jump directly to the corresponding source code location in the editor, with automatic cursor positioning and code highlighting.\",\"category\":\"feature\"}],\"relevantFunctions\":[{\"name\":\"activate\",\"description\":\"Extension entry point that initializes all components when VS Code loads the extension, orchestrating the setup of tree views, commands, file watchers, and AI services\",\"file\":\"src/extension.ts\"},{\"name\":\"analyzeWorkspace\",\"description\":\"Triggers comprehensive analysis of the entire workspace, scanning all source files, extracting metadata, and generating insights about code structure and quality\",\"file\":\"src/extension.ts\"},{\"name\":\"generateProductDocs\",\"description\":\"Invokes AI language model to analyze codebase and generate comprehensive product documentation describing what the application does from a user perspective\"},{\"name\":\"extractTestableFunctions\",\"description\":\"Uses AI to scan source files and identify all functions, methods, and classes that should have unit tests, along with their complexity and testability characteristics\",\"file\":\"src/domain/services/testing/llmFunctionExtractionService.ts\"},{\"name\":\"generateTestPlan\",\"description\":\"Creates prioritized test plans by analyzing functions and determining which ones need testing, organizing them by priority level (critical, high, medium, low)\",\"file\":\"src/domain/services/testing/llmTestPlanningService.ts\"},{\"name\":\"generateTests\",\"description\":\"Generates unit test code for functions in small batches, immediately executes each batch, and tracks generation progress and success rates\",\"file\":\"src/domain/services/testing/llmTestGenerationService.ts\"},{\"name\":\"validateTests\",\"description\":\"Runs generated test files, detects failures, and automatically attempts to fix broken tests using AI assistance until they pass or max retry attempts are reached\",\"file\":\"src/domain/services/testing/llmTestValidationService.ts\"},{\"name\":\"analyzeWithLLM\",\"description\":\"Sends code analysis requests to configured AI provider, handling rate limiting, retries, and response parsing to extract structured insights from natural language responses\",\"file\":\"src/llmIntegration.ts\"},{\"name\":\"parseProductDocumentation\",\"description\":\"Extracts structured product documentation data from LLM text responses, handling both strict JSON parsing and fallback extraction when responses don't match expected format\",\"file\":\"src/ai/llmResponseParser.ts\"},{\"name\":\"checkRateLimit\",\"description\":\"Enforces API rate limits by tracking request counts per time window and preventing requests that would exceed provider quotas\",\"file\":\"src/ai/llmRateLimiter.ts\"},{\"name\":\"retryWithBackoff\",\"description\":\"Implements exponential backoff retry logic for failed API requests, automatically retrying transient errors with increasing delays between attempts\",\"file\":\"src/ai/llmRetryHandler.ts\"},{\"name\":\"navigateToCodeItem\",\"description\":\"Opens editor to specific file location when user clicks on analysis results, positions cursor at target line/column, and highlights relevant code range\",\"file\":\"src/domain/handlers/navigationHandler.ts\"},{\"name\":\"processIncrementalRequests\",\"description\":\"Handles iterative analysis by processing file read and grep search requests from AI across multiple iterations until analysis is complete\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\"},{\"name\":\"detectTestFramework\",\"description\":\"Automatically identifies which testing framework is configured in the project by examining package.json, config files, and existing test patterns\",\"file\":\"src/domain/services/testConfigurationService.ts\"},{\"name\":\"formatDocumentation\",\"description\":\"Converts raw product documentation data into polished Markdown documents with consistent formatting, sections, and quality indicators\",\"file\":\"src/domain/formatters/documentationFormatter.ts\"}],\"relevantDataStructures\":[{\"name\":\"AnalysisResult\",\"description\":\"Comprehensive data structure containing all code analysis results including file metadata, function information, dependencies, test mappings, insights, and quality metrics\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"ProductDocumentation\",\"description\":\"Structured documentation describing what the application does from a user perspective, including overview, features, user interactions, workflows, and architecture\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"TestPlan\",\"description\":\"Organized structure containing testable functions grouped by priority level (critical, high, medium, low) with metadata about complexity and testability\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestGenerationProgress\",\"description\":\"Tracks progress through test generation phases including setup, planning, generation, validation, and completion with statistics on test counts and success rates\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestExecutionResult\",\"description\":\"Contains results from running test files including pass/fail status, execution duration, error messages with stack traces, and overall statistics\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"ArchitectureInsight\",\"description\":\"AI-generated recommendation about code architecture, quality, or improvements with severity level, category, and specific remediation guidance\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FunctionInfo\",\"description\":\"Detailed metadata about a function including name, parameters, return type, dependencies, complexity metrics, and relationships to other code\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"CodeDependency\",\"description\":\"Represents dependency relationships between code files or modules, used to detect circular dependencies and understand code flow\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"TestMapping\",\"description\":\"Links test files to their corresponding source code files to identify coverage gaps and enable test-to-source navigation\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"LLMProviderConfig\",\"description\":\"Configuration settings for AI language model providers including API keys, endpoints, model selection, and provider-specific parameters\",\"type\":\"interface\",\"file\":\"src/config/configurationManager.ts\"},{\"name\":\"TestSetupPlan\",\"description\":\"Details required test environment setup including framework selection, dependencies to install, configuration files to create, and mock requirements\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testSetupTypes.ts\"},{\"name\":\"FileAnalysisContext\",\"description\":\"Context information about analyzed files formatted for LLM consumption, including code content, metadata, and analysis results\",\"type\":\"interface\",\"file\":\"src/context/analysisContextBuilder.ts\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main extension entry point that coordinates all functionality\",\"purpose\":\"Initializes extension components, registers commands, and manages extension lifecycle\",\"role\":\"Entry point\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"Core AI integration providing documentation generation and code analysis capabilities\",\"purpose\":\"Connects to AI language models to generate insights, documentation, and recommendations\",\"role\":\"Core service\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Defines data structures for code analysis results and metrics\",\"purpose\":\"Provides type definitions for representing code structure, dependencies, and quality metrics\",\"role\":\"Data model\"},{\"path\":\"src/insightGenerator.ts\",\"description\":\"Analyzes code to identify quality issues and improvement opportunities\",\"purpose\":\"Generates actionable insights about code organization, dependencies, and potential problems\",\"role\":\"Analysis engine\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Orchestrates automated test generation workflow\",\"purpose\":\"Manages end-to-end process of generating, executing, and validating unit tests\",\"role\":\"Core service\"},{\"path\":\"src/domain/services/testing/llmFunctionExtractionService.ts\",\"description\":\"Identifies functions that need test coverage\",\"purpose\":\"Uses AI to discover testable functions and assess their complexity and testability\",\"role\":\"Analysis service\"},{\"path\":\"src/ai/providers/providerFactory.ts\",\"description\":\"Manages AI provider instantiation and configuration\",\"purpose\":\"Creates and configures AI language model provider instances based on user settings\",\"role\":\"Factory\"},{\"path\":\"src/config/configurationManager.ts\",\"description\":\"Centralizes all extension configuration management\",\"purpose\":\"Provides unified access to user settings and notifies components of configuration changes\",\"role\":\"Configuration manager\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Handles code navigation from UI interactions\",\"purpose\":\"Opens files and positions cursor when users click on insights or analysis results\",\"role\":\"UI handler\"},{\"path\":\"src/domain/formatters/documentationFormatter.ts\",\"description\":\"Formats documentation into polished output\",\"purpose\":\"Converts raw documentation data into well-organized Markdown documents\",\"role\":\"Formatter\"},{\"path\":\"src/cache.ts\",\"description\":\"Manages persistent storage of analysis results\",\"purpose\":\"Caches analysis data to disk for instant workspace reopening and historical tracking\",\"role\":\"Storage service\"},{\"path\":\"src/fileWatcher.ts\",\"description\":\"Monitors file changes to trigger automatic re-analysis\",\"purpose\":\"Watches for file saves and updates analysis results when code changes\",\"role\":\"Event handler\"}],\"exampleInput\":{\"description\":\"Example configuration object that users provide through VS Code settings to configure the extension's behavior, AI provider selection, and analysis parameters\",\"json\":\"{\\\"shadowWatch.enabled\\\":true,\\\"shadowWatch.autoAnalyze\\\":true,\\\"shadowWatch.showInlineHints\\\":true,\\\"shadowWatch.llmProvider\\\":\\\"openai\\\",\\\"shadowWatch.openai.apiKey\\\":\\\"sk-proj-...\\\",\\\"shadowWatch.openai.model\\\":\\\"gpt-4\\\",\\\"shadowWatch.openai.maxTokens\\\":4000,\\\"shadowWatch.analysisTimeout\\\":300000,\\\"shadowWatch.maxFileSize\\\":1048576,\\\"shadowWatch.maxLines\\\":10000,\\\"shadowWatch.diagnosticSeverity\\\":\\\"warning\\\",\\\"shadowWatch.outputFormat\\\":\\\"cursor\\\"}\"},\"exampleOutput\":{\"description\":\"Example analysis result object containing comprehensive code analysis data, insights, and documentation generated by the extension\",\"json\":\"{\\\"files\\\":[{\\\"path\\\":\\\"src/api/users.ts\\\",\\\"lines\\\":245,\\\"functions\\\":[{\\\"name\\\":\\\"createUser\\\",\\\"lineNumber\\\":15,\\\"complexity\\\":3,\\\"parameters\\\":[{\\\"name\\\":\\\"userData\\\",\\\"type\\\":\\\"UserInput\\\"}],\\\"returnType\\\":\\\"Promise<User>\\\"}],\\\"dependencies\\\":[\\\"./database\\\",\\\"./validation\\\"],\\\"hasTests\\\":true,\\\"testFile\\\":\\\"src/api/users.test.ts\\\"}],\\\"insights\\\":[{\\\"type\\\":\\\"warning\\\",\\\"severity\\\":\\\"medium\\\",\\\"category\\\":\\\"complexity\\\",\\\"title\\\":\\\"High Complexity Function\\\",\\\"description\\\":\\\"Function 'processUserData' has cyclomatic complexity of 15, consider refactoring\\\",\\\"file\\\":\\\"src/api/users.ts\\\",\\\"line\\\":42,\\\"recommendation\\\":\\\"Extract validation logic into separate functions\\\"}],\\\"dependencies\\\":[{\\\"source\\\":\\\"src/api/users.ts\\\",\\\"target\\\":\\\"src/database.ts\\\",\\\"type\\\":\\\"import\\\"}],\\\"testCoverage\\\":{\\\"totalFunctions\\\":127,\\\"testedFunctions\\\":98,\\\"coveragePercentage\\\":77.2,\\\"untestedFunctions\\\":[{\\\"name\\\":\\\"handleEdgeCase\\\",\\\"file\\\":\\\"src/utils/helpers.ts\\\",\\\"line\\\":156}]},\\\"productDocumentation\\\":{\\\"overview\\\":\\\"User management system providing authentication, profile management, and access control\\\",\\\"features\\\":[\\\"User registration and login\\\",\\\"Profile updates and password resets\\\",\\\"Role-based access control\\\"],\\\"architecture\\\":\\\"RESTful API with JWT authentication, PostgreSQL database, and Redis caching layer\\\"}}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-21T17:54:15.282Z",
    "generatedAtLocal": "11/21/2025, 9:54:15 AM",
    "runId": "product-docs-2025-11-21T17-33-01-909Z"
  }
}