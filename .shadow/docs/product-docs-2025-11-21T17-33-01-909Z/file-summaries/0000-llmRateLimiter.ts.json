{
  "file": "src/ai/llmRateLimiter.ts",
  "role": "Core Logic",
  "purpose": "Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window",
  "userVisibleActions": [
    "API requests are automatically throttled to prevent rate limit errors",
    "Requests are blocked when rate limits are reached within the time window",
    "Different AI providers (OpenAI, Claude) have independent rate limit tracking"
  ],
  "developerVisibleActions": [
    "Developer checks if a request can be made before calling LLM APIs",
    "Developer records each request to track usage against limits",
    "Developer configures custom rate limits per provider (maxRequests, windowMs)",
    "System automatically cleans up old request history outside the time window",
    "Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute"
  ],
  "keyFunctions": [
    {
      "name": "canMakeRequest",
      "desc": "Checks if a new request is allowed based on recent request history and configured limits",
      "inputs": "provider: 'openai' | 'claude'",
      "outputs": "boolean - true if request allowed, false if rate limit reached"
    },
    {
      "name": "recordRequest",
      "desc": "Records the timestamp of a request to track usage against rate limits",
      "inputs": "provider: 'openai' | 'claude'",
      "outputs": "void - updates internal request history"
    },
    {
      "name": "configure",
      "desc": "Sets custom rate limit configuration for a specific provider",
      "inputs": "provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}",
      "outputs": "void - updates provider configuration"
    }
  ],
  "dependencies": [],
  "intent": "This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.",
  "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding provider rate limits by tracking and enforcing request quotas per time window\",\n  \"userVisibleActions\": [\n    \"API requests are automatically throttled to prevent rate limit errors\",\n    \"Requests are blocked when rate limits are reached within the time window\",\n    \"Different AI providers (OpenAI, Claude) have independent rate limit tracking\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer checks if a request can be made before calling LLM APIs\",\n    \"Developer records each request to track usage against limits\",\n    \"Developer configures custom rate limits per provider (maxRequests, windowMs)\",\n    \"System automatically cleans up old request history outside the time window\",\n    \"Default limits applied: OpenAI at 60 requests/minute, Claude at 50 requests/minute\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on recent request history and configured limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean - true if request allowed, false if rate limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records the timestamp of a request to track usage against rate limits\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"void - updates internal request history\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific provider\",\n      \"inputs\": \"provider: 'openai' | 'claude', config: {maxRequests: number, windowMs: number}\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to protect the application from exceeding API rate limits imposed by LLM providers (OpenAI, Claude), which could result in blocked requests, errors, or service disruption. It provides a sliding window rate limiter that tracks request history per provider and enforces configurable quotas.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-21T17:33:20.795Z"
  }
}