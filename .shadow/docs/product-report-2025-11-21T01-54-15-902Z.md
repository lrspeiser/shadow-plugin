# Product Documentation Report

## Executive Summary

Shadow Watch is an AI-powered VS Code extension that provides comprehensive code intelligence, automated documentation generation, and intelligent testing capabilities for software development teams. The extension analyzes codebases to understand their architecture, identify quality issues, and generate actionable insights automatically. By integrating with leading AI services (OpenAI GPT and Anthropic Claude), Shadow Watch serves as an intelligent assistant that continuously monitors code, provides real-time feedback through inline diagnostics, and generates documentation that explains what your application does and how it works. The extension streamlines code review, documentation creation, test planning, and refactoring workflows while maintaining all insights within the VS Code environment.

## Product Overview

Shadow Watch transforms how developers understand, document, and improve their codebases by combining static analysis with AI-powered insights. The extension performs deep structural analysis by parsing code into abstract syntax trees, extracting metadata about functions, dependencies, and architectural patterns. This structural understanding feeds into an AI integration layer that generates intelligent commentary about code quality, design decisions, and improvement opportunities.

The extension integrates seamlessly into the VS Code environment through sidebar panels, inline diagnostics, and command palette actions. When developers save files, Shadow Watch can automatically re-analyze them and update insights in real-time, ensuring that feedback stays synchronized with the evolving codebase. The extension caches analysis results for 24 hours to ensure fast subsequent loads, while still providing the option to force fresh analysis when needed.

Shadow Watch addresses multiple development workflows simultaneously. For documentation, it automatically generates comprehensive product-level documentation explaining what the application does, how components interact, and what workflows it supports. For testing, it creates AI-powered test plans, generates unit test code, and automatically validates and fixes failing tests. For code quality, it identifies issues like large files, orphaned code, circular dependencies, and god objects, presenting these as actionable diagnostics with specific line numbers and remediation suggestions. For refactoring, it provides step-by-step guidance with before/after examples and migration plans.

The extension's AI capabilities support iterative analysis where the system can request additional files or search results across multiple conversation rounds, building comprehensive understanding incrementally. All insights can be formatted for different AI assistants (Cursor, ChatGPT) or exported as standalone HTML reports for sharing with teams. This flexibility ensures Shadow Watch fits naturally into existing development workflows while providing powerful new capabilities for understanding and improving code.

## What It Does

- **Code Analysis & Understanding**: Analyzes codebases to extract comprehensive metadata about files, functions, dependencies, imports, exports, and entry points; builds complete pictures of codebase structure and relationships
- **AI-Powered Documentation**: Generates comprehensive product documentation automatically, explaining what your application does, key features, user workflows, and problems solved
- **Architecture Insights**: Provides AI-generated explanations of codebase architecture including component relationships, design patterns, and architectural decisions
- **Test Planning & Generation**: Creates AI-powered test plans identifying which functions need testing, recommends test strategies, and automatically generates unit test code
- **Test Validation & Auto-Fix**: Validates generated tests by executing them, analyzes failures, and automatically regenerates corrected test code until tests pass
- **Code Quality Detection**: Identifies quality issues including large files, orphaned code, circular dependencies, god objects, and other code smells
- **Inline Diagnostics**: Shows code quality issues as warnings, errors, or info messages directly in the editor at specific line numbers with remediation suggestions
- **Real-Time Monitoring**: Monitors file changes and automatically re-analyzes code when files are saved, keeping insights synchronized with latest changes
- **Intelligent Navigation**: Enables direct navigation from tree views to specific functions, endpoints, and code sections with automatic cursor positioning
- **Entry Point Detection**: Finds and categorizes entry points including main functions, CLI tools, test files, and application initialization code
- **Dependency Analysis**: Maps import and export relationships across the codebase to understand module dependencies and coupling
- **Refactoring Recommendations**: Provides AI-analyzed suggestions for improving code structure with specific extraction plans, before/after examples, and migration steps
- **Export & Reporting**: Exports analysis results, documentation, and test reports as formatted HTML files for sharing with teams
- **Multi-Format Output**: Formats insights for specific AI assistants (Cursor, ChatGPT, Generic, Compact) to improve code generation workflows
- **Framework Detection**: Automatically detects test frameworks (Jest, Mocha, Vitest, Pytest), configuration files, and identifies missing dependencies
- **Incremental Analysis**: Manages iterative LLM analysis sessions where the system requests additional files or search results across multiple conversation rounds
- **Progress Tracking**: Provides real-time status updates during long-running operations like test generation or comprehensive codebase analysis
- **Caching & Performance**: Caches analysis results and AI-generated insights to disk for fast subsequent loads while supporting cache invalidation

## User Perspective

### GUI (Visual Studio Code Interface)

- **Insights Viewer**: Interactive tree structure displaying AI-generated architecture insights, code quality issues, and recommendations with ability to browse and navigate to relevant code sections
- **Analysis Viewer**: Tree view presenting code analysis results including file statistics, function lists, imports, exports, and entry points providing structural overview
- **Product Navigator**: Tree view showing product-level documentation organized by features, modules, components, and workflows for quick understanding of application purpose
- **Unit Tests Navigator**: Displays test plans, test generation progress, test results, and coverage showing which functions are tested and validation status
- **Reports Viewer**: Shows generated reports including documentation, test reports, and analysis summaries with HTML export capability
- **Inline Diagnostics**: Editor warnings and errors highlighting specific code issues directly at relevant line numbers with descriptions and recommended fixes
- **Status Bar Indicators**: Real-time feedback showing analysis progress and current extension state
- **Interactive Navigation**: Click any code element in tree views to jump directly to its location in the editor with cursor positioning
- **Progress Notifications**: Visual progress indicators during long-running operations with cancel functionality
- **Settings Integration**: Toggle analyze-on-save, switch AI providers, adjust severity thresholds, and configure output formats through VS Code settings

### CLI (Command Palette)

- **Analyze Workspace**: Trigger comprehensive codebase analysis including file parsing, dependency mapping, and quality detection
- **Generate Product Documentation**: Create AI-powered product documentation on-demand
- **Generate Architecture Insights**: Analyze codebase structure to produce insights about patterns and design decisions
- **Generate Test Plan**: Create comprehensive test plans identifying functions to test with recommended strategies
- **Generate Tests**: Run automated test generation for specific files or entire projects
- **Validate Tests**: Execute tests and automatically fix failures through regeneration
- **Clear Cache**: Remove cached analysis results to force fresh analysis
- **Copy Insights**: Copy analysis results to clipboard in formats optimized for different AI assistants
- **Switch LLM Provider**: Change AI provider between OpenAI and Claude
- **Export Reports**: Generate HTML reports for sharing analysis and documentation

### API Integration

- **OpenAI Integration**: Connect to OpenAI GPT models for AI-powered code analysis with configurable API keys and model selection
- **Anthropic Claude Integration**: Integrate with Anthropic Claude for alternative AI analysis with support for Sonnet, Opus, and Haiku models
- **Structured Analysis Requests**: Submit code for analysis and receive structured insights about architecture, quality, and improvements
- **Iterative Context Fetching**: Request additional file content or search patterns during multi-round analysis conversations
- **Multiple Output Formats**: Generate documentation in formats optimized for different tools and workflows
- **Rate Limit Management**: Automatic throttling and retry logic to handle API rate limits transparently
- **Response Parsing**: Transform raw LLM text responses into structured data objects with JSON extraction and validation

### CI/CD Integration

- **Automated Test Generation**: Integrate test generation into CI pipelines for continuous test coverage improvement
- **Build-Time Quality Checks**: Export analysis results for quality validation during build processes
- **Documentation as Code**: Generate documentation as part of release processes with versioned artifacts
- **Coverage Validation**: Track test coverage and quality metrics across builds
- **Automated Reporting**: Generate and archive analysis reports for historical tracking and compliance

## Problems Solved

- **Manual Documentation Burden**: Eliminates time-consuming manual documentation creation by automatically generating comprehensive product and architecture documentation from code analysis
- **Codebase Comprehension**: Reduces time spent understanding unfamiliar codebases by providing AI-powered architecture insights, navigation, and clear explanations of component relationships
- **Test Coverage Gaps**: Increases test coverage by automatically generating test plans identifying untestable functions and creating actual test code with proper setup and assertions
- **Code Review Overhead**: Saves code review time by automatically identifying quality issues, anti-patterns, and code smells before human review begins
- **Technical Debt Accumulation**: Prevents technical debt by continuously monitoring for issues like large files, god objects, circular dependencies, and orphaned code
- **Developer Onboarding**: Reduces onboarding time for new developers by providing clear, automatically-updated documentation and architecture explanations
- **Refactoring Uncertainty**: Eliminates guesswork in refactoring decisions by providing AI-analyzed extraction plans, migration steps, and before/after examples
- **Test Maintenance**: Automates test maintenance by detecting failing tests and automatically regenerating corrected versions until they pass
- **API Rate Limiting**: Prevents AI service disruptions through intelligent throttling, retry logic, and request management
- **Context Switching**: Reduces context switching by providing all insights, documentation, and diagnostics within VS Code without requiring external tools
- **Stale Documentation**: Ensures documentation stays current through automatic re-analysis on file save and real-time insight updates
- **Test Environment Setup**: Simplifies test setup by automatically detecting frameworks, configuration files, and missing dependencies

## Architecture Overview

Shadow Watch follows a modular, layered architecture organized around four primary concerns: code analysis, AI integration, user interface presentation, and persistence.

### Core Architecture Layers

**Analysis Engine Layer**: The foundation performs static code analysis by parsing source files into abstract syntax trees (ASTs). This layer extracts comprehensive metadata about functions, dependencies, imports, exports, complexity metrics, and behavioral patterns. It identifies entry points, maps module relationships, and detects code quality issues. The analysis engine provides structured data that feeds all higher layers.

**AI Integration Layer**: This layer manages all communication with Large Language Model providers (OpenAI GPT and Anthropic Claude). It includes sophisticated request management with rate limiting, exponential backoff retry logic, and response parsing to ensure reliable operation. The AI layer constructs detailed prompts with code context and instructions, sends them to LLM services, and transforms unstructured text responses into structured data objects. It supports both single-shot and iterative multi-round conversations where the AI can request additional context.

**User Interface Layer**: Multiple tree view providers present analysis results, insights, test plans, and documentation in VS Code's sidebar. A diagnostics provider surfaces code quality issues as inline editor warnings with specific line numbers and remediation suggestions. Navigation handlers enable users to jump from tree views directly to relevant code locations. Command handlers expose all functionality through the command palette. Status bar indicators and progress notifications keep users informed during operations.

**Persistence & Caching Layer**: This layer manages storage of analysis results, AI-generated insights, and documentation artifacts to disk. It implements caching strategies that store results for 24 hours to optimize performance while supporting cache invalidation. The persistence layer organizes artifacts in the `.shadow` directory with timestamped subdirectories for version tracking. It consolidates results from multiple analyses into summary files.

### Component Communication

Components communicate through a centralized event system and command registry. The file watcher service monitors workspace changes and emits events that trigger re-analysis. The configuration manager broadcasts settings changes to all components. The progress notification service provides a consistent interface for operation status updates. All components access shared services (AI integration, persistence, configuration) through dependency injection, enabling loose coupling and testability.

### Data Flow

1. User triggers analysis (manually or via file save)
2. Analysis engine parses code and extracts metadata
3. Structured analysis data flows to AI integration layer
4. Prompt builder constructs contextualized prompts
5. LLM service sends requests to AI provider with rate limiting
6. Response parser transforms AI output into structured insights
7. Persistence layer caches results to disk
8. UI layer updates tree views and diagnostics
9. User navigates insights and code through interactive views

### Extensibility Points

The architecture supports extensibility through provider interfaces. New AI providers can be added by implementing the LLM provider interface. Additional analysis capabilities can be integrated by extending the analysis engine. Custom formatters can transform insights into new output formats. The tree view system supports adding new views for different insight types.

## Key Components & Modules

### AI Module (`src/ai`)

**Purpose**: Provides robust infrastructure for interacting with LLM APIs reliably and efficiently

**Capabilities**:
- Automatically manages API rate limits across different providers to prevent service disruptions
- Parses unstructured AI responses into organized, structured data
- Provides resilient operations with automatic retry logic and exponential backoff
- Handles transient errors transparently without user intervention

**Key Components**:
- **LLM Rate Limiter** (`llmRateLimiter.ts`): Tracks and throttles API requests with provider-specific limits
- **LLM Retry Handler** (`llmRetryHandler.ts`): Implements exponential backoff for failed requests
- **LLM Response Parser** (`llmResponseParser.ts`): Transforms raw text into structured data with JSON extraction

### AI Providers Module (`src/ai/providers`)

**Purpose**: Unified abstraction layer for multiple AI language models

**Capabilities**:
- Connect to OpenAI GPT models and Anthropic Claude through single interface
- Automatically select and initialize appropriate provider based on configuration
- Support conversational interactions with full message history
- Validate API keys automatically before making requests

**Key Components**:
- **Provider Factory**: Selects appropriate AI service based on user configuration
- **OpenAI Provider**: Implements OpenAI GPT integration
- **Claude Provider**: Implements Anthropic Claude integration
- **Base Provider Interface**: Defines standard contract for all AI providers

### Analysis Module (`src/analysis`)

**Purpose**: Sophisticated code intelligence through AST parsing and metadata extraction

**Capabilities**:
- Deep code analysis through abstract syntax tree parsing
- Extract comprehensive function metadata including signatures, parameters, behaviors
- Detect conditional branches and code paths within functions
- Identify dependencies, state mutations, and behavioral patterns
- Generate detailed function analysis reports for refactoring

**Key Components**:
- **Function Analyzer**: Extracts function-level metadata and behavioral characteristics
- **File Analyzer**: Parses entire files to extract all functions, imports, exports

### Bootstrap Module (`src/domain/bootstrap`)

**Purpose**: Foundation and entry point for the entire extension

**Capabilities**:
- Registers all extension commands for user interaction
- Initializes complete extension architecture
- Automatically monitors file changes for re-analysis
- Integrates components into VS Code UI

**Key Components**:
- **Command Registry**: Registers all command palette and context menu actions
- **Component Initializer**: Wires together analyzers, viewers, tree providers

### Configuration Module (`src/config`)

**Purpose**: Central configuration hub managing all user preferences

**Capabilities**:
- Centralized management of extension settings
- Real-time configuration change notifications
- Control over activation state and analysis triggers
- Customizable analysis behavior and output formats
- Flexible LLM provider configuration

**Key Component**:
- **Configuration Manager** (`configurationManager.ts`): Manages settings and broadcasts changes

### Context Module (`src/context`)

**Purpose**: Bridge between code analysis and LLM-based documentation

**Capabilities**:
- Captures and structures analysis results for LLM consumption
- Persists analysis snapshots with timestamps
- Maintains persistent documentation in `.shadow/docs` directory
- Provides structured format for AI-assisted development

### Domain Services Module (`src/domain/services`)

**Purpose**: Core infrastructure services for responsiveness and intelligence

**Capabilities**:
- Automatic file system monitoring and change detection
- Iterative LLM analysis sessions with context fetching
- Automatic test framework detection and validation
- Missing dependency identification

**Key Components**:
- **File Watcher Service** (`fileWatcherService.ts`): Monitors workspace changes
- **Incremental Analysis Service**: Manages multi-round AI conversations
- **Test Setup Service**: Detects test environment configuration

### Testing Services Module (`src/domain/services/testing`)

**Purpose**: Comprehensive AI-powered test automation

**Capabilities**:
- Analyze codebases to create prioritized test plans
- Generate unit tests incrementally using AI
- Detect and configure test environments automatically
- Execute test suites and capture detailed results
- Automatically validate and fix failing tests
- Provide real-time progress updates

**Key Components**:
- **LLM Test Planning Service** (`llmTestPlanningService.ts`): Creates test plans
- **LLM Test Generation Service** (`llmTestGenerationService.ts`): Generates test code
- **LLM Test Validation Service** (`llmTestValidationService.ts`): Validates and fixes tests
- **Test Execution Service**: Runs test suites (Jest, Pytest)
- **Test Setup Service**: Detects frameworks and configuration

### Formatters Module (`src/domain/formatters`)

**Purpose**: Transform structured data into polished Markdown documentation

**Capabilities**:
- Format product documentation into organized sections
- Generate timestamped documentation exports
- Structure AI insights into accessible formats
- Organize usage information by interface type

**Key Component**:
- **Documentation Formatter** (`documentationFormatter.ts`): Converts data to Markdown

### Handlers Module (`src/domain/handlers`)

**Purpose**: Enable seamless code navigation from tree views

**Capabilities**:
- Navigate to files, functions, endpoints, and entry points
- Open files at specific line numbers with cursor positioning
- Highlight target code elements
- Preview code details for selected items

**Key Component**:
- **Navigation Handler** (`navigationHandler.ts`): Orchestrates navigation workflow

### Prompts Module (`src/domain/prompts`)

**Purpose**: Central prompt engineering layer for AI operations

**Capabilities**:
- Generate prompts for architecture analysis
- Create prompts for documentation generation
- Build prompts for test planning and generation
- Generate refactoring recommendations
- Produce context-aware prompts with code understanding

**Key Components**:
- **Prompt Builder** (`promptBuilder.ts`): Constructs prompts for all LLM tasks
- **Analysis Prompts**: Templates for code analysis
- **Test Prompts**: Templates for test planning and generation

### Infrastructure Module (`src/infrastructure`)

**Purpose**: Cross-cutting infrastructure services

**Capabilities**:
- Display standardized progress notifications
- Show real-time progress updates with cancel functionality
- Track incremental progress across UI locations
- Provide consistent progress feedback

**Key Component**:
- **Progress Notification Service**: Centralized progress indicator management

### File System Module (`src/infrastructure/fileSystem`)

**Purpose**: High-performance file access layer

**Capabilities**:
- Automatically cache file contents for speed
- Detect file changes and refresh cache
- Filter unwanted directories and files
- Process multiple files in parallel
- Handle errors gracefully

**Key Components**:
- **Cached File Reader**: Memory-cached file access
- **File Processor**: Parallel file processing with filtering

### Persistence Module (`src/infrastructure/persistence`)

**Purpose**: Storage and retrieval of analysis artifacts

**Capabilities**:
- Persistent storage of product documentation
- Archival of architecture insights with timestamps
- Generation of consolidated summary files
- Incremental documentation updates with version tracking
- Organized storage in `.shadow` directory

**Key Component**:
- **Documentation Persistence**: Manages all artifact storage

## Key Functions & Data Structures

### Core Functions

**analyzeWorkspace**: Triggers comprehensive codebase analysis including file parsing, dependency mapping, entry point detection, and quality issue identification. Returns complete `AnalysisResult` with all structural metadata.

**generateProductDocumentation**: Creates AI-powered product documentation by analyzing code structure and generating explanations of application purpose, features, architecture, and workflows. Returns `ProductDocumentation` object.

**generateArchitectureInsights**: Analyzes codebase structure to produce AI-generated insights about architecture patterns, component relationships, design decisions, and improvement opportunities. Returns array of `ArchitectureInsight` objects.

**generateTestPlan**: Analyzes code to identify testable functions, assess complexity, and create prioritized test plans with recommended strategies. Returns `TestPlan` with function groups and priorities.

**generateTests**: Generates unit test code incrementally using AI analysis of function behavior, dependencies, and edge cases. Processes functions in batches with progress updates. Returns generated test code.

**validateTests**: Executes generated tests and automatically regenerates failing tests with AI-powered fixes until they pass or maximum attempts reached. Returns `TestResult` with validation status.

**executeTests**: Runs test suites using appropriate framework (Jest, Pytest) and captures detailed execution results including pass/fail counts, errors, and stack traces. Returns `TestResult`.

**navigateToLocation**: Opens files and positions cursor at specific line numbers when users click tree view items. Highlights target code element. Provides error notifications on failure.

**formatDocumentation**: Converts structured `ProductDocumentation` data into polished, human-readable Markdown format with organized sections. Returns formatted string.

**parseResponse**: Extracts and validates structured data from raw LLM text responses. Handles JSON extraction from markdown code blocks and schema validation. Returns parsed data object.

**throttleRequest**: Manages rate limiting for LLM API requests to prevent exceeding provider quotas. Tracks request counts and applies throttling delays. Returns Promise resolving when safe to proceed.

**retryWithBackoff**: Implements exponential backoff retry logic for failed LLM requests. Automatically retries on rate limits, timeouts, and transient errors. Returns Promise with eventual result or throws error.

**detectTestFramework**: Automatically identifies test framework configuration (Jest, Mocha, Vitest, Pytest) by scanning for config files and package.json. Detects missing dependencies. Returns `TestSetupConfig`.

**buildPrompt**: Constructs detailed prompts for LLM analysis tasks with relevant code context, dependency information, and specific instructions. Returns formatted prompt string.

**watchFiles**: Monitors workspace for file changes using VS Code file watcher API. Triggers automatic re-analysis when configured. Registers change event handlers.

**cacheResults**: Stores analysis results, insights, and documentation to disk with timestamps. Implements 24-hour cache expiration. Organizes artifacts in `.shadow` directory.

**extractFunctionMetadata**: Parses function AST to extract comprehensive metadata including signature, parameters, return type, complexity, branches, dependencies, and behavioral patterns. Returns `FunctionInfo`.

**detectCodeQualityIssues**: Identifies quality problems including large files, orphaned code, circular dependencies, god objects, and code smells. Returns array of `CodeQualityIssue` objects.

**findEntryPoints**: Locates and categorizes entry points including main functions, CLI tools, test files, and initialization code. Returns array of `EntryPoint` objects.

### Key Data Structures

**AnalysisResult** (interface)
```typescript
{
  files: FileAnalysis[];           // All analyzed files
  functions: FunctionInfo[];       // All extracted functions
  dependencies: DependencyGraph;   // Import/export relationships
  qualityIssues: CodeQualityIssue[]; // Detected problems
  entryPoints: EntryPoint[];       // Application entry points
  statistics: {                    // Overall metrics
    totalFiles: number;
    totalFunctions: number;
    totalLines: number;
  };
}
```

**FileAnalysis** (interface)
```typescript
{
  path: string;                    // File path relative to workspace
  functions: FunctionInfo[];       // Functions in this file
  imports: string[];               // Imported modules
  exports: string[];               // Exported identifiers
  lines: number;                   // Total line count
  complexity: number;              // Cyclomatic complexity
  issues: CodeQualityIssue[];      // File-specific problems
}
```

**FunctionInfo** (interface)
```typescript
{
  name: string;                    // Function name
  signature: string;               // Full function signature
  filePath: string;                // Containing file path
  lineNumber: number;              // Start line number
  parameters: Parameter[];         // Parameter details
  returnType: string;              // Return type annotation
  complexity: number;              // Cyclomatic complexity
  dependencies: string[];          // External dependencies
  behaviorHints: string[];         // Pure, async, recursive, etc.
  branches: number;                // Conditional branch count
  stateMutations: string[];        // Modified variables
}
```

**ProductDocumentation** (interface)
```typescript
{
  overview: string;                // Product description
  purpose: string;                 // Main purpose and value
  features: Feature[];             // Key features
  architecture: string;            // Architecture description
  workflows: Workflow[];           // User workflows
  problemsSolved: string[];        // Problems addressed
  usageByInterface: {              // Interface-specific usage
    gui: string[];
    cli: string[];
    api: string[];
    cicd: string[];
  };
}
```

**ArchitectureInsight** (interface)
```typescript
{
  type: string;                    // Pattern, issue, recommendation
  title: string;                   // Brief title
  description: string;             // Detailed explanation
  locations: Location[];           // Relevant code locations
  severity: 'info' | 'warning' | 'error';
  recommendations: string[];       // Actionable suggestions
  relatedPatterns: string[];       // Related architecture patterns
}
```

**TestPlan** (interface)
```typescript
{
  functionGroups: FunctionGroup[]; // Grouped testable functions
  priorities: Priority[];          // Test priorities
  recommendations: string[];       // Testing strategy recommendations
  coverage: {                      // Coverage targets
    target: number;
    current: number;
  };
  estimatedTests: number;          // Estimated test count
}
```

**TestResult** (interface)
```typescript
{
  passed: number;                  // Passed test count
  failed: number;                  // Failed test count
  errors: number;                  // Error count
  details: TestDetail[];           // Individual test results
  duration: number;                // Execution duration (ms)
  coverage?: CoverageReport;       // Coverage report if available
}
```

**CodeQualityIssue** (interface)
```typescript
{
  type: string;                    // Issue type (large file, god object, etc.)
  severity: 'info' | 'warning' | 'error';
  filePath: string;                // File location
  lineNumber?: number;             // Line number if applicable
  description: string;             // Issue description
  recommendation: string;          // How to fix
  metric?: number;                 // Associated metric value
}
```

**LLMRequest** (interface)
```typescript
{
  messages: Message[];             // Conversation messages
  model: string;                   // Model identifier
  temperature: number;             // Randomness (0-1)
  responseFormat?: 'json' | 'text';
  maxTokens?: number;              // Maximum response length
}
```

**LLMResponse** (interface)
```typescript
{
  content: string;                 // Generated content
  tokenUsage: {                    // Token consumption
    prompt: number;
    completion: number;
    total: number;
  };
  model: string;                   // Model used
  finishReason: string;            // Completion reason
}
```

## Workflows & Integration

### Code Analysis Workflow

1. **Trigger Analysis**: User saves file (auto-trigger) or runs "Analyze Workspace" command
2. **File Discovery**: Extension scans workspace, filtering out `node_modules`, `.git`, build directories
3. **Parsing**: Each file parsed into AST to extract functions, imports, exports, dependencies
4. **Metadata Extraction**: Function signatures, complexity, branches, state mutations extracted
5. **Quality Detection**: Large files, orphaned code, circular dependencies identified
6. **Entry Point Detection**: Main functions, CLI tools, test files categorized
7. **Caching**: Results stored in `.shadow` directory with timestamp
8. **UI Update**: Tree views refresh showing new analysis results
9. **Diagnostics**: Code quality issues appear as inline editor warnings

### AI Documentation Generation Workflow

1. **Initiate**: User runs "Generate Product Documentation" command
2. **Context Preparation**: Analysis results loaded from cache or freshly generated
3. **Prompt Construction**: Prompt builder creates detailed request with code context
4. **LLM Request**: Request sent to configured AI provider (OpenAI/Claude) with rate limiting
5. **Response Parsing**: Raw AI text transformed into structured `ProductDocumentation` object
6. **Formatting**: Documentation formatter converts to polished Markdown
7. **Persistence**: Documentation saved to `.shadow/docs` with timestamp
8. **Display**: Product Navigator tree view shows organized documentation
9. **Export**: User can export as HTML report for sharing

### Test Generation Workflow

1. **Plan Creation**: "Generate Test Plan" analyzes code to identify testable functions
2. **Prioritization**: Functions prioritized by complexity and importance
3. **Framework Detection**: Test setup service identifies Jest/Pytest configuration
4. **Batch Processing**: Functions processed in small batches for test generation
5. **AI Test Generation**: Each batch sent to LLM for test code generation
6. **Progress Updates**: Real-time progress shown in Unit Tests Navigator
7. **Test File Creation**: Generated tests written to appropriate test directories
8. **Validation**: Tests executed to verify they pass
9. **Auto-Fix**: Failing tests automatically regenerated with corrections
10. **Report**: Comprehensive test report saved and displayed

### Iterative Analysis Workflow

1. **Initial Request**: User triggers analysis requiring deep understanding
2. **First LLM Round**: Initial analysis identifies need for additional context
3. **Context Request**: LLM requests specific files or search patterns
4. **Context Fetching**: Extension retrieves requested information from workspace
5. **Follow-up Round**: Additional context sent to LLM in continued conversation
6. **Iteration**: Process repeats up to maximum iterations
7. **Consolidation**: Final comprehensive insights generated with full context
8. **Presentation**: Complete insights displayed in tree views

### Real-Time Monitoring Workflow

1. **File Save**: Developer saves edited file in workspace
2. **Change Detection**: File watcher service detects modification
3. **Auto-Trigger Check**: Configuration checked for analyze-on-save setting
4. **Incremental Analysis**: Only changed file re-analyzed (not full workspace)
5. **Insight Update**: AI insights regenerated for modified code
6. **Cache Update**: Analysis cache updated with new results
7. **UI Refresh**: Tree views and diagnostics update automatically
8. **Notification**: Status bar shows analysis complete

### CI/CD Integration Workflow

1. **Pipeline Trigger**: CI/CD pipeline runs on commit/PR
2. **Extension Execution**: Shadow Watch commands invoked via CLI
3. **Analysis Generation**: Codebase analyzed, quality issues identified
4. **Test Generation**: Missing tests generated automatically
5. **Quality Gates**: Analysis results checked against quality thresholds
6. **Documentation Export**: Latest documentation exported as build artifact
7. **Report Archiving**: HTML reports stored for historical tracking
8. **Pass/Fail Decision**: Pipeline continues or fails based on quality metrics

## File Organization

### Entry Point
- **src/extension.ts**: Extension activation entry point; initializes all components, registers commands, establishes UI elements, coordinates lifecycle management

### Core Analysis
- **src/analyzer.ts**: Comprehensive codebase analysis engine; performs file parsing, dependency mapping, quality detection, entry point identification
- **src/analysis/functionAnalyzer.ts**: Function-level AST parsing; extracts signatures, complexity, branches, dependencies, behavioral patterns
- **src/analysis/fileAnalyzer.ts**: File-level analysis; processes entire files to extract all functions, imports, exports

### AI Integration
- **src/llmIntegration.ts**: AI integration coordinator; manages LLM-based insights, documentation, and analysis workflows
- **src/llmService.ts**: AI service interface; sends prompts to AI providers, processes responses
- **src/ai/llmRateLimiter.ts**: Rate limiting component; prevents API quota violations
- **src/ai/llmRetryHandler.ts**: Retry logic; exponential backoff for failed requests
- **src/ai/llmResponseParser.ts**: Response parsing; transforms AI text to structured data
- **src/ai/providers/llmProviderFactory.ts**: Provider selection; chooses appropriate AI service
- **src/ai/providers/openAIProvider.ts**: OpenAI GPT integration
- **src/ai/providers/claudeProvider.ts**: Anthropic Claude integration
- **src/ai/providers/baseLLMProvider.ts**: Provider interface contract

### User Interface
- **src/insightsTreeView.ts**: AI insights tree view; displays architecture insights and quality issues
- **src/productNavigator.ts**: Product documentation tree view; shows features and architecture
- **src/unitTestsNavigator.ts**: Testing tree view; displays test plans, progress, results
- **src/diagnosticsProvider.ts**: Inline diagnostics; surfaces code issues in editor

### Testing Services
- **src/domain/services/testing/llmTestGenerationService.ts**: Generates unit test code using AI
- **src/domain/services/testing/llmTestPlanningService.ts**: Creates AI-powered test plans
- **src/domain/services/testing/llmTestValidationService.ts**: Validates and auto-fixes failing tests
- **src/domain/services/testing/testExecutionService.ts**: Runs test suites (Jest, Pytest)
- **src/domain/services/testing/testSetupService.ts**: Detects test framework configuration
- **src/domain/services/testing/types/**: Type definitions for test workflows

### Domain Services
- **src/domain/services/fileWatcherService.ts**: File monitoring; triggers re-analysis on save
- **src/domain/services/incrementalAnalysisService.ts**: Iterative AI conversations
- **src/domain/formatters/documentationFormatter.ts**: Markdown formatting for documentation
- **src/domain/handlers/navigationHandler.ts**: Code navigation from tree views to editor
- **src/domain/prompts/promptBuilder.ts**: Prompt engineering for all LLM tasks
- **src/domain/prompts/analysisPrompts.ts**: Analysis-specific prompt templates
- **src/domain/prompts/testPrompts.ts**: Test-related prompt templates

### Bootstrap & Configuration
- **src/domain/bootstrap/commandRegistry.ts**: Command registration; exposes all user actions
- **src/domain/bootstrap/componentInitializer.ts**: Component wiring; initializes extension architecture
- **src/config/configurationManager.ts**: Settings management; centralizes configuration access

### Infrastructure
- **src/infrastructure/progressNotificationService.ts**: Progress