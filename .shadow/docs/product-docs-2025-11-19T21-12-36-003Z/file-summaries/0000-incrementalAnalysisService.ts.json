{
  "file": "src/domain/services/incrementalAnalysisService.ts",
  "role": "Core Logic",
  "purpose": "Handles iterative analysis where an LLM makes multiple requests for files or code searches until it has enough information to complete its task",
  "userVisibleActions": [
    "User receives analysis results that may require multiple rounds of file access and code searching",
    "User sees progress updates as the system iterates through analysis rounds",
    "User experiences automatic retrieval of additional file content when the LLM needs more context",
    "User gets grep search results automatically incorporated into analysis when patterns need to be found"
  ],
  "developerVisibleActions": [
    "Developer triggers incremental analysis that automatically handles LLM requests for more information",
    "Developer receives iteration callbacks showing progress through analysis rounds",
    "Developer gets structured results containing the final analysis, iteration count, and all requests made",
    "Developer can configure maximum iterations to prevent infinite loops",
    "Developer sees file read and grep search requests processed automatically up to 5 requests per iteration",
    "Developer receives conversation messages with assistant responses and user-provided additional information"
  ],
  "keyFunctions": [
    {
      "name": "processRequests",
      "desc": "Processes LLM requests for files and grep searches, returning formatted additional information and updated conversation messages",
      "inputs": "requests: LLMRequest[], currentResult: any, messages: conversation array",
      "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
    },
    {
      "name": "IterationResult<T>",
      "desc": "Structure containing the final result, iteration count, all requests made, and whether to continue",
      "inputs": "Generic type T for result",
      "outputs": "result: T, iteration: number, maxIterations: number, requests: LLMRequest[], shouldContinue: boolean"
    },
    {
      "name": "IterationCallbacks<T>",
      "desc": "Optional callbacks for monitoring iteration progress",
      "inputs": "Generic type T for result",
      "outputs": "onIterationStart and onIterationComplete callback functions"
    }
  ],
  "dependencies": [
    "fileAccessHelper",
    "LLMRequest type definitions"
  ],
  "intent": "This file exists to eliminate code duplication and improve testability by extracting the iterative LLM analysis pattern into a reusable service. It solves the problem of LLMs needing multiple rounds of information gathering (file reads, grep searches) before completing an analysis, converting while-loop patterns into async iterator patterns that are easier to test and maintain.",
  "rawContent": "```json\n{\n  \"purpose\": \"Handles iterative analysis where an LLM makes multiple requests for files or code searches until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"User receives analysis results that may require multiple rounds of file access and code searching\",\n    \"User sees progress updates as the system iterates through analysis rounds\",\n    \"User experiences automatic retrieval of additional file content when the LLM needs more context\",\n    \"User gets grep search results automatically incorporated into analysis when patterns need to be found\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers incremental analysis that automatically handles LLM requests for more information\",\n    \"Developer receives iteration callbacks showing progress through analysis rounds\",\n    \"Developer gets structured results containing the final analysis, iteration count, and all requests made\",\n    \"Developer can configure maximum iterations to prevent infinite loops\",\n    \"Developer sees file read and grep search requests processed automatically up to 5 requests per iteration\",\n    \"Developer receives conversation messages with assistant responses and user-provided additional information\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM requests for files and grep searches, returning formatted additional information and updated conversation messages\",\n      \"inputs\": \"requests: LLMRequest[], currentResult: any, messages: conversation array\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"IterationResult<T>\",\n      \"desc\": \"Structure containing the final result, iteration count, all requests made, and whether to continue\",\n      \"inputs\": \"Generic type T for result\",\n      \"outputs\": \"result: T, iteration: number, maxIterations: number, requests: LLMRequest[], shouldContinue: boolean\"\n    },\n    {\n      \"name\": \"IterationCallbacks<T>\",\n      \"desc\": \"Optional callbacks for monitoring iteration progress\",\n      \"inputs\": \"Generic type T for result\",\n      \"outputs\": \"onIterationStart and onIterationComplete callback functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest type definitions\"\n  ],\n  \"intent\": \"This file exists to eliminate code duplication and improve testability by extracting the iterative LLM analysis pattern into a reusable service. It solves the problem of LLMs needing multiple rounds of information gathering (file reads, grep searches) before completing an analysis, converting while-loop patterns into async iterator patterns that are easier to test and maintain.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-19T21:18:09.351Z"
  }
}