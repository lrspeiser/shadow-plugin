{
  "overview": "Shadow Watch is an AI-powered VS Code extension that automatically analyzes codebases to generate human-readable documentation, architectural insights, and actionable code quality recommendations. Users interact with the extension through integrated sidebar panels that display code analysis results, quality metrics, test coverage information, and AI-generated documentation. The extension continuously monitors workspace files and updates its analysis when code changes, providing developers with real-time insights into code structure, complexity, dependencies, and potential issues.\n\nThe extension serves as an intelligent code understanding assistant that bridges the gap between raw source code and comprehensible documentation. It automatically identifies entry points, maps dependencies between files and functions, detects code smells like circular dependencies and orphaned files, and generates test coverage reports. Users can explore their codebase through multiple specialized views including hierarchical analysis trees, insights panels, and documentation browsers that make complex codebases easier to navigate and understand.\n\nShadow Watch integrates AI language models (OpenAI GPT or Anthropic Claude) to generate contextual documentation and refactoring recommendations. Users can trigger analysis on-demand or enable automatic analysis on file save, view generated insights directly in the VS Code Problems panel, export analysis results in formats optimized for different AI assistants, and navigate instantly from analysis results to the corresponding code locations. The extension maintains a persistent knowledge base of analysis results that improves over time and supports iterative AI-powered analysis workflows.",
  "whatItDoes": [
    "Automatically analyzes code structure and generates human-readable documentation explaining what code does from a user perspective",
    "Displays code quality metrics and complexity assessments in interactive sidebar tree views",
    "Identifies test coverage gaps showing which functions have tests and which need testing",
    "Detects code organization issues including large files, orphaned code, circular dependencies, and duplicate code",
    "Generates AI-powered refactoring recommendations with detailed migration guidance",
    "Creates automated test generation plans and executes tests with validation and auto-fixing capabilities",
    "Provides real-time diagnostics in the VS Code Problems panel showing code quality warnings and suggestions",
    "Enables instant navigation from analysis results to specific code locations in the editor",
    "Exports analysis results in formats optimized for ChatGPT, Cursor AI, and other AI assistants",
    "Monitors file changes and automatically refreshes analysis when code is modified",
    "Generates comprehensive product documentation describing application features and architecture",
    "Creates test plans prioritizing which functions need testing based on complexity and risk"
  ],
  "userPerspective": {
    "gui": [
      "Interactive sidebar tree views displaying code analysis hierarchy with files, functions, and metrics",
      "Insights panel showing AI-generated recommendations categorized by type (quality, architecture, testing)",
      "Documentation browser for viewing generated product documentation and architecture insights",
      "Problems panel integration displaying code quality diagnostics with severity levels",
      "Status bar indicators showing analysis progress and current state",
      "Webview panels displaying detailed information about selected code elements with syntax highlighting",
      "Tree view navigation allowing direct jumps to code locations by clicking on analysis items",
      "Progress notifications during long-running analysis and test generation operations",
      "Configuration settings interface for enabling/disabling features and selecting AI providers"
    ],
    "cli": [],
    "api": [],
    "cicd": []
  },
  "workflowIntegration": [
    "Code review workflow: Developers review AI-generated insights before merging code changes to identify quality issues",
    "Documentation generation workflow: Automatically create and update product documentation when codebase changes",
    "Test-driven development workflow: Generate test plans and implement tests based on AI recommendations",
    "Refactoring workflow: Use AI-generated refactoring reports to safely restructure large files and improve code organization",
    "Onboarding workflow: New developers explore codebase through generated documentation and analysis views",
    "Technical debt management workflow: Track and prioritize code quality issues through diagnostics and insights panels"
  ],
  "problemsSolved": [
    "Eliminates manual documentation effort by automatically generating human-readable explanations of code purpose",
    "Reduces time spent understanding unfamiliar codebases through AI-powered architectural insights",
    "Identifies hidden code quality issues that manual review might miss (circular dependencies, orphaned files, complexity hotspots)",
    "Accelerates test writing by automatically generating test plans and test code with validation",
    "Prevents technical debt accumulation by surfacing refactoring opportunities before files become unmaintainable",
    "Improves code navigation in large projects through structured analysis hierarchies and instant jump-to-definition",
    "Standardizes documentation format across projects through consistent AI-generated output",
    "Reduces cognitive load during code review by highlighting specific issues with actionable recommendations"
  ],
  "architecture": "Shadow Watch follows a layered architecture with distinct separation between domain logic, infrastructure concerns, and presentation. The domain layer contains services for code analysis, AI integration, test generation, and insight creation. These services orchestrate workflows like analyzing code structure, generating documentation, planning tests, and creating refactoring recommendations. The infrastructure layer handles persistence, file system operations, caching, and external AI provider integration. The presentation layer consists of VS Code UI components including tree view providers, webview panels, diagnostics providers, and command handlers.\n\nThe extension uses an event-driven architecture where file system watchers detect code changes and trigger analysis pipelines. Analysis results flow through multiple stages: initial code parsing extracts structural information, AI services enrich this data with semantic understanding and recommendations, formatters transform results into human-readable documentation, and UI components display formatted results to users. A caching layer stores analysis results to avoid redundant processing and improve performance.\n\nAI integration follows a provider abstraction pattern allowing seamless switching between OpenAI and Anthropic Claude. The system implements rate limiting, retry logic with exponential backoff, and response parsing to ensure reliable AI interactions. Test generation uses an iterative workflow where the AI analyzes code, creates test plans, generates tests in small batches, executes them, captures results, and automatically fixes failures through multiple refinement cycles. All analysis results are persisted to a workspace directory structure enabling version history and cross-session continuity.",
  "titles": [
    "Code Analysis Engine",
    "AI-Powered Documentation Generator",
    "Test Generation System",
    "Insights and Recommendations Engine",
    "Code Quality Diagnostics",
    "Architecture Insights Viewer",
    "Analysis Tree Navigator",
    "Product Documentation Generator",
    "Refactoring Report Builder",
    "Test Plan Creator",
    "Test Execution and Validation",
    "File System Watcher",
    "Rate Limiter for AI Requests",
    "Response Parser for AI Outputs",
    "Configuration Manager",
    "Navigation Handler",
    "Progress Notification Service",
    "Analysis Context Builder",
    "Incremental Analysis Service",
    "Test Configuration Detector"
  ],
  "descriptions": [
    {
      "title": "Code Analysis Engine",
      "description": "Scans source code files to extract structural information including functions, classes, dependencies, complexity metrics, and code relationships. Identifies entry points, maps call graphs, and detects patterns like circular dependencies and orphaned files.",
      "category": "component"
    },
    {
      "title": "AI-Powered Documentation Generator",
      "description": "Leverages language models to transform raw code structure into human-readable documentation explaining what code does from a user perspective. Generates product overviews, feature descriptions, and architectural summaries.",
      "category": "feature"
    },
    {
      "title": "Test Generation System",
      "description": "Creates comprehensive automated testing workflows including test environment detection, test plan creation, test code generation, execution, validation, and automatic fixing of failing tests. Supports multiple test frameworks like Jest, Mocha, pytest, and JUnit.",
      "category": "feature"
    },
    {
      "title": "Insights and Recommendations Engine",
      "description": "Analyzes code quality, complexity, organization, and structure to generate actionable recommendations for improvements. Identifies refactoring opportunities, test coverage gaps, and code smell patterns.",
      "category": "feature"
    },
    {
      "title": "Code Quality Diagnostics",
      "description": "Displays code quality issues, warnings, and suggestions directly in the VS Code Problems panel. Categorizes diagnostics by severity and provides navigation to problem locations.",
      "category": "feature"
    },
    {
      "title": "Architecture Insights Viewer",
      "description": "Interactive tree view for browsing AI-generated architectural analysis of the codebase. Shows module structure, component relationships, and system design patterns.",
      "category": "feature"
    },
    {
      "title": "Analysis Tree Navigator",
      "description": "Hierarchical view of code analysis results showing statistics, files, functions, and entry points. Enables users to explore code structure and navigate to specific code locations.",
      "category": "feature"
    },
    {
      "title": "Product Documentation Generator",
      "description": "Creates comprehensive product documentation describing application features, user workflows, problems solved, and technical architecture. Formats documentation as structured markdown with timestamped versions.",
      "category": "feature"
    },
    {
      "title": "Refactoring Report Builder",
      "description": "Generates detailed refactoring recommendations for large or complex files. Provides extraction plans, migration guidance, and step-by-step instructions for safely restructuring code.",
      "category": "feature"
    },
    {
      "title": "Test Plan Creator",
      "description": "Analyzes codebase to determine which functions need testing and creates prioritized test plans. Evaluates testability based on complexity, dependencies, and existing test coverage.",
      "category": "feature"
    },
    {
      "title": "Test Execution and Validation",
      "description": "Runs generated tests, captures results including pass/fail status and error messages, and automatically attempts to fix failing tests through iterative AI-powered refinement.",
      "category": "workflow"
    },
    {
      "title": "File System Watcher",
      "description": "Monitors workspace for file changes including creation, modification, and deletion. Triggers automatic re-analysis when files are saved if auto-analysis is enabled.",
      "category": "component"
    },
    {
      "title": "Rate Limiter for AI Requests",
      "description": "Enforces provider-specific API rate limits to prevent quota exhaustion. Automatically queues requests when approaching limits and throttles according to OpenAI (60 req/min) or Claude (50 req/min) constraints.",
      "category": "component"
    },
    {
      "title": "Response Parser for AI Outputs",
      "description": "Extracts structured data from AI-generated text responses. Handles both JSON and natural language outputs, providing fallback text parsing when structured data is unavailable.",
      "category": "component"
    },
    {
      "title": "Configuration Manager",
      "description": "Centralizes all extension settings including enable/disable controls, auto-analysis behavior, diagnostic display preferences, AI provider selection, and performance tuning parameters. Propagates configuration changes to dependent components in real-time.",
      "category": "component"
    },
    {
      "title": "Navigation Handler",
      "description": "Manages navigation between analysis results and source code locations. Opens files, positions editor view, highlights relevant code sections, and displays detailed information in webview panels.",
      "category": "component"
    },
    {
      "title": "Progress Notification Service",
      "description": "Displays progress indicators during long-running operations like analysis, test generation, and AI requests. Supports cancellation for interruptible operations.",
      "category": "component"
    },
    {
      "title": "Analysis Context Builder",
      "description": "Transforms code analysis results into structured format optimized for AI processing. Persists analysis data to workspace directory for reuse across sessions.",
      "category": "component"
    },
    {
      "title": "Incremental Analysis Service",
      "description": "Manages iterative AI analysis where the language model can progressively request additional files or grep searches until sufficient information is gathered for completion.",
      "category": "workflow"
    },
    {
      "title": "Test Configuration Detector",
      "description": "Automatically identifies test frameworks in use, validates configuration, and detects missing dependencies. Ensures generated tests can execute without manual setup.",
      "category": "component"
    }
  ],
  "relevantFunctions": [
    {
      "name": "analyzeCodebase",
      "description": "Performs comprehensive code analysis across all workspace files, extracting functions, dependencies, complexity metrics, and structural patterns",
      "file": "src/analyzer.ts",
      "module": "analyzer"
    },
    {
      "name": "generateInsights",
      "description": "Creates actionable code quality insights by analyzing code structure, complexity, and organization patterns",
      "file": "src/insightGenerator.ts",
      "module": "insightGenerator"
    },
    {
      "name": "generateProductDocumentation",
      "description": "Leverages AI to create comprehensive product documentation from code analysis results",
      "file": "src/llmIntegration.ts",
      "module": "llmIntegration"
    },
    {
      "name": "generateArchitectureInsights",
      "description": "Uses AI to analyze codebase architecture and generate high-level architectural insights",
      "file": "src/llmIntegration.ts",
      "module": "llmIntegration"
    },
    {
      "name": "createTestPlan",
      "description": "Analyzes functions to determine testability and creates prioritized test generation plans",
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "module": "llmTestPlanningService"
    },
    {
      "name": "generateTests",
      "description": "Creates test code for functions using AI, executing tests in small batches with validation",
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "module": "llmTestGenerationService"
    },
    {
      "name": "validateTests",
      "description": "Executes generated tests, detects failures, and automatically fixes failing tests through iterative refinement",
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "module": "llmTestValidationService"
    },
    {
      "name": "navigateToLocation",
      "description": "Opens files in the editor and positions cursor at specific code locations from analysis results",
      "file": "src/domain/handlers/navigationHandler.ts",
      "module": "navigationHandler"
    },
    {
      "name": "buildPromptForAnalysis",
      "description": "Constructs specialized prompts that guide AI interactions for code analysis tasks",
      "file": "src/domain/prompts/promptBuilder.ts",
      "module": "promptBuilder"
    },
    {
      "name": "parseAnalysisResponse",
      "description": "Extracts structured data from AI text responses, handling both JSON and natural language outputs",
      "file": "src/ai/llmResponseParser.ts",
      "module": "llmResponseParser"
    },
    {
      "name": "enforceRateLimit",
      "description": "Throttles AI API requests to prevent quota exhaustion based on provider-specific limits",
      "file": "src/ai/llmRateLimiter.ts",
      "module": "llmRateLimiter"
    },
    {
      "name": "processFileChanges",
      "description": "Handles file system change events and triggers appropriate analysis updates",
      "file": "src/domain/services/fileWatcherService.ts",
      "module": "fileWatcherService"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "AnalysisResult",
      "description": "Represents complete code analysis output including file metrics, functions, dependencies, entry points, and code relationships",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FileAnalysis",
      "description": "Contains detailed analysis of a single file including functions, imports, exports, complexity metrics, and test mappings",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FunctionInfo",
      "description": "Describes a function including name, signature, location, complexity, dependencies, and behavioral metadata",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "CodeInsight",
      "description": "Represents an actionable code quality recommendation with severity, category, description, and affected locations",
      "type": "interface",
      "file": "src/insightGenerator.ts"
    },
    {
      "name": "ProductDocumentation",
      "description": "Structured product documentation including overview, features, user perspectives, architecture, and examples",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "TestPlan",
      "description": "Organized plan for test generation including functions to test, priorities, testability assessments, and generation strategy",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestResult",
      "description": "Results from test execution including pass/fail status, error messages, stack traces, and execution timing",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestSetupPlan",
      "description": "Configuration plan for test environment including framework detection, required dependencies, and setup instructions",
      "type": "interface",
      "file": "src/domain/services/testing/types/testSetupTypes.ts"
    },
    {
      "name": "AnalysisTreeItem",
      "description": "Tree view item representing a node in the analysis hierarchy for display in VS Code sidebar",
      "type": "class",
      "file": "src/analysisViewer.ts"
    },
    {
      "name": "InsightTreeItem",
      "description": "Tree view item representing an insight or recommendation for display in the insights panel",
      "type": "class",
      "file": "src/insightsTreeView.ts"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Main entry point that initializes the extension and orchestrates all features when VS Code activates",
      "purpose": "Bootstraps all extension components including analyzers, tree views, diagnostics, file watchers, and command handlers",
      "role": "Entry point and orchestration"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Core analysis engine that scans code files to extract functions, dependencies, complexity metrics, and structural information",
      "purpose": "Performs comprehensive static code analysis across the workspace",
      "role": "Core analysis engine"
    },
    {
      "path": "src/insightGenerator.ts",
      "description": "Generates actionable code quality insights by analyzing patterns like complexity, large files, orphaned code, and circular dependencies",
      "purpose": "Creates recommendations for code improvements based on analysis results",
      "role": "Insight generation"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "Coordinates AI-powered features including documentation generation, architecture insights, and refactoring recommendations",
      "purpose": "Integrates language models into the analysis workflow for semantic understanding",
      "role": "AI integration orchestration"
    },
    {
      "path": "src/llmService.ts",
      "description": "Provides AI services for generating documentation, insights, test plans, and refactoring guidance using language models",
      "purpose": "Handles all interactions with AI providers for analysis enrichment",
      "role": "AI service layer"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Generates automated tests using AI in small batches with execution and validation",
      "purpose": "Creates test code for functions identified in test plans",
      "role": "Test generation workflow"
    },
    {
      "path": "src/domain/services/testing/llmTestPlanningService.ts",
      "description": "Creates prioritized test plans by analyzing which functions need testing and determining test strategy",
      "purpose": "Plans test generation workflow based on complexity and coverage analysis",
      "role": "Test planning"
    },
    {
      "path": "src/analysisViewer.ts",
      "description": "Provides interactive tree view displaying analysis hierarchy including files, functions, and metrics",
      "purpose": "Enables users to explore code structure through visual tree navigation",
      "role": "UI component for analysis browsing"
    },
    {
      "path": "src/insightsTreeView.ts",
      "description": "Displays AI-generated insights, recommendations, and documentation in an interactive sidebar panel",
      "purpose": "Presents code quality insights and documentation to users",
      "role": "UI component for insights display"
    },
    {
      "path": "src/diagnosticsProvider.ts",
      "description": "Manages code quality diagnostics displayed in the VS Code Problems panel",
      "purpose": "Shows warnings and suggestions alongside native VS Code diagnostics",
      "role": "Diagnostics integration"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Handles navigation from analysis results to source code locations with highlighting and detailed information display",
      "purpose": "Enables instant jumps from analysis views to corresponding code",
      "role": "Navigation management"
    },
    {
      "path": "src/domain/prompts/promptBuilder.ts",
      "description": "Constructs specialized prompts for all AI-powered analysis tasks",
      "purpose": "Guides AI interactions to produce consistent, structured analysis results",
      "role": "Prompt engineering"
    }
  ],
  "exampleInput": {
    "description": "Example analysis context passed to AI for generating product documentation, showing how code analysis results are structured for AI processing",
    "json": "{\"stats\":{\"totalFiles\":65,\"totalLines\":25156,\"averageComplexity\":8.3},\"entryPoints\":[{\"file\":\"src/extension.ts\",\"function\":\"activate\",\"type\":\"extension_entry\"}],\"files\":[{\"path\":\"src/analyzer.ts\",\"purpose\":\"Core code analysis engine\",\"exports\":[\"analyzeCodebase\",\"AnalysisResult\"],\"complexity\":12.4},{\"path\":\"src/llmService.ts\",\"purpose\":\"AI service integration\",\"exports\":[\"generateDocumentation\",\"createTestPlan\"],\"complexity\":15.7}],\"dependencies\":{\"src/analyzer.ts\":[\"typescript\",\"@typescript-eslint/parser\"],\"src/llmService.ts\":[\"openai\",\"@anthropic-ai/sdk\"]},\"insights\":[{\"type\":\"large_file\",\"severity\":\"warning\",\"file\":\"src/llmIntegration.ts\",\"message\":\"File has 2849 lines - consider refactoring\",\"recommendation\":\"Split into smaller modules\"}]}"
  },
  "exampleOutput": {
    "description": "Example product documentation output generated by AI from code analysis, showing the structured documentation format returned to users",
    "json": "{\"overview\":\"Shadow Watch is an AI-powered VS Code extension that automatically analyzes codebases to generate documentation and insights...\",\"whatItDoes\":[\"Automatically analyzes code structure\",\"Generates human-readable documentation\",\"Creates test plans and generates tests\"],\"userPerspective\":{\"gui\":[\"Interactive sidebar tree views\",\"Problems panel diagnostics\",\"Webview documentation browser\"],\"cli\":[],\"api\":[],\"cicd\":[]},\"architecture\":\"Shadow Watch follows a layered architecture with domain services, infrastructure components, and presentation layers...\",\"titles\":[\"Code Analysis Engine\",\"AI Documentation Generator\",\"Test Generation System\"],\"descriptions\":[{\"title\":\"Code Analysis Engine\",\"description\":\"Scans source code to extract structural information\",\"category\":\"component\"}],\"relevantFunctions\":[{\"name\":\"analyzeCodebase\",\"description\":\"Performs comprehensive code analysis\",\"file\":\"src/analyzer.ts\"}],\"relevantDataStructures\":[{\"name\":\"AnalysisResult\",\"description\":\"Complete code analysis output\",\"type\":\"interface\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main entry point\",\"purpose\":\"Bootstraps extension\"}]}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Configures the Jest testing framework for TypeScript-based unit tests",
        "Enables developers to run automated tests to verify code functionality",
        "Provides test environment setup for quality assurance workflows"
      ],
      "summary": "This module provides the Jest testing framework configuration for the project. It sets up the testing environment specifically for TypeScript-based unit tests, enabling developers to write and execute automated tests that verify code functionality and prevent regressions.\n\nAs a development infrastructure component, this module does not expose user-facing features directly. Instead, it supports developers in maintaining code quality by providing a configured testing environment. The configuration determines how tests are discovered, executed, and reported, ensuring consistent test behavior across the development team.\n\nDevelopers interact with this configuration indirectly when running test commands (typically 'npm test' or 'jest'), which use these settings to execute the test suite. The module ensures that TypeScript files are properly transformed and tested, supporting the overall development workflow and continuous integration processes.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest test framework for running TypeScript unit tests in the project",
          "userVisibleActions": [
            "No direct user-facing actions - this is a development configuration file"
          ],
          "developerVisibleActions": [
            "Run tests using Jest with 'npm test' or 'jest' command",
            "View test results from files matching '**/*.test.ts' or '**/*.spec.ts' patterns",
            "Generate code coverage reports in text, lcov, and HTML formats",
            "Tests run with a 10-second timeout per test",
            "TypeScript files are automatically compiled and tested without manual build step",
            "Code coverage collected from all source files except type definitions, test files, and mocks",
            "VSCode module is automatically mocked for testing extension code"
          ],
          "keyFunctions": [
            {
              "name": "preset",
              "desc": "Uses ts-jest preset to enable TypeScript testing",
              "inputs": "Configuration string",
              "outputs": "Jest configuration with TypeScript support"
            },
            {
              "name": "testMatch",
              "desc": "Defines which files are recognized as test files",
              "inputs": "Array of glob patterns",
              "outputs": "Matches *.test.ts and *.spec.ts files"
            },
            {
              "name": "transform",
              "desc": "Configures TypeScript compilation for test files",
              "inputs": "TypeScript files with ES2020 target",
              "outputs": "Compiled JavaScript executable by Jest"
            },
            {
              "name": "collectCoverageFrom",
              "desc": "Specifies which files to include in coverage reports",
              "inputs": "Array of glob patterns",
              "outputs": "Coverage data excluding mocks, tests, and type definitions"
            },
            {
              "name": "moduleNameMapper",
              "desc": "Maps vscode module imports to mock implementation",
              "inputs": "Module path mappings",
              "outputs": "Mocked vscode module for testing"
            }
          ],
          "dependencies": [
            "ts-jest",
            "jest"
          ],
          "intent": "Provides a complete Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to write and run unit tests with proper TypeScript compilation, code coverage reporting, and VSCode API mocking",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest test framework for running TypeScript unit tests in the project\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this is a development configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run tests using Jest with 'npm test' or 'jest' command\",\n    \"View test results from files matching '**/*.test.ts' or '**/*.spec.ts' patterns\",\n    \"Generate code coverage reports in text, lcov, and HTML formats\",\n    \"Tests run with a 10-second timeout per test\",\n    \"TypeScript files are automatically compiled and tested without manual build step\",\n    \"Code coverage collected from all source files except type definitions, test files, and mocks\",\n    \"VSCode module is automatically mocked for testing extension code\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"preset\",\n      \"desc\": \"Uses ts-jest preset to enable TypeScript testing\",\n      \"inputs\": \"Configuration string\",\n      \"outputs\": \"Jest configuration with TypeScript support\"\n    },\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Defines which files are recognized as test files\",\n      \"inputs\": \"Array of glob patterns\",\n      \"outputs\": \"Matches *.test.ts and *.spec.ts files\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Configures TypeScript compilation for test files\",\n      \"inputs\": \"TypeScript files with ES2020 target\",\n      \"outputs\": \"Compiled JavaScript executable by Jest\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which files to include in coverage reports\",\n      \"inputs\": \"Array of glob patterns\",\n      \"outputs\": \"Coverage data excluding mocks, tests, and type definitions\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Maps vscode module imports to mock implementation\",\n      \"inputs\": \"Module path mappings\",\n      \"outputs\": \"Mocked vscode module for testing\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\"\n  ],\n  \"intent\": \"Provides a complete Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to write and run unit tests with proper TypeScript compilation, code coverage reporting, and VSCode API mocking\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Automatic rate limiting for LLM API requests across multiple providers (OpenAI, Claude)",
        "Intelligent retry handling with exponential backoff for failed API requests",
        "Structured parsing of AI-generated documentation into typed objects",
        "Transparent error recovery without user intervention for temporary failures",
        "Provider-specific rate limit enforcement (OpenAI: 60 requests/min, Claude: 50 requests/min)",
        "Fallback text parsing when AI returns non-JSON responses"
      ],
      "summary": "This module provides the core infrastructure for reliable and efficient communication with LLM providers. It ensures that all AI requests are automatically throttled to stay within API quotas, handles transient failures gracefully through automatic retries, and transforms raw AI responses into structured, typed documentation objects.\n\nWhen users trigger AI-powered documentation generation, this module works behind the scenes to manage the request lifecycle. Rate limiting prevents API quota exhaustion by enforcing provider-specific request limits, while the retry handler automatically recovers from temporary failures like rate limit errors or timeouts using exponential backoff. The response parser then converts AI-generated text into organized documentation structures for file summaries, module summaries, insights, and product documentation.\n\nThe user experience is seamless: requests are automatically queued when rate limits are approached, failures are retried transparently, and only non-recoverable errors surface to the user after all retry attempts are exhausted. This creates a reliable AI documentation pipeline that handles the complexities of API management, allowing users to focus on generating high-quality documentation without worrying about API limits or transient errors.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Manages rate limiting for LLM API requests to prevent exceeding provider API quotas",
          "userVisibleActions": [
            "API requests to OpenAI and Claude are automatically throttled to stay within rate limits",
            "Requests that would exceed rate limits are prevented from being sent",
            "Different rate limits are enforced for different LLM providers (OpenAI: 60/min, Claude: 50/min)"
          ],
          "developerVisibleActions": [
            "Check if an API request is allowed before making it using canMakeRequest()",
            "Record successful API requests with recordRequest() to track usage",
            "Configure custom rate limits for providers using configure()",
            "Track request history per provider automatically",
            "Get automatic cleanup of old request timestamps outside the time window"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes rate limiter with default limits for OpenAI (60/min) and Claude (50/min)",
              "inputs": "none",
              "outputs": "RateLimiter instance"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limit configuration for a specific LLM provider",
              "inputs": "provider (LLMProvider), config (RateLimitConfig with maxRequests and windowMs)",
              "outputs": "void"
            },
            {
              "name": "canMakeRequest",
              "desc": "Checks if a new request is allowed based on current rate limit status",
              "inputs": "provider (LLMProvider)",
              "outputs": "boolean - true if request can be made, false if rate limit would be exceeded"
            },
            {
              "name": "recordRequest",
              "desc": "Records a request timestamp for rate limiting tracking",
              "inputs": "provider (LLMProvider)",
              "outputs": "void"
            }
          ],
          "dependencies": [],
          "intent": "This file exists to protect against exceeding API rate limits from LLM providers (OpenAI and Claude) by tracking request frequency and enforcing configurable throttling windows, preventing API errors and potential service disruptions",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages rate limiting for LLM API requests to prevent exceeding provider API quotas\",\n  \"userVisibleActions\": [\n    \"API requests to OpenAI and Claude are automatically throttled to stay within rate limits\",\n    \"Requests that would exceed rate limits are prevented from being sent\",\n    \"Different rate limits are enforced for different LLM providers (OpenAI: 60/min, Claude: 50/min)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Check if an API request is allowed before making it using canMakeRequest()\",\n    \"Record successful API requests with recordRequest() to track usage\",\n    \"Configure custom rate limits for providers using configure()\",\n    \"Track request history per provider automatically\",\n    \"Get automatic cleanup of old request timestamps outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits for OpenAI (60/min) and Claude (50/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (LLMProvider), config (RateLimitConfig with maxRequests and windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on current rate limit status\",\n      \"inputs\": \"provider (LLMProvider)\",\n      \"outputs\": \"boolean - true if request can be made, false if rate limit would be exceeded\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a request timestamp for rate limiting tracking\",\n      \"inputs\": \"provider (LLMProvider)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to protect against exceeding API rate limits from LLM providers (OpenAI and Claude) by tracking request frequency and enforcing configurable throttling windows, preventing API errors and potential service disruptions\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).",
          "userVisibleActions": [
            "Converts raw AI-generated text responses into organized documentation",
            "Extracts file purposes and actions from AI analysis",
            "Generates structured module and product documentation from AI responses",
            "Provides fallback text parsing when AI returns non-JSON responses"
          ],
          "developerVisibleActions": [
            "Call parseFileSummary() to convert LLM response into FileSummary object",
            "Call parseModuleSummary() to extract module-level documentation from LLM text",
            "Call parseInsights() to structure AI-generated insights about codebase",
            "Call parseProductDocumentation() to build comprehensive product docs from LLM output",
            "Call parsePurposeAnalysis() to extract product purpose analysis",
            "Handles both JSON and plain text LLM response formats automatically",
            "Returns typed TypeScript objects with fallback values for missing data"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into a FileSummary object with purpose, actions, and dependencies",
              "inputs": "content (LLM response text), filePath (string), role (string)",
              "outputs": "FileSummary object"
            },
            {
              "name": "parseModuleSummary",
              "desc": "Extracts module-level documentation including purpose, features, and structure from LLM response",
              "inputs": "content (LLM response text), moduleName (string)",
              "outputs": "ModuleSummary object"
            },
            {
              "name": "parseInsights",
              "desc": "Structures AI insights about the codebase into categories like architecture patterns and improvement areas",
              "inputs": "content (LLM response text), context (AnalysisContext)",
              "outputs": "LLMInsights object"
            },
            {
              "name": "parseProductDocumentation",
              "desc": "Builds comprehensive product documentation from LLM analysis including overview, features, and use cases",
              "inputs": "content (LLM response text)",
              "outputs": "EnhancedProductDocumentation object"
            },
            {
              "name": "parsePurposeAnalysis",
              "desc": "Extracts product purpose analysis including main purpose, target audience, and value proposition",
              "inputs": "content (LLM response text)",
              "outputs": "ProductPurposeAnalysis object"
            },
            {
              "name": "extractSection",
              "desc": "Helper that pulls out a specific labeled section from unstructured text",
              "inputs": "content (text), sectionName (string)",
              "outputs": "Extracted section text or empty string"
            },
            {
              "name": "extractListSection",
              "desc": "Helper that extracts bullet points or list items from a text section",
              "inputs": "content (text), sectionName (string)",
              "outputs": "Array of list items"
            }
          ],
          "dependencies": [
            "../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)",
            "../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)"
          ],
          "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.",
          "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).\",\n  \"userVisibleActions\": [\n    \"Converts raw AI-generated text responses into organized documentation\",\n    \"Extracts file purposes and actions from AI analysis\",\n    \"Generates structured module and product documentation from AI responses\",\n    \"Provides fallback text parsing when AI returns non-JSON responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM response into FileSummary object\",\n    \"Call parseModuleSummary() to extract module-level documentation from LLM text\",\n    \"Call parseInsights() to structure AI-generated insights about codebase\",\n    \"Call parseProductDocumentation() to build comprehensive product docs from LLM output\",\n    \"Call parsePurposeAnalysis() to extract product purpose analysis\",\n    \"Handles both JSON and plain text LLM response formats automatically\",\n    \"Returns typed TypeScript objects with fallback values for missing data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object with purpose, actions, and dependencies\",\n      \"inputs\": \"content (LLM response text), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level documentation including purpose, features, and structure from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName (string)\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseInsights\",\n      \"desc\": \"Structures AI insights about the codebase into categories like architecture patterns and improvement areas\",\n      \"inputs\": \"content (LLM response text), context (AnalysisContext)\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Builds comprehensive product documentation from LLM analysis including overview, features, and use cases\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parsePurposeAnalysis\",\n      \"desc\": \"Extracts product purpose analysis including main purpose, target audience, and value proposition\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Helper that pulls out a specific labeled section from unstructured text\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Extracted section text or empty string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Helper that extracts bullet points or list items from a text section\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Array of list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)\",\n    \"../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors",
          "userVisibleActions": [
            "Automatic retry when AI requests fail due to rate limits or temporary issues",
            "Delayed retry attempts that increase wait time between retries",
            "Transparent error recovery without user intervention for recoverable errors",
            "Final error display only after all retry attempts are exhausted"
          ],
          "developerVisibleActions": [
            "Configure maximum number of retry attempts for LLM requests",
            "Set initial delay and maximum delay between retries",
            "Define which error types should trigger automatic retries",
            "Receive callbacks on each retry attempt for logging or monitoring",
            "Execute any async LLM operation with automatic retry handling",
            "Get result with attempt count after successful retry",
            "Handle non-retryable errors immediately without retry attempts"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an LLM operation with automatic retry on failure",
              "inputs": "operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)",
              "outputs": "Promise resolving to the operation result, or throws error after all retries exhausted"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines if an error should trigger a retry attempt",
              "inputs": "error object, list of retryable error patterns",
              "outputs": "Boolean indicating whether the error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors\",\n  \"userVisibleActions\": [\n    \"Automatic retry when AI requests fail due to rate limits or temporary issues\",\n    \"Delayed retry attempts that increase wait time between retries\",\n    \"Transparent error recovery without user intervention for recoverable errors\",\n    \"Final error display only after all retry attempts are exhausted\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum number of retry attempts for LLM requests\",\n    \"Set initial delay and maximum delay between retries\",\n    \"Define which error types should trigger automatic retries\",\n    \"Receive callbacks on each retry attempt for logging or monitoring\",\n    \"Execute any async LLM operation with automatic retry handling\",\n    \"Get result with attempt count after successful retry\",\n    \"Handle non-retryable errors immediately without retry attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an LLM operation with automatic retry on failure\",\n      \"inputs\": \"operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)\",\n      \"outputs\": \"Promise resolving to the operation result, or throws error after all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry attempt\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"Boolean indicating whether the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Switch between multiple AI provider backends (OpenAI GPT and Anthropic Claude) seamlessly",
        "Send natural language prompts to AI models and receive intelligent text responses",
        "Request and receive structured JSON data from AI for parsed information extraction",
        "Experience consistent AI-powered features regardless of which provider is active",
        "Get timeout protection with automatic 5-minute maximum wait time for AI responses",
        "Receive clear error messages when API keys are not configured"
      ],
      "summary": "This module provides a unified interface for interacting with multiple AI language model providers within the extension. Users can leverage AI capabilities powered by either OpenAI's GPT models or Anthropic's Claude models without needing to know which backend is being used. The module abstracts away provider-specific implementation details and presents a consistent experience across different AI services.\n\nUsers can send code-related queries and receive intelligent AI-generated responses for tasks like code explanation, refactoring suggestions, documentation generation, and other code analysis features. The module supports both conversational text responses and structured JSON outputs for data extraction tasks. A factory pattern manages provider instances, allowing users to switch between AI providers while maintaining the same workflow and user experience.\n\nThe module includes built-in safety features like timeout protection to prevent indefinite waits and clear error messaging when API credentials are missing or misconfigured. This ensures users have a reliable and predictable experience when using AI-powered features throughout the extension.",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines a standard interface for interacting with different AI language model providers (OpenAI, Claude, custom providers) in a unified way",
          "userVisibleActions": [
            "User receives AI-generated text responses to their queries",
            "User receives structured JSON data from AI for parsed information",
            "User may experience different response formats (text or JSON) depending on request type"
          ],
          "developerVisibleActions": [
            "Developer can check if an AI provider is configured and ready to use",
            "Developer can send text-based requests to AI and receive string responses",
            "Developer can send requests for structured JSON output with type safety",
            "Developer can specify model, temperature, max tokens, and system prompts for AI requests",
            "Developer can retrieve the provider name to identify which AI service is being used",
            "Developer can pass conversation history with messages in system/user/assistant roles"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if the AI provider has valid credentials and is ready to accept requests",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt to the AI and receives a text response",
              "inputs": "LLMRequestOptions (model, system prompt, messages, max tokens, temperature, response format)",
              "outputs": "LLMResponse containing content string, finish reason, model name, and raw response"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt to the AI and receives parsed JSON data with optional follow-up requests",
              "inputs": "LLMRequestOptions and optional JSON schema",
              "outputs": "StructuredOutputResponse with typed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the identifier of the AI provider",
              "inputs": "none",
              "outputs": "string with provider name"
            }
          ],
          "dependencies": [],
          "intent": "This file exists to abstract away differences between various AI language model providers (OpenAI, Claude, custom services), allowing the rest of the application to interact with any AI provider through a consistent interface without worrying about provider-specific implementation details or API differences",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines a standard interface for interacting with different AI language model providers (OpenAI, Claude, custom providers) in a unified way\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON data from AI for parsed information\",\n    \"User may experience different response formats (text or JSON) depending on request type\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can check if an AI provider is configured and ready to use\",\n    \"Developer can send text-based requests to AI and receive string responses\",\n    \"Developer can send requests for structured JSON output with type safety\",\n    \"Developer can specify model, temperature, max tokens, and system prompts for AI requests\",\n    \"Developer can retrieve the provider name to identify which AI service is being used\",\n    \"Developer can pass conversation history with messages in system/user/assistant roles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the AI provider has valid credentials and is ready to accept requests\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the AI and receives a text response\",\n      \"inputs\": \"LLMRequestOptions (model, system prompt, messages, max tokens, temperature, response format)\",\n      \"outputs\": \"LLMResponse containing content string, finish reason, model name, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to the AI and receives parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema\",\n      \"outputs\": \"StructuredOutputResponse with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier of the AI provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to abstract away differences between various AI language model providers (OpenAI, Claude, custom services), allowing the rest of the application to interact with any AI provider through a consistent interface without worrying about provider-specific implementation details or API differences\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Integrates Anthropic's Claude AI models to provide language model capabilities for code analysis and generation within the extension.",
          "userVisibleActions": [
            "Sends prompts to Claude AI and receives intelligent responses for code-related tasks",
            "Receives structured JSON responses from Claude for data extraction tasks",
            "Experiences Claude AI-powered features like code explanation, refactoring suggestions, and documentation generation",
            "Gets error messages when Claude API key is not configured"
          ],
          "developerVisibleActions": [
            "Configures Claude API key through configuration manager to enable the provider",
            "Sends requests with custom system prompts, conversation history, and model selection",
            "Receives structured or unstructured responses from Claude models",
            "Handles token usage statistics and response metadata",
            "Catches and handles API errors including rate limits, authentication failures, and invalid requests",
            "Uses 'claude-sonnet-4-5' as the default model with 8192 max tokens",
            "Converts OpenAI message format to Claude's format automatically",
            "Extracts JSON from text responses when structured output is requested"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is set up and provider is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt to Claude and returns the AI-generated response",
              "inputs": "LLMRequestOptions with messages, system prompt, model, and max tokens",
              "outputs": "LLMResponse with generated text and usage statistics"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt to Claude expecting a JSON response and extracts structured data",
              "inputs": "LLMRequestOptions with messages and schema information",
              "outputs": "StructuredOutputResponse with parsed JSON data and usage statistics"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Anthropic client with API key from configuration",
              "inputs": "none (reads from config manager)",
              "outputs": "none (initializes client)"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to provide a unified interface for interacting with Anthropic's Claude AI models, handling API authentication, message format conversion, error handling, and response parsing so that other parts of the extension can leverage Claude's capabilities without dealing with API-specific implementation details.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates Anthropic's Claude AI models to provide language model capabilities for code analysis and generation within the extension.\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives intelligent responses for code-related tasks\",\n    \"Receives structured JSON responses from Claude for data extraction tasks\",\n    \"Experiences Claude AI-powered features like code explanation, refactoring suggestions, and documentation generation\",\n    \"Gets error messages when Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configures Claude API key through configuration manager to enable the provider\",\n    \"Sends requests with custom system prompts, conversation history, and model selection\",\n    \"Receives structured or unstructured responses from Claude models\",\n    \"Handles token usage statistics and response metadata\",\n    \"Catches and handles API errors including rate limits, authentication failures, and invalid requests\",\n    \"Uses 'claude-sonnet-4-5' as the default model with 8192 max tokens\",\n    \"Converts OpenAI message format to Claude's format automatically\",\n    \"Extracts JSON from text responses when structured output is requested\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to Claude and returns the AI-generated response\",\n      \"inputs\": \"LLMRequestOptions with messages, system prompt, model, and max tokens\",\n      \"outputs\": \"LLMResponse with generated text and usage statistics\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to Claude expecting a JSON response and extracts structured data\",\n      \"inputs\": \"LLMRequestOptions with messages and schema information\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data and usage statistics\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"none (initializes client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to provide a unified interface for interacting with Anthropic's Claude AI models, handling API authentication, message format conversion, error handling, and response parsing so that other parts of the extension can leverage Claude's capabilities without dealing with API-specific implementation details.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.",
          "userVisibleActions": [
            "Sends chat messages to OpenAI's GPT models and receives AI-generated responses",
            "Receives structured JSON responses from AI when requested",
            "Experiences timeout protection with 5-minute maximum wait time for responses",
            "Gets error messages when OpenAI API key is not configured"
          ],
          "developerVisibleActions": [
            "Configure OpenAI API key through configuration manager to enable the provider",
            "Send chat requests with custom system prompts, messages, and model selection",
            "Request structured JSON outputs with specific schemas",
            "Check if provider is properly configured before use",
            "Receive parsed JSON objects from AI responses",
            "Handle errors when API key is missing or requests fail",
            "Use default GPT-4o model or specify alternative OpenAI models"
          ],
          "keyFunctions": [
            {
              "name": "initialize",
              "desc": "Sets up OpenAI client with API key from configuration",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "isConfigured",
              "desc": "Checks if provider has valid API key and is ready to use",
              "inputs": "None",
              "outputs": "boolean indicating if configured"
            },
            {
              "name": "getName",
              "desc": "Returns provider identifier",
              "inputs": "None",
              "outputs": "string 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends chat completion request to OpenAI and returns response",
              "inputs": "LLMRequestOptions (system prompt, messages, model, response format)",
              "outputs": "Promise<LLMResponse> with content and finish reason"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Sends request expecting structured JSON response conforming to a schema",
              "inputs": "LLMRequestOptions with JSON schema",
              "outputs": "Promise<StructuredOutputResponse> with parsed JSON object"
            }
          ],
          "dependencies": [
            "openai",
            "ILLMProvider",
            "configurationManager",
            "jsonExtractor"
          ],
          "intent": "This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.\",\n  \"userVisibleActions\": [\n    \"Sends chat messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Receives structured JSON responses from AI when requested\",\n    \"Experiences timeout protection with 5-minute maximum wait time for responses\",\n    \"Gets error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager to enable the provider\",\n    \"Send chat requests with custom system prompts, messages, and model selection\",\n    \"Request structured JSON outputs with specific schemas\",\n    \"Check if provider is properly configured before use\",\n    \"Receive parsed JSON objects from AI responses\",\n    \"Handle errors when API key is missing or requests fail\",\n    \"Use default GPT-4o model or specify alternative OpenAI models\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if provider has valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends chat completion request to OpenAI and returns response\",\n      \"inputs\": \"LLMRequestOptions (system prompt, messages, model, response format)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting structured JSON response conforming to a schema\",\n      \"inputs\": \"LLMRequestOptions with JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON object\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Factory that creates and manages AI provider instances (OpenAI, Claude) for the application",
          "userVisibleActions": [
            "Switch between different AI providers (OpenAI or Claude) for generating responses",
            "Receive AI responses from the currently configured provider",
            "Experience consistent AI functionality regardless of which provider is active"
          ],
          "developerVisibleActions": [
            "Request an AI provider instance by name (openai or claude)",
            "Get the currently configured provider from user settings",
            "Check which AI providers have valid API keys configured",
            "Retrieve a list of all properly configured providers",
            "Use singleton pattern - same provider instance is reused across requests"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns a specific AI provider instance by name",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the AI provider that is currently active in configuration",
              "inputs": "none",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks if a specific provider has valid configuration/API key",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "boolean"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns list of all providers that have valid API keys",
              "inputs": "none",
              "outputs": "LLMProvider[] array"
            }
          ],
          "dependencies": [
            "./ILLMProvider",
            "./openAIProvider",
            "./anthropicProvider",
            "../../config/configurationManager"
          ],
          "intent": "Centralizes the creation and management of AI provider instances, allowing the application to support multiple AI services while maintaining a consistent interface. Ensures only one instance of each provider exists (singleton pattern) and provides utilities to check provider availability before use.",
          "rawContent": "```json\n{\n  \"purpose\": \"Factory that creates and manages AI provider instances (OpenAI, Claude) for the application\",\n  \"userVisibleActions\": [\n    \"Switch between different AI providers (OpenAI or Claude) for generating responses\",\n    \"Receive AI responses from the currently configured provider\",\n    \"Experience consistent AI functionality regardless of which provider is active\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request an AI provider instance by name (openai or claude)\",\n    \"Get the currently configured provider from user settings\",\n    \"Check which AI providers have valid API keys configured\",\n    \"Retrieve a list of all properly configured providers\",\n    \"Use singleton pattern - same provider instance is reused across requests\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a specific AI provider instance by name\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently active in configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific provider has valid configuration/API key\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all providers that have valid API keys\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider[] array\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Centralizes the creation and management of AI provider instances, allowing the application to support multiple AI services while maintaining a consistent interface. Ensures only one instance of each provider exists (singleton pattern) and provides utilities to check provider availability before use.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Deep code analysis using AST parsing to understand code structure and behavior",
        "Function-level metadata extraction including signatures, dependencies, and responsibilities",
        "Branch logic and complexity analysis to identify testing gaps",
        "State mutation and side effect detection",
        "Behavioral pattern recognition to understand what code does from a user perspective",
        "Large file refactoring recommendations based on function relationships",
        "Enhanced test coverage suggestions based on actual code paths and complexity"
      ],
      "summary": "The analysis module provides comprehensive code intelligence capabilities that help users understand, refactor, and test their codebase more effectively. It uses AST parsing to extract deep insights about code behavior, function relationships, and structural patterns.\n\nUsers can leverage this module to receive detailed reports about function responsibilities, dependencies, and behavioral characteristics. The module analyzes branching logic, state mutations, and complexity metrics to generate actionable recommendations for test coverage improvements. For large files, it identifies refactoring opportunities by mapping out function relationships and responsibilities, making it easier to split monolithic code into maintainable units.\n\nThe analysis workflow starts with parsing code files to build a structural understanding, then extracts function-level metadata including what each function does, what it depends on, and how it affects system state. This information feeds into recommendation engines that suggest where to add tests, which functions to refactor, and how code behavior impacts the overall system. The module bridges the gap between raw code structure and human-understandable insights about code purpose and quality.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Provides deep code analysis capabilities that extract function metadata, branch logic, dependencies, state mutations, and behavioral patterns from code files using AST parsing.",
          "userVisibleActions": [
            "Receives detailed analysis of code behavior including what functions do and how they interact",
            "Gets information about code complexity and branching logic",
            "Sees enhanced test coverage recommendations based on code structure",
            "Receives behavioral hints about what code does from a user perspective"
          ],
          "developerVisibleActions": [
            "Developer calls analyzeFileMetadata() to get comprehensive function metadata for a file",
            "Developer receives structured data about branches, dependencies, and state mutations",
            "Developer gets AST-based analysis for TypeScript/JavaScript and regex-based fallback for other languages",
            "Developer accesses branch information showing conditional logic and decision points in code",
            "Developer receives dependency profiling showing which modules and functions are imported/used",
            "Developer gets state mutation tracking showing which variables and properties are modified",
            "Developer receives behavioral hints describing what code does from an external perspective",
            "Developer can extract function content between specific line ranges",
            "Developer gets test mapping suggestions for better code coverage"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and behavioral patterns",
              "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
              "outputs": "Promise<Map<string, FunctionMetadata>> - Map of function names to their metadata"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata",
              "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
              "outputs": "Promise<FunctionMetadata> - Detailed function metadata including AST-parsed information"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Provides fallback regex-based analysis for languages that don't have AST parsing support",
              "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
              "outputs": "FunctionMetadata - Basic function metadata extracted via pattern matching"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the source code content of a function between specified line numbers",
              "inputs": "content (string), startLine (number), endLine (number)",
              "outputs": "string - The extracted function source code"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)"
          ],
          "intent": "This file exists to provide sophisticated code understanding capabilities that go beyond basic parsing. It solves the problem of deeply understanding code behavior by extracting not just what functions exist, but how they work (branches), what they depend on (imports), what they change (mutations), and what they do from a behavioral perspective. This enables intelligent test generation, documentation, and code comprehension features.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities that extract function metadata, branch logic, dependencies, state mutations, and behavioral patterns from code files using AST parsing.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code behavior including what functions do and how they interact\",\n    \"Gets information about code complexity and branching logic\",\n    \"Sees enhanced test coverage recommendations based on code structure\",\n    \"Receives behavioral hints about what code does from a user perspective\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls analyzeFileMetadata() to get comprehensive function metadata for a file\",\n    \"Developer receives structured data about branches, dependencies, and state mutations\",\n    \"Developer gets AST-based analysis for TypeScript/JavaScript and regex-based fallback for other languages\",\n    \"Developer accesses branch information showing conditional logic and decision points in code\",\n    \"Developer receives dependency profiling showing which modules and functions are imported/used\",\n    \"Developer gets state mutation tracking showing which variables and properties are modified\",\n    \"Developer receives behavioral hints describing what code does from an external perspective\",\n    \"Developer can extract function content between specific line ranges\",\n    \"Developer gets test mapping suggestions for better code coverage\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and behavioral patterns\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Promise<Map<string, FunctionMetadata>> - Map of function names to their metadata\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"Promise<FunctionMetadata> - Detailed function metadata including AST-parsed information\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for languages that don't have AST parsing support\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata - Basic function metadata extracted via pattern matching\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function between specified line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"string - The extracted function source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)\"\n  ],\n  \"intent\": \"This file exists to provide sophisticated code understanding capabilities that go beyond basic parsing. It solves the problem of deeply understanding code behavior by extracting not just what functions exist, but how they work (branches), what they depend on (imports), what they change (mutations), and what they do from a behavioral perspective. This enables intelligent test generation, documentation, and code comprehension features.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Analyzes functions in large code files to extract detailed information about signatures, dependencies, and responsibilities for refactoring recommendations.",
          "userVisibleActions": [
            "Receives refactoring reports that identify which functions in large files should be split or refactored",
            "Gets function-level insights showing what each function does and what it depends on",
            "Views function responsibilities and their relationships to other code"
          ],
          "developerVisibleActions": [
            "Analyzes functions in files exceeding a size threshold (default 500 lines)",
            "Extracts function signatures, parameters, and return types from TypeScript code",
            "Identifies function dependencies (what other code the function calls)",
            "Identifies function dependents (what other code calls this function)",
            "Determines function responsibilities and purpose",
            "Generates structured FunctionAnalysis objects for each function in large files",
            "Handles analysis failures gracefully with warnings when individual functions cannot be analyzed",
            "Resolves file paths and verifies file existence before analysis"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in files larger than the threshold size",
              "inputs": "codeAnalysis (CodeAnalysis object), largeFileThreshold (optional, default 500 lines)",
              "outputs": "Promise<FunctionAnalysis[]> - array of detailed function analyses"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs detailed analysis on a single function",
              "inputs": "filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)",
              "outputs": "Promise<FunctionAnalysis | null> - detailed function analysis or null if failed"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves and validates the full path to a source file",
              "inputs": "filePath (string), codeAnalysis (CodeAnalysis)",
              "outputs": "string or null - full resolved file path"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to provide deep function-level analysis for refactoring recommendations. When developers work with large files, they need to understand which functions can be safely extracted or refactored. This analyzer inspects each function's signature, what it calls, what calls it, and what it does, enabling intelligent refactoring suggestions that maintain code correctness while improving maintainability.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed information about signatures, dependencies, and responsibilities for refactoring recommendations.\",\n  \"userVisibleActions\": [\n    \"Receives refactoring reports that identify which functions in large files should be split or refactored\",\n    \"Gets function-level insights showing what each function does and what it depends on\",\n    \"Views function responsibilities and their relationships to other code\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes functions in files exceeding a size threshold (default 500 lines)\",\n    \"Extracts function signatures, parameters, and return types from TypeScript code\",\n    \"Identifies function dependencies (what other code the function calls)\",\n    \"Identifies function dependents (what other code calls this function)\",\n    \"Determines function responsibilities and purpose\",\n    \"Generates structured FunctionAnalysis objects for each function in large files\",\n    \"Handles analysis failures gracefully with warnings when individual functions cannot be analyzed\",\n    \"Resolves file paths and verifies file existence before analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files larger than the threshold size\",\n      \"inputs\": \"codeAnalysis (CodeAnalysis object), largeFileThreshold (optional, default 500 lines)\",\n      \"outputs\": \"Promise<FunctionAnalysis[]> - array of detailed function analyses\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"Promise<FunctionAnalysis | null> - detailed function analysis or null if failed\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves and validates the full path to a source file\",\n      \"inputs\": \"filePath (string), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"string or null - full resolved file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep function-level analysis for refactoring recommendations. When developers work with large files, they need to understand which functions can be safely extracted or refactored. This analyzer inspects each function's signature, what it calls, what calls it, and what it does, enabling intelligent refactoring suggestions that maintain code correctness while improving maintainability.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "Automated code analysis and insight generation for understanding codebase architecture and behavior",
        "AI-powered documentation generation that explains what code does from a user perspective",
        "Real-time code quality diagnostics and warnings displayed in VS Code Problems panel",
        "Interactive tree views for browsing analysis results, insights, and documentation",
        "Intelligent file and function navigation based on entry points and dependencies",
        "Test coverage analysis showing which functions have tests and which don't",
        "Code complexity and risk assessment to prioritize maintenance efforts",
        "Orphaned file detection to identify unused code",
        "Duplicate code detection across the codebase",
        "LLM-optimized prompt generation for AI-assisted code analysis",
        "Automatic analysis refresh with intelligent caching (24-hour expiration)",
        "File watching with auto-analysis on save",
        "Pattern-based code search with grep integration",
        "Architecture violation detection and refactoring suggestions"
      ],
      "summary": "This module provides a comprehensive VS Code extension that leverages AI and static analysis to help developers understand, navigate, and improve their codebase. It automatically analyzes code structure, generates human-readable documentation, and surfaces actionable insights about code quality, organization, and architecture. The extension integrates deeply with VS Code's UI through tree views, diagnostics panels, and status bar indicators to provide a seamless experience.\n\nUsers can explore their codebase through multiple interactive views: an Analysis Viewer showing file/function hierarchies, an Insights Tree View displaying AI-generated recommendations, and an Insights Viewer for architecture documentation. The extension automatically detects entry points, maps dependencies, identifies test coverage gaps, and highlights problematic patterns like large files, orphaned code, circular dependencies, and overly complex functions. All analysis results are cached for performance and can be exported or viewed in various formats optimized for different AI assistants.\n\nThe workflow begins when users open a workspace or save files (if auto-analysis is enabled). The extension scans code, generates insights using LLM services, and displays results in sidebar tree views and the Problems panel. Users can click on any insight, file, or function to navigate directly to the relevant code location. The extension also provides specialized commands for generating documentation, creating test plans, and formatting analysis results for AI assistants like ChatGPT or Cursor AI.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view UI in VSCode that displays structured code analysis results including statistics, files, functions, and entry points",
          "userVisibleActions": [
            "View a hierarchical tree of code analysis results in the sidebar",
            "See 'No analysis available' message when no analysis has been run",
            "Browse analysis statistics (total files, functions, entry points, lines of code)",
            "Explore files organized by directory structure",
            "View details about each analyzed file (path, language, line count, function count)",
            "Browse all functions found in the codebase with their locations",
            "See entry points detected in the code",
            "Click on files, functions, or entry points to navigate to their location in the editor",
            "View tooltips with additional context when hovering over tree items",
            "Refresh the analysis view when new analysis results are available"
          ],
          "developerVisibleActions": [
            "TreeDataProvider that integrates with VSCode's tree view API",
            "Receives CodeAnalysis data from the analyzer module",
            "Updates the tree view when setAnalysis() is called with new analysis results",
            "Organizes analysis data into expandable/collapsible tree nodes",
            "Generates AnalysisItem objects representing different types of nodes (statistics, files, functions, directories)",
            "Provides navigation to source code locations when items are clicked",
            "Handles hierarchical data display for nested directory structures",
            "Emits tree data change events to trigger UI updates"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the viewer with new code analysis results and refreshes the display",
              "inputs": "analysis: CodeAnalysis | null",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers the tree view to update and redraw",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the VSCode TreeItem representation for a given analysis item",
              "inputs": "element: AnalysisItem",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node or root items if no element provided",
              "inputs": "element?: AnalysisItem",
              "outputs": "Thenable<AnalysisItem[]>"
            },
            {
              "name": "getRootItems",
              "desc": "Generates top-level tree items (statistics, files, functions, entry points)",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Creates tree items showing analysis statistics (counts and metrics)",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFilesItems",
              "desc": "Generates tree items for files organized by directory structure",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFileDetails",
              "desc": "Returns detailed information about a specific file including functions",
              "inputs": "element: AnalysisItem",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getDirectoryFiles",
              "desc": "Returns files and subdirectories within a directory node",
              "inputs": "element: AnalysisItem",
              "outputs": "AnalysisItem[]"
            }
          ],
          "dependencies": [
            "vscode",
            "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
            "path"
          ],
          "intent": "This file exists to provide a visual, interactive tree-based browser for code analysis results in VSCode, allowing users to explore analyzed code structure (files, functions, entry points) and navigate to specific code locations, solving the problem of presenting complex hierarchical analysis data in an accessible, browsable format",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view UI in VSCode that displays structured code analysis results including statistics, files, functions, and entry points\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"See 'No analysis available' message when no analysis has been run\",\n    \"Browse analysis statistics (total files, functions, entry points, lines of code)\",\n    \"Explore files organized by directory structure\",\n    \"View details about each analyzed file (path, language, line count, function count)\",\n    \"Browse all functions found in the codebase with their locations\",\n    \"See entry points detected in the code\",\n    \"Click on files, functions, or entry points to navigate to their location in the editor\",\n    \"View tooltips with additional context when hovering over tree items\",\n    \"Refresh the analysis view when new analysis results are available\"\n  ],\n  \"developerVisibleActions\": [\n    \"TreeDataProvider that integrates with VSCode's tree view API\",\n    \"Receives CodeAnalysis data from the analyzer module\",\n    \"Updates the tree view when setAnalysis() is called with new analysis results\",\n    \"Organizes analysis data into expandable/collapsible tree nodes\",\n    \"Generates AnalysisItem objects representing different types of nodes (statistics, files, functions, directories)\",\n    \"Provides navigation to source code locations when items are clicked\",\n    \"Handles hierarchical data display for nested directory structures\",\n    \"Emits tree data change events to trigger UI updates\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the viewer with new code analysis results and refreshes the display\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers the tree view to update and redraw\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VSCode TreeItem representation for a given analysis item\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level tree items (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing analysis statistics (counts and metrics)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Generates tree items for files organized by directory structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information about a specific file including functions\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getDirectoryFiles\",\n      \"desc\": \"Returns files and subdirectories within a directory node\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive tree-based browser for code analysis results in VSCode, allowing users to explore analyzed code structure (files, functions, entry points) and navigate to specific code locations, solving the problem of presenting complex hierarchical analysis data in an accessible, browsable format\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Defines data structures and interfaces for representing code analysis results including file metrics, function metadata, dependencies, test mappings, and code relationships",
          "userVisibleActions": [
            "View total file, line, and function counts across the codebase",
            "See list of large files that may need optimization",
            "Identify orphaned files not imported anywhere",
            "Discover entry points into the application",
            "Find duplicate code blocks across the codebase",
            "Review function risk levels (high, medium, low) for maintenance priority",
            "See which functions have test coverage and which don't",
            "View import relationships between files",
            "Identify functions with external dependencies (databases, HTTP, filesystem, etc.)"
          ],
          "developerVisibleActions": [
            "Import and use CodeAnalysis interface to structure analysis results",
            "Access function metadata including parameters, return types, and visibility",
            "Query branch complexity information (if/else, loops, try/catch)",
            "Examine dependency information to understand external service calls",
            "Track state mutations within functions (assignments, modifications, deletions)",
            "Map source files to their corresponding test files",
            "Identify uncovered functions that lack tests",
            "Use AnalysisCache for performance optimization",
            "Access circular dependency detection results",
            "Review similarity scores for duplicate code detection"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main interface representing complete codebase analysis results",
              "inputs": "N/A (interface)",
              "outputs": "Structure containing files, functions, imports, orphans, entry points, duplicates, and optional enhanced metadata"
            },
            {
              "name": "FunctionMetadata",
              "desc": "Detailed metadata about a single function including parameters, branches, dependencies, and risk assessment",
              "inputs": "N/A (interface)",
              "outputs": "Function name, file location, parameters, return type, visibility, branches, dependencies, state mutations, risk level"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source code to test coverage",
              "inputs": "N/A (interface)",
              "outputs": "Source files to test files mapping, functions to test names mapping, list of uncovered functions"
            },
            {
              "name": "DependencyInfo",
              "desc": "Describes external or internal dependencies used by functions",
              "inputs": "N/A (interface)",
              "outputs": "Dependency name, type (db/http/filesystem/etc), whether internal or external, line number"
            },
            {
              "name": "BranchInfo",
              "desc": "Represents control flow branches for complexity analysis",
              "inputs": "N/A (interface)",
              "outputs": "Branch type (if/loop/try/etc), human-readable condition, line number"
            },
            {
              "name": "StateMutationInfo",
              "desc": "Tracks how functions modify state",
              "inputs": "N/A (interface)",
              "outputs": "Target of mutation, mutation type (assign/modify/delete/read), line number"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache"
          ],
          "intent": "This file exists to provide a comprehensive, structured schema for representing static code analysis results. It solves the problem of consistently capturing and communicating code quality metrics, architectural relationships, test coverage, complexity indicators, and maintenance risk factors. It enables other parts of the system to work with a standardized representation of codebase structure and behavior, supporting decisions about refactoring, testing, and code organization.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for representing code analysis results including file metrics, function metadata, dependencies, test mappings, and code relationships\",\n  \"userVisibleActions\": [\n    \"View total file, line, and function counts across the codebase\",\n    \"See list of large files that may need optimization\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points into the application\",\n    \"Find duplicate code blocks across the codebase\",\n    \"Review function risk levels (high, medium, low) for maintenance priority\",\n    \"See which functions have test coverage and which don't\",\n    \"View import relationships between files\",\n    \"Identify functions with external dependencies (databases, HTTP, filesystem, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access function metadata including parameters, return types, and visibility\",\n    \"Query branch complexity information (if/else, loops, try/catch)\",\n    \"Examine dependency information to understand external service calls\",\n    \"Track state mutations within functions (assignments, modifications, deletions)\",\n    \"Map source files to their corresponding test files\",\n    \"Identify uncovered functions that lack tests\",\n    \"Use AnalysisCache for performance optimization\",\n    \"Access circular dependency detection results\",\n    \"Review similarity scores for duplicate code detection\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface representing complete codebase analysis results\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Structure containing files, functions, imports, orphans, entry points, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function including parameters, branches, dependencies, and risk assessment\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Function name, file location, parameters, return type, visibility, branches, dependencies, state mutations, risk level\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Source files to test files mapping, functions to test names mapping, list of uncovered functions\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Describes external or internal dependencies used by functions\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Dependency name, type (db/http/filesystem/etc), whether internal or external, line number\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Represents control flow branches for complexity analysis\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Branch type (if/loop/try/etc), human-readable condition, line number\"\n    },\n    {\n      \"name\": \"StateMutationInfo\",\n      \"desc\": \"Tracks how functions modify state\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Target of mutation, mutation type (assign/modify/delete/read), line number\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file exists to provide a comprehensive, structured schema for representing static code analysis results. It solves the problem of consistently capturing and communicating code quality metrics, architectural relationships, test coverage, complexity indicators, and maintenance risk factors. It enables other parts of the system to work with a standardized representation of codebase structure and behavior, supporting decisions about refactoring, testing, and code organization.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration",
          "userVisibleActions": [
            "Faster workspace analysis on subsequent loads (cached results loaded instantly)",
            "Automatic refresh of analysis after 24 hours to ensure accuracy",
            "Analysis cache cleared when user requests it"
          ],
          "developerVisibleActions": [
            "Extension stores analysis results in .shadowwatch-cache directory",
            "Cache files are automatically created in workspace storage path",
            "Cache entries expire after 24 hours and trigger re-analysis",
            "Failed cache operations fall back gracefully without breaking analysis",
            "Cache can be manually cleared to force fresh analysis"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes cache storage location and ensures directory exists",
              "inputs": "storagePath: string (where to store cache files)",
              "outputs": "AnalysisCache instance"
            },
            {
              "name": "get",
              "desc": "Retrieves cached analysis for a workspace if available and not expired",
              "inputs": "workspaceRoot: string (workspace identifier)",
              "outputs": "Promise<CodeAnalysis | null> (cached data or null if missing/expired)"
            },
            {
              "name": "set",
              "desc": "Saves analysis results to cache with current timestamp",
              "inputs": "workspaceRoot: string, data: CodeAnalysis (analysis to cache)",
              "outputs": "Promise<void>"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis files from storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "getCacheKey",
              "desc": "Generates safe filename from workspace path",
              "inputs": "workspaceRoot: string",
              "outputs": "string (base64-encoded safe filename)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer (CodeAnalysis type)"
          ],
          "intent": "Improves extension performance by caching expensive code analysis results, reducing repeated analysis of unchanged workspaces while ensuring data freshness through automatic expiration",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration\",\n  \"userVisibleActions\": [\n    \"Faster workspace analysis on subsequent loads (cached results loaded instantly)\",\n    \"Automatic refresh of analysis after 24 hours to ensure accuracy\",\n    \"Analysis cache cleared when user requests it\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension stores analysis results in .shadowwatch-cache directory\",\n    \"Cache files are automatically created in workspace storage path\",\n    \"Cache entries expire after 24 hours and trigger re-analysis\",\n    \"Failed cache operations fall back gracefully without breaking analysis\",\n    \"Cache can be manually cleared to force fresh analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache storage location and ensures directory exists\",\n      \"inputs\": \"storagePath: string (where to store cache files)\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis for a workspace if available and not expired\",\n      \"inputs\": \"workspaceRoot: string (workspace identifier)\",\n      \"outputs\": \"Promise<CodeAnalysis | null> (cached data or null if missing/expired)\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis (analysis to cache)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates safe filename from workspace path\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (base64-encoded safe filename)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis type)\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis results, reducing repeated analysis of unchanged workspaces while ensuring data freshness through automatic expiration\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Manages the display of code insights and warnings in the VS Code Problems panel by creating and updating diagnostic markers.",
          "userVisibleActions": [
            "Code insights appear as warnings or errors in the Problems panel",
            "Inline squiggly lines appear under problematic code lines",
            "Clicking on a problem in the Problems panel navigates to the affected code location",
            "Problem markers are grouped by file in the Problems panel",
            "Diagnostics show 'Shadow Watch' as the source in the Problems panel"
          ],
          "developerVisibleActions": [
            "Diagnostics are automatically updated when new insights are generated",
            "All diagnostics are cleared when the diagnostics collection is reset",
            "Diagnostics can be updated for individual files or all files at once",
            "Each diagnostic is linked to an insight ID for traceability",
            "Severity levels (error, warning, info) determine the visual appearance of diagnostics"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Updates all diagnostic markers across all files based on a collection of insights",
              "inputs": "insights: Insight[] - array of code insights to display",
              "outputs": "void - displays diagnostics in Problems panel"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostic markers for a specific file only",
              "inputs": "uri: vscode.Uri - file location, insights: Insight[] - insights for that file",
              "outputs": "void - displays diagnostics for the specified file"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostic markers from the Problems panel",
              "inputs": "none",
              "outputs": "void - clears all displayed diagnostics"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts an insight into a VS Code diagnostic marker with severity, location, and description",
              "inputs": "insight: Insight - the insight to convert",
              "outputs": "vscode.Diagnostic - a VS Code diagnostic object"
            },
            {
              "name": "dispose",
              "desc": "Cleans up and removes the diagnostic collection when no longer needed",
              "inputs": "none",
              "outputs": "void - releases resources"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "This file exists to bridge between the Shadow Watch insight generation system and VS Code's built-in Problems panel, making code insights visible and actionable for users by displaying them as standard IDE diagnostics that users are familiar with.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages the display of code insights and warnings in the VS Code Problems panel by creating and updating diagnostic markers.\",\n  \"userVisibleActions\": [\n    \"Code insights appear as warnings or errors in the Problems panel\",\n    \"Inline squiggly lines appear under problematic code lines\",\n    \"Clicking on a problem in the Problems panel navigates to the affected code location\",\n    \"Problem markers are grouped by file in the Problems panel\",\n    \"Diagnostics show 'Shadow Watch' as the source in the Problems panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Diagnostics are automatically updated when new insights are generated\",\n    \"All diagnostics are cleared when the diagnostics collection is reset\",\n    \"Diagnostics can be updated for individual files or all files at once\",\n    \"Each diagnostic is linked to an insight ID for traceability\",\n    \"Severity levels (error, warning, info) determine the visual appearance of diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostic markers across all files based on a collection of insights\",\n      \"inputs\": \"insights: Insight[] - array of code insights to display\",\n      \"outputs\": \"void - displays diagnostics in Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostic markers for a specific file only\",\n      \"inputs\": \"uri: vscode.Uri - file location, insights: Insight[] - insights for that file\",\n      \"outputs\": \"void - displays diagnostics for the specified file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostic markers from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - clears all displayed diagnostics\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic marker with severity, location, and description\",\n      \"inputs\": \"insight: Insight - the insight to convert\",\n      \"outputs\": \"vscode.Diagnostic - a VS Code diagnostic object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up and removes the diagnostic collection when no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - releases resources\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge between the Shadow Watch insight generation system and VS Code's built-in Problems panel, making code insights visible and actionable for users by displaying them as standard IDE diagnostics that users are familiar with.\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "Main extension entry point that activates and orchestrates all Code Analyzer features, commands, and UI components in VSCode",
          "userVisibleActions": [
            "Analyze code files to generate insights about behavior and dependencies",
            "View generated insights in a tree view sidebar",
            "Generate LLM-optimized prompts for AI code analysis",
            "Navigate to code locations from insights",
            "See real-time diagnostic warnings and errors in files",
            "Get status updates via status bar showing analysis progress",
            "Refresh analysis when files change automatically",
            "Export insights and analysis results",
            "Configure analysis settings through extension settings",
            "See insights organized by entry points, functions, and dependencies"
          ],
          "developerVisibleActions": [
            "Extension activates when VSCode starts or when code analysis commands are triggered",
            "Bootstrapper initializes all core components (analyzer, insight generator, LLM formatter, file watcher, etc.)",
            "Command handlers are registered for all user-triggerable actions",
            "File watcher monitors workspace for code changes and triggers re-analysis",
            "Cache system stores analysis results to avoid redundant processing",
            "Diagnostics provider surfaces code issues in the Problems panel",
            "Tree view provider displays structured insights in the sidebar",
            "Status bar updates to show current analysis state",
            "Error handler catches and displays user-friendly error messages",
            "Configuration manager loads and validates user settings",
            "Navigation handler allows jumping to code locations from insights",
            "Cleanup occurs on extension deactivation to dispose resources"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Initializes the extension when VSCode loads it, sets up all components, registers commands, and starts file watching",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "void"
            },
            {
              "name": "deactivate",
              "desc": "Cleans up resources when the extension is unloaded or disabled",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "ExtensionBootstrapper.initialize",
              "desc": "Creates and wires together all extension components (analyzer, generators, providers, handlers)",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "ExtensionComponents"
            },
            {
              "name": "CommandRegistry.registerAll",
              "desc": "Registers all user-facing commands with VSCode command palette",
              "inputs": "context, components, commandHandlers",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler"
          ],
          "intent": "This file exists to serve as the main entry point for the VSCode extension, orchestrating the initialization, lifecycle management, and coordination of all code analysis features. It solves the problem of bootstrapping a complex multi-component extension by centralizing activation logic, registering commands, and ensuring all parts work together cohesively to provide code analysis and AI-assisted insights to developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Main extension entry point that activates and orchestrates all Code Analyzer features, commands, and UI components in VSCode\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights about behavior and dependencies\",\n    \"View generated insights in a tree view sidebar\",\n    \"Generate LLM-optimized prompts for AI code analysis\",\n    \"Navigate to code locations from insights\",\n    \"See real-time diagnostic warnings and errors in files\",\n    \"Get status updates via status bar showing analysis progress\",\n    \"Refresh analysis when files change automatically\",\n    \"Export insights and analysis results\",\n    \"Configure analysis settings through extension settings\",\n    \"See insights organized by entry points, functions, and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or when code analysis commands are triggered\",\n    \"Bootstrapper initializes all core components (analyzer, insight generator, LLM formatter, file watcher, etc.)\",\n    \"Command handlers are registered for all user-triggerable actions\",\n    \"File watcher monitors workspace for code changes and triggers re-analysis\",\n    \"Cache system stores analysis results to avoid redundant processing\",\n    \"Diagnostics provider surfaces code issues in the Problems panel\",\n    \"Tree view provider displays structured insights in the sidebar\",\n    \"Status bar updates to show current analysis state\",\n    \"Error handler catches and displays user-friendly error messages\",\n    \"Configuration manager loads and validates user settings\",\n    \"Navigation handler allows jumping to code locations from insights\",\n    \"Cleanup occurs on extension deactivation to dispose resources\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension when VSCode loads it, sets up all components, registers commands, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when the extension is unloaded or disabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"ExtensionBootstrapper.initialize\",\n      \"desc\": \"Creates and wires together all extension components (analyzer, generators, providers, handlers)\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents\"\n    },\n    {\n      \"name\": \"CommandRegistry.registerAll\",\n      \"desc\": \"Registers all user-facing commands with VSCode command palette\",\n      \"inputs\": \"context, components, commandHandlers\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file exists to serve as the main entry point for the VSCode extension, orchestrating the initialization, lifecycle management, and coordination of all code analysis features. It solves the problem of bootstrapping a complex multi-component extension by centralizing activation logic, registering commands, and ensuring all parts work together cohesively to provide code analysis and AI-assisted insights to developers.\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and grep search functionality to enable LLM-powered code analysis with iterative file access and pattern matching",
          "userVisibleActions": [
            "Search for code patterns across multiple files using grep",
            "View file contents with line counts",
            "See organized file listings grouped by folder",
            "Get search results with line numbers and surrounding context",
            "Receive limited search results to avoid overwhelming output"
          ],
          "developerVisibleActions": [
            "Request specific files by path with optional reason for transparency",
            "Perform grep searches with optional file patterns (e.g., '*.ts') to filter search scope",
            "Set maximum result limits to control output size",
            "Process file access requests and grep requests through unified interface",
            "Receive structured responses with file metadata (path, lines, existence)",
            "Get grep matches with context lines before and after each match",
            "Track whether search results were truncated due to limits"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Organizes and formats a list of files grouped by their directory paths",
              "inputs": "Array of file objects with path, lines, and language properties",
              "outputs": "Formatted string showing files organized by folder with metadata"
            },
            {
              "name": "readFile",
              "desc": "Reads a file from the workspace and returns its content with metadata",
              "inputs": "File path relative to workspace root",
              "outputs": "FileResponse with content, line count, and existence status"
            },
            {
              "name": "grepFiles",
              "desc": "Searches for a pattern across files with optional filtering and result limiting",
              "inputs": "Search pattern, optional file pattern filter, optional max results limit",
              "outputs": "GrepResponse with matches, context lines, total count, and truncation flag"
            },
            {
              "name": "processRequest",
              "desc": "Handles both file read and grep requests through a unified interface",
              "inputs": "LLMRequest object (FileRequest or GrepRequest)",
              "outputs": "Either FileResponse or GrepResponse depending on request type"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to bridge the gap between LLM code analysis needs and file system access, allowing AI to iteratively explore codebases by reading specific files and searching for patterns without overwhelming the context window, enabling intelligent code understanding through targeted queries",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable LLM-powered code analysis with iterative file access and pattern matching\",\n  \"userVisibleActions\": [\n    \"Search for code patterns across multiple files using grep\",\n    \"View file contents with line counts\",\n    \"See organized file listings grouped by folder\",\n    \"Get search results with line numbers and surrounding context\",\n    \"Receive limited search results to avoid overwhelming output\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path with optional reason for transparency\",\n    \"Perform grep searches with optional file patterns (e.g., '*.ts') to filter search scope\",\n    \"Set maximum result limits to control output size\",\n    \"Process file access requests and grep requests through unified interface\",\n    \"Receive structured responses with file metadata (path, lines, existence)\",\n    \"Get grep matches with context lines before and after each match\",\n    \"Track whether search results were truncated due to limits\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by their directory paths\",\n      \"inputs\": \"Array of file objects with path, lines, and language properties\",\n      \"outputs\": \"Formatted string showing files organized by folder with metadata\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its content with metadata\",\n      \"inputs\": \"File path relative to workspace root\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches for a pattern across files with optional filtering and result limiting\",\n      \"inputs\": \"Search pattern, optional file pattern filter, optional max results limit\",\n      \"outputs\": \"GrepResponse with matches, context lines, total count, and truncation flag\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Handles both file read and grep requests through a unified interface\",\n      \"inputs\": \"LLMRequest object (FileRequest or GrepRequest)\",\n      \"outputs\": \"Either FileResponse or GrepResponse depending on request type\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM code analysis needs and file system access, allowing AI to iteratively explore codebases by reading specific files and searching for patterns without overwhelming the context window, enabling intelligent code understanding through targeted queries\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.",
          "userVisibleActions": [
            "View organized documentation showing what each file does from a user perspective",
            "See categorized actions for GUI, CLI, API, and CI/CD interfaces",
            "Access structured summaries of features and capabilities",
            "Review workflow integration examples and problems solved by the product"
          ],
          "developerVisibleActions": [
            "Define documentation structure using FileSummary, ModuleSummary, and EnhancedProductDocumentation interfaces",
            "Organize code files by role (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface)",
            "Document file purposes, user-visible actions, and developer-visible actions",
            "Structure module capabilities with endpoints, commands, and worker job flows",
            "Create product-level documentation with overview, architecture, and component diagrams"
          ],
          "keyFunctions": [],
          "dependencies": [
            "fs",
            "path",
            "./analyzer (CodeAnalysis, FileInfo types)"
          ],
          "intent": "This file exists to provide a standardized schema for documenting codebases at multiple levels of abstraction (file  module  product), enabling automated documentation generation that separates user-facing behavior from implementation details and organizes information by role and capability.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"View organized documentation showing what each file does from a user perspective\",\n    \"See categorized actions for GUI, CLI, API, and CI/CD interfaces\",\n    \"Access structured summaries of features and capabilities\",\n    \"Review workflow integration examples and problems solved by the product\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define documentation structure using FileSummary, ModuleSummary, and EnhancedProductDocumentation interfaces\",\n    \"Organize code files by role (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface)\",\n    \"Document file purposes, user-visible actions, and developer-visible actions\",\n    \"Structure module capabilities with endpoints, commands, and worker job flows\",\n    \"Create product-level documentation with overview, architecture, and component diagrams\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo types)\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for documenting codebases at multiple levels of abstraction (file  module  product), enabling automated documentation generation that separates user-facing behavior from implementation details and organizes information by role and capability.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file changes and triggers code analysis when files are saved in the workspace.",
          "userVisibleActions": [
            "Automatically analyzes code when a file is saved (if 'analyzeOnSave' setting is enabled)",
            "Displays code insights and diagnostics after file save",
            "Updates insights tree view with latest analysis results",
            "Shows analysis status in output channel"
          ],
          "developerVisibleActions": [
            "Watches document save events in VS Code workspace",
            "Triggers code analysis with configurable debounce delay to avoid excessive analysis",
            "Coordinates between CodeAnalyzer, InsightGenerator, DiagnosticsProvider, and InsightsTreeProvider",
            "Can be started and stopped programmatically to control when analysis occurs",
            "Prevents duplicate analysis when multiple files are saved rapidly",
            "Handles errors during analysis and logs them via ErrorHandler"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins watching for file save events and enables automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops watching file save events and cancels any pending analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save event and schedules analysis with debounce",
              "inputs": "document (TextDocument)",
              "outputs": "void"
            },
            {
              "name": "analyzeFile",
              "desc": "Performs code analysis on a file and updates all providers with results",
              "inputs": "document (TextDocument)",
              "outputs": "Promise<void>"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources and stops the file watcher",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "configurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of keeping code insights synchronized with the latest file changes without requiring manual analysis triggers. It acts as the orchestration layer that connects file system events to the analysis pipeline, ensuring users always see up-to-date insights while preventing performance issues through debouncing and duplicate analysis prevention.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes and triggers code analysis when files are saved in the workspace.\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when a file is saved (if 'analyzeOnSave' setting is enabled)\",\n    \"Displays code insights and diagnostics after file save\",\n    \"Updates insights tree view with latest analysis results\",\n    \"Shows analysis status in output channel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Watches document save events in VS Code workspace\",\n    \"Triggers code analysis with configurable debounce delay to avoid excessive analysis\",\n    \"Coordinates between CodeAnalyzer, InsightGenerator, DiagnosticsProvider, and InsightsTreeProvider\",\n    \"Can be started and stopped programmatically to control when analysis occurs\",\n    \"Prevents duplicate analysis when multiple files are saved rapidly\",\n    \"Handles errors during analysis and logs them via ErrorHandler\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching file save events and cancels any pending analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save event and schedules analysis with debounce\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Performs code analysis on a file and updates all providers with results\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources and stops the file watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of keeping code insights synchronized with the latest file changes without requiring manual analysis triggers. It acts as the orchestration layer that connects file system events to the analysis pipeline, ensuring users always see up-to-date insights while preventing performance issues through debouncing and duplicate analysis prevention.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Generates actionable code quality insights and recommendations by analyzing code structure, complexity, and organization patterns.",
          "userVisibleActions": [
            "Receives warnings about files that are too large (over 500 lines)",
            "Gets alerts about orphaned files that aren't imported anywhere",
            "Sees suggestions to split large files into smaller modules",
            "Receives notifications about missing entry points in the project",
            "Gets warnings about potential circular dependencies between files",
            "Sees alerts about 'god objects' (files with too many responsibilities)",
            "Receives suggestions about dead code that may be unused",
            "Gets recommendations for better file organization",
            "Sees warnings about overly complex functions",
            "Views insights categorized by severity (error, warning, info)",
            "Reads specific suggestions with file paths and line numbers for each issue"
          ],
          "developerVisibleActions": [
            "Pass CodeAnalysis object to generate comprehensive insights across entire codebase",
            "Generate file-specific insights by providing analysis and file path",
            "Receive structured Insight objects with id, title, description, severity, category, file location, and actionable suggestions",
            "Access insights filtered by severity levels (error, warning, info)",
            "Use insights to identify code smells and architectural issues",
            "Get code snippets attached to relevant insights for context",
            "Integrate insights into code review workflows",
            "Track technical debt through categorized insight reports"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Analyzes entire codebase and produces a comprehensive list of code quality insights covering multiple categories",
              "inputs": "CodeAnalysis object containing file and function information",
              "outputs": "Array of Insight objects with recommendations"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Generates targeted insights for a specific file in the codebase",
              "inputs": "CodeAnalysis object and file path string",
              "outputs": "Array of Insight objects specific to that file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Identifies files exceeding recommended line count threshold",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about oversized files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Detects files that are not imported by any other file in the project",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about potentially unused files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Validates presence of required entry points in the project",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Identifies potential circular dependency patterns between files",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about circular dependencies"
            },
            {
              "name": "checkGodObjects",
              "desc": "Detects files with too many responsibilities or excessive complexity",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about god objects"
            },
            {
              "name": "checkDeadCode",
              "desc": "Identifies code that appears to be unused or unreachable",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about potential dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Evaluates project structure and file organization patterns",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about file organization"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Analyzes function complexity metrics to identify overly complex code",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about function complexity"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to transform raw code analysis data into meaningful, actionable recommendations that help developers improve code quality, maintainability, and architecture by identifying anti-patterns, code smells, and organizational issues.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates actionable code quality insights and recommendations by analyzing code structure, complexity, and organization patterns.\",\n  \"userVisibleActions\": [\n    \"Receives warnings about files that are too large (over 500 lines)\",\n    \"Gets alerts about orphaned files that aren't imported anywhere\",\n    \"Sees suggestions to split large files into smaller modules\",\n    \"Receives notifications about missing entry points in the project\",\n    \"Gets warnings about potential circular dependencies between files\",\n    \"Sees alerts about 'god objects' (files with too many responsibilities)\",\n    \"Receives suggestions about dead code that may be unused\",\n    \"Gets recommendations for better file organization\",\n    \"Sees warnings about overly complex functions\",\n    \"Views insights categorized by severity (error, warning, info)\",\n    \"Reads specific suggestions with file paths and line numbers for each issue\"\n  ],\n  \"developerVisibleActions\": [\n    \"Pass CodeAnalysis object to generate comprehensive insights across entire codebase\",\n    \"Generate file-specific insights by providing analysis and file path\",\n    \"Receive structured Insight objects with id, title, description, severity, category, file location, and actionable suggestions\",\n    \"Access insights filtered by severity levels (error, warning, info)\",\n    \"Use insights to identify code smells and architectural issues\",\n    \"Get code snippets attached to relevant insights for context\",\n    \"Integrate insights into code review workflows\",\n    \"Track technical debt through categorized insight reports\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and produces a comprehensive list of code quality insights covering multiple categories\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates targeted insights for a specific file in the codebase\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to that file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count threshold\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Detects files that are not imported by any other file in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about potentially unused files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry points in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Identifies potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Detects files with too many responsibilities or excessive complexity\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Identifies code that appears to be unused or unreachable\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about potential dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file organization patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about file organization\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity metrics to identify overly complex code\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about function complexity\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into meaningful, actionable recommendations that help developers improve code quality, maintainability, and architecture by identifying anti-patterns, code smells, and organizational issues.\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view GUI in VS Code that displays AI-generated insights, documentation, reports, and analysis results for the codebase",
          "userVisibleActions": [
            "View a tree structure showing code insights, documentation status, and analysis reports",
            "Click on 'Product Documentation' node to see documentation generation status and access generated docs",
            "Click on 'AI Insights' node to view AI-generated insights about the codebase",
            "Click on 'Unit Test Analysis' node to see test coverage and recommendations",
            "Click on 'Static Analysis' node to view code quality analysis results",
            "Open generated reports (Workspace Report, Product Documentation Report, Architecture Report, Unit Test Report) by clicking on them",
            "Refresh the tree view to update all insights and reports",
            "See timestamp labels showing when each analysis was last generated",
            "View status indicators (idle, generating, complete) for various analysis tasks",
            "Expand/collapse sections to navigate through different types of insights",
            "See individual insight items with titles, descriptions, and severity indicators"
          ],
          "developerVisibleActions": [
            "Tree view updates automatically when new insights are generated",
            "Persisted state maintains report paths and timestamps across VS Code sessions",
            "Integration with LLM service for AI-generated insights and analysis",
            "Tree items show icons and context values for command registration",
            "Report files are created in workspace .code-insights directory",
            "Tree provider fires change events to refresh the view when data updates",
            "Supports multiple report types: workspace, product docs, architecture, and unit tests",
            "Status tracking for asynchronous generation processes (idle/generating/complete)",
            "File system checks validate report existence before displaying in tree"
          ],
          "keyFunctions": [
            {
              "name": "getTreeItem",
              "desc": "Returns the visual representation of a tree node",
              "inputs": "element: TreeItem",
              "outputs": "TreeItem or Promise<TreeItem>"
            },
            {
              "name": "getChildren",
              "desc": "Returns child nodes for a given tree element to build the tree structure",
              "inputs": "element?: TreeItem",
              "outputs": "Promise<TreeItem[]>"
            },
            {
              "name": "updateInsights",
              "desc": "Updates the displayed insights list and refreshes the tree view",
              "inputs": "insights: Insight[]",
              "outputs": "void"
            },
            {
              "name": "updateLLMInsights",
              "desc": "Updates AI-generated insights and their generation status",
              "inputs": "llmInsights: LLMInsights | null, status: 'idle' | 'generating' | 'complete'",
              "outputs": "void"
            },
            {
              "name": "setReportPath",
              "desc": "Sets the file path for a generated report and updates the tree",
              "inputs": "reportPath: string | null",
              "outputs": "void"
            },
            {
              "name": "setProductDocsStatus",
              "desc": "Updates the status of product documentation generation",
              "inputs": "status: 'idle' | 'generating' | 'complete'",
              "outputs": "void"
            },
            {
              "name": "setAnalysisStatus",
              "desc": "Updates the status of static analysis completion",
              "inputs": "status: 'idle' | 'complete'",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a full refresh of the tree view display",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "loadPersistedState",
              "desc": "Loads previously saved report paths and timestamps from workspace storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "persistState",
              "desc": "Saves current report paths and timestamps to workspace storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "createRootItems",
              "desc": "Creates the top-level tree nodes (Product Docs, AI Insights, Unit Tests, Analysis)",
              "inputs": "none",
              "outputs": "TreeItem[]"
            },
            {
              "name": "createProductDocsChildren",
              "desc": "Creates child nodes showing product documentation status and reports",
              "inputs": "none",
              "outputs": "Promise<TreeItem[]>"
            },
            {
              "name": "createInsightsChildren",
              "desc": "Creates child nodes showing AI insights and workspace reports",
              "inputs": "none",
              "outputs": "Promise<TreeItem[]>"
            },
            {
              "name": "createUnitTestChildren",
              "desc": "Creates child nodes showing unit test analysis results",
              "inputs": "none",
              "outputs": "Promise<TreeItem[]>"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator",
            "./llmFormatter",
            "./llmService"
          ],
          "intent": "This file exists to provide a visual, hierarchical interface in VS Code's sidebar for users to access and navigate through various AI-generated code insights, documentation, test analysis, and reports. It solves the problem of organizing and presenting multiple types of code analysis results in an easily accessible tree structure with persistent state and real-time status updates.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view GUI in VS Code that displays AI-generated insights, documentation, reports, and analysis results for the codebase\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code insights, documentation status, and analysis reports\",\n    \"Click on 'Product Documentation' node to see documentation generation status and access generated docs\",\n    \"Click on 'AI Insights' node to view AI-generated insights about the codebase\",\n    \"Click on 'Unit Test Analysis' node to see test coverage and recommendations\",\n    \"Click on 'Static Analysis' node to view code quality analysis results\",\n    \"Open generated reports (Workspace Report, Product Documentation Report, Architecture Report, Unit Test Report) by clicking on them\",\n    \"Refresh the tree view to update all insights and reports\",\n    \"See timestamp labels showing when each analysis was last generated\",\n    \"View status indicators (idle, generating, complete) for various analysis tasks\",\n    \"Expand/collapse sections to navigate through different types of insights\",\n    \"See individual insight items with titles, descriptions, and severity indicators\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when new insights are generated\",\n    \"Persisted state maintains report paths and timestamps across VS Code sessions\",\n    \"Integration with LLM service for AI-generated insights and analysis\",\n    \"Tree items show icons and context values for command registration\",\n    \"Report files are created in workspace .code-insights directory\",\n    \"Tree provider fires change events to refresh the view when data updates\",\n    \"Supports multiple report types: workspace, product docs, architecture, and unit tests\",\n    \"Status tracking for asynchronous generation processes (idle/generating/complete)\",\n    \"File system checks validate report existence before displaying in tree\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the visual representation of a tree node\",\n      \"inputs\": \"element: TreeItem\",\n      \"outputs\": \"TreeItem or Promise<TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child nodes for a given tree element to build the tree structure\",\n      \"inputs\": \"element?: TreeItem\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights list and refreshes the tree view\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"updateLLMInsights\",\n      \"desc\": \"Updates AI-generated insights and their generation status\",\n      \"inputs\": \"llmInsights: LLMInsights | null, status: 'idle' | 'generating' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and updates the tree\",\n      \"inputs\": \"reportPath: string | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of static analysis completion\",\n      \"inputs\": \"status: 'idle' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a full refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Loads previously saved report paths and timestamps from workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"persistState\",\n      \"desc\": \"Saves current report paths and timestamps to workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"createRootItems\",\n      \"desc\": \"Creates the top-level tree nodes (Product Docs, AI Insights, Unit Tests, Analysis)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"TreeItem[]\"\n    },\n    {\n      \"name\": \"createProductDocsChildren\",\n      \"desc\": \"Creates child nodes showing product documentation status and reports\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"createInsightsChildren\",\n      \"desc\": \"Creates child nodes showing AI insights and workspace reports\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"createUnitTestChildren\",\n      \"desc\": \"Creates child nodes showing unit test analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual, hierarchical interface in VS Code's sidebar for users to access and navigate through various AI-generated code insights, documentation, test analysis, and reports. It solves the problem of organizing and presenting multiple types of code analysis results in an easily accessible tree structure with persistent state and real-time status updates.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VS Code to browse and navigate AI-generated architecture insights about the codebase",
          "userVisibleActions": [
            "View hierarchical tree of architecture insights in the sidebar",
            "Click on insights to navigate to corresponding files",
            "See architecture insights organized by file and section",
            "View documentation insights with descriptions",
            "Click on file items to open files in the editor",
            "Expand/collapse insight categories",
            "View insights automatically updated when files change",
            "See 'No insights available' message when no data exists"
          ],
          "developerVisibleActions": [
            "Tree view automatically refreshes when insights files are modified",
            "Insights are loaded from .shadow/insights.json file",
            "Purpose documentation loaded from .shadow/docs/purpose.json",
            "File system watchers monitor changes to insights and purpose files",
            "Tree view provides navigation to source files via file paths",
            "Insights are structured with parent-child relationships",
            "Can programmatically trigger tree refresh via refresh() method",
            "Supports collapsible tree items with different states"
          ],
          "keyFunctions": [
            {
              "name": "setInsights",
              "desc": "Updates the insights data and refreshes the tree view",
              "inputs": "LLMInsights object containing architecture insights",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a refresh of the tree view display",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the tree item representation for display in VS Code",
              "inputs": "InsightItem",
              "outputs": "vscode.TreeItem or Promise<vscode.TreeItem>"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given parent in the tree hierarchy",
              "inputs": "Optional InsightItem parent",
              "outputs": "Promise<InsightItem[]>"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Establishes file system watchers to auto-refresh when insights change",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file watchers and resources when view is closed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "llmService",
            "path",
            "fs",
            "fileWatcherService"
          ],
          "intent": "This file exists to provide a user-friendly tree view interface for browsing AI-generated architecture insights, making it easy to explore documentation about code structure, file purposes, and architectural decisions directly within VS Code's sidebar with automatic updates when insights change.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code to browse and navigate AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View hierarchical tree of architecture insights in the sidebar\",\n    \"Click on insights to navigate to corresponding files\",\n    \"See architecture insights organized by file and section\",\n    \"View documentation insights with descriptions\",\n    \"Click on file items to open files in the editor\",\n    \"Expand/collapse insight categories\",\n    \"View insights automatically updated when files change\",\n    \"See 'No insights available' message when no data exists\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when insights files are modified\",\n    \"Insights are loaded from .shadow/insights.json file\",\n    \"Purpose documentation loaded from .shadow/docs/purpose.json\",\n    \"File system watchers monitor changes to insights and purpose files\",\n    \"Tree view provides navigation to source files via file paths\",\n    \"Insights are structured with parent-child relationships\",\n    \"Can programmatically trigger tree refresh via refresh() method\",\n    \"Supports collapsible tree items with different states\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data and refreshes the tree view\",\n      \"inputs\": \"LLMInsights object containing architecture insights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display in VS Code\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"vscode.TreeItem or Promise<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given parent in the tree hierarchy\",\n      \"inputs\": \"Optional InsightItem parent\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Establishes file system watchers to auto-refresh when insights change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and resources when view is closed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmService\",\n    \"path\",\n    \"fs\",\n    \"fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide a user-friendly tree view interface for browsing AI-generated architecture insights, making it easy to explore documentation about code structure, file purposes, and architectural decisions directly within VS Code's sidebar with automatic updates when insights change.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different output formats optimized for various AI assistants and human readers.",
          "userVisibleActions": [
            "View architecture issues grouped by severity (Critical/Warnings/Informational)",
            "See issues formatted specifically for Cursor AI with actionable prompts",
            "See issues formatted for ChatGPT with structured analysis sections",
            "View compact summaries of issues by category",
            "Read generic formatted reports with detailed issue breakdowns",
            "See formatted suggestions asking for prioritization and refactoring help",
            "View architecture violations with file locations and suggested fixes"
          ],
          "developerVisibleActions": [
            "Choose between 4 output formats: cursor, chatgpt, compact, or generic",
            "Call formatInsights() with insights array and format preference",
            "Receive markdown-formatted output ready for AI assistant consumption",
            "Get insights automatically grouped by severity levels",
            "Obtain structured reports with severity indicators (, , )",
            "Generate format-specific prompts that guide AI assistant responses",
            "Produce outputs optimized for different AI assistant conversation styles"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Main entry point that routes insights to the appropriate formatter based on specified format",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "string - formatted markdown text"
            },
            {
              "name": "formatForCursor",
              "desc": "Formats insights optimized for Cursor AI with severity grouping and actionable prompts",
              "inputs": "insights: Insight[]",
              "outputs": "string - Cursor-optimized markdown"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Formats insights for ChatGPT with structured sections and conversation-style prompts",
              "inputs": "insights: Insight[]",
              "outputs": "string - ChatGPT-optimized markdown"
            },
            {
              "name": "formatCompact",
              "desc": "Creates a condensed summary of issues grouped by category without detailed formatting",
              "inputs": "insights: Insight[]",
              "outputs": "string - compact markdown summary"
            },
            {
              "name": "formatGeneric",
              "desc": "Produces a standard detailed report suitable for any AI assistant or human reader",
              "inputs": "insights: Insight[]",
              "outputs": "string - generic formatted markdown"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats individual insight with file location, description, and suggested action",
              "inputs": "insight: Insight",
              "outputs": "string - formatted insight block"
            },
            {
              "name": "formatInsightForChatGPT",
              "desc": "Formats individual insight with numbered structure and conversational tone",
              "inputs": "insight: Insight",
              "outputs": "string - formatted insight block"
            },
            {
              "name": "formatInsightCompact",
              "desc": "Formats individual insight as a single line with essential information",
              "inputs": "insight: Insight",
              "outputs": "string - one-line insight summary"
            },
            {
              "name": "formatInsightGeneric",
              "desc": "Formats individual insight with all details in a standard structure",
              "inputs": "insight: Insight",
              "outputs": "string - formatted insight block"
            }
          ],
          "dependencies": [
            "./insightGenerator (Insight type)"
          ],
          "intent": "Transforms raw code analysis insights into AI assistant-specific formats that maximize the effectiveness of automated code improvement suggestions by tailoring the presentation style to each AI's conversation patterns and capabilities.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various AI assistants and human readers.\",\n  \"userVisibleActions\": [\n    \"View architecture issues grouped by severity (Critical/Warnings/Informational)\",\n    \"See issues formatted specifically for Cursor AI with actionable prompts\",\n    \"See issues formatted for ChatGPT with structured analysis sections\",\n    \"View compact summaries of issues by category\",\n    \"Read generic formatted reports with detailed issue breakdowns\",\n    \"See formatted suggestions asking for prioritization and refactoring help\",\n    \"View architecture violations with file locations and suggested fixes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Choose between 4 output formats: cursor, chatgpt, compact, or generic\",\n    \"Call formatInsights() with insights array and format preference\",\n    \"Receive markdown-formatted output ready for AI assistant consumption\",\n    \"Get insights automatically grouped by severity levels\",\n    \"Obtain structured reports with severity indicators (, , )\",\n    \"Generate format-specific prompts that guide AI assistant responses\",\n    \"Produce outputs optimized for different AI assistant conversation styles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes insights to the appropriate formatter based on specified format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"string - formatted markdown text\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Formats insights optimized for Cursor AI with severity grouping and actionable prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - Cursor-optimized markdown\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Formats insights for ChatGPT with structured sections and conversation-style prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - ChatGPT-optimized markdown\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates a condensed summary of issues grouped by category without detailed formatting\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - compact markdown summary\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Produces a standard detailed report suitable for any AI assistant or human reader\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - generic formatted markdown\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file location, description, and suggested action\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats individual insight with numbered structure and conversational tone\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats individual insight as a single line with essential information\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - one-line insight summary\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats individual insight with all details in a standard structure\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator (Insight type)\"\n  ],\n  \"intent\": \"Transforms raw code analysis insights into AI assistant-specific formats that maximize the effectiveness of automated code improvement suggestions by tailoring the presentation style to each AI's conversation patterns and capabilities.\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Integrates LLM-powered analysis features into the VS Code extension, coordinating code analysis, documentation generation, and insights display.",
          "userVisibleActions": [
            "Generates AI-powered insights about codebase structure and behavior",
            "Creates comprehensive product documentation from code analysis",
            "Displays code analysis results in tree views and panels",
            "Shows entry points and navigation structure of the project",
            "Presents unit test coverage and organization",
            "Provides interactive insights viewer with AI-generated explanations",
            "Updates and refreshes documentation when code changes",
            "Shows status of analysis and documentation generation in output panel"
          ],
          "developerVisibleActions": [
            "Initialize LLM service with API key configuration",
            "Trigger code analysis on workspace or specific files",
            "Generate documentation for entire product or individual files",
            "Regenerate insights when code or analysis changes",
            "Access saved analysis results and cached documentation",
            "Configure LLM provider and model settings",
            "View logs and debug information in output channel",
            "Manage state of analysis, documentation, and insights across sessions",
            "Export and import analysis contexts for persistence"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Sets up the LLM service and registers configuration change listeners",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "generateInsights",
              "desc": "Generates AI-powered insights from code analysis context",
              "inputs": "AnalysisContext",
              "outputs": "Promise<LLMInsights>"
            },
            {
              "name": "generateDocumentation",
              "desc": "Creates comprehensive product documentation from analysis results",
              "inputs": "CodeAnalysis, workspace path",
              "outputs": "Promise<EnhancedProductDocumentation>"
            },
            {
              "name": "analyzeCode",
              "desc": "Performs code analysis on workspace or specific files",
              "inputs": "workspace path or file paths",
              "outputs": "Promise<CodeAnalysis>"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to storage",
              "inputs": "CodeAnalysis, workspace path",
              "outputs": "Promise<void>"
            },
            {
              "name": "loadSavedCodeAnalysis",
              "desc": "Retrieves previously saved code analysis from storage",
              "inputs": "workspace path",
              "outputs": "Promise<CodeAnalysis | null>"
            },
            {
              "name": "refreshViews",
              "desc": "Updates all tree views and panels with latest data",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms code analysis results into LLM-compatible context format",
              "inputs": "CodeAnalysis",
              "outputs": "AnalysisContext"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "./llmService",
            "./insightsTreeView",
            "./fileDocumentation",
            "./analyzer",
            "./productNavigator",
            "./analysisViewer",
            "./insightsViewer",
            "./unitTestsNavigator",
            "./logger",
            "./state/llmStateManager",
            "./context/analysisContextBuilder",
            "./domain/formatters/documentationFormatter",
            "./infrastructure/persistence/analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis and AI-powered features, orchestrating the flow from code scanning to insight generation to user-facing documentation and visualizations. It solves the problem of coordinating multiple complex operations (analysis, LLM processing, state management, UI updates) into a cohesive system that helps developers understand their codebase through AI assistance.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered analysis features into the VS Code extension, coordinating code analysis, documentation generation, and insights display.\",\n  \"userVisibleActions\": [\n    \"Generates AI-powered insights about codebase structure and behavior\",\n    \"Creates comprehensive product documentation from code analysis\",\n    \"Displays code analysis results in tree views and panels\",\n    \"Shows entry points and navigation structure of the project\",\n    \"Presents unit test coverage and organization\",\n    \"Provides interactive insights viewer with AI-generated explanations\",\n    \"Updates and refreshes documentation when code changes\",\n    \"Shows status of analysis and documentation generation in output panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service with API key configuration\",\n    \"Trigger code analysis on workspace or specific files\",\n    \"Generate documentation for entire product or individual files\",\n    \"Regenerate insights when code or analysis changes\",\n    \"Access saved analysis results and cached documentation\",\n    \"Configure LLM provider and model settings\",\n    \"View logs and debug information in output channel\",\n    \"Manage state of analysis, documentation, and insights across sessions\",\n    \"Export and import analysis contexts for persistence\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service and registers configuration change listeners\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates AI-powered insights from code analysis context\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Promise<LLMInsights>\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation from analysis results\",\n      \"inputs\": \"CodeAnalysis, workspace path\",\n      \"outputs\": \"Promise<EnhancedProductDocumentation>\"\n    },\n    {\n      \"name\": \"analyzeCode\",\n      \"desc\": \"Performs code analysis on workspace or specific files\",\n      \"inputs\": \"workspace path or file paths\",\n      \"outputs\": \"Promise<CodeAnalysis>\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to storage\",\n      \"inputs\": \"CodeAnalysis, workspace path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved code analysis from storage\",\n      \"inputs\": \"workspace path\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"refreshViews\",\n      \"desc\": \"Updates all tree views and panels with latest data\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis results into LLM-compatible context format\",\n      \"inputs\": \"CodeAnalysis\",\n      \"outputs\": \"AnalysisContext\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and AI-powered features, orchestrating the flow from code scanning to insight generation to user-facing documentation and visualizations. It solves the problem of coordinating multiple complex operations (analysis, LLM processing, state management, UI updates) into a cohesive system that helps developers understand their codebase through AI assistance.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure and validate AI-generated responses for code analysis tasks, ensuring consistent, parseable outputs without manual parsing.",
          "userVisibleActions": [
            "Receives structured product purpose analysis with clear sections for goals, architecture reasoning, and design decisions",
            "Gets organized issue reports with clear titles, descriptions, relevant files, and severity levels",
            "Views categorized code analysis results separated into user-facing vs developer-facing behavior",
            "Sees detailed function documentation with inputs, outputs, and behavioral descriptions",
            "Receives file classifications (Core Logic, Configuration, Testing, etc.) with clear purpose statements"
          ],
          "developerVisibleActions": [
            "Uses predefined schemas to request structured AI analysis of codebases",
            "Receives guaranteed valid JSON responses from Claude API without parsing errors",
            "Gets code behavior extracted as user-facing actions and developer-facing actions separately",
            "Obtains dependency lists and relationship mappings between files",
            "Receives categorized issues (Architecture, Documentation, Code Quality, etc.) with severity ratings",
            "Gets function signatures extracted with behavioral descriptions instead of implementation details"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to enforce consistent structure in AI-generated code analysis responses. It solves the problem of unreliable, unparseable AI outputs by defining strict JSON schemas that guarantee valid, structured data for product purpose analysis, issue detection, code behavior extraction, and documentation generation. It ensures the AI focuses on WHAT code does (user/developer perspective) rather than HOW it's implemented.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate AI-generated responses for code analysis tasks, ensuring consistent, parseable outputs without manual parsing.\",\n  \"userVisibleActions\": [\n    \"Receives structured product purpose analysis with clear sections for goals, architecture reasoning, and design decisions\",\n    \"Gets organized issue reports with clear titles, descriptions, relevant files, and severity levels\",\n    \"Views categorized code analysis results separated into user-facing vs developer-facing behavior\",\n    \"Sees detailed function documentation with inputs, outputs, and behavioral descriptions\",\n    \"Receives file classifications (Core Logic, Configuration, Testing, etc.) with clear purpose statements\"\n  ],\n  \"developerVisibleActions\": [\n    \"Uses predefined schemas to request structured AI analysis of codebases\",\n    \"Receives guaranteed valid JSON responses from Claude API without parsing errors\",\n    \"Gets code behavior extracted as user-facing actions and developer-facing actions separately\",\n    \"Obtains dependency lists and relationship mappings between files\",\n    \"Receives categorized issues (Architecture, Documentation, Code Quality, etc.) with severity ratings\",\n    \"Gets function signatures extracted with behavioral descriptions instead of implementation details\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to enforce consistent structure in AI-generated code analysis responses. It solves the problem of unreliable, unparseable AI outputs by defining strict JSON schemas that guarantee valid, structured data for product purpose analysis, issue detection, code behavior extraction, and documentation generation. It ensures the AI focuses on WHAT code does (user/developer perspective) rather than HOW it's implemented.\"\n}\n```"
        },
        {
          "file": "src/llmService.ts",
          "role": "Core Logic",
          "purpose": "Provides AI-powered code analysis services by coordinating with OpenAI/Claude to generate intelligent insights about code purpose, architecture, refactoring suggestions, and test plans.",
          "userVisibleActions": [
            "Generates explanations of what the codebase does and why it was built",
            "Provides intelligent refactoring suggestions for improving code quality",
            "Creates test plans showing what should be tested and why",
            "Explains the purpose and architecture of the entire product",
            "Generates comprehensive product documentation from code analysis",
            "Analyzes code complexity and suggests improvements",
            "Explains relationships between files and modules"
          ],
          "developerVisibleActions": [
            "Call AI service to analyze codebase and get product purpose analysis",
            "Request refactoring suggestions for specific functions or files",
            "Generate unit test plans based on code analysis",
            "Get insights about code quality, architecture patterns, and improvements",
            "Analyze file summaries to understand module structure",
            "Retrieve enhanced product documentation with AI-generated insights",
            "Process incremental analysis updates as code changes",
            "Configure which AI provider to use (OpenAI, Claude, or Gemini)",
            "Set custom API endpoints and model preferences",
            "Handle rate limiting and retry logic for AI requests automatically"
          ],
          "keyFunctions": [
            {
              "name": "analyzeProductPurpose",
              "desc": "Analyzes the entire codebase to determine what the product does and why it exists",
              "inputs": "context (file structure, imports, entry points), codeAnalysis (detailed code metrics)",
              "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, key features, and design decisions"
            },
            {
              "name": "generateProductDocumentation",
              "desc": "Creates comprehensive product documentation using AI analysis of code structure and patterns",
              "inputs": "fileSummaries (per-file analysis), moduleSummaries (module-level groupings), productPurpose (high-level purpose)",
              "outputs": "EnhancedProductDocumentation with overview, architecture, modules, features, and technical details"
            },
            {
              "name": "generateRefactoringSuggestion",
              "desc": "Provides AI-generated suggestions for improving code quality and structure",
              "inputs": "fileInfo (file metadata), functionMetadata (function details), codeContent (actual code)",
              "outputs": "Refactoring suggestions with severity, description, benefits, and implementation steps"
            },
            {
              "name": "generateUnitTestPlan",
              "desc": "Creates a test plan showing what should be tested and why based on code analysis",
              "inputs": "fileInfo, functionMetadata, codeContent, and existing test files",
              "outputs": "UnitTestPlan with test strategies, scenarios, coverage recommendations, and priority areas"
            },
            {
              "name": "getInsights",
              "desc": "Generates intelligent insights about code quality, patterns, and improvements",
              "inputs": "context (codebase structure), codeAnalysis (metrics), configuration (settings)",
              "outputs": "Array of insights categorized by type with descriptions and actionable recommendations"
            },
            {
              "name": "analyzeIncrementally",
              "desc": "Performs incremental analysis on changed files to provide fast, targeted insights",
              "inputs": "changedFiles (list of modified files), existingAnalysis (previous results)",
              "outputs": "Updated analysis results focusing only on changes"
            },
            {
              "name": "callLLM",
              "desc": "Internal method that handles communication with AI providers (OpenAI, Claude, Gemini)",
              "inputs": "prompt (question/task), schema (expected response format), options (provider settings)",
              "outputs": "AI-generated response parsed according to schema"
            }
          ],
          "dependencies": [
            "vscode",
            "./fileDocumentation",
            "./analyzer",
            "./analysis/enhancedAnalyzer",
            "./llmSchemas",
            "./fileAccessHelper",
            "./logger",
            "./config/configurationManager",
            "./ai/providers/providerFactory",
            "./ai/llmResponseParser",
            "./ai/llmRateLimiter",
            "./ai/llmRetryHandler",
            "./domain/prompts/promptBuilder",
            "./domain/services/incrementalAnalysisService",
            "./domain/prompts/refactoringPromptBuilder",
            "./analysis/functionAnalyzer"
          ],
          "intent": "This file exists to bridge the gap between static code analysis and intelligent insights by leveraging AI language models. It solves the problem of understanding large codebases by providing human-readable explanations of code purpose, architecture decisions, quality issues, and improvement opportunities. It abstracts away the complexity of working with multiple AI providers and handles concerns like rate limiting, retries, and response parsing, allowing the extension to provide consistent AI-powered features regardless of which provider the user chooses.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis services by coordinating with OpenAI/Claude to generate intelligent insights about code purpose, architecture, refactoring suggestions, and test plans.\",\n  \"userVisibleActions\": [\n    \"Generates explanations of what the codebase does and why it was built\",\n    \"Provides intelligent refactoring suggestions for improving code quality\",\n    \"Creates test plans showing what should be tested and why\",\n    \"Explains the purpose and architecture of the entire product\",\n    \"Generates comprehensive product documentation from code analysis\",\n    \"Analyzes code complexity and suggests improvements\",\n    \"Explains relationships between files and modules\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call AI service to analyze codebase and get product purpose analysis\",\n    \"Request refactoring suggestions for specific functions or files\",\n    \"Generate unit test plans based on code analysis\",\n    \"Get insights about code quality, architecture patterns, and improvements\",\n    \"Analyze file summaries to understand module structure\",\n    \"Retrieve enhanced product documentation with AI-generated insights\",\n    \"Process incremental analysis updates as code changes\",\n    \"Configure which AI provider to use (OpenAI, Claude, or Gemini)\",\n    \"Set custom API endpoints and model preferences\",\n    \"Handle rate limiting and retry logic for AI requests automatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine what the product does and why it exists\",\n      \"inputs\": \"context (file structure, imports, entry points), codeAnalysis (detailed code metrics)\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, key features, and design decisions\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation using AI analysis of code structure and patterns\",\n      \"inputs\": \"fileSummaries (per-file analysis), moduleSummaries (module-level groupings), productPurpose (high-level purpose)\",\n      \"outputs\": \"EnhancedProductDocumentation with overview, architecture, modules, features, and technical details\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestion\",\n      \"desc\": \"Provides AI-generated suggestions for improving code quality and structure\",\n      \"inputs\": \"fileInfo (file metadata), functionMetadata (function details), codeContent (actual code)\",\n      \"outputs\": \"Refactoring suggestions with severity, description, benefits, and implementation steps\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a test plan showing what should be tested and why based on code analysis\",\n      \"inputs\": \"fileInfo, functionMetadata, codeContent, and existing test files\",\n      \"outputs\": \"UnitTestPlan with test strategies, scenarios, coverage recommendations, and priority areas\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and improvements\",\n      \"inputs\": \"context (codebase structure), codeAnalysis (metrics), configuration (settings)\",\n      \"outputs\": \"Array of insights categorized by type with descriptions and actionable recommendations\"\n    },\n    {\n      \"name\": \"analyzeIncrementally\",\n      \"desc\": \"Performs incremental analysis on changed files to provide fast, targeted insights\",\n      \"inputs\": \"changedFiles (list of modified files), existingAnalysis (previous results)\",\n      \"outputs\": \"Updated analysis results focusing only on changes\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Internal method that handles communication with AI providers (OpenAI, Claude, Gemini)\",\n      \"inputs\": \"prompt (question/task), schema (expected response format), options (provider settings)\",\n      \"outputs\": \"AI-generated response parsed according to schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent insights by leveraging AI language models. It solves the problem of understanding large codebases by providing human-readable explanations of code purpose, architecture decisions, quality issues, and improvement opportunities. It abstracts away the complexity of working with multiple AI providers and handles concerns like rate limiting, retries, and response parsing, allowing the extension to provide consistent AI-powered features regardless of which provider the user chooses.\"\n}\n```"
        },
        {
          "file": "src/logger.ts",
          "role": "Core Logic",
          "purpose": "Provides logging functionality to write timestamped messages to a log file in the workspace's .shadow/logs directory",
          "userVisibleActions": [
            "Log files are created in the .shadow/logs directory at the workspace root",
            "A shadow-watch.log file contains timestamped entries of extension activity",
            "Log entries show timestamps in ISO format for tracking when events occurred"
          ],
          "developerVisibleActions": [
            "Developers can call SWLogger.log() to write timestamped messages to the log file",
            "Developers can call SWLogger.section() to create visual section separators in the log",
            "Log messages automatically include ISO timestamp prefixes",
            "Logging failures are silently ignored (best-effort) to prevent extension crashes"
          ],
          "keyFunctions": [
            {
              "name": "log",
              "desc": "Writes a timestamped message to the shadow-watch.log file",
              "inputs": "message: string - The text to log",
              "outputs": "void - No return value"
            },
            {
              "name": "section",
              "desc": "Creates a visual section separator in the log with a title",
              "inputs": "title: string - The section title to display",
              "outputs": "void - No return value"
            },
            {
              "name": "getLogPath",
              "desc": "Determines the file path for the log file in the workspace",
              "inputs": "None",
              "outputs": "string | null - Path to log file or null if no workspace is open"
            },
            {
              "name": "ensureDir",
              "desc": "Creates a directory if it doesn't exist",
              "inputs": "dir: string - Directory path to create",
              "outputs": "void - No return value"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "vscode"
          ],
          "intent": "This file exists to provide centralized, timestamped logging for the Shadow Watch extension, allowing developers to track extension behavior and debug issues by writing activity to a persistent log file in the workspace",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality to write timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are created in the .shadow/logs directory at the workspace root\",\n    \"A shadow-watch.log file contains timestamped entries of extension activity\",\n    \"Log entries show timestamps in ISO format for tracking when events occurred\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can call SWLogger.log() to write timestamped messages to the log file\",\n    \"Developers can call SWLogger.section() to create visual section separators in the log\",\n    \"Log messages automatically include ISO timestamp prefixes\",\n    \"Logging failures are silently ignored (best-effort) to prevent extension crashes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - The text to log\",\n      \"outputs\": \"void - No return value\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a visual section separator in the log with a title\",\n      \"inputs\": \"title: string - The section title to display\",\n      \"outputs\": \"void - No return value\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path for the log file in the workspace\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string | null - Path to log file or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory if it doesn't exist\",\n      \"inputs\": \"dir: string - Directory path to create\",\n      \"outputs\": \"void - No return value\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide centralized, timestamped logging for the Shadow Watch extension, allowing developers to track extension behavior and debug issues by writing activity to a persistent log file in the workspace\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadow-watch.analyzeCode",
          "description": "Analyzes the entire workspace to generate insights about code behavior, dependencies, and architecture"
        },
        {
          "command": "shadow-watch.generatePrompt",
          "description": "Creates LLM-optimized prompts for AI code analysis with structured context"
        },
        {
          "command": "shadow-watch.refreshInsights",
          "description": "Refreshes all analysis results, insights, and documentation views"
        },
        {
          "command": "shadow-watch.exportInsights",
          "description": "Exports analysis results and insights to external formats"
        },
        {
          "command": "shadow-watch.navigateToCode",
          "description": "Navigates to specific code locations from insights or analysis results"
        },
        {
          "command": "shadow-watch.clearCache",
          "description": "Clears cached analysis results to force a fresh analysis"
        },
        {
          "command": "shadow-watch.generateDocumentation",
          "description": "Generates comprehensive AI-powered product documentation from code analysis"
        },
        {
          "command": "shadow-watch.generateTestPlan",
          "description": "Creates intelligent test plans showing what should be tested and why"
        },
        {
          "command": "shadow-watch.formatForAI",
          "description": "Formats analysis results optimally for different AI assistants (ChatGPT, Cursor, etc.)"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized configuration management for all Shadow Watch extension settings",
        "Real-time configuration updates with change notifications to dependent components",
        "User-controlled extension activation and automatic analysis behavior",
        "Customizable diagnostic display and severity filtering",
        "Flexible LLM provider selection and output format configuration",
        "Performance tuning through file size limits and debounce settings",
        "File exclusion management via pattern-based ignore rules"
      ],
      "summary": "The config module provides comprehensive configuration management for the Shadow Watch extension, serving as the central hub for all user preferences and settings. It enables users to customize every aspect of the extension's behavior, from basic on/off controls to advanced LLM integration settings and performance parameters.\n\nUsers interact with this module primarily through VS Code's settings interface, where they can enable or disable the extension, control when automatic analysis occurs (such as on file save), and configure how diagnostics appear in their editor. The module supports fine-grained control over diagnostic severity thresholds, allowing users to filter which issues are shown based on importance. Additionally, users can select their preferred LLM provider (OpenAI or Claude) and choose from multiple output formats tailored for different AI chat interfaces.\n\nThe module implements a reactive architecture that immediately propagates configuration changes to all dependent components throughout the extension. This ensures that when users adjust settings like file size limits, ignored file patterns, or analysis debounce delays, the changes take effect without requiring extension restarts. This real-time responsiveness creates a seamless configuration experience while maintaining performance through intelligent debouncing and validation.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes",
          "userVisibleActions": [
            "User can enable/disable the Shadow Watch extension through settings",
            "User can toggle automatic analysis when saving files",
            "User can show/hide inline hints for diagnostics in the editor",
            "User can configure severity thresholds for diagnostics",
            "User can select LLM provider (OpenAI or Claude) for analysis",
            "User can choose output format for LLM reports (Cursor, ChatGPT, Generic, Compact)",
            "User can set file size limits for analysis",
            "User can configure ignored file patterns",
            "User can adjust analysis debounce delays"
          ],
          "developerVisibleActions": [
            "Provides type-safe access to all extension configuration properties",
            "Triggers callbacks when any Shadow Watch configuration changes",
            "Centralizes configuration validation logic",
            "Exposes typed configuration values (LLMProvider, LLMFormat, SeverityThreshold)",
            "Manages workspace-level configuration updates",
            "Allows registering and removing configuration change listeners"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes the configuration manager and sets up the configuration change watcher",
              "inputs": "none",
              "outputs": "ConfigurationManager instance"
            },
            {
              "name": "onConfigurationChange",
              "desc": "Registers a callback to be notified when Shadow Watch settings change",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Unregisters a configuration change callback",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "enabled",
              "desc": "Gets whether the Shadow Watch extension is enabled",
              "inputs": "none (getter)",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave",
              "desc": "Gets whether analysis should run automatically when files are saved",
              "inputs": "none (getter)",
              "outputs": "boolean"
            },
            {
              "name": "showInlineHints",
              "desc": "Gets whether inline diagnostic hints should be displayed in the editor",
              "inputs": "none (getter)",
              "outputs": "boolean"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to provide a single, type-safe point of access for all Shadow Watch configuration settings, eliminating scattered config.get() calls throughout the codebase and ensuring consistent configuration handling with change notifications for reactive updates.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes\",\n  \"userVisibleActions\": [\n    \"User can enable/disable the Shadow Watch extension through settings\",\n    \"User can toggle automatic analysis when saving files\",\n    \"User can show/hide inline hints for diagnostics in the editor\",\n    \"User can configure severity thresholds for diagnostics\",\n    \"User can select LLM provider (OpenAI or Claude) for analysis\",\n    \"User can choose output format for LLM reports (Cursor, ChatGPT, Generic, Compact)\",\n    \"User can set file size limits for analysis\",\n    \"User can configure ignored file patterns\",\n    \"User can adjust analysis debounce delays\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides type-safe access to all extension configuration properties\",\n    \"Triggers callbacks when any Shadow Watch configuration changes\",\n    \"Centralizes configuration validation logic\",\n    \"Exposes typed configuration values (LLMProvider, LLMFormat, SeverityThreshold)\",\n    \"Manages workspace-level configuration updates\",\n    \"Allows registering and removing configuration change listeners\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the configuration manager and sets up the configuration change watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback to be notified when Shadow Watch settings change\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Gets whether the Shadow Watch extension is enabled\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Gets whether analysis should run automatically when files are saved\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Gets whether inline diagnostic hints should be displayed in the editor\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, type-safe point of access for all Shadow Watch configuration settings, eliminating scattered config.get() calls throughout the codebase and ensuring consistent configuration handling with change notifications for reactive updates.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Converts code analysis results into structured context for LLM processing",
        "Persists analysis data to disk for reuse across sessions",
        "Maintains historical analysis data in the workspace",
        "Provides formatted context suitable for AI-powered code operations",
        "Enables faster subsequent operations by caching analysis results"
      ],
      "summary": "This module serves as a bridge between code analysis operations and LLM-powered features. It takes raw code analysis results and transforms them into a structured format optimized for AI processing, making the codebase's structure and relationships comprehensible to language models.\n\nThe module automatically saves all analysis results to .shadow/docs/code-analysis.json in the workspace, creating a persistent knowledge base about the codebase. This persistence means that after the initial analysis, subsequent operations can leverage cached data for improved performance. The structured format ensures that AI features have consistent, well-organized access to information about functions, classes, dependencies, and code relationships.\n\nUsers benefit from this module indirectly through faster and more accurate AI-powered code operations. The saved analysis context enables features like intelligent code suggestions, documentation generation, and semantic search to work more effectively by providing the LLM with comprehensive understanding of the codebase structure and conventions.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis results into a format suitable for LLM processing and saves them to disk for future reference",
          "userVisibleActions": [
            "Code analysis results are automatically saved to .shadow/docs/code-analysis.json in the workspace",
            "Analysis data persists between sessions for faster subsequent operations"
          ],
          "developerVisibleActions": [
            "Transform raw code analysis data into a structured context format that LLMs can process",
            "Persist analysis results with metadata (timestamp, version) to the .shadow/docs directory",
            "Access previously generated analysis data without re-scanning the codebase",
            "View saved analysis including file structure, imports, entry points, and code statistics"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption",
              "inputs": "CodeAnalysis object containing files, imports, entry points, and statistics",
              "outputs": "AnalysisContext object with formatted file information, imports, entry points, orphaned files, and totals"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to a JSON file in the workspace's .shadow/docs directory with generation metadata",
              "inputs": "CodeAnalysis object to be saved",
              "outputs": "void (writes to file system)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer",
            "../llmService"
          ],
          "intent": "This file bridges the gap between raw code analysis and LLM processing by transforming analysis data into an LLM-friendly format and caching it to disk. This allows documentation generation to reuse expensive analysis results across multiple requests and sessions, improving performance and enabling consistent context for AI-generated documentation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a format suitable for LLM processing and saves them to disk for future reference\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to .shadow/docs/code-analysis.json in the workspace\",\n    \"Analysis data persists between sessions for faster subsequent operations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transform raw code analysis data into a structured context format that LLMs can process\",\n    \"Persist analysis results with metadata (timestamp, version) to the .shadow/docs directory\",\n    \"Access previously generated analysis data without re-scanning the codebase\",\n    \"View saved analysis including file structure, imports, entry points, and code statistics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file information, imports, entry points, orphaned files, and totals\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to a JSON file in the workspace's .shadow/docs directory with generation metadata\",\n      \"inputs\": \"CodeAnalysis object to be saved\",\n      \"outputs\": \"void (writes to file system)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file bridges the gap between raw code analysis and LLM processing by transforming analysis data into an LLM-friendly format and caching it to disk. This allows documentation generation to reuse expensive analysis results across multiple requests and sessions, improving performance and enabling consistent context for AI-generated documentation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Extension initialization and activation with all core components",
        "Command registration for code analysis, insights management, and LLM provider switching",
        "Automated workspace and file analysis for code intelligence",
        "Interactive navigation through code structure and analysis results",
        "Report generation and viewing for analysis insights and unit tests",
        "Real-time file monitoring and automatic re-analysis on code changes",
        "Multi-provider LLM integration with configurable AI backends",
        "Clipboard operations for sharing insights and analysis results",
        "Settings and data management for extension configuration"
      ],
      "summary": "The bootstrap module serves as the foundation layer that activates and initializes the VS Code extension, orchestrating all components necessary for code intelligence and analysis capabilities. When the extension starts, it automatically sets up analyzers, tree view providers, diagnostics panels, file watchers, and the status bar interface, making the full suite of features immediately available to users.\n\nThis module provides comprehensive command registration for all user interactions, including workspace-wide and file-specific analysis, insight management (viewing, copying, clearing), LLM provider configuration, and navigation through code structure and analysis reports. Users can trigger analysis through command palette actions or contextual menus, switch between different AI providers (OpenAI, Anthropic, etc.), and manage their analysis data through various clearing and export operations.\n\nThe bootstrapping process establishes automatic workflows such as real-time file watching that triggers re-analysis when code changes, populating tree views with structured insights and test results, and displaying diagnostics for code issues. This creates a seamless experience where the extension continuously monitors the workspace and provides up-to-date code intelligence without manual intervention, while still offering granular control through registered commands for specific analysis tasks and configuration changes.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers all VS Code commands for the extension, mapping command IDs to their handler functions",
          "userVisibleActions": [
            "Analyze entire workspace to generate insights",
            "Analyze current file for code insights",
            "Copy all generated insights to clipboard",
            "Copy insights for a specific file to clipboard",
            "Copy individual insight to clipboard",
            "Clear cached analysis results",
            "Clear all extension data",
            "Open extension settings",
            "Open latest analysis report",
            "Open latest unit test report",
            "Switch between different LLM providers (OpenAI, Anthropic, etc.)",
            "Copy menu structure to clipboard",
            "View current LLM provider status",
            "Navigate to product items in the code",
            "Navigate to analysis items in reports",
            "View detailed information about product items",
            "View detailed information about insights",
            "View detailed information about unit test results"
          ],
          "developerVisibleActions": [
            "Commands are registered when extension activates",
            "Command handlers interact with CodeAnalyzer for analysis",
            "Command handlers use InsightGenerator to create insights",
            "Command handlers interact with LLM services for AI-powered features",
            "Commands manage cache through AnalysisCache",
            "Commands update tree views (InsightsTreeProvider, AnalysisViewerProvider)",
            "Commands trigger diagnostics updates through DiagnosticsProvider",
            "Commands read/write configuration through ConfigurationManager",
            "All commands are bound to the extension context for lifecycle management"
          ],
          "keyFunctions": [
            {
              "name": "register",
              "desc": "Registers all VS Code commands with their handler functions",
              "inputs": "context (ExtensionContext), components (ExtensionComponents)",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Triggers analysis of entire workspace",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeCurrentFile",
              "desc": "Triggers analysis of the currently open file",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyAllInsights",
              "desc": "Copies all generated insights to clipboard",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "copyInsight",
              "desc": "Copies a specific insight item to clipboard",
              "inputs": "item (insight object)",
              "outputs": "Promise<void>"
            },
            {
              "name": "clearCache",
              "desc": "Clears cached analysis data",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "switchProvider",
              "desc": "Switches between different LLM providers",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to a product item in the code",
              "inputs": "item (ProductNavItem)",
              "outputs": "Promise<void>"
            },
            {
              "name": "showProviderStatus",
              "desc": "Displays current LLM provider status",
              "inputs": "none",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "This file centralizes command registration logic to organize and manage all user-facing commands in the extension, separating command registration concerns from the main extension activation logic and providing a single source of truth for all available commands",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension, mapping command IDs to their handler functions\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to generate insights\",\n    \"Analyze current file for code insights\",\n    \"Copy all generated insights to clipboard\",\n    \"Copy insights for a specific file to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis results\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between different LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to product items in the code\",\n    \"Navigate to analysis items in reports\",\n    \"View detailed information about product items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit test results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Commands are registered when extension activates\",\n    \"Command handlers interact with CodeAnalyzer for analysis\",\n    \"Command handlers use InsightGenerator to create insights\",\n    \"Command handlers interact with LLM services for AI-powered features\",\n    \"Commands manage cache through AnalysisCache\",\n    \"Commands update tree views (InsightsTreeProvider, AnalysisViewerProvider)\",\n    \"Commands trigger diagnostics updates through DiagnosticsProvider\",\n    \"Commands read/write configuration through ConfigurationManager\",\n    \"All commands are bound to the extension context for lifecycle management\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their handler functions\",\n      \"inputs\": \"context (ExtensionContext), components (ExtensionComponents)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers analysis of entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Triggers analysis of the currently open file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyAllInsights\",\n      \"desc\": \"Copies all generated insights to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyInsight\",\n      \"desc\": \"Copies a specific insight item to clipboard\",\n      \"inputs\": \"item (insight object)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears cached analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"switchProvider\",\n      \"desc\": \"Switches between different LLM providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product item in the code\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProviderStatus\",\n      \"desc\": \"Displays current LLM provider status\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file centralizes command registration logic to organize and manage all user-facing commands in the extension, separating command registration concerns from the main extension activation logic and providing a single source of truth for all available commands\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Initializes and bootstraps all extension components when the VS Code extension activates, setting up analyzers, viewers, providers, and services needed for code intelligence features.",
          "userVisibleActions": [
            "Extension activates and displays status bar item showing analysis status",
            "Tree views populate with insights, analysis results, unit tests, and reports",
            "Diagnostics panel shows code issues and warnings from static analysis",
            "Product navigator becomes available for browsing code structure",
            "Reports viewer displays generated analysis reports",
            "File watching begins for automatic re-analysis on code changes"
          ],
          "developerVisibleActions": [
            "Extension creates and registers all core components (analyzer, insight generator, formatters)",
            "Sets up tree data providers for multiple custom views (insights, analysis, static analysis, unit tests, reports)",
            "Initializes caching system for analysis results",
            "Configures file watcher service to monitor workspace changes",
            "Establishes diagnostics provider for displaying code issues",
            "Registers LLM integration for AI-powered code analysis",
            "Creates status bar item for displaying extension state",
            "Instantiates configuration and state managers for persistent settings"
          ],
          "keyFunctions": [
            {
              "name": "bootstrap",
              "desc": "Main entry point that initializes all extension components in proper order",
              "inputs": "vscode.ExtensionContext",
              "outputs": "ExtensionComponents object containing all initialized services"
            },
            {
              "name": "createAnalyzer",
              "desc": "Instantiates the code analyzer component",
              "inputs": "none",
              "outputs": "CodeAnalyzer instance"
            },
            {
              "name": "createInsightGenerator",
              "desc": "Creates the insight generation service",
              "inputs": "none",
              "outputs": "InsightGenerator instance"
            },
            {
              "name": "createTreeProviders",
              "desc": "Sets up all tree view data providers for displaying structured data",
              "inputs": "none",
              "outputs": "Multiple tree provider instances"
            },
            {
              "name": "registerViews",
              "desc": "Registers custom VS Code views for insights, analysis, and reports",
              "inputs": "vscode.ExtensionContext, tree providers",
              "outputs": "Registered tree views"
            },
            {
              "name": "initializeServices",
              "desc": "Starts background services like file watching and diagnostics",
              "inputs": "ExtensionComponents",
              "outputs": "void"
            },
            {
              "name": "setupStatusBar",
              "desc": "Creates and configures the status bar item for displaying extension state",
              "inputs": "vscode.ExtensionContext",
              "outputs": "vscode.StatusBarItem"
            }
          ],
          "dependencies": [
            "vscode",
            "../../analyzer",
            "../../insightGenerator",
            "../../llmFormatter",
            "../../fileWatcher",
            "../../insightsTreeView",
            "../../diagnosticsProvider",
            "../../cache",
            "../../llmIntegration",
            "../../productNavigator",
            "../../analysisViewer",
            "../../insightsViewer",
            "../../staticAnalysisViewer",
            "../../unitTestsNavigator",
            "../../config/configurationManager",
            "../../utils/errorHandler",
            "../../domain/services/fileWatcherService",
            "../../ui/reportsViewer",
            "../../reportsTreeProvider",
            "../../state/llmStateManager"
          ],
          "intent": "This file exists to centralize and orchestrate the complex initialization sequence of the extension, separating activation logic from the main extension entry point. It ensures all components are created in the correct order, properly wired together, and registered with VS Code's extension host. This separation makes the codebase more maintainable and testable by isolating bootstrapping concerns.",
          "rawContent": "```json\n{\n  \"purpose\": \"Initializes and bootstraps all extension components when the VS Code extension activates, setting up analyzers, viewers, providers, and services needed for code intelligence features.\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis status\",\n    \"Tree views populate with insights, analysis results, unit tests, and reports\",\n    \"Diagnostics panel shows code issues and warnings from static analysis\",\n    \"Product navigator becomes available for browsing code structure\",\n    \"Reports viewer displays generated analysis reports\",\n    \"File watching begins for automatic re-analysis on code changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension creates and registers all core components (analyzer, insight generator, formatters)\",\n    \"Sets up tree data providers for multiple custom views (insights, analysis, static analysis, unit tests, reports)\",\n    \"Initializes caching system for analysis results\",\n    \"Configures file watcher service to monitor workspace changes\",\n    \"Establishes diagnostics provider for displaying code issues\",\n    \"Registers LLM integration for AI-powered code analysis\",\n    \"Creates status bar item for displaying extension state\",\n    \"Instantiates configuration and state managers for persistent settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components in proper order\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object containing all initialized services\"\n    },\n    {\n      \"name\": \"createAnalyzer\",\n      \"desc\": \"Instantiates the code analyzer component\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CodeAnalyzer instance\"\n    },\n    {\n      \"name\": \"createInsightGenerator\",\n      \"desc\": \"Creates the insight generation service\",\n      \"inputs\": \"none\",\n      \"outputs\": \"InsightGenerator instance\"\n    },\n    {\n      \"name\": \"createTreeProviders\",\n      \"desc\": \"Sets up all tree view data providers for displaying structured data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Multiple tree provider instances\"\n    },\n    {\n      \"name\": \"registerViews\",\n      \"desc\": \"Registers custom VS Code views for insights, analysis, and reports\",\n      \"inputs\": \"vscode.ExtensionContext, tree providers\",\n      \"outputs\": \"Registered tree views\"\n    },\n    {\n      \"name\": \"initializeServices\",\n      \"desc\": \"Starts background services like file watching and diagnostics\",\n      \"inputs\": \"ExtensionComponents\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupStatusBar\",\n      \"desc\": \"Creates and configures the status bar item for displaying extension state\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"vscode.StatusBarItem\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer\",\n    \"../../insightGenerator\",\n    \"../../llmFormatter\",\n    \"../../fileWatcher\",\n    \"../../insightsTreeView\",\n    \"../../diagnosticsProvider\",\n    \"../../cache\",\n    \"../../llmIntegration\",\n    \"../../productNavigator\",\n    \"../../analysisViewer\",\n    \"../../insightsViewer\",\n    \"../../staticAnalysisViewer\",\n    \"../../unitTestsNavigator\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler\",\n    \"../../domain/services/fileWatcherService\",\n    \"../../ui/reportsViewer\",\n    \"../../reportsTreeProvider\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and orchestrate the complex initialization sequence of the extension, separating activation logic from the main extension entry point. It ensures all components are created in the correct order, properly wired together, and registered with VS Code's extension host. This separation makes the codebase more maintainable and testable by isolating bootstrapping concerns.\"\n}\n```"
        }
      ],
      "commands": [
        {
          "command": "analyze-workspace",
          "description": "Analyzes the entire workspace to generate comprehensive code insights and intelligence"
        },
        {
          "command": "analyze-file",
          "description": "Analyzes the currently open file for code insights and recommendations"
        },
        {
          "command": "copy-all-insights",
          "description": "Copies all generated insights across the workspace to the clipboard"
        },
        {
          "command": "copy-file-insights",
          "description": "Copies insights for a specific file to the clipboard"
        },
        {
          "command": "copy-single-insight",
          "description": "Copies an individual insight item to the clipboard"
        },
        {
          "command": "clear-cache",
          "description": "Clears all cached analysis results to force fresh analysis"
        },
        {
          "command": "clear-data",
          "description": "Clears all extension data including settings and cached results"
        },
        {
          "command": "open-settings",
          "description": "Opens the extension's configuration settings panel"
        },
        {
          "command": "open-analysis-report",
          "description": "Opens the latest analysis report with detailed insights"
        },
        {
          "command": "open-unit-test-report",
          "description": "Opens the latest unit test analysis report"
        },
        {
          "command": "switch-llm-provider",
          "description": "Switches between different LLM providers (OpenAI, Anthropic, etc.)"
        },
        {
          "command": "copy-menu-structure",
          "description": "Copies the current menu structure to the clipboard for reference"
        },
        {
          "command": "view-provider-status",
          "description": "Displays the current LLM provider configuration and status"
        },
        {
          "command": "navigate-to-product-item",
          "description": "Navigates to a specific product/code item in the editor"
        },
        {
          "command": "navigate-to-analysis-item",
          "description": "Navigates to a specific analysis result item in reports"
        },
        {
          "command": "view-product-details",
          "description": "Shows detailed information about a product/code structure item"
        },
        {
          "command": "view-insight-details",
          "description": "Shows detailed information about a specific insight"
        },
        {
          "command": "view-unit-test-details",
          "description": "Shows detailed information about unit test analysis results"
        }
      ]
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Formats product documentation into structured Markdown documents with metadata",
        "Organizes documentation by interaction types (GUI, CLI, API)",
        "Presents code analysis insights with quality metrics and risk assessments",
        "Categorizes files by their architectural roles (Core, UI, Config, Tests)",
        "Displays technical debt items with priority levels and effort estimates",
        "Shows dependency information and external service integrations",
        "Generates timestamped documentation with generation metadata"
      ],
      "summary": "The formatters module transforms raw code analysis data and product insights into human-readable, well-structured Markdown documentation. It serves as the presentation layer that converts technical findings into accessible documentation format for developers and stakeholders.\n\nUsers can view comprehensive product documentation that includes feature descriptions, architectural insights, quality metrics, and user perspectives organized by interaction type. The module structures information into logical sections including overviews, feature lists, file categorizations, code quality findings, technical debt assessments, and dependency mappings.\n\nThe documentation workflow generates timestamped reports that present code quality findings with risk levels, improvement recommendations with effort estimates, and categorized file listings that help users understand the codebase structure. All output is formatted in Markdown for easy integration into documentation systems, version control, and knowledge bases.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and code analysis insights into human-readable Markdown documents with structured sections and metadata.",
          "userVisibleActions": [
            "Views product documentation in Markdown format with overview, features, and user perspectives",
            "Sees documentation organized by GUI, CLI, and API interaction types",
            "Reads feature descriptions, architectural insights, and quality metrics in formatted sections",
            "Views timestamped documentation with generation date and time",
            "Reviews code quality findings with risk levels and improvement recommendations",
            "Sees categorized file listings organized by role (Core, UI, Config, Tests)",
            "Reads technical debt items with priority levels and effort estimates",
            "Views dependency information and external service integrations"
          ],
          "developerVisibleActions": [
            "Calls formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown",
            "Calls formatInsightsAsMarkdown() to convert LLM analysis insights into Markdown",
            "Receives formatted Markdown strings ready for display or file writing",
            "Provides EnhancedProductDocumentation objects containing structured doc data",
            "Provides LLMInsights objects containing code analysis results",
            "Gets consistent Markdown formatting with headers, lists, and separators",
            "Receives formatted sections for overview, features, architecture, quality, and more"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation into a complete Markdown document with all sections",
              "inputs": "EnhancedProductDocumentation object with overview, features, user perspectives, architecture, etc.",
              "outputs": "Formatted Markdown string with headers, lists, and metadata"
            },
            {
              "name": "formatInsightsAsMarkdown",
              "desc": "Converts LLM code analysis insights into a structured Markdown report",
              "inputs": "LLMInsights object with strengths, improvements, architecture, quality metrics, etc.",
              "outputs": "Formatted Markdown string with analysis sections and findings"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "Separates formatting concerns from core logic by providing a dedicated formatter that transforms structured documentation and analysis objects into consistent, readable Markdown output for users and reports.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and code analysis insights into human-readable Markdown documents with structured sections and metadata.\",\n  \"userVisibleActions\": [\n    \"Views product documentation in Markdown format with overview, features, and user perspectives\",\n    \"Sees documentation organized by GUI, CLI, and API interaction types\",\n    \"Reads feature descriptions, architectural insights, and quality metrics in formatted sections\",\n    \"Views timestamped documentation with generation date and time\",\n    \"Reviews code quality findings with risk levels and improvement recommendations\",\n    \"Sees categorized file listings organized by role (Core, UI, Config, Tests)\",\n    \"Reads technical debt items with priority levels and effort estimates\",\n    \"Views dependency information and external service integrations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown\",\n    \"Calls formatInsightsAsMarkdown() to convert LLM analysis insights into Markdown\",\n    \"Receives formatted Markdown strings ready for display or file writing\",\n    \"Provides EnhancedProductDocumentation objects containing structured doc data\",\n    \"Provides LLMInsights objects containing code analysis results\",\n    \"Gets consistent Markdown formatting with headers, lists, and separators\",\n    \"Receives formatted sections for overview, features, architecture, quality, and more\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation into a complete Markdown document with all sections\",\n      \"inputs\": \"EnhancedProductDocumentation object with overview, features, user perspectives, architecture, etc.\",\n      \"outputs\": \"Formatted Markdown string with headers, lists, and metadata\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM code analysis insights into a structured Markdown report\",\n      \"inputs\": \"LLMInsights object with strengths, improvements, architecture, quality metrics, etc.\",\n      \"outputs\": \"Formatted Markdown string with analysis sections and findings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates formatting concerns from core logic by providing a dedicated formatter that transforms structured documentation and analysis objects into consistent, readable Markdown output for users and reports.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate directly to any file in the workspace from analysis results",
        "Jump to specific functions within files with automatic highlighting",
        "Navigate to API endpoint definitions in the codebase",
        "View detailed information about analysis items in rich webview panels",
        "See formatted code snippets with syntax highlighting for better readability",
        "View comprehensive function metadata including signatures, parameters, and return types",
        "Access precise file locations with paths and line numbers",
        "View formatted entry point details with contextual information",
        "Receive clear error notifications when navigation operations fail"
      ],
      "summary": "The Navigation Handler module provides comprehensive navigation and information display capabilities within the VS Code editor. It acts as the bridge between analysis results and the actual codebase, enabling users to seamlessly move from abstract analysis data to concrete code locations.\n\nUsers can navigate directly to files, functions, and API endpoints discovered during code analysis. When navigating to functions, the handler automatically positions the cursor and highlights the relevant code section. The module also provides rich information displays through webview panels, showing formatted code snippets with syntax highlighting, function signatures with parameter details, and file location information.\n\nThe primary workflow involves users interacting with analysis results (such as API endpoints, functions, or entry points) and clicking to navigate to their definitions in the code. The handler manages the entire process of opening files, positioning the editor view, highlighting relevant code sections, and displaying detailed contextual information. Error handling ensures users receive clear feedback when navigation attempts fail due to missing files or invalid locations.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation between code files, functions, and displays detailed information about analysis items in the VS Code editor.",
          "userVisibleActions": [
            "Navigate to a specific file in the workspace",
            "Navigate to a specific function within a file and highlight it",
            "Navigate to API endpoints and see their location in code",
            "View detailed information about analysis items in a webview panel",
            "See formatted code snippets with syntax highlighting",
            "View function signatures, parameters, and return types",
            "See file paths and line numbers for code locations",
            "View entry point details with formatted information",
            "See error messages when navigation fails"
          ],
          "developerVisibleActions": [
            "Trigger navigation to product items (files, functions, endpoints) from tree views",
            "Display analysis item details in a dedicated webview panel",
            "Open files and position cursor at specific line numbers",
            "Handle navigation for different item types (file, function, navigate)",
            "Generate HTML views with syntax-highlighted code snippets",
            "Format and display complex data structures in readable format",
            "Handle absolute and relative file paths within workspace",
            "Show error messages when file operations fail"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Opens a file or navigates to a function location based on the product navigation item type",
              "inputs": "ProductNavItem (containing file path, function name, and line information)",
              "outputs": "Promise<void> (opens document in editor)"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Opens a file and positions cursor at a specific line number for analysis items",
              "inputs": "AnalysisItem (containing file path and line number)",
              "outputs": "Promise<void> (opens document and reveals line)"
            },
            {
              "name": "showItemDetails",
              "desc": "Displays detailed information about an analysis item in a webview panel with formatted HTML",
              "inputs": "AnalysisItem (analysis data to display)",
              "outputs": "void (creates or updates webview panel)"
            },
            {
              "name": "generateDetailsHtml",
              "desc": "Creates formatted HTML content for displaying item details with syntax highlighting and structured layout",
              "inputs": "AnalysisItem (item to format)",
              "outputs": "string (HTML content)"
            },
            {
              "name": "escapeHtml",
              "desc": "Sanitizes text content for safe HTML rendering",
              "inputs": "string (text to escape)",
              "outputs": "string (escaped HTML)"
            },
            {
              "name": "formatValue",
              "desc": "Converts various data types into readable HTML-formatted strings",
              "inputs": "any (value to format)",
              "outputs": "string (formatted HTML)"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "ProductNavItem (from productNavigator)",
            "AnalysisItem (from analysisViewer)",
            "EntryPoint (from analyzer)"
          ],
          "intent": "This file exists to separate navigation concerns from the main extension logic, providing a centralized way to handle all user navigation actions (opening files, jumping to functions, viewing details) and displaying analysis results in a user-friendly format with proper syntax highlighting and structured information presentation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation between code files, functions, and displays detailed information about analysis items in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the workspace\",\n    \"Navigate to a specific function within a file and highlight it\",\n    \"Navigate to API endpoints and see their location in code\",\n    \"View detailed information about analysis items in a webview panel\",\n    \"See formatted code snippets with syntax highlighting\",\n    \"View function signatures, parameters, and return types\",\n    \"See file paths and line numbers for code locations\",\n    \"View entry point details with formatted information\",\n    \"See error messages when navigation fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger navigation to product items (files, functions, endpoints) from tree views\",\n    \"Display analysis item details in a dedicated webview panel\",\n    \"Open files and position cursor at specific line numbers\",\n    \"Handle navigation for different item types (file, function, navigate)\",\n    \"Generate HTML views with syntax-highlighted code snippets\",\n    \"Format and display complex data structures in readable format\",\n    \"Handle absolute and relative file paths within workspace\",\n    \"Show error messages when file operations fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Opens a file or navigates to a function location based on the product navigation item type\",\n      \"inputs\": \"ProductNavItem (containing file path, function name, and line information)\",\n      \"outputs\": \"Promise<void> (opens document in editor)\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Opens a file and positions cursor at a specific line number for analysis items\",\n      \"inputs\": \"AnalysisItem (containing file path and line number)\",\n      \"outputs\": \"Promise<void> (opens document and reveals line)\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about an analysis item in a webview panel with formatted HTML\",\n      \"inputs\": \"AnalysisItem (analysis data to display)\",\n      \"outputs\": \"void (creates or updates webview panel)\"\n    },\n    {\n      \"name\": \"generateDetailsHtml\",\n      \"desc\": \"Creates formatted HTML content for displaying item details with syntax highlighting and structured layout\",\n      \"inputs\": \"AnalysisItem (item to format)\",\n      \"outputs\": \"string (HTML content)\"\n    },\n    {\n      \"name\": \"escapeHtml\",\n      \"desc\": \"Sanitizes text content for safe HTML rendering\",\n      \"inputs\": \"string (text to escape)\",\n      \"outputs\": \"string (escaped HTML)\"\n    },\n    {\n      \"name\": \"formatValue\",\n      \"desc\": \"Converts various data types into readable HTML-formatted strings\",\n      \"inputs\": \"any (value to format)\",\n      \"outputs\": \"string (formatted HTML)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem (from productNavigator)\",\n    \"AnalysisItem (from analysisViewer)\",\n    \"EntryPoint (from analyzer)\"\n  ],\n  \"intent\": \"This file exists to separate navigation concerns from the main extension logic, providing a centralized way to handle all user navigation actions (opening files, jumping to functions, viewing details) and displaying analysis results in a user-friendly format with proper syntax highlighting and structured information presentation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Generates structured prompts for AI-driven code analysis and architecture evaluation",
        "Creates prompts for automated documentation generation from source code",
        "Produces prompts for comprehensive test generation including setup, planning, and test code",
        "Builds prescriptive refactoring prompts with extraction plans and migration guidance",
        "Generates prompts for analyzing project structure, purpose, and target audience",
        "Creates prompts for module-level summaries and relationship mapping",
        "Provides templates for test framework setup and dependency recommendations"
      ],
      "summary": "This module serves as the prompt engineering layer that powers all AI-driven code analysis and generation features. It constructs specialized, structured prompts that guide LLM interactions for tasks like architecture analysis, documentation creation, test generation, and code refactoring. Each prompt is carefully crafted to extract specific insights from codebases or generate particular outputs.\n\nThe module supports three primary workflows: (1) Code Analysis - generating prompts to understand project architecture, file relationships, and module structure; (2) Documentation Generation - creating prompts that produce product documentation, API references, and code summaries from source files; (3) Test & Refactoring - building prompts for automated test generation with full test plans and actual test code, plus detailed refactoring recommendations with step-by-step migration instructions.\n\nUsers interact with this module indirectly through higher-level features that leverage these prompts. The prompts handle context injection, constraint specification, and output formatting requirements to ensure LLM responses are consistent, actionable, and tailored to specific code analysis needs. This centralized approach ensures all AI interactions maintain quality standards and produce results in expected formats.",
      "files": [
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.",
          "userVisibleActions": [
            "Generates AI prompts that analyze project architecture and structure",
            "Creates AI prompts for generating product documentation from code",
            "Produces AI prompts that determine product purpose and target audience",
            "Generates AI prompts for analyzing individual code files",
            "Creates AI prompts for summarizing code modules and their relationships",
            "Produces AI prompts for generating comprehensive test plans for code files",
            "Generates AI prompts for creating actual test code from test plans"
          ],
          "developerVisibleActions": [
            "Developer calls prompt builder methods to generate LLM prompts for different analysis tasks",
            "System constructs architecture analysis prompts by combining code analysis, product docs, and context",
            "System builds product documentation prompts from project context and file structure",
            "System generates file-specific analysis prompts including code content and role information",
            "System creates module rollup prompts aggregating file summaries within a module",
            "System produces product-level documentation prompts combining all summaries and analysis",
            "System generates test planning prompts with function metadata and existing test information",
            "System creates test code generation prompts with test plans and source code references",
            "All prompts include token budgets and structured output requirements for consistent LLM responses"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure",
              "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
              "outputs": "Formatted string prompt with architecture analysis instructions and context"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Creates a prompt for generating product-level documentation from code structure",
              "inputs": "context (AnalysisContext)",
              "outputs": "Formatted string prompt requesting product documentation generation"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Generates a prompt for determining product purpose, target audience, and value proposition",
              "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
              "outputs": "Formatted string prompt for product purpose analysis"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Creates a prompt for analyzing a single code file's behavior and purpose",
              "inputs": "file (FileInfo), content (string), role (string)",
              "outputs": "Formatted string prompt with file content and analysis instructions"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Generates a prompt for summarizing a module by aggregating its file summaries",
              "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
              "outputs": "Formatted string prompt for module-level summary generation"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Creates a comprehensive prompt for product-level documentation combining all analysis results",
              "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper",
              "outputs": "Formatted string prompt for complete product documentation"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Generates a prompt for creating a test plan for a specific file's functions",
              "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
              "outputs": "Formatted string prompt requesting structured test plan generation"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Creates a prompt for generating actual test code from a test plan item",
              "inputs": "testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)",
              "outputs": "Formatted string prompt with test plan and code context for test generation"
            }
          ],
          "dependencies": [
            "../../llmService (AnalysisContext, ProductPurposeAnalysis)",
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)",
            "../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)",
            "../../fileAccessHelper (FileAccessHelper)"
          ],
          "intent": "This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.",
          "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.\",\n  \"userVisibleActions\": [\n    \"Generates AI prompts that analyze project architecture and structure\",\n    \"Creates AI prompts for generating product documentation from code\",\n    \"Produces AI prompts that determine product purpose and target audience\",\n    \"Generates AI prompts for analyzing individual code files\",\n    \"Creates AI prompts for summarizing code modules and their relationships\",\n    \"Produces AI prompts for generating comprehensive test plans for code files\",\n    \"Generates AI prompts for creating actual test code from test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls prompt builder methods to generate LLM prompts for different analysis tasks\",\n    \"System constructs architecture analysis prompts by combining code analysis, product docs, and context\",\n    \"System builds product documentation prompts from project context and file structure\",\n    \"System generates file-specific analysis prompts including code content and role information\",\n    \"System creates module rollup prompts aggregating file summaries within a module\",\n    \"System produces product-level documentation prompts combining all summaries and analysis\",\n    \"System generates test planning prompts with function metadata and existing test information\",\n    \"System creates test code generation prompts with test plans and source code references\",\n    \"All prompts include token budgets and structured output requirements for consistent LLM responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt with architecture analysis instructions and context\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates a prompt for generating product-level documentation from code structure\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt requesting product documentation generation\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Generates a prompt for determining product purpose, target audience, and value proposition\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for product purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates a prompt for analyzing a single code file's behavior and purpose\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted string prompt with file content and analysis instructions\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Generates a prompt for summarizing a module by aggregating its file summaries\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted string prompt for module-level summary generation\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for product-level documentation combining all analysis results\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for complete product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Generates a prompt for creating a test plan for a specific file's functions\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted string prompt requesting structured test plan generation\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Creates a prompt for generating actual test code from a test plan item\",\n      \"inputs\": \"testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)\",\n      \"outputs\": \"Formatted string prompt with test plan and code context for test generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService (AnalysisContext, ProductPurposeAnalysis)\",\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)\",\n    \"../../fileAccessHelper (FileAccessHelper)\"\n  ],\n  \"intent\": \"This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.",
          "userVisibleActions": [
            "Receives detailed refactoring recommendations showing which code should be extracted and where",
            "Gets step-by-step migration instructions for moving code between files",
            "Sees before-and-after code examples demonstrating proposed refactorings",
            "Views function dependency relationships to understand refactoring impacts",
            "Receives prescriptive guidance on how to organize code into better structures"
          ],
          "developerVisibleActions": [
            "Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions",
            "Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance",
            "Receives structured extraction plans showing which functions to move from source to target files",
            "Gets migration steps and code examples to execute the refactoring safely",
            "Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]",
              "outputs": "Formatted string prompt containing refactoring instructions and requirements"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Creates the foundation prompt with context, code analysis, and architectural insights",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
              "outputs": "Base prompt string"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Adds detailed function-level analysis including dependencies and responsibilities to the prompt",
              "inputs": "FunctionAnalysis[]",
              "outputs": "Formatted section describing function characteristics"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Specifies requirements for code extraction plans including target files and migration steps",
              "inputs": "None",
              "outputs": "Section detailing extraction plan requirements"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
            "../../llmService (AnalysisContext, LLMInsights)",
            "../../fileDocumentation (EnhancedProductDocumentation)"
          ],
          "intent": "This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.",
          "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations showing which code should be extracted and where\",\n    \"Gets step-by-step migration instructions for moving code between files\",\n    \"Sees before-and-after code examples demonstrating proposed refactorings\",\n    \"Views function dependency relationships to understand refactoring impacts\",\n    \"Receives prescriptive guidance on how to organize code into better structures\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions\",\n    \"Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance\",\n    \"Receives structured extraction plans showing which functions to move from source to target files\",\n    \"Gets migration steps and code examples to execute the refactoring safely\",\n    \"Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]\",\n      \"outputs\": \"Formatted string prompt containing refactoring instructions and requirements\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundation prompt with context, code analysis, and architectural insights\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function-level analysis including dependencies and responsibilities to the prompt\",\n      \"inputs\": \"FunctionAnalysis[]\",\n      \"outputs\": \"Formatted section describing function characteristics\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Specifies requirements for code extraction plans including target files and migration steps\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Section detailing extraction plan requirements\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides prompt templates for LLM-based automated test generation and test configuration setup",
          "userVisibleActions": [
            "Automatically generates test setup recommendations for the codebase",
            "Creates prioritized test plans identifying which functions need testing",
            "Generates actual test code with assertions and edge cases",
            "Analyzes codebase to determine optimal testing framework and dependencies"
          ],
          "developerVisibleActions": [
            "Call buildSetupPrompt() to get LLM prompt for test configuration analysis",
            "Call buildPlanningPrompt() to get LLM prompt for test strategy creation",
            "Call buildGenerationPrompt() to get LLM prompt for actual test code generation",
            "Provide workspace root, file lists, and function details as inputs",
            "Receive structured JSON responses with test setup configurations, test plans, or generated test code",
            "Pass in optional product documentation and architecture insights to improve test generation quality"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Creates prompt for LLM to analyze codebase and recommend test setup configuration",
              "inputs": "workspaceRoot (string), fileList (array), optional packageJsonContent (string)",
              "outputs": "Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Creates prompt for LLM to generate prioritized test plan for functions",
              "inputs": "context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights",
              "outputs": "Formatted prompt string requesting prioritized list of functions to test with complexity assessments"
            },
            {
              "name": "buildGenerationPrompt",
              "desc": "Creates prompt for LLM to generate actual test code for specific function",
              "inputs": "testableFunction (TestableFunction), framework (string), optional fileContext (string)",
              "outputs": "Formatted prompt string requesting complete test code with imports, mocks, and assertions"
            }
          ],
          "dependencies": [
            "../../analyzer",
            "../services/testing/types/testPlanTypes"
          ],
          "intent": "Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based automated test generation and test configuration setup\",\n  \"userVisibleActions\": [\n    \"Automatically generates test setup recommendations for the codebase\",\n    \"Creates prioritized test plans identifying which functions need testing\",\n    \"Generates actual test code with assertions and edge cases\",\n    \"Analyzes codebase to determine optimal testing framework and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() to get LLM prompt for test configuration analysis\",\n    \"Call buildPlanningPrompt() to get LLM prompt for test strategy creation\",\n    \"Call buildGenerationPrompt() to get LLM prompt for actual test code generation\",\n    \"Provide workspace root, file lists, and function details as inputs\",\n    \"Receive structured JSON responses with test setup configurations, test plans, or generated test code\",\n    \"Pass in optional product documentation and architecture insights to improve test generation quality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates prompt for LLM to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate prioritized test plan for functions\",\n      \"inputs\": \"context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted prompt string requesting prioritized list of functions to test with complexity assessments\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate actual test code for specific function\",\n      \"inputs\": \"testableFunction (TestableFunction), framework (string), optional fileContext (string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test code with imports, mocks, and assertions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatic detection and monitoring of file system changes across the workspace",
        "Intelligent test framework detection and configuration validation",
        "Iterative AI-powered codebase analysis with progressive information gathering",
        "Consolidated event handling to prevent duplicate processing of file changes",
        "Automatic dependency and configuration validation for test frameworks"
      ],
      "summary": "This module provides core services that power the extension's intelligent automation features. It monitors file system changes and document saves to keep the UI and analysis up-to-date without user intervention. When files are created, modified, or deleted, the service automatically detects these changes and triggers appropriate updates across the extension.\n\nThe module enables AI-powered analysis through an iterative process where the LLM can progressively request additional files or perform grep searches across the codebase until it has sufficient information to complete its task. This allows for thorough, context-aware analysis without overwhelming the AI with unnecessary information upfront.\n\nFor test generation workflows, the module automatically detects which test framework is in use (Jest, Mocha, Vitest, or Pytest), validates the configuration, and identifies missing dependencies. Users receive clear feedback about what needs to be installed or configured before generated tests can run, eliminating manual setup and configuration guesswork.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides a unified service for watching file system changes and document saves across the extension to eliminate code duplication.",
          "userVisibleActions": [
            "File changes are automatically detected when files matching watched patterns are created, modified, or deleted",
            "Document saves trigger automatic updates and refreshes in related UI components",
            "Changes to specific file types (like documentation files) are monitored and processed",
            "File system events are consolidated to prevent duplicate processing of the same changes"
          ],
          "developerVisibleActions": [
            "Register file watchers with custom patterns and handlers to respond to file system changes",
            "Subscribe to document save events with custom callback functions",
            "Configure ignore patterns to exclude specific files or directories from being watched",
            "Control which types of events to watch (create, change, delete) per pattern",
            "Manage multiple handlers for the same file pattern with unique identifiers",
            "Dispose of specific watchers or all watchers to clean up resources",
            "Receive standardized FileChangeEvent objects with URI and event type information"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Registers a file system watcher for a specific pattern with options to filter event types and ignore patterns",
              "inputs": "id (string), pattern (string or RelativePattern), handler (FileChangeHandler), options (watchCreate, watchChange, watchDelete, ignorePatterns)",
              "outputs": "Disposable object to unregister the watcher"
            },
            {
              "name": "onDocumentSave",
              "desc": "Registers a handler to be called whenever any document is saved in the workspace",
              "inputs": "handler function that receives a TextDocument",
              "outputs": "Disposable object to unregister the handler"
            },
            {
              "name": "unwatch",
              "desc": "Removes a specific file watcher by its unique identifier",
              "inputs": "id (string)",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all watchers and handlers, releasing system resources",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getPatternKey",
              "desc": "Generates a unique key for a file pattern to identify and deduplicate watchers",
              "inputs": "pattern (string or RelativePattern)",
              "outputs": "string key"
            },
            {
              "name": "shouldIgnore",
              "desc": "Determines if a file URI should be ignored based on configured ignore patterns",
              "inputs": "uri (vscode.Uri), ignorePatterns (array of strings)",
              "outputs": "boolean"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to consolidate duplicate file watching logic that was previously scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file watching behavior and prevents resource leaks by providing a single, well-managed service that can handle multiple watchers with different patterns, ignore rules, and event handlers while ensuring proper cleanup and disposal.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified service for watching file system changes and document saves across the extension to eliminate code duplication.\",\n  \"userVisibleActions\": [\n    \"File changes are automatically detected when files matching watched patterns are created, modified, or deleted\",\n    \"Document saves trigger automatic updates and refreshes in related UI components\",\n    \"Changes to specific file types (like documentation files) are monitored and processed\",\n    \"File system events are consolidated to prevent duplicate processing of the same changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers with custom patterns and handlers to respond to file system changes\",\n    \"Subscribe to document save events with custom callback functions\",\n    \"Configure ignore patterns to exclude specific files or directories from being watched\",\n    \"Control which types of events to watch (create, change, delete) per pattern\",\n    \"Manage multiple handlers for the same file pattern with unique identifiers\",\n    \"Dispose of specific watchers or all watchers to clean up resources\",\n    \"Receive standardized FileChangeEvent objects with URI and event type information\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file system watcher for a specific pattern with options to filter event types and ignore patterns\",\n      \"inputs\": \"id (string), pattern (string or RelativePattern), handler (FileChangeHandler), options (watchCreate, watchChange, watchDelete, ignorePatterns)\",\n      \"outputs\": \"Disposable object to unregister the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever any document is saved in the workspace\",\n      \"inputs\": \"handler function that receives a TextDocument\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific file watcher by its unique identifier\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers, releasing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to identify and deduplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file URI should be ignored based on configured ignore patterns\",\n      \"inputs\": \"uri (vscode.Uri), ignorePatterns (array of strings)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate duplicate file watching logic that was previously scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file watching behavior and prevents resource leaks by providing a single, well-managed service that can handle multiple watchers with different patterns, ignore rules, and event handlers while ensuring proper cleanup and disposal.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task",
          "userVisibleActions": [
            "AI progressively gathers more information about the codebase by requesting specific files",
            "AI performs grep searches to find relevant code patterns across the project",
            "Analysis completes after gathering sufficient information or reaching maximum iteration limit",
            "Receives additional context information formatted as markdown sections"
          ],
          "developerVisibleActions": [
            "Trigger incremental analysis that automatically handles LLM requests for files and grep searches",
            "Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)",
            "Control maximum number of analysis iterations to prevent infinite loops",
            "Receive structured results including all processed requests and conversation history",
            "Access shouldContinue flag to determine if analysis needs more iterations"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages",
              "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation history)",
              "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
            },
            {
              "name": "iterativeAnalysis (implied by async iterator pattern)",
              "desc": "Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached",
              "inputs": "iteration callbacks, max iterations, initial result and messages",
              "outputs": "IterationResult containing final result, iteration count, all requests, and continuation status"
            }
          ],
          "dependencies": [
            "fileAccessHelper",
            "LLMRequest interface",
            "FileAccessHelper class"
          ],
          "intent": "Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"AI progressively gathers more information about the codebase by requesting specific files\",\n    \"AI performs grep searches to find relevant code patterns across the project\",\n    \"Analysis completes after gathering sufficient information or reaching maximum iteration limit\",\n    \"Receives additional context information formatted as markdown sections\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger incremental analysis that automatically handles LLM requests for files and grep searches\",\n    \"Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)\",\n    \"Control maximum number of analysis iterations to prevent infinite loops\",\n    \"Receive structured results including all processed requests and conversation history\",\n    \"Access shouldContinue flag to determine if analysis needs more iterations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"iterativeAnalysis (implied by async iterator pattern)\",\n      \"desc\": \"Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached\",\n      \"inputs\": \"iteration callbacks, max iterations, initial result and messages\",\n      \"outputs\": \"IterationResult containing final result, iteration count, all requests, and continuation status\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest interface\",\n    \"FileAccessHelper class\"\n  ],\n  \"intent\": \"Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects test framework configuration and dependencies to ensure generated tests work without manual user setup",
          "userVisibleActions": [
            "Automatically detects which test framework is being used (Jest, Mocha, Vitest, or Pytest)",
            "Identifies missing test dependencies that need to be installed",
            "Provides setup recommendations when test configuration is incomplete",
            "Warns about missing configuration files needed for tests to run",
            "Reports whether the workspace is ready to run generated tests"
          ],
          "developerVisibleActions": [
            "Scans package.json to detect test framework from scripts and dependencies",
            "Checks for framework-specific configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini)",
            "Validates TypeScript-related test dependencies (ts-jest, @jest/globals)",
            "Determines if additional setup actions are required before tests can run",
            "Returns structured status information about test configuration state"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Analyzes workspace to determine test framework and configuration status",
              "inputs": "workspaceRoot: string (path to workspace folder)",
              "outputs": "TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "SWLogger"
          ],
          "intent": "Eliminates the need for users to manually configure test frameworks by automatically detecting what's available and what's missing, ensuring a smooth experience when generating and running tests. Solves the problem of tests failing due to missing configuration or dependencies by proactively identifying issues.",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration and dependencies to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used (Jest, Mocha, Vitest, or Pytest)\",\n    \"Identifies missing test dependencies that need to be installed\",\n    \"Provides setup recommendations when test configuration is incomplete\",\n    \"Warns about missing configuration files needed for tests to run\",\n    \"Reports whether the workspace is ready to run generated tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans package.json to detect test framework from scripts and dependencies\",\n    \"Checks for framework-specific configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini)\",\n    \"Validates TypeScript-related test dependencies (ts-jest, @jest/globals)\",\n    \"Determines if additional setup actions are required before tests can run\",\n    \"Returns structured status information about test configuration state\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to determine test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to workspace folder)\",\n      \"outputs\": \"TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates the need for users to manually configure test frameworks by automatically detecting what's available and what's missing, ensuring a smooth experience when generating and running tests. Solves the problem of tests failing due to missing configuration or dependencies by proactively identifying issues.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automatically generates AI-powered tests for code functions in the workspace",
        "Creates prioritized test plans that determine which functions need testing and in what order",
        "Detects existing test framework configuration (Jest, pytest, JUnit, etc.) and generates appropriate test setups",
        "Executes tests and captures detailed results including pass/fail status, error messages, and coverage metrics",
        "Automatically fixes failing tests through iterative LLM-powered refinement",
        "Provides real-time progress updates during test generation, execution, and validation",
        "Generates comprehensive test reports with statistics on coverage, success rates, and identified issues"
      ],
      "summary": "This module provides an AI-powered automated testing system that generates, executes, and validates tests for code in the workspace. It analyzes the codebase to create intelligent test plans, prioritizing which functions need testing based on complexity, risk, and existing coverage. The system automatically detects the test framework being used (Jest, Mocha, pytest, JUnit, etc.) and generates tests that follow the project's conventions and structure.\n\nThe testing workflow operates in stages: first analyzing functions to determine testability, then generating tests in small batches for incremental validation, executing those tests to capture results, and automatically fixing any failures through LLM-powered iteration. Users receive continuous progress updates showing which function is being tested (e.g., '3 of 10: validateUser'), along with real-time pass/fail results and detailed error messages for any failures.\n\nThe module handles the complete testing lifecycle from setup to reporting, including detecting missing test infrastructure, generating appropriate test directory structures, executing test suites with timeout handling, and producing comprehensive coverage reports. It supports multiple testing frameworks and programming languages, adapting its test generation strategy to match the project's existing patterns and conventions. Failed tests are automatically refined through multiple fix attempts, with each iteration learning from previous failures to improve test quality.",
      "files": [
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates automated tests for code functions using AI/LLM in small batches, executing and validating them incrementally.",
          "userVisibleActions": [
            "Tests are generated automatically for selected functions in the codebase",
            "Progress updates show which function is currently being tested (e.g., '3 of 10: validateUser')",
            "Test results display pass/fail status for each generated test",
            "Coverage reports show which functions have tests and which need them",
            "Failed tests show error messages and execution details"
          ],
          "developerVisibleActions": [
            "Developer triggers test generation for a batch of functions",
            "System reads function source code and existing mocks automatically",
            "LLM generates test code based on function signatures and implementation",
            "Generated tests are written to the test directory structure",
            "Tests are executed immediately to verify they work",
            "Progress callback provides real-time updates during generation",
            "Results include test code, execution status, and any errors encountered"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for multiple functions in sequence with progress tracking",
              "inputs": "functions array, workspace root path, LLM service, optional progress callback",
              "outputs": "Map of function names to test generation results (code, execution status, errors)"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Retrieves the source code for a specific function from the file system",
              "inputs": "function metadata, workspace root",
              "outputs": "Source code string"
            },
            {
              "name": "buildGenerationPrompt",
              "desc": "Constructs the AI prompt with function details, source code, and existing mocks",
              "inputs": "function metadata, source code, test framework type, existing mock code",
              "outputs": "Formatted prompt string for LLM"
            },
            {
              "name": "generateTestForFunction",
              "desc": "Calls LLM service to generate test code for a single function",
              "inputs": "Prompt string",
              "outputs": "Test generation result with code and metadata"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestableFunction",
            "TestGenerationState",
            "TestGenerationResult",
            "buildGenerationPrompt",
            "TestExecutionService",
            "SWLogger"
          ],
          "intent": "This service solves the problem of manually writing tests by automating test generation using AI. It processes functions in manageable batches to avoid overwhelming the system, provides real-time progress feedback, and validates generated tests by executing them immediately. This enables developers to quickly achieve test coverage across their codebase.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates automated tests for code functions using AI/LLM in small batches, executing and validating them incrementally.\",\n  \"userVisibleActions\": [\n    \"Tests are generated automatically for selected functions in the codebase\",\n    \"Progress updates show which function is currently being tested (e.g., '3 of 10: validateUser')\",\n    \"Test results display pass/fail status for each generated test\",\n    \"Coverage reports show which functions have tests and which need them\",\n    \"Failed tests show error messages and execution details\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for a batch of functions\",\n    \"System reads function source code and existing mocks automatically\",\n    \"LLM generates test code based on function signatures and implementation\",\n    \"Generated tests are written to the test directory structure\",\n    \"Tests are executed immediately to verify they work\",\n    \"Progress callback provides real-time updates during generation\",\n    \"Results include test code, execution status, and any errors encountered\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in sequence with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service, optional progress callback\",\n      \"outputs\": \"Map of function names to test generation results (code, execution status, errors)\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Retrieves the source code for a specific function from the file system\",\n      \"inputs\": \"function metadata, workspace root\",\n      \"outputs\": \"Source code string\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Constructs the AI prompt with function details, source code, and existing mocks\",\n      \"inputs\": \"function metadata, source code, test framework type, existing mock code\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"generateTestForFunction\",\n      \"desc\": \"Calls LLM service to generate test code for a single function\",\n      \"inputs\": \"Prompt string\",\n      \"outputs\": \"Test generation result with code and metadata\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service solves the problem of manually writing tests by automating test generation using AI. It processes functions in manageable batches to avoid overwhelming the system, provides real-time progress feedback, and validates generated tests by executing them immediately. This enables developers to quickly achieve test coverage across their codebase.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Creates AI-powered prioritized test plans by analyzing code functions and determining which ones need testing and in what order.",
          "userVisibleActions": [
            "System analyzes code functions and determines which ones can be tested",
            "System generates a prioritized test plan showing which functions to test first",
            "System explains why certain functions are testable or not testable",
            "Test plan is saved to disk for review and implementation"
          ],
          "developerVisibleActions": [
            "Developer triggers test plan creation for analyzed code",
            "System analyzes function complexity, parameters, and return types",
            "LLM evaluates functions against product documentation and architecture insights",
            "System categorizes functions into priority groups (high, medium, low priority)",
            "Test plan with function groups and testing recommendations is generated",
            "Plan is saved as JSON file in output directory for developer review"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts function metadata from code analysis including name, location, complexity, and signature",
              "inputs": "codeAnalysis object containing function data",
              "outputs": "Array of function metadata objects"
            },
            {
              "name": "createTestPlan",
              "desc": "Uses LLM to generate prioritized test strategy based on functions, documentation, and architecture",
              "inputs": "context, functions array, llmService, optional productDocs and architectureInsights",
              "outputs": "TestPlan object with function groups and testing recommendations"
            },
            {
              "name": "saveTestPlan",
              "desc": "Persists the generated test plan to disk as a JSON file",
              "inputs": "testPlan object, output directory path",
              "outputs": "File path where plan was saved"
            }
          ],
          "dependencies": [
            "fs (file system operations)",
            "path (file path handling)",
            "TestPlan and TestableFunction types",
            "buildPlanningPrompt from testPrompts",
            "AnalysisContext from analyzer",
            "SWLogger for logging",
            "LLM service for AI-powered analysis"
          ],
          "intent": "This file solves the problem of determining which code functions should be tested and in what order. Instead of manually reviewing code to decide testing priorities, it uses AI to analyze function complexity, dependencies, and business importance to create an intelligent, prioritized test plan that guides developers on where to focus testing efforts first.",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates AI-powered prioritized test plans by analyzing code functions and determining which ones need testing and in what order.\",\n  \"userVisibleActions\": [\n    \"System analyzes code functions and determines which ones can be tested\",\n    \"System generates a prioritized test plan showing which functions to test first\",\n    \"System explains why certain functions are testable or not testable\",\n    \"Test plan is saved to disk for review and implementation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test plan creation for analyzed code\",\n    \"System analyzes function complexity, parameters, and return types\",\n    \"LLM evaluates functions against product documentation and architecture insights\",\n    \"System categorizes functions into priority groups (high, medium, low priority)\",\n    \"Test plan with function groups and testing recommendations is generated\",\n    \"Plan is saved as JSON file in output directory for developer review\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts function metadata from code analysis including name, location, complexity, and signature\",\n      \"inputs\": \"codeAnalysis object containing function data\",\n      \"outputs\": \"Array of function metadata objects\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Uses LLM to generate prioritized test strategy based on functions, documentation, and architecture\",\n      \"inputs\": \"context, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups and testing recommendations\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to disk as a JSON file\",\n      \"inputs\": \"testPlan object, output directory path\",\n      \"outputs\": \"File path where plan was saved\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs (file system operations)\",\n    \"path (file path handling)\",\n    \"TestPlan and TestableFunction types\",\n    \"buildPlanningPrompt from testPrompts\",\n    \"AnalysisContext from analyzer\",\n    \"SWLogger for logging\",\n    \"LLM service for AI-powered analysis\"\n  ],\n  \"intent\": \"This file solves the problem of determining which code functions should be tested and in what order. Instead of manually reviewing code to decide testing priorities, it uses AI to analyze function complexity, dependencies, and business importance to create an intelligent, prioritized test plan that guides developers on where to focus testing efforts first.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Detects test environment configuration and generates test setup plans using LLM analysis of the codebase structure",
          "userVisibleActions": [
            "Automatic detection of test framework (Jest, pytest, JUnit, etc.) in the workspace",
            "Identification of primary programming language used in the project",
            "Generation of test setup configuration based on existing project structure",
            "Detection of missing test infrastructure components",
            "Automated test directory structure recognition"
          ],
          "developerVisibleActions": [
            "Scans workspace for package.json, tsconfig.json, jest.config.js and test directories",
            "Analyzes file extensions to determine primary language (TypeScript, JavaScript, Python, Java, C++)",
            "Counts file types across the workspace to identify language distribution",
            "Detects installed testing frameworks and dependencies from package.json",
            "Builds prompts for LLM to generate test setup recommendations",
            "Returns TestEnvironment object containing detected configuration",
            "Provides TestSetupPlan with recommended setup steps"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Analyzes workspace to identify testing framework, language, and existing test infrastructure",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestEnvironment object with detected configuration details"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively scans workspace to get all file paths for analysis",
              "inputs": "workspaceRoot: string",
              "outputs": "Array of file paths"
            },
            {
              "name": "buildSetupPrompt",
              "desc": "Creates LLM prompt for generating test setup recommendations",
              "inputs": "TestEnvironment data",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "testSetupTypes",
            "testPrompts",
            "SWLogger"
          ],
          "intent": "This service exists to automate the initial test setup process by intelligently detecting the current project's testing environment and generating appropriate configuration recommendations, eliminating manual setup work and reducing configuration errors for developers starting with testing.",
          "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates test setup plans using LLM analysis of the codebase structure\",\n  \"userVisibleActions\": [\n    \"Automatic detection of test framework (Jest, pytest, JUnit, etc.) in the workspace\",\n    \"Identification of primary programming language used in the project\",\n    \"Generation of test setup configuration based on existing project structure\",\n    \"Detection of missing test infrastructure components\",\n    \"Automated test directory structure recognition\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace for package.json, tsconfig.json, jest.config.js and test directories\",\n    \"Analyzes file extensions to determine primary language (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Counts file types across the workspace to identify language distribution\",\n    \"Detects installed testing frameworks and dependencies from package.json\",\n    \"Builds prompts for LLM to generate test setup recommendations\",\n    \"Returns TestEnvironment object containing detected configuration\",\n    \"Provides TestSetupPlan with recommended setup steps\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to identify testing framework, language, and existing test infrastructure\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object with detected configuration details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans workspace to get all file paths for analysis\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates LLM prompt for generating test setup recommendations\",\n      \"inputs\": \"TestEnvironment data\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to automate the initial test setup process by intelligently detecting the current project's testing environment and generating appropriate configuration recommendations, eliminating manual setup work and reducing configuration errors for developers starting with testing.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates tests by running them, detecting failures, and automatically fixing failing tests using an LLM.",
          "userVisibleActions": [
            "Tests are automatically executed in the workspace",
            "Test results are displayed showing passed, failed, and total test counts",
            "Failing tests are automatically fixed through multiple attempts",
            "Progress updates are shown for each fix attempt",
            "Final test validation reports are generated with success/failure statistics"
          ],
          "developerVisibleActions": [
            "Trigger test execution for entire workspace or specific test files",
            "Initiate automatic fixing of failing tests with configurable retry attempts",
            "Receive structured test execution results with pass/fail counts per file",
            "Get detailed test reports including failure messages and stack traces",
            "Access test report summaries with overall statistics",
            "Monitor fix attempt progress through logged messages"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or tests in a specific file and captures results",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> - array of test results per file"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to automatically fix a failing test using LLM with retry logic",
              "inputs": "testFilePath (string), executionResult (TestExecutionResult), workspaceRoot (string), llmService (any), optional maxAttempts (number, default 3)",
              "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}>"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "testResultTypes (TestExecutionResult, TestReport, TestReportSummary)",
            "testPrompts (buildFixPrompt)",
            "SWLogger"
          ],
          "intent": "This file exists to automate the test validation workflow by running tests, identifying failures, and using LLM capabilities to automatically fix broken tests with intelligent retry logic. It solves the problem of manual test debugging and fixing by providing an automated validation and repair pipeline for generated or existing tests.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them, detecting failures, and automatically fixing failing tests using an LLM.\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed in the workspace\",\n    \"Test results are displayed showing passed, failed, and total test counts\",\n    \"Failing tests are automatically fixed through multiple attempts\",\n    \"Progress updates are shown for each fix attempt\",\n    \"Final test validation reports are generated with success/failure statistics\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test execution for entire workspace or specific test files\",\n    \"Initiate automatic fixing of failing tests with configurable retry attempts\",\n    \"Receive structured test execution results with pass/fail counts per file\",\n    \"Get detailed test reports including failure messages and stack traces\",\n    \"Access test report summaries with overall statistics\",\n    \"Monitor fix attempt progress through logged messages\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or tests in a specific file and captures results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - array of test results per file\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with retry logic\",\n      \"inputs\": \"testFilePath (string), executionResult (TestExecutionResult), workspaceRoot (string), llmService (any), optional maxAttempts (number, default 3)\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"testResultTypes (TestExecutionResult, TestReport, TestReportSummary)\",\n    \"testPrompts (buildFixPrompt)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation workflow by running tests, identifying failures, and using LLM capabilities to automatically fix broken tests with intelligent retry logic. It solves the problem of manual test debugging and fixing by providing an automated validation and repair pipeline for generated or existing tests.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes test suites (Jest, Mocha, Pytest) and captures their results for analysis and reporting",
          "userVisibleActions": [
            "Runs tests for a specific file or all tests in the workspace",
            "Shows test execution progress with status updates",
            "Displays test results including passed, failed, and error counts",
            "Shows test execution duration for each test suite",
            "Reports detailed error messages and stack traces for failed tests",
            "Indicates when tests timeout or fail to execute"
          ],
          "developerVisibleActions": [
            "Calls runJest() to execute Jest tests with optional file parameter",
            "Calls runMocha() to execute Mocha tests with optional file parameter",
            "Calls runPytest() to execute Python tests with optional file parameter",
            "Receives TestExecutionResult[] containing pass/fail status, counts, duration, and error details",
            "Handles test execution errors and timeouts gracefully",
            "Works with workspace root path to locate test files",
            "Parses test framework output (JSON format) into structured results",
            "Provides detailed error information including test name, message, and stack trace"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Executes Jest test suite for a specific file or all tests",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runMocha",
              "desc": "Executes Mocha test suite for a specific file or all tests",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runPytest",
              "desc": "Executes Pytest test suite for a specific file or all tests",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "parseJestOutput",
              "desc": "Parses Jest JSON output into structured test results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parseMochaOutput",
              "desc": "Parses Mocha JSON output into structured test results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parsePytestOutput",
              "desc": "Parses Pytest JSON output into structured test results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "This service solves the problem of running different test frameworks (Jest, Mocha, Pytest) in a unified way and translating their diverse output formats into a consistent structured format that can be analyzed, reported, and acted upon. It abstracts away the complexity of executing shell commands, parsing framework-specific output, and handling errors.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest) and captures their results for analysis and reporting\",\n  \"userVisibleActions\": [\n    \"Runs tests for a specific file or all tests in the workspace\",\n    \"Shows test execution progress with status updates\",\n    \"Displays test results including passed, failed, and error counts\",\n    \"Shows test execution duration for each test suite\",\n    \"Reports detailed error messages and stack traces for failed tests\",\n    \"Indicates when tests timeout or fail to execute\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls runJest() to execute Jest tests with optional file parameter\",\n    \"Calls runMocha() to execute Mocha tests with optional file parameter\",\n    \"Calls runPytest() to execute Python tests with optional file parameter\",\n    \"Receives TestExecutionResult[] containing pass/fail status, counts, duration, and error details\",\n    \"Handles test execution errors and timeouts gracefully\",\n    \"Works with workspace root path to locate test files\",\n    \"Parses test framework output (JSON format) into structured results\",\n    \"Provides detailed error information including test name, message, and stack trace\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Pytest test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses Mocha JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses Pytest JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This service solves the problem of running different test frameworks (Jest, Mocha, Pytest) in a unified way and translating their diverse output formats into a consistent structured format that can be analyzed, reported, and acted upon. It abstracts away the complexity of executing shell commands, parsing framework-specific output, and handling errors.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Define structured type definitions for test generation workflows across setup, planning, generation, validation, and execution phases",
        "Track test generation progress and status for each function in the codebase with detailed phase tracking",
        "Monitor test execution results including pass/fail status, error details, and performance metrics",
        "Organize functions by testing complexity and priority for systematic test generation",
        "Configure test environments with language-specific frameworks and dependencies",
        "Generate comprehensive test reports with quality recommendations and pass rate statistics",
        "Track retry attempts and failure reasons for failed test generation or validation"
      ],
      "summary": "This module provides the complete type system for automated test generation and execution workflows. It defines three core type categories: test setup types for environment configuration, test plan types for organizing and tracking which functions need tests generated, and test result types for capturing execution outcomes and generating reports.\n\nUsers interact with these types through a multi-phase workflow: first configuring the test environment with appropriate frameworks and dependencies, then planning which functions to test based on complexity and priority, generating tests for those functions, validating the generated tests, and finally executing them to produce detailed reports. The type system tracks each function's journey through these phases, maintaining status information, error details, retry counts, and timing metrics.\n\nThe module enables comprehensive visibility into the testing process, allowing users to see exactly which functions are testable, how many tests have been generated and validated, which tests are passing or failing, and where improvements are needed. Test reports include pass rates, execution durations, error messages with stack traces, and actionable recommendations for enhancing test quality. This structured approach ensures systematic test coverage across the entire codebase while providing clear feedback at every step.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for organizing and tracking automated test generation for code functions",
          "userVisibleActions": [
            "View test generation progress through different phases (setup, planning, generation, validation, complete)",
            "See how many functions are testable out of total functions in the codebase",
            "Track which functions have tests generated and validated",
            "Monitor test generation failures with error details and retry attempts",
            "Understand function complexity and testing priority through grouped organization"
          ],
          "developerVisibleActions": [
            "Define test plans that organize functions into prioritized groups for systematic test generation",
            "Track test generation workflow state across multiple phases",
            "Specify function metadata including file location, line numbers, complexity, and dependencies",
            "Identify which functions require mocking based on external dependencies",
            "Monitor batch processing of test generation with real-time counts and timestamps",
            "Handle and record test generation failures with error tracking and retry logic"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to provide a structured type system for managing automated test generation workflows. It solves the problem of organizing and tracking the complex process of generating tests for multiple functions by defining clear phases, grouping strategies, function metadata, and failure tracking mechanisms. It ensures type safety when planning which functions to test, monitoring generation progress, and handling errors during automated test creation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for organizing and tracking automated test generation for code functions\",\n  \"userVisibleActions\": [\n    \"View test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"See how many functions are testable out of total functions in the codebase\",\n    \"Track which functions have tests generated and validated\",\n    \"Monitor test generation failures with error details and retry attempts\",\n    \"Understand function complexity and testing priority through grouped organization\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define test plans that organize functions into prioritized groups for systematic test generation\",\n    \"Track test generation workflow state across multiple phases\",\n    \"Specify function metadata including file location, line numbers, complexity, and dependencies\",\n    \"Identify which functions require mocking based on external dependencies\",\n    \"Monitor batch processing of test generation with real-time counts and timestamps\",\n    \"Handle and record test generation failures with error tracking and retry logic\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a structured type system for managing automated test generation workflows. It solves the problem of organizing and tracking the complex process of generating tests for multiple functions by defining clear phases, grouping strategies, function metadata, and failure tracking mechanisms. It ensures type safety when planning which functions to test, monitoring generation progress, and handling errors during automated test creation.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test generation, validation, execution, and reporting results.",
          "userVisibleActions": [
            "View test execution status (pass/fail/error) for each test file",
            "See how many tests passed, failed, or encountered errors",
            "Review test execution duration and timing information",
            "Read error messages and stack traces for failed tests",
            "View test report summary with pass rates and file statistics",
            "Access recommendations for improving test quality",
            "See which test files were generated and which are passing"
          ],
          "developerVisibleActions": [
            "Define structured test generation results with imports, mocks, and test code",
            "Represent mock statements with explanations for clarity",
            "Handle test validation results with fixed code and remaining issues",
            "Track detailed test execution metrics including passed/failed/error counts",
            "Capture error details with test names, messages, and stack traces",
            "Generate comprehensive test reports with summaries and recommendations",
            "Structure test report summaries with pass rates and file counts"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a standardized type system for representing test-related data throughout the testing workflow, ensuring consistent structure for test generation output, validation feedback, execution results, and comprehensive reporting with metrics and recommendations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test generation, validation, execution, and reporting results.\",\n  \"userVisibleActions\": [\n    \"View test execution status (pass/fail/error) for each test file\",\n    \"See how many tests passed, failed, or encountered errors\",\n    \"Review test execution duration and timing information\",\n    \"Read error messages and stack traces for failed tests\",\n    \"View test report summary with pass rates and file statistics\",\n    \"Access recommendations for improving test quality\",\n    \"See which test files were generated and which are passing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structured test generation results with imports, mocks, and test code\",\n    \"Represent mock statements with explanations for clarity\",\n    \"Handle test validation results with fixed code and remaining issues\",\n    \"Track detailed test execution metrics including passed/failed/error counts\",\n    \"Capture error details with test names, messages, and stack traces\",\n    \"Generate comprehensive test reports with summaries and recommendations\",\n    \"Structure test report summaries with pass rates and file counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for representing test-related data throughout the testing workflow, ensuring consistent structure for test generation output, validation feedback, execution results, and comprehensive reporting with metrics and recommendations.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test setup and configuration management in a testing service",
          "userVisibleActions": [
            "User can set up test environments with specified languages and frameworks",
            "User receives feedback on test setup success or failure with created files and installed dependencies",
            "User can view which dependencies and configuration files are needed for testing",
            "User sees information about existing test environment components and what's missing"
          ],
          "developerVisibleActions": [
            "Developer defines test setup plans with language, framework, and dependencies",
            "Developer specifies configuration files with paths and content for test setup",
            "Developer checks test environment state including package.json, TypeScript config, and Jest config",
            "Developer receives structured execution results with success status, messages, and errors",
            "Developer defines mock requirements with type and reason for testing needs",
            "Developer tracks which dependencies are missing and which test frameworks exist"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to provide a type-safe contract for test setup operations, ensuring consistent structure when creating test environments, managing dependencies, generating configuration files, and reporting setup results across the testing service",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup and configuration management in a testing service\",\n  \"userVisibleActions\": [\n    \"User can set up test environments with specified languages and frameworks\",\n    \"User receives feedback on test setup success or failure with created files and installed dependencies\",\n    \"User can view which dependencies and configuration files are needed for testing\",\n    \"User sees information about existing test environment components and what's missing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines test setup plans with language, framework, and dependencies\",\n    \"Developer specifies configuration files with paths and content for test setup\",\n    \"Developer checks test environment state including package.json, TypeScript config, and Jest config\",\n    \"Developer receives structured execution results with success status, messages, and errors\",\n    \"Developer defines mock requirements with type and reason for testing needs\",\n    \"Developer tracks which dependencies are missing and which test frameworks exist\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a type-safe contract for test setup operations, ensuring consistent structure when creating test environments, managing dependencies, generating configuration files, and reporting setup results across the testing service\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Accelerates file operations through intelligent in-memory caching",
        "Automatically filters out non-source directories and files during processing",
        "Processes multiple files simultaneously for improved performance",
        "Detects file changes automatically to ensure content accuracy",
        "Handles file processing errors gracefully without disrupting workflows"
      ],
      "summary": "The fileSystem module provides high-performance file operations for the extension through intelligent caching and parallel processing. It ensures users experience fast, responsive file access by maintaining an in-memory cache that automatically detects and reflects file changes, eliminating redundant disk reads when analyzing or processing the same files multiple times.\n\nWhen working with multiple files, the module automatically filters out common non-source directories (node_modules, .git, dist, build, etc.) to focus on relevant source code. It processes files in parallel for maximum throughput while maintaining robust error handling that prevents individual file failures from disrupting entire operations. This results in faster analysis, smoother navigation, and more reliable file operations throughout the extension.\n\nThe module serves as the foundation for all file-based operations in the extension, providing a unified system that balances performance with accuracy. Users benefit from near-instantaneous access to previously opened files while always seeing current content, making workflows like code analysis, documentation generation, and multi-file operations significantly faster and more efficient.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Caches file contents in memory to avoid redundant disk reads and improve performance across the extension",
          "userVisibleActions": [
            "File operations complete faster when accessing previously opened files",
            "Extension responds more quickly when analyzing or processing the same files multiple times",
            "Automatic detection of file changes ensures users always see current content"
          ],
          "developerVisibleActions": [
            "Retrieve file contents with automatic caching via getFile()",
            "Cache automatically invalidates when files are modified, created, or deleted",
            "LRU (Least Recently Used) eviction policy manages memory usage automatically",
            "File system watcher monitors changes and keeps cache synchronized",
            "Cache statistics track hits, misses, evictions, and memory usage",
            "Configurable maximum cache size and time-to-live (TTL) settings"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "constructor",
              "desc": "Initializes the cache with configurable size limit and TTL, sets up file system watcher",
              "inputs": "maxSize: number (default 500), ttl: number (default 5000ms)",
              "outputs": "FileCache instance"
            },
            {
              "name": "isStale",
              "desc": "Checks if cached entry has exceeded its time-to-live period",
              "inputs": "cached: CachedFile",
              "outputs": "boolean - true if stale"
            },
            {
              "name": "setupWatcher",
              "desc": "Creates file system watcher to automatically invalidate cache entries when files change",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "evictIfNeeded",
              "desc": "Removes least recently used cache entries when cache exceeds maximum size",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getFileHash",
              "desc": "Computes hash of file to detect content changes",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file hash"
            },
            {
              "name": "readFileFromDisk",
              "desc": "Reads file content directly from filesystem",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.",
          "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to avoid redundant disk reads and improve performance across the extension\",\n  \"userVisibleActions\": [\n    \"File operations complete faster when accessing previously opened files\",\n    \"Extension responds more quickly when analyzing or processing the same files multiple times\",\n    \"Automatic detection of file changes ensures users always see current content\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file contents with automatic caching via getFile()\",\n    \"Cache automatically invalidates when files are modified, created, or deleted\",\n    \"LRU (Least Recently Used) eviction policy manages memory usage automatically\",\n    \"File system watcher monitors changes and keeps cache synchronized\",\n    \"Cache statistics track hits, misses, evictions, and memory usage\",\n    \"Configurable maximum cache size and time-to-live (TTL) settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the cache with configurable size limit and TTL, sets up file system watcher\",\n      \"inputs\": \"maxSize: number (default 500), ttl: number (default 5000ms)\",\n      \"outputs\": \"FileCache instance\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Checks if cached entry has exceeded its time-to-live period\",\n      \"inputs\": \"cached: CachedFile\",\n      \"outputs\": \"boolean - true if stale\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Creates file system watcher to automatically invalidate cache entries when files change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used cache entries when cache exceeds maximum size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getFileHash\",\n      \"desc\": \"Computes hash of file to detect content changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file hash\"\n    },\n    {\n      \"name\": \"readFileFromDisk\",\n      \"desc\": \"Reads file content directly from filesystem\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling",
          "userVisibleActions": [
            "Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)",
            "Multiple files are processed simultaneously for faster performance",
            "File processing errors are handled gracefully without crashing the application"
          ],
          "developerVisibleActions": [
            "Developer calls processFiles() with an array of file paths and a custom processor function",
            "Files are automatically filtered based on configurable patterns before processing",
            "Each file's content is read and passed to the developer's processor function",
            "Results are collected and returned as an array in the same order as input files",
            "Developer can inject custom file filters and file readers for testing or specialized behavior",
            "Error context can be provided for detailed error tracking and debugging"
          ],
          "keyFunctions": [
            {
              "name": "shouldProcess",
              "desc": "Determines if a file should be processed based on its path",
              "inputs": "filePath: string",
              "outputs": "boolean indicating if file should be processed"
            },
            {
              "name": "readFile",
              "desc": "Reads the content of a file asynchronously",
              "inputs": "filePath: string",
              "outputs": "Promise<string> containing file content"
            },
            {
              "name": "processFiles",
              "desc": "Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each",
              "inputs": "files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext",
              "outputs": "Promise<T[]> containing processed results for each file"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "../../utils/errorHandler"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)\",\n    \"Multiple files are processed simultaneously for faster performance\",\n    \"File processing errors are handled gracefully without crashing the application\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls processFiles() with an array of file paths and a custom processor function\",\n    \"Files are automatically filtered based on configurable patterns before processing\",\n    \"Each file's content is read and passed to the developer's processor function\",\n    \"Results are collected and returned as an array in the same order as input files\",\n    \"Developer can inject custom file filters and file readers for testing or specialized behavior\",\n    \"Error context can be provided for detailed error tracking and debugging\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads the content of a file asynchronously\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> containing file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext\",\n      \"outputs\": \"Promise<T[]> containing processed results for each file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Persist AI-generated analysis results to a structured .shadow directory in the workspace",
        "Store product documentation with timestamp-based versioning",
        "Save architecture insights in organized, timestamped directories",
        "Maintain historical analysis runs through timestamped directory structure",
        "Organize documentation as markdown files structured by file paths",
        "Preserve analysis history by creating new directories for each run"
      ],
      "summary": "The persistence module manages the storage and organization of AI-generated analysis results within the workspace. It provides a structured approach to saving different types of analysis outputs including product documentation, architecture insights, and analysis summaries to a dedicated .shadow directory hierarchy.\n\nUsers benefit from automatic organization of analysis results into timestamped directories, ensuring that each analysis run is preserved and easily accessible. Product documentation is saved to .shadow/docs/product-docs-[timestamp]/ directories, while architecture insights are stored in .shadow/insights/architecture-[timestamp]/ directories. All documentation is formatted as markdown files and organized according to the source file paths they document.\n\nThe module implements a versioning strategy through timestamp-based directories, allowing users to maintain a complete history of analysis runs without overwriting previous results. This enables comparison of analyses over time and provides a reliable audit trail of how documentation and insights have evolved throughout the development process.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages storage and retrieval of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory structure.",
          "userVisibleActions": [
            "Product documentation files are saved to .shadow/docs/product-docs-[timestamp]/ directory",
            "Architecture insights are saved to .shadow/insights/architecture-[timestamp]/ directory",
            "Analysis summaries are stored in timestamped run directories",
            "Each analysis run creates a new timestamped directory to preserve history",
            "Documentation is formatted and saved as markdown files organized by file path"
          ],
          "developerVisibleActions": [
            "Initialize product documentation runs to create storage directories",
            "Initialize architecture insights runs to create storage directories",
            "Save enhanced product documentation with markdown formatting",
            "Save architecture insights with metadata and analysis details",
            "Save analysis summaries with statistics and file counts",
            "Retrieve current run directories for ongoing analysis operations",
            "Reset run contexts when analysis completes or needs to restart",
            "Access formatted documentation through the documentation formatter"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Creates a new timestamped directory for storing product documentation results",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Creates a new timestamped directory for storing architecture insights results",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "saveProductDocs",
              "desc": "Persists enhanced product documentation to markdown files organized by file path",
              "inputs": "workspaceRoot: string, filePath: string, documentation: EnhancedProductDocumentation",
              "outputs": "void"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Persists architecture insights and analysis to JSON file with metadata",
              "inputs": "workspaceRoot: string, insights: LLMInsights",
              "outputs": "void"
            },
            {
              "name": "saveAnalysisSummary",
              "desc": "Saves analysis summary with file counts and statistics to timestamped storage",
              "inputs": "workspaceRoot: string, summary: object",
              "outputs": "void"
            },
            {
              "name": "getCurrentProductDocsRunDir",
              "desc": "Retrieves the current product documentation run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "getCurrentArchitectureInsightsRunDir",
              "desc": "Retrieves the current architecture insights run directory path",
              "inputs": "none",
              "outputs": "string | null"
            },
            {
              "name": "resetProductDocsRun",
              "desc": "Clears the current product documentation run context to allow new runs",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "resetArchitectureInsightsRun",
              "desc": "Clears the current architecture insights run context to allow new runs",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "fileDocumentation (EnhancedProductDocumentation)",
            "llmService (LLMInsights)",
            "domain/formatters/documentationFormatter",
            "storage/incrementalStorage"
          ],
          "intent": "Separates persistence concerns from AI analysis logic by providing a dedicated repository for storing analysis results in an organized, timestamped directory structure, enabling historical tracking of documentation and insights while keeping the file system operations isolated from the core analysis code.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages storage and retrieval of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory structure.\",\n  \"userVisibleActions\": [\n    \"Product documentation files are saved to .shadow/docs/product-docs-[timestamp]/ directory\",\n    \"Architecture insights are saved to .shadow/insights/architecture-[timestamp]/ directory\",\n    \"Analysis summaries are stored in timestamped run directories\",\n    \"Each analysis run creates a new timestamped directory to preserve history\",\n    \"Documentation is formatted and saved as markdown files organized by file path\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to create storage directories\",\n    \"Initialize architecture insights runs to create storage directories\",\n    \"Save enhanced product documentation with markdown formatting\",\n    \"Save architecture insights with metadata and analysis details\",\n    \"Save analysis summaries with statistics and file counts\",\n    \"Retrieve current run directories for ongoing analysis operations\",\n    \"Reset run contexts when analysis completes or needs to restart\",\n    \"Access formatted documentation through the documentation formatter\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocs\",\n      \"desc\": \"Persists enhanced product documentation to markdown files organized by file path\",\n      \"inputs\": \"workspaceRoot: string, filePath: string, documentation: EnhancedProductDocumentation\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Persists architecture insights and analysis to JSON file with metadata\",\n      \"inputs\": \"workspaceRoot: string, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveAnalysisSummary\",\n      \"desc\": \"Saves analysis summary with file counts and statistics to timestamped storage\",\n      \"inputs\": \"workspaceRoot: string, summary: object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Retrieves the current product documentation run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Retrieves the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product documentation run context to allow new runs\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context to allow new runs\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates persistence concerns from AI analysis logic by providing a dedicated repository for storing analysis results in an organized, timestamped directory structure, enabling historical tracking of documentation and insights while keeping the file system operations isolated from the core analysis code.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display progress notifications to users during long-running operations with customizable titles and messages",
        "Provide cancellation support for operations that can be interrupted by user request",
        "Show progress indicators in different UI locations such as notification areas and windows",
        "Track and report incremental progress updates as operations advance",
        "Manage multiple concurrent progress notifications for parallel operations"
      ],
      "summary": "The infrastructure module provides a centralized progress notification service that keeps users informed during long-running operations. Users can see real-time progress updates with descriptive titles and messages, allowing them to understand what the application is doing and how much work remains.\n\nThis module enables users to monitor operations that take significant time to complete, such as file processing, data analysis, or network requests. Progress notifications can appear in various locations throughout the interface, providing visibility without blocking other work. For operations that support cancellation, users can interrupt the process if they change their mind or need to prioritize other tasks.\n\nThe service handles the complexity of managing multiple simultaneous operations, ensuring that users can track several processes at once without confusion. Progress updates increment as work completes, giving users clear feedback about operation status and estimated completion.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a centralized service for displaying progress notifications to users during long-running operations",
          "userVisibleActions": [
            "See progress notifications with titles and messages during operations",
            "Cancel ongoing operations if they are marked as cancellable",
            "View progress indicators in different locations (notification area, window, etc.)",
            "Track operation progress with incremental updates"
          ],
          "developerVisibleActions": [
            "Wrap any async operation with standardized progress reporting using withProgress method",
            "Pass either a simple string title or detailed options object for progress configuration",
            "Receive a ProgressReporter object to report incremental progress updates",
            "Control whether operations are cancellable and where progress is displayed",
            "Access cancellation token to check if user cancelled the operation"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying a progress notification to the user",
              "inputs": "options (title, cancellable flag, location) and async task function that receives a ProgressReporter",
              "outputs": "Promise that resolves to the task result"
            },
            {
              "name": "report (ProgressReporter)",
              "desc": "Updates the progress notification with a new message and optional increment value",
              "inputs": "message string and optional increment number",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This service exists to standardize and simplify progress reporting across the extension, reducing boilerplate code by wrapping VSCode's progress API with consistent defaults and a cleaner interface for developers to show operation progress to users",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for displaying progress notifications to users during long-running operations\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during operations\",\n    \"Cancel ongoing operations if they are marked as cancellable\",\n    \"View progress indicators in different locations (notification area, window, etc.)\",\n    \"Track operation progress with incremental updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any async operation with standardized progress reporting using withProgress method\",\n    \"Pass either a simple string title or detailed options object for progress configuration\",\n    \"Receive a ProgressReporter object to report incremental progress updates\",\n    \"Control whether operations are cancellable and where progress is displayed\",\n    \"Access cancellation token to check if user cancelled the operation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise that resolves to the task result\"\n    },\n    {\n      \"name\": \"report (ProgressReporter)\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment value\",\n      \"inputs\": \"message string and optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This service exists to standardize and simplify progress reporting across the extension, reducing boilerplate code by wrapping VSCode's progress API with consistent defaults and a cleaner interface for developers to show operation progress to users\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest test framework for running TypeScript unit tests in the project",
      "userVisibleActions": [
        "No direct user-facing actions - this is a development configuration file"
      ],
      "developerVisibleActions": [
        "Run tests using Jest with 'npm test' or 'jest' command",
        "View test results from files matching '**/*.test.ts' or '**/*.spec.ts' patterns",
        "Generate code coverage reports in text, lcov, and HTML formats",
        "Tests run with a 10-second timeout per test",
        "TypeScript files are automatically compiled and tested without manual build step",
        "Code coverage collected from all source files except type definitions, test files, and mocks",
        "VSCode module is automatically mocked for testing extension code"
      ],
      "keyFunctions": [
        {
          "name": "preset",
          "desc": "Uses ts-jest preset to enable TypeScript testing",
          "inputs": "Configuration string",
          "outputs": "Jest configuration with TypeScript support"
        },
        {
          "name": "testMatch",
          "desc": "Defines which files are recognized as test files",
          "inputs": "Array of glob patterns",
          "outputs": "Matches *.test.ts and *.spec.ts files"
        },
        {
          "name": "transform",
          "desc": "Configures TypeScript compilation for test files",
          "inputs": "TypeScript files with ES2020 target",
          "outputs": "Compiled JavaScript executable by Jest"
        },
        {
          "name": "collectCoverageFrom",
          "desc": "Specifies which files to include in coverage reports",
          "inputs": "Array of glob patterns",
          "outputs": "Coverage data excluding mocks, tests, and type definitions"
        },
        {
          "name": "moduleNameMapper",
          "desc": "Maps vscode module imports to mock implementation",
          "inputs": "Module path mappings",
          "outputs": "Mocked vscode module for testing"
        }
      ],
      "dependencies": [
        "ts-jest",
        "jest"
      ],
      "intent": "Provides a complete Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to write and run unit tests with proper TypeScript compilation, code coverage reporting, and VSCode API mocking",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest test framework for running TypeScript unit tests in the project\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this is a development configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run tests using Jest with 'npm test' or 'jest' command\",\n    \"View test results from files matching '**/*.test.ts' or '**/*.spec.ts' patterns\",\n    \"Generate code coverage reports in text, lcov, and HTML formats\",\n    \"Tests run with a 10-second timeout per test\",\n    \"TypeScript files are automatically compiled and tested without manual build step\",\n    \"Code coverage collected from all source files except type definitions, test files, and mocks\",\n    \"VSCode module is automatically mocked for testing extension code\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"preset\",\n      \"desc\": \"Uses ts-jest preset to enable TypeScript testing\",\n      \"inputs\": \"Configuration string\",\n      \"outputs\": \"Jest configuration with TypeScript support\"\n    },\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Defines which files are recognized as test files\",\n      \"inputs\": \"Array of glob patterns\",\n      \"outputs\": \"Matches *.test.ts and *.spec.ts files\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Configures TypeScript compilation for test files\",\n      \"inputs\": \"TypeScript files with ES2020 target\",\n      \"outputs\": \"Compiled JavaScript executable by Jest\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which files to include in coverage reports\",\n      \"inputs\": \"Array of glob patterns\",\n      \"outputs\": \"Coverage data excluding mocks, tests, and type definitions\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Maps vscode module imports to mock implementation\",\n      \"inputs\": \"Module path mappings\",\n      \"outputs\": \"Mocked vscode module for testing\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\"\n  ],\n  \"intent\": \"Provides a complete Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to write and run unit tests with proper TypeScript compilation, code coverage reporting, and VSCode API mocking\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Manages rate limiting for LLM API requests to prevent exceeding provider API quotas",
      "userVisibleActions": [
        "API requests to OpenAI and Claude are automatically throttled to stay within rate limits",
        "Requests that would exceed rate limits are prevented from being sent",
        "Different rate limits are enforced for different LLM providers (OpenAI: 60/min, Claude: 50/min)"
      ],
      "developerVisibleActions": [
        "Check if an API request is allowed before making it using canMakeRequest()",
        "Record successful API requests with recordRequest() to track usage",
        "Configure custom rate limits for providers using configure()",
        "Track request history per provider automatically",
        "Get automatic cleanup of old request timestamps outside the time window"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes rate limiter with default limits for OpenAI (60/min) and Claude (50/min)",
          "inputs": "none",
          "outputs": "RateLimiter instance"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limit configuration for a specific LLM provider",
          "inputs": "provider (LLMProvider), config (RateLimitConfig with maxRequests and windowMs)",
          "outputs": "void"
        },
        {
          "name": "canMakeRequest",
          "desc": "Checks if a new request is allowed based on current rate limit status",
          "inputs": "provider (LLMProvider)",
          "outputs": "boolean - true if request can be made, false if rate limit would be exceeded"
        },
        {
          "name": "recordRequest",
          "desc": "Records a request timestamp for rate limiting tracking",
          "inputs": "provider (LLMProvider)",
          "outputs": "void"
        }
      ],
      "dependencies": [],
      "intent": "This file exists to protect against exceeding API rate limits from LLM providers (OpenAI and Claude) by tracking request frequency and enforcing configurable throttling windows, preventing API errors and potential service disruptions",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages rate limiting for LLM API requests to prevent exceeding provider API quotas\",\n  \"userVisibleActions\": [\n    \"API requests to OpenAI and Claude are automatically throttled to stay within rate limits\",\n    \"Requests that would exceed rate limits are prevented from being sent\",\n    \"Different rate limits are enforced for different LLM providers (OpenAI: 60/min, Claude: 50/min)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Check if an API request is allowed before making it using canMakeRequest()\",\n    \"Record successful API requests with recordRequest() to track usage\",\n    \"Configure custom rate limits for providers using configure()\",\n    \"Track request history per provider automatically\",\n    \"Get automatic cleanup of old request timestamps outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits for OpenAI (60/min) and Claude (50/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (LLMProvider), config (RateLimitConfig with maxRequests and windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request is allowed based on current rate limit status\",\n      \"inputs\": \"provider (LLMProvider)\",\n      \"outputs\": \"boolean - true if request can be made, false if rate limit would be exceeded\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a request timestamp for rate limiting tracking\",\n      \"inputs\": \"provider (LLMProvider)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to protect against exceeding API rate limits from LLM providers (OpenAI and Claude) by tracking request frequency and enforcing configurable throttling windows, preventing API errors and potential service disruptions\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).",
      "userVisibleActions": [
        "Converts raw AI-generated text responses into organized documentation",
        "Extracts file purposes and actions from AI analysis",
        "Generates structured module and product documentation from AI responses",
        "Provides fallback text parsing when AI returns non-JSON responses"
      ],
      "developerVisibleActions": [
        "Call parseFileSummary() to convert LLM response into FileSummary object",
        "Call parseModuleSummary() to extract module-level documentation from LLM text",
        "Call parseInsights() to structure AI-generated insights about codebase",
        "Call parseProductDocumentation() to build comprehensive product docs from LLM output",
        "Call parsePurposeAnalysis() to extract product purpose analysis",
        "Handles both JSON and plain text LLM response formats automatically",
        "Returns typed TypeScript objects with fallback values for missing data"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into a FileSummary object with purpose, actions, and dependencies",
          "inputs": "content (LLM response text), filePath (string), role (string)",
          "outputs": "FileSummary object"
        },
        {
          "name": "parseModuleSummary",
          "desc": "Extracts module-level documentation including purpose, features, and structure from LLM response",
          "inputs": "content (LLM response text), moduleName (string)",
          "outputs": "ModuleSummary object"
        },
        {
          "name": "parseInsights",
          "desc": "Structures AI insights about the codebase into categories like architecture patterns and improvement areas",
          "inputs": "content (LLM response text), context (AnalysisContext)",
          "outputs": "LLMInsights object"
        },
        {
          "name": "parseProductDocumentation",
          "desc": "Builds comprehensive product documentation from LLM analysis including overview, features, and use cases",
          "inputs": "content (LLM response text)",
          "outputs": "EnhancedProductDocumentation object"
        },
        {
          "name": "parsePurposeAnalysis",
          "desc": "Extracts product purpose analysis including main purpose, target audience, and value proposition",
          "inputs": "content (LLM response text)",
          "outputs": "ProductPurposeAnalysis object"
        },
        {
          "name": "extractSection",
          "desc": "Helper that pulls out a specific labeled section from unstructured text",
          "inputs": "content (text), sectionName (string)",
          "outputs": "Extracted section text or empty string"
        },
        {
          "name": "extractListSection",
          "desc": "Helper that extracts bullet points or list items from a text section",
          "inputs": "content (text), sectionName (string)",
          "outputs": "Array of list items"
        }
      ],
      "dependencies": [
        "../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)",
        "../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)"
      ],
      "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.",
      "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).\",\n  \"userVisibleActions\": [\n    \"Converts raw AI-generated text responses into organized documentation\",\n    \"Extracts file purposes and actions from AI analysis\",\n    \"Generates structured module and product documentation from AI responses\",\n    \"Provides fallback text parsing when AI returns non-JSON responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM response into FileSummary object\",\n    \"Call parseModuleSummary() to extract module-level documentation from LLM text\",\n    \"Call parseInsights() to structure AI-generated insights about codebase\",\n    \"Call parseProductDocumentation() to build comprehensive product docs from LLM output\",\n    \"Call parsePurposeAnalysis() to extract product purpose analysis\",\n    \"Handles both JSON and plain text LLM response formats automatically\",\n    \"Returns typed TypeScript objects with fallback values for missing data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object with purpose, actions, and dependencies\",\n      \"inputs\": \"content (LLM response text), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level documentation including purpose, features, and structure from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName (string)\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseInsights\",\n      \"desc\": \"Structures AI insights about the codebase into categories like architecture patterns and improvement areas\",\n      \"inputs\": \"content (LLM response text), context (AnalysisContext)\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Builds comprehensive product documentation from LLM analysis including overview, features, and use cases\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parsePurposeAnalysis\",\n      \"desc\": \"Extracts product purpose analysis including main purpose, target audience, and value proposition\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Helper that pulls out a specific labeled section from unstructured text\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Extracted section text or empty string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Helper that extracts bullet points or list items from a text section\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Array of list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)\",\n    \"../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors",
      "userVisibleActions": [
        "Automatic retry when AI requests fail due to rate limits or temporary issues",
        "Delayed retry attempts that increase wait time between retries",
        "Transparent error recovery without user intervention for recoverable errors",
        "Final error display only after all retry attempts are exhausted"
      ],
      "developerVisibleActions": [
        "Configure maximum number of retry attempts for LLM requests",
        "Set initial delay and maximum delay between retries",
        "Define which error types should trigger automatic retries",
        "Receive callbacks on each retry attempt for logging or monitoring",
        "Execute any async LLM operation with automatic retry handling",
        "Get result with attempt count after successful retry",
        "Handle non-retryable errors immediately without retry attempts"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an LLM operation with automatic retry on failure",
          "inputs": "operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)",
          "outputs": "Promise resolving to the operation result, or throws error after all retries exhausted"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines if an error should trigger a retry attempt",
          "inputs": "error object, list of retryable error patterns",
          "outputs": "Boolean indicating whether the error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors\",\n  \"userVisibleActions\": [\n    \"Automatic retry when AI requests fail due to rate limits or temporary issues\",\n    \"Delayed retry attempts that increase wait time between retries\",\n    \"Transparent error recovery without user intervention for recoverable errors\",\n    \"Final error display only after all retry attempts are exhausted\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum number of retry attempts for LLM requests\",\n    \"Set initial delay and maximum delay between retries\",\n    \"Define which error types should trigger automatic retries\",\n    \"Receive callbacks on each retry attempt for logging or monitoring\",\n    \"Execute any async LLM operation with automatic retry handling\",\n    \"Get result with attempt count after successful retry\",\n    \"Handle non-retryable errors immediately without retry attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an LLM operation with automatic retry on failure\",\n      \"inputs\": \"operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)\",\n      \"outputs\": \"Promise resolving to the operation result, or throws error after all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry attempt\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"Boolean indicating whether the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines a standard interface for interacting with different AI language model providers (OpenAI, Claude, custom providers) in a unified way",
      "userVisibleActions": [
        "User receives AI-generated text responses to their queries",
        "User receives structured JSON data from AI for parsed information",
        "User may experience different response formats (text or JSON) depending on request type"
      ],
      "developerVisibleActions": [
        "Developer can check if an AI provider is configured and ready to use",
        "Developer can send text-based requests to AI and receive string responses",
        "Developer can send requests for structured JSON output with type safety",
        "Developer can specify model, temperature, max tokens, and system prompts for AI requests",
        "Developer can retrieve the provider name to identify which AI service is being used",
        "Developer can pass conversation history with messages in system/user/assistant roles"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if the AI provider has valid credentials and is ready to accept requests",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt to the AI and receives a text response",
          "inputs": "LLMRequestOptions (model, system prompt, messages, max tokens, temperature, response format)",
          "outputs": "LLMResponse containing content string, finish reason, model name, and raw response"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt to the AI and receives parsed JSON data with optional follow-up requests",
          "inputs": "LLMRequestOptions and optional JSON schema",
          "outputs": "StructuredOutputResponse with typed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the identifier of the AI provider",
          "inputs": "none",
          "outputs": "string with provider name"
        }
      ],
      "dependencies": [],
      "intent": "This file exists to abstract away differences between various AI language model providers (OpenAI, Claude, custom services), allowing the rest of the application to interact with any AI provider through a consistent interface without worrying about provider-specific implementation details or API differences",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines a standard interface for interacting with different AI language model providers (OpenAI, Claude, custom providers) in a unified way\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON data from AI for parsed information\",\n    \"User may experience different response formats (text or JSON) depending on request type\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can check if an AI provider is configured and ready to use\",\n    \"Developer can send text-based requests to AI and receive string responses\",\n    \"Developer can send requests for structured JSON output with type safety\",\n    \"Developer can specify model, temperature, max tokens, and system prompts for AI requests\",\n    \"Developer can retrieve the provider name to identify which AI service is being used\",\n    \"Developer can pass conversation history with messages in system/user/assistant roles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the AI provider has valid credentials and is ready to accept requests\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the AI and receives a text response\",\n      \"inputs\": \"LLMRequestOptions (model, system prompt, messages, max tokens, temperature, response format)\",\n      \"outputs\": \"LLMResponse containing content string, finish reason, model name, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to the AI and receives parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema\",\n      \"outputs\": \"StructuredOutputResponse with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier of the AI provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to abstract away differences between various AI language model providers (OpenAI, Claude, custom services), allowing the rest of the application to interact with any AI provider through a consistent interface without worrying about provider-specific implementation details or API differences\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Integrates Anthropic's Claude AI models to provide language model capabilities for code analysis and generation within the extension.",
      "userVisibleActions": [
        "Sends prompts to Claude AI and receives intelligent responses for code-related tasks",
        "Receives structured JSON responses from Claude for data extraction tasks",
        "Experiences Claude AI-powered features like code explanation, refactoring suggestions, and documentation generation",
        "Gets error messages when Claude API key is not configured"
      ],
      "developerVisibleActions": [
        "Configures Claude API key through configuration manager to enable the provider",
        "Sends requests with custom system prompts, conversation history, and model selection",
        "Receives structured or unstructured responses from Claude models",
        "Handles token usage statistics and response metadata",
        "Catches and handles API errors including rate limits, authentication failures, and invalid requests",
        "Uses 'claude-sonnet-4-5' as the default model with 8192 max tokens",
        "Converts OpenAI message format to Claude's format automatically",
        "Extracts JSON from text responses when structured output is requested"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is set up and provider is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt to Claude and returns the AI-generated response",
          "inputs": "LLMRequestOptions with messages, system prompt, model, and max tokens",
          "outputs": "LLMResponse with generated text and usage statistics"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt to Claude expecting a JSON response and extracts structured data",
          "inputs": "LLMRequestOptions with messages and schema information",
          "outputs": "StructuredOutputResponse with parsed JSON data and usage statistics"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Anthropic client with API key from configuration",
          "inputs": "none (reads from config manager)",
          "outputs": "none (initializes client)"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to provide a unified interface for interacting with Anthropic's Claude AI models, handling API authentication, message format conversion, error handling, and response parsing so that other parts of the extension can leverage Claude's capabilities without dealing with API-specific implementation details.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates Anthropic's Claude AI models to provide language model capabilities for code analysis and generation within the extension.\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives intelligent responses for code-related tasks\",\n    \"Receives structured JSON responses from Claude for data extraction tasks\",\n    \"Experiences Claude AI-powered features like code explanation, refactoring suggestions, and documentation generation\",\n    \"Gets error messages when Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configures Claude API key through configuration manager to enable the provider\",\n    \"Sends requests with custom system prompts, conversation history, and model selection\",\n    \"Receives structured or unstructured responses from Claude models\",\n    \"Handles token usage statistics and response metadata\",\n    \"Catches and handles API errors including rate limits, authentication failures, and invalid requests\",\n    \"Uses 'claude-sonnet-4-5' as the default model with 8192 max tokens\",\n    \"Converts OpenAI message format to Claude's format automatically\",\n    \"Extracts JSON from text responses when structured output is requested\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to Claude and returns the AI-generated response\",\n      \"inputs\": \"LLMRequestOptions with messages, system prompt, model, and max tokens\",\n      \"outputs\": \"LLMResponse with generated text and usage statistics\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to Claude expecting a JSON response and extracts structured data\",\n      \"inputs\": \"LLMRequestOptions with messages and schema information\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data and usage statistics\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Anthropic client with API key from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"none (initializes client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to provide a unified interface for interacting with Anthropic's Claude AI models, handling API authentication, message format conversion, error handling, and response parsing so that other parts of the extension can leverage Claude's capabilities without dealing with API-specific implementation details.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.",
      "userVisibleActions": [
        "Sends chat messages to OpenAI's GPT models and receives AI-generated responses",
        "Receives structured JSON responses from AI when requested",
        "Experiences timeout protection with 5-minute maximum wait time for responses",
        "Gets error messages when OpenAI API key is not configured"
      ],
      "developerVisibleActions": [
        "Configure OpenAI API key through configuration manager to enable the provider",
        "Send chat requests with custom system prompts, messages, and model selection",
        "Request structured JSON outputs with specific schemas",
        "Check if provider is properly configured before use",
        "Receive parsed JSON objects from AI responses",
        "Handle errors when API key is missing or requests fail",
        "Use default GPT-4o model or specify alternative OpenAI models"
      ],
      "keyFunctions": [
        {
          "name": "initialize",
          "desc": "Sets up OpenAI client with API key from configuration",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "isConfigured",
          "desc": "Checks if provider has valid API key and is ready to use",
          "inputs": "None",
          "outputs": "boolean indicating if configured"
        },
        {
          "name": "getName",
          "desc": "Returns provider identifier",
          "inputs": "None",
          "outputs": "string 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends chat completion request to OpenAI and returns response",
          "inputs": "LLMRequestOptions (system prompt, messages, model, response format)",
          "outputs": "Promise<LLMResponse> with content and finish reason"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Sends request expecting structured JSON response conforming to a schema",
          "inputs": "LLMRequestOptions with JSON schema",
          "outputs": "Promise<StructuredOutputResponse> with parsed JSON object"
        }
      ],
      "dependencies": [
        "openai",
        "ILLMProvider",
        "configurationManager",
        "jsonExtractor"
      ],
      "intent": "This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.\",\n  \"userVisibleActions\": [\n    \"Sends chat messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Receives structured JSON responses from AI when requested\",\n    \"Experiences timeout protection with 5-minute maximum wait time for responses\",\n    \"Gets error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager to enable the provider\",\n    \"Send chat requests with custom system prompts, messages, and model selection\",\n    \"Request structured JSON outputs with specific schemas\",\n    \"Check if provider is properly configured before use\",\n    \"Receive parsed JSON objects from AI responses\",\n    \"Handle errors when API key is missing or requests fail\",\n    \"Use default GPT-4o model or specify alternative OpenAI models\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if provider has valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends chat completion request to OpenAI and returns response\",\n      \"inputs\": \"LLMRequestOptions (system prompt, messages, model, response format)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting structured JSON response conforming to a schema\",\n      \"inputs\": \"LLMRequestOptions with JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON object\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Factory that creates and manages AI provider instances (OpenAI, Claude) for the application",
      "userVisibleActions": [
        "Switch between different AI providers (OpenAI or Claude) for generating responses",
        "Receive AI responses from the currently configured provider",
        "Experience consistent AI functionality regardless of which provider is active"
      ],
      "developerVisibleActions": [
        "Request an AI provider instance by name (openai or claude)",
        "Get the currently configured provider from user settings",
        "Check which AI providers have valid API keys configured",
        "Retrieve a list of all properly configured providers",
        "Use singleton pattern - same provider instance is reused across requests"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns a specific AI provider instance by name",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the AI provider that is currently active in configuration",
          "inputs": "none",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks if a specific provider has valid configuration/API key",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "boolean"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns list of all providers that have valid API keys",
          "inputs": "none",
          "outputs": "LLMProvider[] array"
        }
      ],
      "dependencies": [
        "./ILLMProvider",
        "./openAIProvider",
        "./anthropicProvider",
        "../../config/configurationManager"
      ],
      "intent": "Centralizes the creation and management of AI provider instances, allowing the application to support multiple AI services while maintaining a consistent interface. Ensures only one instance of each provider exists (singleton pattern) and provides utilities to check provider availability before use.",
      "rawContent": "```json\n{\n  \"purpose\": \"Factory that creates and manages AI provider instances (OpenAI, Claude) for the application\",\n  \"userVisibleActions\": [\n    \"Switch between different AI providers (OpenAI or Claude) for generating responses\",\n    \"Receive AI responses from the currently configured provider\",\n    \"Experience consistent AI functionality regardless of which provider is active\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request an AI provider instance by name (openai or claude)\",\n    \"Get the currently configured provider from user settings\",\n    \"Check which AI providers have valid API keys configured\",\n    \"Retrieve a list of all properly configured providers\",\n    \"Use singleton pattern - same provider instance is reused across requests\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a specific AI provider instance by name\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently active in configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific provider has valid configuration/API key\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all providers that have valid API keys\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider[] array\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Centralizes the creation and management of AI provider instances, allowing the application to support multiple AI services while maintaining a consistent interface. Ensures only one instance of each provider exists (singleton pattern) and provides utilities to check provider availability before use.\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Provides deep code analysis capabilities that extract function metadata, branch logic, dependencies, state mutations, and behavioral patterns from code files using AST parsing.",
      "userVisibleActions": [
        "Receives detailed analysis of code behavior including what functions do and how they interact",
        "Gets information about code complexity and branching logic",
        "Sees enhanced test coverage recommendations based on code structure",
        "Receives behavioral hints about what code does from a user perspective"
      ],
      "developerVisibleActions": [
        "Developer calls analyzeFileMetadata() to get comprehensive function metadata for a file",
        "Developer receives structured data about branches, dependencies, and state mutations",
        "Developer gets AST-based analysis for TypeScript/JavaScript and regex-based fallback for other languages",
        "Developer accesses branch information showing conditional logic and decision points in code",
        "Developer receives dependency profiling showing which modules and functions are imported/used",
        "Developer gets state mutation tracking showing which variables and properties are modified",
        "Developer receives behavioral hints describing what code does from an external perspective",
        "Developer can extract function content between specific line ranges",
        "Developer gets test mapping suggestions for better code coverage"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and behavioral patterns",
          "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
          "outputs": "Promise<Map<string, FunctionMetadata>> - Map of function names to their metadata"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata",
          "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
          "outputs": "Promise<FunctionMetadata> - Detailed function metadata including AST-parsed information"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Provides fallback regex-based analysis for languages that don't have AST parsing support",
          "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
          "outputs": "FunctionMetadata - Basic function metadata extracted via pattern matching"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the source code content of a function between specified line numbers",
          "inputs": "content (string), startLine (number), endLine (number)",
          "outputs": "string - The extracted function source code"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)"
      ],
      "intent": "This file exists to provide sophisticated code understanding capabilities that go beyond basic parsing. It solves the problem of deeply understanding code behavior by extracting not just what functions exist, but how they work (branches), what they depend on (imports), what they change (mutations), and what they do from a behavioral perspective. This enables intelligent test generation, documentation, and code comprehension features.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities that extract function metadata, branch logic, dependencies, state mutations, and behavioral patterns from code files using AST parsing.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code behavior including what functions do and how they interact\",\n    \"Gets information about code complexity and branching logic\",\n    \"Sees enhanced test coverage recommendations based on code structure\",\n    \"Receives behavioral hints about what code does from a user perspective\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls analyzeFileMetadata() to get comprehensive function metadata for a file\",\n    \"Developer receives structured data about branches, dependencies, and state mutations\",\n    \"Developer gets AST-based analysis for TypeScript/JavaScript and regex-based fallback for other languages\",\n    \"Developer accesses branch information showing conditional logic and decision points in code\",\n    \"Developer receives dependency profiling showing which modules and functions are imported/used\",\n    \"Developer gets state mutation tracking showing which variables and properties are modified\",\n    \"Developer receives behavioral hints describing what code does from an external perspective\",\n    \"Developer can extract function content between specific line ranges\",\n    \"Developer gets test mapping suggestions for better code coverage\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a file and extracts enhanced metadata for all functions including branches, dependencies, and behavioral patterns\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Promise<Map<string, FunctionMetadata>> - Map of function names to their metadata\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"Promise<FunctionMetadata> - Detailed function metadata including AST-parsed information\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for languages that don't have AST parsing support\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata - Basic function metadata extracted via pattern matching\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function between specified line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"string - The extracted function source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer (CodeAnalysis, FunctionMetadata, BranchInfo, DependencyInfo, StateMutationInfo, TestMapping, BehavioralHints, FunctionInfo)\"\n  ],\n  \"intent\": \"This file exists to provide sophisticated code understanding capabilities that go beyond basic parsing. It solves the problem of deeply understanding code behavior by extracting not just what functions exist, but how they work (branches), what they depend on (imports), what they change (mutations), and what they do from a behavioral perspective. This enables intelligent test generation, documentation, and code comprehension features.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Analyzes functions in large code files to extract detailed information about signatures, dependencies, and responsibilities for refactoring recommendations.",
      "userVisibleActions": [
        "Receives refactoring reports that identify which functions in large files should be split or refactored",
        "Gets function-level insights showing what each function does and what it depends on",
        "Views function responsibilities and their relationships to other code"
      ],
      "developerVisibleActions": [
        "Analyzes functions in files exceeding a size threshold (default 500 lines)",
        "Extracts function signatures, parameters, and return types from TypeScript code",
        "Identifies function dependencies (what other code the function calls)",
        "Identifies function dependents (what other code calls this function)",
        "Determines function responsibilities and purpose",
        "Generates structured FunctionAnalysis objects for each function in large files",
        "Handles analysis failures gracefully with warnings when individual functions cannot be analyzed",
        "Resolves file paths and verifies file existence before analysis"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in files larger than the threshold size",
          "inputs": "codeAnalysis (CodeAnalysis object), largeFileThreshold (optional, default 500 lines)",
          "outputs": "Promise<FunctionAnalysis[]> - array of detailed function analyses"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs detailed analysis on a single function",
          "inputs": "filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)",
          "outputs": "Promise<FunctionAnalysis | null> - detailed function analysis or null if failed"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves and validates the full path to a source file",
          "inputs": "filePath (string), codeAnalysis (CodeAnalysis)",
          "outputs": "string or null - full resolved file path"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to provide deep function-level analysis for refactoring recommendations. When developers work with large files, they need to understand which functions can be safely extracted or refactored. This analyzer inspects each function's signature, what it calls, what calls it, and what it does, enabling intelligent refactoring suggestions that maintain code correctness while improving maintainability.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed information about signatures, dependencies, and responsibilities for refactoring recommendations.\",\n  \"userVisibleActions\": [\n    \"Receives refactoring reports that identify which functions in large files should be split or refactored\",\n    \"Gets function-level insights showing what each function does and what it depends on\",\n    \"Views function responsibilities and their relationships to other code\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes functions in files exceeding a size threshold (default 500 lines)\",\n    \"Extracts function signatures, parameters, and return types from TypeScript code\",\n    \"Identifies function dependencies (what other code the function calls)\",\n    \"Identifies function dependents (what other code calls this function)\",\n    \"Determines function responsibilities and purpose\",\n    \"Generates structured FunctionAnalysis objects for each function in large files\",\n    \"Handles analysis failures gracefully with warnings when individual functions cannot be analyzed\",\n    \"Resolves file paths and verifies file existence before analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files larger than the threshold size\",\n      \"inputs\": \"codeAnalysis (CodeAnalysis object), largeFileThreshold (optional, default 500 lines)\",\n      \"outputs\": \"Promise<FunctionAnalysis[]> - array of detailed function analyses\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"Promise<FunctionAnalysis | null> - detailed function analysis or null if failed\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves and validates the full path to a source file\",\n      \"inputs\": \"filePath (string), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"string or null - full resolved file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep function-level analysis for refactoring recommendations. When developers work with large files, they need to understand which functions can be safely extracted or refactored. This analyzer inspects each function's signature, what it calls, what calls it, and what it does, enabling intelligent refactoring suggestions that maintain code correctness while improving maintainability.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view UI in VSCode that displays structured code analysis results including statistics, files, functions, and entry points",
      "userVisibleActions": [
        "View a hierarchical tree of code analysis results in the sidebar",
        "See 'No analysis available' message when no analysis has been run",
        "Browse analysis statistics (total files, functions, entry points, lines of code)",
        "Explore files organized by directory structure",
        "View details about each analyzed file (path, language, line count, function count)",
        "Browse all functions found in the codebase with their locations",
        "See entry points detected in the code",
        "Click on files, functions, or entry points to navigate to their location in the editor",
        "View tooltips with additional context when hovering over tree items",
        "Refresh the analysis view when new analysis results are available"
      ],
      "developerVisibleActions": [
        "TreeDataProvider that integrates with VSCode's tree view API",
        "Receives CodeAnalysis data from the analyzer module",
        "Updates the tree view when setAnalysis() is called with new analysis results",
        "Organizes analysis data into expandable/collapsible tree nodes",
        "Generates AnalysisItem objects representing different types of nodes (statistics, files, functions, directories)",
        "Provides navigation to source code locations when items are clicked",
        "Handles hierarchical data display for nested directory structures",
        "Emits tree data change events to trigger UI updates"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the viewer with new code analysis results and refreshes the display",
          "inputs": "analysis: CodeAnalysis | null",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers the tree view to update and redraw",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the VSCode TreeItem representation for a given analysis item",
          "inputs": "element: AnalysisItem",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node or root items if no element provided",
          "inputs": "element?: AnalysisItem",
          "outputs": "Thenable<AnalysisItem[]>"
        },
        {
          "name": "getRootItems",
          "desc": "Generates top-level tree items (statistics, files, functions, entry points)",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Creates tree items showing analysis statistics (counts and metrics)",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFilesItems",
          "desc": "Generates tree items for files organized by directory structure",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFileDetails",
          "desc": "Returns detailed information about a specific file including functions",
          "inputs": "element: AnalysisItem",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getDirectoryFiles",
          "desc": "Returns files and subdirectories within a directory node",
          "inputs": "element: AnalysisItem",
          "outputs": "AnalysisItem[]"
        }
      ],
      "dependencies": [
        "vscode",
        "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
        "path"
      ],
      "intent": "This file exists to provide a visual, interactive tree-based browser for code analysis results in VSCode, allowing users to explore analyzed code structure (files, functions, entry points) and navigate to specific code locations, solving the problem of presenting complex hierarchical analysis data in an accessible, browsable format",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view UI in VSCode that displays structured code analysis results including statistics, files, functions, and entry points\",\n  \"userVisibleActions\": [\n    \"View a hierarchical tree of code analysis results in the sidebar\",\n    \"See 'No analysis available' message when no analysis has been run\",\n    \"Browse analysis statistics (total files, functions, entry points, lines of code)\",\n    \"Explore files organized by directory structure\",\n    \"View details about each analyzed file (path, language, line count, function count)\",\n    \"Browse all functions found in the codebase with their locations\",\n    \"See entry points detected in the code\",\n    \"Click on files, functions, or entry points to navigate to their location in the editor\",\n    \"View tooltips with additional context when hovering over tree items\",\n    \"Refresh the analysis view when new analysis results are available\"\n  ],\n  \"developerVisibleActions\": [\n    \"TreeDataProvider that integrates with VSCode's tree view API\",\n    \"Receives CodeAnalysis data from the analyzer module\",\n    \"Updates the tree view when setAnalysis() is called with new analysis results\",\n    \"Organizes analysis data into expandable/collapsible tree nodes\",\n    \"Generates AnalysisItem objects representing different types of nodes (statistics, files, functions, directories)\",\n    \"Provides navigation to source code locations when items are clicked\",\n    \"Handles hierarchical data display for nested directory structures\",\n    \"Emits tree data change events to trigger UI updates\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the viewer with new code analysis results and refreshes the display\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers the tree view to update and redraw\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VSCode TreeItem representation for a given analysis item\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if no element provided\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Generates top-level tree items (statistics, files, functions, entry points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Creates tree items showing analysis statistics (counts and metrics)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Generates tree items for files organized by directory structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information about a specific file including functions\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getDirectoryFiles\",\n      \"desc\": \"Returns files and subdirectories within a directory node\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide a visual, interactive tree-based browser for code analysis results in VSCode, allowing users to explore analyzed code structure (files, functions, entry points) and navigate to specific code locations, solving the problem of presenting complex hierarchical analysis data in an accessible, browsable format\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Defines data structures and interfaces for representing code analysis results including file metrics, function metadata, dependencies, test mappings, and code relationships",
      "userVisibleActions": [
        "View total file, line, and function counts across the codebase",
        "See list of large files that may need optimization",
        "Identify orphaned files not imported anywhere",
        "Discover entry points into the application",
        "Find duplicate code blocks across the codebase",
        "Review function risk levels (high, medium, low) for maintenance priority",
        "See which functions have test coverage and which don't",
        "View import relationships between files",
        "Identify functions with external dependencies (databases, HTTP, filesystem, etc.)"
      ],
      "developerVisibleActions": [
        "Import and use CodeAnalysis interface to structure analysis results",
        "Access function metadata including parameters, return types, and visibility",
        "Query branch complexity information (if/else, loops, try/catch)",
        "Examine dependency information to understand external service calls",
        "Track state mutations within functions (assignments, modifications, deletions)",
        "Map source files to their corresponding test files",
        "Identify uncovered functions that lack tests",
        "Use AnalysisCache for performance optimization",
        "Access circular dependency detection results",
        "Review similarity scores for duplicate code detection"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main interface representing complete codebase analysis results",
          "inputs": "N/A (interface)",
          "outputs": "Structure containing files, functions, imports, orphans, entry points, duplicates, and optional enhanced metadata"
        },
        {
          "name": "FunctionMetadata",
          "desc": "Detailed metadata about a single function including parameters, branches, dependencies, and risk assessment",
          "inputs": "N/A (interface)",
          "outputs": "Function name, file location, parameters, return type, visibility, branches, dependencies, state mutations, risk level"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source code to test coverage",
          "inputs": "N/A (interface)",
          "outputs": "Source files to test files mapping, functions to test names mapping, list of uncovered functions"
        },
        {
          "name": "DependencyInfo",
          "desc": "Describes external or internal dependencies used by functions",
          "inputs": "N/A (interface)",
          "outputs": "Dependency name, type (db/http/filesystem/etc), whether internal or external, line number"
        },
        {
          "name": "BranchInfo",
          "desc": "Represents control flow branches for complexity analysis",
          "inputs": "N/A (interface)",
          "outputs": "Branch type (if/loop/try/etc), human-readable condition, line number"
        },
        {
          "name": "StateMutationInfo",
          "desc": "Tracks how functions modify state",
          "inputs": "N/A (interface)",
          "outputs": "Target of mutation, mutation type (assign/modify/delete/read), line number"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache"
      ],
      "intent": "This file exists to provide a comprehensive, structured schema for representing static code analysis results. It solves the problem of consistently capturing and communicating code quality metrics, architectural relationships, test coverage, complexity indicators, and maintenance risk factors. It enables other parts of the system to work with a standardized representation of codebase structure and behavior, supporting decisions about refactoring, testing, and code organization.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines data structures and interfaces for representing code analysis results including file metrics, function metadata, dependencies, test mappings, and code relationships\",\n  \"userVisibleActions\": [\n    \"View total file, line, and function counts across the codebase\",\n    \"See list of large files that may need optimization\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points into the application\",\n    \"Find duplicate code blocks across the codebase\",\n    \"Review function risk levels (high, medium, low) for maintenance priority\",\n    \"See which functions have test coverage and which don't\",\n    \"View import relationships between files\",\n    \"Identify functions with external dependencies (databases, HTTP, filesystem, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import and use CodeAnalysis interface to structure analysis results\",\n    \"Access function metadata including parameters, return types, and visibility\",\n    \"Query branch complexity information (if/else, loops, try/catch)\",\n    \"Examine dependency information to understand external service calls\",\n    \"Track state mutations within functions (assignments, modifications, deletions)\",\n    \"Map source files to their corresponding test files\",\n    \"Identify uncovered functions that lack tests\",\n    \"Use AnalysisCache for performance optimization\",\n    \"Access circular dependency detection results\",\n    \"Review similarity scores for duplicate code detection\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface representing complete codebase analysis results\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Structure containing files, functions, imports, orphans, entry points, duplicates, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed metadata about a single function including parameters, branches, dependencies, and risk assessment\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Function name, file location, parameters, return type, visibility, branches, dependencies, state mutations, risk level\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Source files to test files mapping, functions to test names mapping, list of uncovered functions\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Describes external or internal dependencies used by functions\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Dependency name, type (db/http/filesystem/etc), whether internal or external, line number\"\n    },\n    {\n      \"name\": \"BranchInfo\",\n      \"desc\": \"Represents control flow branches for complexity analysis\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Branch type (if/loop/try/etc), human-readable condition, line number\"\n    },\n    {\n      \"name\": \"StateMutationInfo\",\n      \"desc\": \"Tracks how functions modify state\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Target of mutation, mutation type (assign/modify/delete/read), line number\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file exists to provide a comprehensive, structured schema for representing static code analysis results. It solves the problem of consistently capturing and communicating code quality metrics, architectural relationships, test coverage, complexity indicators, and maintenance risk factors. It enables other parts of the system to work with a standardized representation of codebase structure and behavior, supporting decisions about refactoring, testing, and code organization.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent storage and retrieval of code analysis results with automatic expiration",
      "userVisibleActions": [
        "Faster workspace analysis on subsequent loads (cached results loaded instantly)",
        "Automatic refresh of analysis after 24 hours to ensure accuracy",
        "Analysis cache cleared when user requests it"
      ],
      "developerVisibleActions": [
        "Extension stores analysis results in .shadowwatch-cache directory",
        "Cache files are automatically created in workspace storage path",
        "Cache entries expire after 24 hours and trigger re-analysis",
        "Failed cache operations fall back gracefully without breaking analysis",
        "Cache can be manually cleared to force fresh analysis"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes cache storage location and ensures directory exists",
          "inputs": "storagePath: string (where to store cache files)",
          "outputs": "AnalysisCache instance"
        },
        {
          "name": "get",
          "desc": "Retrieves cached analysis for a workspace if available and not expired",
          "inputs": "workspaceRoot: string (workspace identifier)",
          "outputs": "Promise<CodeAnalysis | null> (cached data or null if missing/expired)"
        },
        {
          "name": "set",
          "desc": "Saves analysis results to cache with current timestamp",
          "inputs": "workspaceRoot: string, data: CodeAnalysis (analysis to cache)",
          "outputs": "Promise<void>"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis files from storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "getCacheKey",
          "desc": "Generates safe filename from workspace path",
          "inputs": "workspaceRoot: string",
          "outputs": "string (base64-encoded safe filename)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer (CodeAnalysis type)"
      ],
      "intent": "Improves extension performance by caching expensive code analysis results, reducing repeated analysis of unchanged workspaces while ensuring data freshness through automatic expiration",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent storage and retrieval of code analysis results with automatic expiration\",\n  \"userVisibleActions\": [\n    \"Faster workspace analysis on subsequent loads (cached results loaded instantly)\",\n    \"Automatic refresh of analysis after 24 hours to ensure accuracy\",\n    \"Analysis cache cleared when user requests it\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension stores analysis results in .shadowwatch-cache directory\",\n    \"Cache files are automatically created in workspace storage path\",\n    \"Cache entries expire after 24 hours and trigger re-analysis\",\n    \"Failed cache operations fall back gracefully without breaking analysis\",\n    \"Cache can be manually cleared to force fresh analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache storage location and ensures directory exists\",\n      \"inputs\": \"storagePath: string (where to store cache files)\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis for a workspace if available and not expired\",\n      \"inputs\": \"workspaceRoot: string (workspace identifier)\",\n      \"outputs\": \"Promise<CodeAnalysis | null> (cached data or null if missing/expired)\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis (analysis to cache)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates safe filename from workspace path\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (base64-encoded safe filename)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis type)\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis results, reducing repeated analysis of unchanged workspaces while ensuring data freshness through automatic expiration\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes",
      "userVisibleActions": [
        "User can enable/disable the Shadow Watch extension through settings",
        "User can toggle automatic analysis when saving files",
        "User can show/hide inline hints for diagnostics in the editor",
        "User can configure severity thresholds for diagnostics",
        "User can select LLM provider (OpenAI or Claude) for analysis",
        "User can choose output format for LLM reports (Cursor, ChatGPT, Generic, Compact)",
        "User can set file size limits for analysis",
        "User can configure ignored file patterns",
        "User can adjust analysis debounce delays"
      ],
      "developerVisibleActions": [
        "Provides type-safe access to all extension configuration properties",
        "Triggers callbacks when any Shadow Watch configuration changes",
        "Centralizes configuration validation logic",
        "Exposes typed configuration values (LLMProvider, LLMFormat, SeverityThreshold)",
        "Manages workspace-level configuration updates",
        "Allows registering and removing configuration change listeners"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes the configuration manager and sets up the configuration change watcher",
          "inputs": "none",
          "outputs": "ConfigurationManager instance"
        },
        {
          "name": "onConfigurationChange",
          "desc": "Registers a callback to be notified when Shadow Watch settings change",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Unregisters a configuration change callback",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "enabled",
          "desc": "Gets whether the Shadow Watch extension is enabled",
          "inputs": "none (getter)",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave",
          "desc": "Gets whether analysis should run automatically when files are saved",
          "inputs": "none (getter)",
          "outputs": "boolean"
        },
        {
          "name": "showInlineHints",
          "desc": "Gets whether inline diagnostic hints should be displayed in the editor",
          "inputs": "none (getter)",
          "outputs": "boolean"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to provide a single, type-safe point of access for all Shadow Watch configuration settings, eliminating scattered config.get() calls throughout the codebase and ensuring consistent configuration handling with change notifications for reactive updates.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes\",\n  \"userVisibleActions\": [\n    \"User can enable/disable the Shadow Watch extension through settings\",\n    \"User can toggle automatic analysis when saving files\",\n    \"User can show/hide inline hints for diagnostics in the editor\",\n    \"User can configure severity thresholds for diagnostics\",\n    \"User can select LLM provider (OpenAI or Claude) for analysis\",\n    \"User can choose output format for LLM reports (Cursor, ChatGPT, Generic, Compact)\",\n    \"User can set file size limits for analysis\",\n    \"User can configure ignored file patterns\",\n    \"User can adjust analysis debounce delays\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides type-safe access to all extension configuration properties\",\n    \"Triggers callbacks when any Shadow Watch configuration changes\",\n    \"Centralizes configuration validation logic\",\n    \"Exposes typed configuration values (LLMProvider, LLMFormat, SeverityThreshold)\",\n    \"Manages workspace-level configuration updates\",\n    \"Allows registering and removing configuration change listeners\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the configuration manager and sets up the configuration change watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback to be notified when Shadow Watch settings change\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Gets whether the Shadow Watch extension is enabled\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Gets whether analysis should run automatically when files are saved\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Gets whether inline diagnostic hints should be displayed in the editor\",\n      \"inputs\": \"none (getter)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, type-safe point of access for all Shadow Watch configuration settings, eliminating scattered config.get() calls throughout the codebase and ensuring consistent configuration handling with change notifications for reactive updates.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis results into a format suitable for LLM processing and saves them to disk for future reference",
      "userVisibleActions": [
        "Code analysis results are automatically saved to .shadow/docs/code-analysis.json in the workspace",
        "Analysis data persists between sessions for faster subsequent operations"
      ],
      "developerVisibleActions": [
        "Transform raw code analysis data into a structured context format that LLMs can process",
        "Persist analysis results with metadata (timestamp, version) to the .shadow/docs directory",
        "Access previously generated analysis data without re-scanning the codebase",
        "View saved analysis including file structure, imports, entry points, and code statistics"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption",
          "inputs": "CodeAnalysis object containing files, imports, entry points, and statistics",
          "outputs": "AnalysisContext object with formatted file information, imports, entry points, orphaned files, and totals"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to a JSON file in the workspace's .shadow/docs directory with generation metadata",
          "inputs": "CodeAnalysis object to be saved",
          "outputs": "void (writes to file system)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer",
        "../llmService"
      ],
      "intent": "This file bridges the gap between raw code analysis and LLM processing by transforming analysis data into an LLM-friendly format and caching it to disk. This allows documentation generation to reuse expensive analysis results across multiple requests and sessions, improving performance and enabling consistent context for AI-generated documentation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a format suitable for LLM processing and saves them to disk for future reference\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to .shadow/docs/code-analysis.json in the workspace\",\n    \"Analysis data persists between sessions for faster subsequent operations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transform raw code analysis data into a structured context format that LLMs can process\",\n    \"Persist analysis results with metadata (timestamp, version) to the .shadow/docs directory\",\n    \"Access previously generated analysis data without re-scanning the codebase\",\n    \"View saved analysis including file structure, imports, entry points, and code statistics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file information, imports, entry points, orphaned files, and totals\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to a JSON file in the workspace's .shadow/docs directory with generation metadata\",\n      \"inputs\": \"CodeAnalysis object to be saved\",\n      \"outputs\": \"void (writes to file system)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file bridges the gap between raw code analysis and LLM processing by transforming analysis data into an LLM-friendly format and caching it to disk. This allows documentation generation to reuse expensive analysis results across multiple requests and sessions, improving performance and enabling consistent context for AI-generated documentation.\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Manages the display of code insights and warnings in the VS Code Problems panel by creating and updating diagnostic markers.",
      "userVisibleActions": [
        "Code insights appear as warnings or errors in the Problems panel",
        "Inline squiggly lines appear under problematic code lines",
        "Clicking on a problem in the Problems panel navigates to the affected code location",
        "Problem markers are grouped by file in the Problems panel",
        "Diagnostics show 'Shadow Watch' as the source in the Problems panel"
      ],
      "developerVisibleActions": [
        "Diagnostics are automatically updated when new insights are generated",
        "All diagnostics are cleared when the diagnostics collection is reset",
        "Diagnostics can be updated for individual files or all files at once",
        "Each diagnostic is linked to an insight ID for traceability",
        "Severity levels (error, warning, info) determine the visual appearance of diagnostics"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Updates all diagnostic markers across all files based on a collection of insights",
          "inputs": "insights: Insight[] - array of code insights to display",
          "outputs": "void - displays diagnostics in Problems panel"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostic markers for a specific file only",
          "inputs": "uri: vscode.Uri - file location, insights: Insight[] - insights for that file",
          "outputs": "void - displays diagnostics for the specified file"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostic markers from the Problems panel",
          "inputs": "none",
          "outputs": "void - clears all displayed diagnostics"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts an insight into a VS Code diagnostic marker with severity, location, and description",
          "inputs": "insight: Insight - the insight to convert",
          "outputs": "vscode.Diagnostic - a VS Code diagnostic object"
        },
        {
          "name": "dispose",
          "desc": "Cleans up and removes the diagnostic collection when no longer needed",
          "inputs": "none",
          "outputs": "void - releases resources"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "This file exists to bridge between the Shadow Watch insight generation system and VS Code's built-in Problems panel, making code insights visible and actionable for users by displaying them as standard IDE diagnostics that users are familiar with.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages the display of code insights and warnings in the VS Code Problems panel by creating and updating diagnostic markers.\",\n  \"userVisibleActions\": [\n    \"Code insights appear as warnings or errors in the Problems panel\",\n    \"Inline squiggly lines appear under problematic code lines\",\n    \"Clicking on a problem in the Problems panel navigates to the affected code location\",\n    \"Problem markers are grouped by file in the Problems panel\",\n    \"Diagnostics show 'Shadow Watch' as the source in the Problems panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Diagnostics are automatically updated when new insights are generated\",\n    \"All diagnostics are cleared when the diagnostics collection is reset\",\n    \"Diagnostics can be updated for individual files or all files at once\",\n    \"Each diagnostic is linked to an insight ID for traceability\",\n    \"Severity levels (error, warning, info) determine the visual appearance of diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostic markers across all files based on a collection of insights\",\n      \"inputs\": \"insights: Insight[] - array of code insights to display\",\n      \"outputs\": \"void - displays diagnostics in Problems panel\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostic markers for a specific file only\",\n      \"inputs\": \"uri: vscode.Uri - file location, insights: Insight[] - insights for that file\",\n      \"outputs\": \"void - displays diagnostics for the specified file\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostic markers from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - clears all displayed diagnostics\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic marker with severity, location, and description\",\n      \"inputs\": \"insight: Insight - the insight to convert\",\n      \"outputs\": \"vscode.Diagnostic - a VS Code diagnostic object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up and removes the diagnostic collection when no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - releases resources\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge between the Shadow Watch insight generation system and VS Code's built-in Problems panel, making code insights visible and actionable for users by displaying them as standard IDE diagnostics that users are familiar with.\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers all VS Code commands for the extension, mapping command IDs to their handler functions",
      "userVisibleActions": [
        "Analyze entire workspace to generate insights",
        "Analyze current file for code insights",
        "Copy all generated insights to clipboard",
        "Copy insights for a specific file to clipboard",
        "Copy individual insight to clipboard",
        "Clear cached analysis results",
        "Clear all extension data",
        "Open extension settings",
        "Open latest analysis report",
        "Open latest unit test report",
        "Switch between different LLM providers (OpenAI, Anthropic, etc.)",
        "Copy menu structure to clipboard",
        "View current LLM provider status",
        "Navigate to product items in the code",
        "Navigate to analysis items in reports",
        "View detailed information about product items",
        "View detailed information about insights",
        "View detailed information about unit test results"
      ],
      "developerVisibleActions": [
        "Commands are registered when extension activates",
        "Command handlers interact with CodeAnalyzer for analysis",
        "Command handlers use InsightGenerator to create insights",
        "Command handlers interact with LLM services for AI-powered features",
        "Commands manage cache through AnalysisCache",
        "Commands update tree views (InsightsTreeProvider, AnalysisViewerProvider)",
        "Commands trigger diagnostics updates through DiagnosticsProvider",
        "Commands read/write configuration through ConfigurationManager",
        "All commands are bound to the extension context for lifecycle management"
      ],
      "keyFunctions": [
        {
          "name": "register",
          "desc": "Registers all VS Code commands with their handler functions",
          "inputs": "context (ExtensionContext), components (ExtensionComponents)",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Triggers analysis of entire workspace",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeCurrentFile",
          "desc": "Triggers analysis of the currently open file",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyAllInsights",
          "desc": "Copies all generated insights to clipboard",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "copyInsight",
          "desc": "Copies a specific insight item to clipboard",
          "inputs": "item (insight object)",
          "outputs": "Promise<void>"
        },
        {
          "name": "clearCache",
          "desc": "Clears cached analysis data",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "switchProvider",
          "desc": "Switches between different LLM providers",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to a product item in the code",
          "inputs": "item (ProductNavItem)",
          "outputs": "Promise<void>"
        },
        {
          "name": "showProviderStatus",
          "desc": "Displays current LLM provider status",
          "inputs": "none",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "This file centralizes command registration logic to organize and manage all user-facing commands in the extension, separating command registration concerns from the main extension activation logic and providing a single source of truth for all available commands",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension, mapping command IDs to their handler functions\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to generate insights\",\n    \"Analyze current file for code insights\",\n    \"Copy all generated insights to clipboard\",\n    \"Copy insights for a specific file to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear cached analysis results\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between different LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to product items in the code\",\n    \"Navigate to analysis items in reports\",\n    \"View detailed information about product items\",\n    \"View detailed information about insights\",\n    \"View detailed information about unit test results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Commands are registered when extension activates\",\n    \"Command handlers interact with CodeAnalyzer for analysis\",\n    \"Command handlers use InsightGenerator to create insights\",\n    \"Command handlers interact with LLM services for AI-powered features\",\n    \"Commands manage cache through AnalysisCache\",\n    \"Commands update tree views (InsightsTreeProvider, AnalysisViewerProvider)\",\n    \"Commands trigger diagnostics updates through DiagnosticsProvider\",\n    \"Commands read/write configuration through ConfigurationManager\",\n    \"All commands are bound to the extension context for lifecycle management\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their handler functions\",\n      \"inputs\": \"context (ExtensionContext), components (ExtensionComponents)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Triggers analysis of entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeCurrentFile\",\n      \"desc\": \"Triggers analysis of the currently open file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyAllInsights\",\n      \"desc\": \"Copies all generated insights to clipboard\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"copyInsight\",\n      \"desc\": \"Copies a specific insight item to clipboard\",\n      \"inputs\": \"item (insight object)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearCache\",\n      \"desc\": \"Clears cached analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"switchProvider\",\n      \"desc\": \"Switches between different LLM providers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product item in the code\",\n      \"inputs\": \"item (ProductNavItem)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showProviderStatus\",\n      \"desc\": \"Displays current LLM provider status\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"This file centralizes command registration logic to organize and manage all user-facing commands in the extension, separating command registration concerns from the main extension activation logic and providing a single source of truth for all available commands\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Initializes and bootstraps all extension components when the VS Code extension activates, setting up analyzers, viewers, providers, and services needed for code intelligence features.",
      "userVisibleActions": [
        "Extension activates and displays status bar item showing analysis status",
        "Tree views populate with insights, analysis results, unit tests, and reports",
        "Diagnostics panel shows code issues and warnings from static analysis",
        "Product navigator becomes available for browsing code structure",
        "Reports viewer displays generated analysis reports",
        "File watching begins for automatic re-analysis on code changes"
      ],
      "developerVisibleActions": [
        "Extension creates and registers all core components (analyzer, insight generator, formatters)",
        "Sets up tree data providers for multiple custom views (insights, analysis, static analysis, unit tests, reports)",
        "Initializes caching system for analysis results",
        "Configures file watcher service to monitor workspace changes",
        "Establishes diagnostics provider for displaying code issues",
        "Registers LLM integration for AI-powered code analysis",
        "Creates status bar item for displaying extension state",
        "Instantiates configuration and state managers for persistent settings"
      ],
      "keyFunctions": [
        {
          "name": "bootstrap",
          "desc": "Main entry point that initializes all extension components in proper order",
          "inputs": "vscode.ExtensionContext",
          "outputs": "ExtensionComponents object containing all initialized services"
        },
        {
          "name": "createAnalyzer",
          "desc": "Instantiates the code analyzer component",
          "inputs": "none",
          "outputs": "CodeAnalyzer instance"
        },
        {
          "name": "createInsightGenerator",
          "desc": "Creates the insight generation service",
          "inputs": "none",
          "outputs": "InsightGenerator instance"
        },
        {
          "name": "createTreeProviders",
          "desc": "Sets up all tree view data providers for displaying structured data",
          "inputs": "none",
          "outputs": "Multiple tree provider instances"
        },
        {
          "name": "registerViews",
          "desc": "Registers custom VS Code views for insights, analysis, and reports",
          "inputs": "vscode.ExtensionContext, tree providers",
          "outputs": "Registered tree views"
        },
        {
          "name": "initializeServices",
          "desc": "Starts background services like file watching and diagnostics",
          "inputs": "ExtensionComponents",
          "outputs": "void"
        },
        {
          "name": "setupStatusBar",
          "desc": "Creates and configures the status bar item for displaying extension state",
          "inputs": "vscode.ExtensionContext",
          "outputs": "vscode.StatusBarItem"
        }
      ],
      "dependencies": [
        "vscode",
        "../../analyzer",
        "../../insightGenerator",
        "../../llmFormatter",
        "../../fileWatcher",
        "../../insightsTreeView",
        "../../diagnosticsProvider",
        "../../cache",
        "../../llmIntegration",
        "../../productNavigator",
        "../../analysisViewer",
        "../../insightsViewer",
        "../../staticAnalysisViewer",
        "../../unitTestsNavigator",
        "../../config/configurationManager",
        "../../utils/errorHandler",
        "../../domain/services/fileWatcherService",
        "../../ui/reportsViewer",
        "../../reportsTreeProvider",
        "../../state/llmStateManager"
      ],
      "intent": "This file exists to centralize and orchestrate the complex initialization sequence of the extension, separating activation logic from the main extension entry point. It ensures all components are created in the correct order, properly wired together, and registered with VS Code's extension host. This separation makes the codebase more maintainable and testable by isolating bootstrapping concerns.",
      "rawContent": "```json\n{\n  \"purpose\": \"Initializes and bootstraps all extension components when the VS Code extension activates, setting up analyzers, viewers, providers, and services needed for code intelligence features.\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis status\",\n    \"Tree views populate with insights, analysis results, unit tests, and reports\",\n    \"Diagnostics panel shows code issues and warnings from static analysis\",\n    \"Product navigator becomes available for browsing code structure\",\n    \"Reports viewer displays generated analysis reports\",\n    \"File watching begins for automatic re-analysis on code changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension creates and registers all core components (analyzer, insight generator, formatters)\",\n    \"Sets up tree data providers for multiple custom views (insights, analysis, static analysis, unit tests, reports)\",\n    \"Initializes caching system for analysis results\",\n    \"Configures file watcher service to monitor workspace changes\",\n    \"Establishes diagnostics provider for displaying code issues\",\n    \"Registers LLM integration for AI-powered code analysis\",\n    \"Creates status bar item for displaying extension state\",\n    \"Instantiates configuration and state managers for persistent settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components in proper order\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object containing all initialized services\"\n    },\n    {\n      \"name\": \"createAnalyzer\",\n      \"desc\": \"Instantiates the code analyzer component\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CodeAnalyzer instance\"\n    },\n    {\n      \"name\": \"createInsightGenerator\",\n      \"desc\": \"Creates the insight generation service\",\n      \"inputs\": \"none\",\n      \"outputs\": \"InsightGenerator instance\"\n    },\n    {\n      \"name\": \"createTreeProviders\",\n      \"desc\": \"Sets up all tree view data providers for displaying structured data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Multiple tree provider instances\"\n    },\n    {\n      \"name\": \"registerViews\",\n      \"desc\": \"Registers custom VS Code views for insights, analysis, and reports\",\n      \"inputs\": \"vscode.ExtensionContext, tree providers\",\n      \"outputs\": \"Registered tree views\"\n    },\n    {\n      \"name\": \"initializeServices\",\n      \"desc\": \"Starts background services like file watching and diagnostics\",\n      \"inputs\": \"ExtensionComponents\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupStatusBar\",\n      \"desc\": \"Creates and configures the status bar item for displaying extension state\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"vscode.StatusBarItem\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer\",\n    \"../../insightGenerator\",\n    \"../../llmFormatter\",\n    \"../../fileWatcher\",\n    \"../../insightsTreeView\",\n    \"../../diagnosticsProvider\",\n    \"../../cache\",\n    \"../../llmIntegration\",\n    \"../../productNavigator\",\n    \"../../analysisViewer\",\n    \"../../insightsViewer\",\n    \"../../staticAnalysisViewer\",\n    \"../../unitTestsNavigator\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler\",\n    \"../../domain/services/fileWatcherService\",\n    \"../../ui/reportsViewer\",\n    \"../../reportsTreeProvider\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and orchestrate the complex initialization sequence of the extension, separating activation logic from the main extension entry point. It ensures all components are created in the correct order, properly wired together, and registered with VS Code's extension host. This separation makes the codebase more maintainable and testable by isolating bootstrapping concerns.\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and code analysis insights into human-readable Markdown documents with structured sections and metadata.",
      "userVisibleActions": [
        "Views product documentation in Markdown format with overview, features, and user perspectives",
        "Sees documentation organized by GUI, CLI, and API interaction types",
        "Reads feature descriptions, architectural insights, and quality metrics in formatted sections",
        "Views timestamped documentation with generation date and time",
        "Reviews code quality findings with risk levels and improvement recommendations",
        "Sees categorized file listings organized by role (Core, UI, Config, Tests)",
        "Reads technical debt items with priority levels and effort estimates",
        "Views dependency information and external service integrations"
      ],
      "developerVisibleActions": [
        "Calls formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown",
        "Calls formatInsightsAsMarkdown() to convert LLM analysis insights into Markdown",
        "Receives formatted Markdown strings ready for display or file writing",
        "Provides EnhancedProductDocumentation objects containing structured doc data",
        "Provides LLMInsights objects containing code analysis results",
        "Gets consistent Markdown formatting with headers, lists, and separators",
        "Receives formatted sections for overview, features, architecture, quality, and more"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation into a complete Markdown document with all sections",
          "inputs": "EnhancedProductDocumentation object with overview, features, user perspectives, architecture, etc.",
          "outputs": "Formatted Markdown string with headers, lists, and metadata"
        },
        {
          "name": "formatInsightsAsMarkdown",
          "desc": "Converts LLM code analysis insights into a structured Markdown report",
          "inputs": "LLMInsights object with strengths, improvements, architecture, quality metrics, etc.",
          "outputs": "Formatted Markdown string with analysis sections and findings"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "Separates formatting concerns from core logic by providing a dedicated formatter that transforms structured documentation and analysis objects into consistent, readable Markdown output for users and reports.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and code analysis insights into human-readable Markdown documents with structured sections and metadata.\",\n  \"userVisibleActions\": [\n    \"Views product documentation in Markdown format with overview, features, and user perspectives\",\n    \"Sees documentation organized by GUI, CLI, and API interaction types\",\n    \"Reads feature descriptions, architectural insights, and quality metrics in formatted sections\",\n    \"Views timestamped documentation with generation date and time\",\n    \"Reviews code quality findings with risk levels and improvement recommendations\",\n    \"Sees categorized file listings organized by role (Core, UI, Config, Tests)\",\n    \"Reads technical debt items with priority levels and effort estimates\",\n    \"Views dependency information and external service integrations\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls formatEnhancedDocsAsMarkdown() to convert product documentation objects into Markdown\",\n    \"Calls formatInsightsAsMarkdown() to convert LLM analysis insights into Markdown\",\n    \"Receives formatted Markdown strings ready for display or file writing\",\n    \"Provides EnhancedProductDocumentation objects containing structured doc data\",\n    \"Provides LLMInsights objects containing code analysis results\",\n    \"Gets consistent Markdown formatting with headers, lists, and separators\",\n    \"Receives formatted sections for overview, features, architecture, quality, and more\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation into a complete Markdown document with all sections\",\n      \"inputs\": \"EnhancedProductDocumentation object with overview, features, user perspectives, architecture, etc.\",\n      \"outputs\": \"Formatted Markdown string with headers, lists, and metadata\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM code analysis insights into a structured Markdown report\",\n      \"inputs\": \"LLMInsights object with strengths, improvements, architecture, quality metrics, etc.\",\n      \"outputs\": \"Formatted Markdown string with analysis sections and findings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates formatting concerns from core logic by providing a dedicated formatter that transforms structured documentation and analysis objects into consistent, readable Markdown output for users and reports.\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation between code files, functions, and displays detailed information about analysis items in the VS Code editor.",
      "userVisibleActions": [
        "Navigate to a specific file in the workspace",
        "Navigate to a specific function within a file and highlight it",
        "Navigate to API endpoints and see their location in code",
        "View detailed information about analysis items in a webview panel",
        "See formatted code snippets with syntax highlighting",
        "View function signatures, parameters, and return types",
        "See file paths and line numbers for code locations",
        "View entry point details with formatted information",
        "See error messages when navigation fails"
      ],
      "developerVisibleActions": [
        "Trigger navigation to product items (files, functions, endpoints) from tree views",
        "Display analysis item details in a dedicated webview panel",
        "Open files and position cursor at specific line numbers",
        "Handle navigation for different item types (file, function, navigate)",
        "Generate HTML views with syntax-highlighted code snippets",
        "Format and display complex data structures in readable format",
        "Handle absolute and relative file paths within workspace",
        "Show error messages when file operations fail"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Opens a file or navigates to a function location based on the product navigation item type",
          "inputs": "ProductNavItem (containing file path, function name, and line information)",
          "outputs": "Promise<void> (opens document in editor)"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Opens a file and positions cursor at a specific line number for analysis items",
          "inputs": "AnalysisItem (containing file path and line number)",
          "outputs": "Promise<void> (opens document and reveals line)"
        },
        {
          "name": "showItemDetails",
          "desc": "Displays detailed information about an analysis item in a webview panel with formatted HTML",
          "inputs": "AnalysisItem (analysis data to display)",
          "outputs": "void (creates or updates webview panel)"
        },
        {
          "name": "generateDetailsHtml",
          "desc": "Creates formatted HTML content for displaying item details with syntax highlighting and structured layout",
          "inputs": "AnalysisItem (item to format)",
          "outputs": "string (HTML content)"
        },
        {
          "name": "escapeHtml",
          "desc": "Sanitizes text content for safe HTML rendering",
          "inputs": "string (text to escape)",
          "outputs": "string (escaped HTML)"
        },
        {
          "name": "formatValue",
          "desc": "Converts various data types into readable HTML-formatted strings",
          "inputs": "any (value to format)",
          "outputs": "string (formatted HTML)"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "ProductNavItem (from productNavigator)",
        "AnalysisItem (from analysisViewer)",
        "EntryPoint (from analyzer)"
      ],
      "intent": "This file exists to separate navigation concerns from the main extension logic, providing a centralized way to handle all user navigation actions (opening files, jumping to functions, viewing details) and displaying analysis results in a user-friendly format with proper syntax highlighting and structured information presentation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation between code files, functions, and displays detailed information about analysis items in the VS Code editor.\",\n  \"userVisibleActions\": [\n    \"Navigate to a specific file in the workspace\",\n    \"Navigate to a specific function within a file and highlight it\",\n    \"Navigate to API endpoints and see their location in code\",\n    \"View detailed information about analysis items in a webview panel\",\n    \"See formatted code snippets with syntax highlighting\",\n    \"View function signatures, parameters, and return types\",\n    \"See file paths and line numbers for code locations\",\n    \"View entry point details with formatted information\",\n    \"See error messages when navigation fails\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger navigation to product items (files, functions, endpoints) from tree views\",\n    \"Display analysis item details in a dedicated webview panel\",\n    \"Open files and position cursor at specific line numbers\",\n    \"Handle navigation for different item types (file, function, navigate)\",\n    \"Generate HTML views with syntax-highlighted code snippets\",\n    \"Format and display complex data structures in readable format\",\n    \"Handle absolute and relative file paths within workspace\",\n    \"Show error messages when file operations fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Opens a file or navigates to a function location based on the product navigation item type\",\n      \"inputs\": \"ProductNavItem (containing file path, function name, and line information)\",\n      \"outputs\": \"Promise<void> (opens document in editor)\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Opens a file and positions cursor at a specific line number for analysis items\",\n      \"inputs\": \"AnalysisItem (containing file path and line number)\",\n      \"outputs\": \"Promise<void> (opens document and reveals line)\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about an analysis item in a webview panel with formatted HTML\",\n      \"inputs\": \"AnalysisItem (analysis data to display)\",\n      \"outputs\": \"void (creates or updates webview panel)\"\n    },\n    {\n      \"name\": \"generateDetailsHtml\",\n      \"desc\": \"Creates formatted HTML content for displaying item details with syntax highlighting and structured layout\",\n      \"inputs\": \"AnalysisItem (item to format)\",\n      \"outputs\": \"string (HTML content)\"\n    },\n    {\n      \"name\": \"escapeHtml\",\n      \"desc\": \"Sanitizes text content for safe HTML rendering\",\n      \"inputs\": \"string (text to escape)\",\n      \"outputs\": \"string (escaped HTML)\"\n    },\n    {\n      \"name\": \"formatValue\",\n      \"desc\": \"Converts various data types into readable HTML-formatted strings\",\n      \"inputs\": \"any (value to format)\",\n      \"outputs\": \"string (formatted HTML)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem (from productNavigator)\",\n    \"AnalysisItem (from analysisViewer)\",\n    \"EntryPoint (from analyzer)\"\n  ],\n  \"intent\": \"This file exists to separate navigation concerns from the main extension logic, providing a centralized way to handle all user navigation actions (opening files, jumping to functions, viewing details) and displaying analysis results in a user-friendly format with proper syntax highlighting and structured information presentation.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.",
      "userVisibleActions": [
        "Generates AI prompts that analyze project architecture and structure",
        "Creates AI prompts for generating product documentation from code",
        "Produces AI prompts that determine product purpose and target audience",
        "Generates AI prompts for analyzing individual code files",
        "Creates AI prompts for summarizing code modules and their relationships",
        "Produces AI prompts for generating comprehensive test plans for code files",
        "Generates AI prompts for creating actual test code from test plans"
      ],
      "developerVisibleActions": [
        "Developer calls prompt builder methods to generate LLM prompts for different analysis tasks",
        "System constructs architecture analysis prompts by combining code analysis, product docs, and context",
        "System builds product documentation prompts from project context and file structure",
        "System generates file-specific analysis prompts including code content and role information",
        "System creates module rollup prompts aggregating file summaries within a module",
        "System produces product-level documentation prompts combining all summaries and analysis",
        "System generates test planning prompts with function metadata and existing test information",
        "System creates test code generation prompts with test plans and source code references",
        "All prompts include token budgets and structured output requirements for consistent LLM responses"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure",
          "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
          "outputs": "Formatted string prompt with architecture analysis instructions and context"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Creates a prompt for generating product-level documentation from code structure",
          "inputs": "context (AnalysisContext)",
          "outputs": "Formatted string prompt requesting product documentation generation"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Generates a prompt for determining product purpose, target audience, and value proposition",
          "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
          "outputs": "Formatted string prompt for product purpose analysis"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Creates a prompt for analyzing a single code file's behavior and purpose",
          "inputs": "file (FileInfo), content (string), role (string)",
          "outputs": "Formatted string prompt with file content and analysis instructions"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Generates a prompt for summarizing a module by aggregating its file summaries",
          "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
          "outputs": "Formatted string prompt for module-level summary generation"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Creates a comprehensive prompt for product-level documentation combining all analysis results",
          "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper",
          "outputs": "Formatted string prompt for complete product documentation"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Generates a prompt for creating a test plan for a specific file's functions",
          "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
          "outputs": "Formatted string prompt requesting structured test plan generation"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Creates a prompt for generating actual test code from a test plan item",
          "inputs": "testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)",
          "outputs": "Formatted string prompt with test plan and code context for test generation"
        }
      ],
      "dependencies": [
        "../../llmService (AnalysisContext, ProductPurposeAnalysis)",
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)",
        "../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)",
        "../../fileAccessHelper (FileAccessHelper)"
      ],
      "intent": "This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.\",\n  \"userVisibleActions\": [\n    \"Generates AI prompts that analyze project architecture and structure\",\n    \"Creates AI prompts for generating product documentation from code\",\n    \"Produces AI prompts that determine product purpose and target audience\",\n    \"Generates AI prompts for analyzing individual code files\",\n    \"Creates AI prompts for summarizing code modules and their relationships\",\n    \"Produces AI prompts for generating comprehensive test plans for code files\",\n    \"Generates AI prompts for creating actual test code from test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls prompt builder methods to generate LLM prompts for different analysis tasks\",\n    \"System constructs architecture analysis prompts by combining code analysis, product docs, and context\",\n    \"System builds product documentation prompts from project context and file structure\",\n    \"System generates file-specific analysis prompts including code content and role information\",\n    \"System creates module rollup prompts aggregating file summaries within a module\",\n    \"System produces product-level documentation prompts combining all summaries and analysis\",\n    \"System generates test planning prompts with function metadata and existing test information\",\n    \"System creates test code generation prompts with test plans and source code references\",\n    \"All prompts include token budgets and structured output requirements for consistent LLM responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt with architecture analysis instructions and context\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates a prompt for generating product-level documentation from code structure\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt requesting product documentation generation\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Generates a prompt for determining product purpose, target audience, and value proposition\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for product purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates a prompt for analyzing a single code file's behavior and purpose\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted string prompt with file content and analysis instructions\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Generates a prompt for summarizing a module by aggregating its file summaries\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted string prompt for module-level summary generation\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for product-level documentation combining all analysis results\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for complete product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Generates a prompt for creating a test plan for a specific file's functions\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted string prompt requesting structured test plan generation\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Creates a prompt for generating actual test code from a test plan item\",\n      \"inputs\": \"testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)\",\n      \"outputs\": \"Formatted string prompt with test plan and code context for test generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService (AnalysisContext, ProductPurposeAnalysis)\",\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)\",\n    \"../../fileAccessHelper (FileAccessHelper)\"\n  ],\n  \"intent\": \"This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations showing which code should be extracted and where",
        "Gets step-by-step migration instructions for moving code between files",
        "Sees before-and-after code examples demonstrating proposed refactorings",
        "Views function dependency relationships to understand refactoring impacts",
        "Receives prescriptive guidance on how to organize code into better structures"
      ],
      "developerVisibleActions": [
        "Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions",
        "Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance",
        "Receives structured extraction plans showing which functions to move from source to target files",
        "Gets migration steps and code examples to execute the refactoring safely",
        "Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]",
          "outputs": "Formatted string prompt containing refactoring instructions and requirements"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Creates the foundation prompt with context, code analysis, and architectural insights",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
          "outputs": "Base prompt string"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Adds detailed function-level analysis including dependencies and responsibilities to the prompt",
          "inputs": "FunctionAnalysis[]",
          "outputs": "Formatted section describing function characteristics"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Specifies requirements for code extraction plans including target files and migration steps",
          "inputs": "None",
          "outputs": "Section detailing extraction plan requirements"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations showing which code should be extracted and where\",\n    \"Gets step-by-step migration instructions for moving code between files\",\n    \"Sees before-and-after code examples demonstrating proposed refactorings\",\n    \"Views function dependency relationships to understand refactoring impacts\",\n    \"Receives prescriptive guidance on how to organize code into better structures\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions\",\n    \"Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance\",\n    \"Receives structured extraction plans showing which functions to move from source to target files\",\n    \"Gets migration steps and code examples to execute the refactoring safely\",\n    \"Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]\",\n      \"outputs\": \"Formatted string prompt containing refactoring instructions and requirements\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundation prompt with context, code analysis, and architectural insights\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function-level analysis including dependencies and responsibilities to the prompt\",\n      \"inputs\": \"FunctionAnalysis[]\",\n      \"outputs\": \"Formatted section describing function characteristics\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Specifies requirements for code extraction plans including target files and migration steps\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Section detailing extraction plan requirements\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt templates for LLM-based automated test generation and test configuration setup",
      "userVisibleActions": [
        "Automatically generates test setup recommendations for the codebase",
        "Creates prioritized test plans identifying which functions need testing",
        "Generates actual test code with assertions and edge cases",
        "Analyzes codebase to determine optimal testing framework and dependencies"
      ],
      "developerVisibleActions": [
        "Call buildSetupPrompt() to get LLM prompt for test configuration analysis",
        "Call buildPlanningPrompt() to get LLM prompt for test strategy creation",
        "Call buildGenerationPrompt() to get LLM prompt for actual test code generation",
        "Provide workspace root, file lists, and function details as inputs",
        "Receive structured JSON responses with test setup configurations, test plans, or generated test code",
        "Pass in optional product documentation and architecture insights to improve test generation quality"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates prompt for LLM to analyze codebase and recommend test setup configuration",
          "inputs": "workspaceRoot (string), fileList (array), optional packageJsonContent (string)",
          "outputs": "Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates prompt for LLM to generate prioritized test plan for functions",
          "inputs": "context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights",
          "outputs": "Formatted prompt string requesting prioritized list of functions to test with complexity assessments"
        },
        {
          "name": "buildGenerationPrompt",
          "desc": "Creates prompt for LLM to generate actual test code for specific function",
          "inputs": "testableFunction (TestableFunction), framework (string), optional fileContext (string)",
          "outputs": "Formatted prompt string requesting complete test code with imports, mocks, and assertions"
        }
      ],
      "dependencies": [
        "../../analyzer",
        "../services/testing/types/testPlanTypes"
      ],
      "intent": "Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based automated test generation and test configuration setup\",\n  \"userVisibleActions\": [\n    \"Automatically generates test setup recommendations for the codebase\",\n    \"Creates prioritized test plans identifying which functions need testing\",\n    \"Generates actual test code with assertions and edge cases\",\n    \"Analyzes codebase to determine optimal testing framework and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() to get LLM prompt for test configuration analysis\",\n    \"Call buildPlanningPrompt() to get LLM prompt for test strategy creation\",\n    \"Call buildGenerationPrompt() to get LLM prompt for actual test code generation\",\n    \"Provide workspace root, file lists, and function details as inputs\",\n    \"Receive structured JSON responses with test setup configurations, test plans, or generated test code\",\n    \"Pass in optional product documentation and architecture insights to improve test generation quality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates prompt for LLM to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate prioritized test plan for functions\",\n      \"inputs\": \"context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted prompt string requesting prioritized list of functions to test with complexity assessments\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate actual test code for specific function\",\n      \"inputs\": \"testableFunction (TestableFunction), framework (string), optional fileContext (string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test code with imports, mocks, and assertions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides a unified service for watching file system changes and document saves across the extension to eliminate code duplication.",
      "userVisibleActions": [
        "File changes are automatically detected when files matching watched patterns are created, modified, or deleted",
        "Document saves trigger automatic updates and refreshes in related UI components",
        "Changes to specific file types (like documentation files) are monitored and processed",
        "File system events are consolidated to prevent duplicate processing of the same changes"
      ],
      "developerVisibleActions": [
        "Register file watchers with custom patterns and handlers to respond to file system changes",
        "Subscribe to document save events with custom callback functions",
        "Configure ignore patterns to exclude specific files or directories from being watched",
        "Control which types of events to watch (create, change, delete) per pattern",
        "Manage multiple handlers for the same file pattern with unique identifiers",
        "Dispose of specific watchers or all watchers to clean up resources",
        "Receive standardized FileChangeEvent objects with URI and event type information"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Registers a file system watcher for a specific pattern with options to filter event types and ignore patterns",
          "inputs": "id (string), pattern (string or RelativePattern), handler (FileChangeHandler), options (watchCreate, watchChange, watchDelete, ignorePatterns)",
          "outputs": "Disposable object to unregister the watcher"
        },
        {
          "name": "onDocumentSave",
          "desc": "Registers a handler to be called whenever any document is saved in the workspace",
          "inputs": "handler function that receives a TextDocument",
          "outputs": "Disposable object to unregister the handler"
        },
        {
          "name": "unwatch",
          "desc": "Removes a specific file watcher by its unique identifier",
          "inputs": "id (string)",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all watchers and handlers, releasing system resources",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getPatternKey",
          "desc": "Generates a unique key for a file pattern to identify and deduplicate watchers",
          "inputs": "pattern (string or RelativePattern)",
          "outputs": "string key"
        },
        {
          "name": "shouldIgnore",
          "desc": "Determines if a file URI should be ignored based on configured ignore patterns",
          "inputs": "uri (vscode.Uri), ignorePatterns (array of strings)",
          "outputs": "boolean"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to consolidate duplicate file watching logic that was previously scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file watching behavior and prevents resource leaks by providing a single, well-managed service that can handle multiple watchers with different patterns, ignore rules, and event handlers while ensuring proper cleanup and disposal.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified service for watching file system changes and document saves across the extension to eliminate code duplication.\",\n  \"userVisibleActions\": [\n    \"File changes are automatically detected when files matching watched patterns are created, modified, or deleted\",\n    \"Document saves trigger automatic updates and refreshes in related UI components\",\n    \"Changes to specific file types (like documentation files) are monitored and processed\",\n    \"File system events are consolidated to prevent duplicate processing of the same changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers with custom patterns and handlers to respond to file system changes\",\n    \"Subscribe to document save events with custom callback functions\",\n    \"Configure ignore patterns to exclude specific files or directories from being watched\",\n    \"Control which types of events to watch (create, change, delete) per pattern\",\n    \"Manage multiple handlers for the same file pattern with unique identifiers\",\n    \"Dispose of specific watchers or all watchers to clean up resources\",\n    \"Receive standardized FileChangeEvent objects with URI and event type information\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file system watcher for a specific pattern with options to filter event types and ignore patterns\",\n      \"inputs\": \"id (string), pattern (string or RelativePattern), handler (FileChangeHandler), options (watchCreate, watchChange, watchDelete, ignorePatterns)\",\n      \"outputs\": \"Disposable object to unregister the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever any document is saved in the workspace\",\n      \"inputs\": \"handler function that receives a TextDocument\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific file watcher by its unique identifier\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers, releasing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to identify and deduplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file URI should be ignored based on configured ignore patterns\",\n      \"inputs\": \"uri (vscode.Uri), ignorePatterns (array of strings)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate duplicate file watching logic that was previously scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It solves the problem of maintaining consistent file watching behavior and prevents resource leaks by providing a single, well-managed service that can handle multiple watchers with different patterns, ignore rules, and event handlers while ensuring proper cleanup and disposal.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task",
      "userVisibleActions": [
        "AI progressively gathers more information about the codebase by requesting specific files",
        "AI performs grep searches to find relevant code patterns across the project",
        "Analysis completes after gathering sufficient information or reaching maximum iteration limit",
        "Receives additional context information formatted as markdown sections"
      ],
      "developerVisibleActions": [
        "Trigger incremental analysis that automatically handles LLM requests for files and grep searches",
        "Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)",
        "Control maximum number of analysis iterations to prevent infinite loops",
        "Receive structured results including all processed requests and conversation history",
        "Access shouldContinue flag to determine if analysis needs more iterations"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages",
          "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation history)",
          "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
        },
        {
          "name": "iterativeAnalysis (implied by async iterator pattern)",
          "desc": "Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached",
          "inputs": "iteration callbacks, max iterations, initial result and messages",
          "outputs": "IterationResult containing final result, iteration count, all requests, and continuation status"
        }
      ],
      "dependencies": [
        "fileAccessHelper",
        "LLMRequest interface",
        "FileAccessHelper class"
      ],
      "intent": "Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"AI progressively gathers more information about the codebase by requesting specific files\",\n    \"AI performs grep searches to find relevant code patterns across the project\",\n    \"Analysis completes after gathering sufficient information or reaching maximum iteration limit\",\n    \"Receives additional context information formatted as markdown sections\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger incremental analysis that automatically handles LLM requests for files and grep searches\",\n    \"Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)\",\n    \"Control maximum number of analysis iterations to prevent infinite loops\",\n    \"Receive structured results including all processed requests and conversation history\",\n    \"Access shouldContinue flag to determine if analysis needs more iterations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"iterativeAnalysis (implied by async iterator pattern)\",\n      \"desc\": \"Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached\",\n      \"inputs\": \"iteration callbacks, max iterations, initial result and messages\",\n      \"outputs\": \"IterationResult containing final result, iteration count, all requests, and continuation status\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest interface\",\n    \"FileAccessHelper class\"\n  ],\n  \"intent\": \"Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects test framework configuration and dependencies to ensure generated tests work without manual user setup",
      "userVisibleActions": [
        "Automatically detects which test framework is being used (Jest, Mocha, Vitest, or Pytest)",
        "Identifies missing test dependencies that need to be installed",
        "Provides setup recommendations when test configuration is incomplete",
        "Warns about missing configuration files needed for tests to run",
        "Reports whether the workspace is ready to run generated tests"
      ],
      "developerVisibleActions": [
        "Scans package.json to detect test framework from scripts and dependencies",
        "Checks for framework-specific configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini)",
        "Validates TypeScript-related test dependencies (ts-jest, @jest/globals)",
        "Determines if additional setup actions are required before tests can run",
        "Returns structured status information about test configuration state"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Analyzes workspace to determine test framework and configuration status",
          "inputs": "workspaceRoot: string (path to workspace folder)",
          "outputs": "TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "SWLogger"
      ],
      "intent": "Eliminates the need for users to manually configure test frameworks by automatically detecting what's available and what's missing, ensuring a smooth experience when generating and running tests. Solves the problem of tests failing due to missing configuration or dependencies by proactively identifying issues.",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration and dependencies to ensure generated tests work without manual user setup\",\n  \"userVisibleActions\": [\n    \"Automatically detects which test framework is being used (Jest, Mocha, Vitest, or Pytest)\",\n    \"Identifies missing test dependencies that need to be installed\",\n    \"Provides setup recommendations when test configuration is incomplete\",\n    \"Warns about missing configuration files needed for tests to run\",\n    \"Reports whether the workspace is ready to run generated tests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans package.json to detect test framework from scripts and dependencies\",\n    \"Checks for framework-specific configuration files (jest.config.js, .mocharc.json, vitest.config.ts, pytest.ini)\",\n    \"Validates TypeScript-related test dependencies (ts-jest, @jest/globals)\",\n    \"Determines if additional setup actions are required before tests can run\",\n    \"Returns structured status information about test configuration state\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to determine test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to workspace folder)\",\n      \"outputs\": \"TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates the need for users to manually configure test frameworks by automatically detecting what's available and what's missing, ensuring a smooth experience when generating and running tests. Solves the problem of tests failing due to missing configuration or dependencies by proactively identifying issues.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates automated tests for code functions using AI/LLM in small batches, executing and validating them incrementally.",
      "userVisibleActions": [
        "Tests are generated automatically for selected functions in the codebase",
        "Progress updates show which function is currently being tested (e.g., '3 of 10: validateUser')",
        "Test results display pass/fail status for each generated test",
        "Coverage reports show which functions have tests and which need them",
        "Failed tests show error messages and execution details"
      ],
      "developerVisibleActions": [
        "Developer triggers test generation for a batch of functions",
        "System reads function source code and existing mocks automatically",
        "LLM generates test code based on function signatures and implementation",
        "Generated tests are written to the test directory structure",
        "Tests are executed immediately to verify they work",
        "Progress callback provides real-time updates during generation",
        "Results include test code, execution status, and any errors encountered"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for multiple functions in sequence with progress tracking",
          "inputs": "functions array, workspace root path, LLM service, optional progress callback",
          "outputs": "Map of function names to test generation results (code, execution status, errors)"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Retrieves the source code for a specific function from the file system",
          "inputs": "function metadata, workspace root",
          "outputs": "Source code string"
        },
        {
          "name": "buildGenerationPrompt",
          "desc": "Constructs the AI prompt with function details, source code, and existing mocks",
          "inputs": "function metadata, source code, test framework type, existing mock code",
          "outputs": "Formatted prompt string for LLM"
        },
        {
          "name": "generateTestForFunction",
          "desc": "Calls LLM service to generate test code for a single function",
          "inputs": "Prompt string",
          "outputs": "Test generation result with code and metadata"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestableFunction",
        "TestGenerationState",
        "TestGenerationResult",
        "buildGenerationPrompt",
        "TestExecutionService",
        "SWLogger"
      ],
      "intent": "This service solves the problem of manually writing tests by automating test generation using AI. It processes functions in manageable batches to avoid overwhelming the system, provides real-time progress feedback, and validates generated tests by executing them immediately. This enables developers to quickly achieve test coverage across their codebase.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates automated tests for code functions using AI/LLM in small batches, executing and validating them incrementally.\",\n  \"userVisibleActions\": [\n    \"Tests are generated automatically for selected functions in the codebase\",\n    \"Progress updates show which function is currently being tested (e.g., '3 of 10: validateUser')\",\n    \"Test results display pass/fail status for each generated test\",\n    \"Coverage reports show which functions have tests and which need them\",\n    \"Failed tests show error messages and execution details\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test generation for a batch of functions\",\n    \"System reads function source code and existing mocks automatically\",\n    \"LLM generates test code based on function signatures and implementation\",\n    \"Generated tests are written to the test directory structure\",\n    \"Tests are executed immediately to verify they work\",\n    \"Progress callback provides real-time updates during generation\",\n    \"Results include test code, execution status, and any errors encountered\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in sequence with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service, optional progress callback\",\n      \"outputs\": \"Map of function names to test generation results (code, execution status, errors)\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Retrieves the source code for a specific function from the file system\",\n      \"inputs\": \"function metadata, workspace root\",\n      \"outputs\": \"Source code string\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Constructs the AI prompt with function details, source code, and existing mocks\",\n      \"inputs\": \"function metadata, source code, test framework type, existing mock code\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    },\n    {\n      \"name\": \"generateTestForFunction\",\n      \"desc\": \"Calls LLM service to generate test code for a single function\",\n      \"inputs\": \"Prompt string\",\n      \"outputs\": \"Test generation result with code and metadata\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service solves the problem of manually writing tests by automating test generation using AI. It processes functions in manageable batches to avoid overwhelming the system, provides real-time progress feedback, and validates generated tests by executing them immediately. This enables developers to quickly achieve test coverage across their codebase.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Creates AI-powered prioritized test plans by analyzing code functions and determining which ones need testing and in what order.",
      "userVisibleActions": [
        "System analyzes code functions and determines which ones can be tested",
        "System generates a prioritized test plan showing which functions to test first",
        "System explains why certain functions are testable or not testable",
        "Test plan is saved to disk for review and implementation"
      ],
      "developerVisibleActions": [
        "Developer triggers test plan creation for analyzed code",
        "System analyzes function complexity, parameters, and return types",
        "LLM evaluates functions against product documentation and architecture insights",
        "System categorizes functions into priority groups (high, medium, low priority)",
        "Test plan with function groups and testing recommendations is generated",
        "Plan is saved as JSON file in output directory for developer review"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts function metadata from code analysis including name, location, complexity, and signature",
          "inputs": "codeAnalysis object containing function data",
          "outputs": "Array of function metadata objects"
        },
        {
          "name": "createTestPlan",
          "desc": "Uses LLM to generate prioritized test strategy based on functions, documentation, and architecture",
          "inputs": "context, functions array, llmService, optional productDocs and architectureInsights",
          "outputs": "TestPlan object with function groups and testing recommendations"
        },
        {
          "name": "saveTestPlan",
          "desc": "Persists the generated test plan to disk as a JSON file",
          "inputs": "testPlan object, output directory path",
          "outputs": "File path where plan was saved"
        }
      ],
      "dependencies": [
        "fs (file system operations)",
        "path (file path handling)",
        "TestPlan and TestableFunction types",
        "buildPlanningPrompt from testPrompts",
        "AnalysisContext from analyzer",
        "SWLogger for logging",
        "LLM service for AI-powered analysis"
      ],
      "intent": "This file solves the problem of determining which code functions should be tested and in what order. Instead of manually reviewing code to decide testing priorities, it uses AI to analyze function complexity, dependencies, and business importance to create an intelligent, prioritized test plan that guides developers on where to focus testing efforts first.",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates AI-powered prioritized test plans by analyzing code functions and determining which ones need testing and in what order.\",\n  \"userVisibleActions\": [\n    \"System analyzes code functions and determines which ones can be tested\",\n    \"System generates a prioritized test plan showing which functions to test first\",\n    \"System explains why certain functions are testable or not testable\",\n    \"Test plan is saved to disk for review and implementation\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test plan creation for analyzed code\",\n    \"System analyzes function complexity, parameters, and return types\",\n    \"LLM evaluates functions against product documentation and architecture insights\",\n    \"System categorizes functions into priority groups (high, medium, low priority)\",\n    \"Test plan with function groups and testing recommendations is generated\",\n    \"Plan is saved as JSON file in output directory for developer review\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts function metadata from code analysis including name, location, complexity, and signature\",\n      \"inputs\": \"codeAnalysis object containing function data\",\n      \"outputs\": \"Array of function metadata objects\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Uses LLM to generate prioritized test strategy based on functions, documentation, and architecture\",\n      \"inputs\": \"context, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups and testing recommendations\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to disk as a JSON file\",\n      \"inputs\": \"testPlan object, output directory path\",\n      \"outputs\": \"File path where plan was saved\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs (file system operations)\",\n    \"path (file path handling)\",\n    \"TestPlan and TestableFunction types\",\n    \"buildPlanningPrompt from testPrompts\",\n    \"AnalysisContext from analyzer\",\n    \"SWLogger for logging\",\n    \"LLM service for AI-powered analysis\"\n  ],\n  \"intent\": \"This file solves the problem of determining which code functions should be tested and in what order. Instead of manually reviewing code to decide testing priorities, it uses AI to analyze function complexity, dependencies, and business importance to create an intelligent, prioritized test plan that guides developers on where to focus testing efforts first.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Detects test environment configuration and generates test setup plans using LLM analysis of the codebase structure",
      "userVisibleActions": [
        "Automatic detection of test framework (Jest, pytest, JUnit, etc.) in the workspace",
        "Identification of primary programming language used in the project",
        "Generation of test setup configuration based on existing project structure",
        "Detection of missing test infrastructure components",
        "Automated test directory structure recognition"
      ],
      "developerVisibleActions": [
        "Scans workspace for package.json, tsconfig.json, jest.config.js and test directories",
        "Analyzes file extensions to determine primary language (TypeScript, JavaScript, Python, Java, C++)",
        "Counts file types across the workspace to identify language distribution",
        "Detects installed testing frameworks and dependencies from package.json",
        "Builds prompts for LLM to generate test setup recommendations",
        "Returns TestEnvironment object containing detected configuration",
        "Provides TestSetupPlan with recommended setup steps"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Analyzes workspace to identify testing framework, language, and existing test infrastructure",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestEnvironment object with detected configuration details"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively scans workspace to get all file paths for analysis",
          "inputs": "workspaceRoot: string",
          "outputs": "Array of file paths"
        },
        {
          "name": "buildSetupPrompt",
          "desc": "Creates LLM prompt for generating test setup recommendations",
          "inputs": "TestEnvironment data",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "testSetupTypes",
        "testPrompts",
        "SWLogger"
      ],
      "intent": "This service exists to automate the initial test setup process by intelligently detecting the current project's testing environment and generating appropriate configuration recommendations, eliminating manual setup work and reducing configuration errors for developers starting with testing.",
      "rawContent": "```json\n{\n  \"purpose\": \"Detects test environment configuration and generates test setup plans using LLM analysis of the codebase structure\",\n  \"userVisibleActions\": [\n    \"Automatic detection of test framework (Jest, pytest, JUnit, etc.) in the workspace\",\n    \"Identification of primary programming language used in the project\",\n    \"Generation of test setup configuration based on existing project structure\",\n    \"Detection of missing test infrastructure components\",\n    \"Automated test directory structure recognition\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace for package.json, tsconfig.json, jest.config.js and test directories\",\n    \"Analyzes file extensions to determine primary language (TypeScript, JavaScript, Python, Java, C++)\",\n    \"Counts file types across the workspace to identify language distribution\",\n    \"Detects installed testing frameworks and dependencies from package.json\",\n    \"Builds prompts for LLM to generate test setup recommendations\",\n    \"Returns TestEnvironment object containing detected configuration\",\n    \"Provides TestSetupPlan with recommended setup steps\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to identify testing framework, language, and existing test infrastructure\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object with detected configuration details\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans workspace to get all file paths for analysis\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates LLM prompt for generating test setup recommendations\",\n      \"inputs\": \"TestEnvironment data\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This service exists to automate the initial test setup process by intelligently detecting the current project's testing environment and generating appropriate configuration recommendations, eliminating manual setup work and reducing configuration errors for developers starting with testing.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates tests by running them, detecting failures, and automatically fixing failing tests using an LLM.",
      "userVisibleActions": [
        "Tests are automatically executed in the workspace",
        "Test results are displayed showing passed, failed, and total test counts",
        "Failing tests are automatically fixed through multiple attempts",
        "Progress updates are shown for each fix attempt",
        "Final test validation reports are generated with success/failure statistics"
      ],
      "developerVisibleActions": [
        "Trigger test execution for entire workspace or specific test files",
        "Initiate automatic fixing of failing tests with configurable retry attempts",
        "Receive structured test execution results with pass/fail counts per file",
        "Get detailed test reports including failure messages and stack traces",
        "Access test report summaries with overall statistics",
        "Monitor fix attempt progress through logged messages"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or tests in a specific file and captures results",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> - array of test results per file"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to automatically fix a failing test using LLM with retry logic",
          "inputs": "testFilePath (string), executionResult (TestExecutionResult), workspaceRoot (string), llmService (any), optional maxAttempts (number, default 3)",
          "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}>"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "testResultTypes (TestExecutionResult, TestReport, TestReportSummary)",
        "testPrompts (buildFixPrompt)",
        "SWLogger"
      ],
      "intent": "This file exists to automate the test validation workflow by running tests, identifying failures, and using LLM capabilities to automatically fix broken tests with intelligent retry logic. It solves the problem of manual test debugging and fixing by providing an automated validation and repair pipeline for generated or existing tests.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates tests by running them, detecting failures, and automatically fixing failing tests using an LLM.\",\n  \"userVisibleActions\": [\n    \"Tests are automatically executed in the workspace\",\n    \"Test results are displayed showing passed, failed, and total test counts\",\n    \"Failing tests are automatically fixed through multiple attempts\",\n    \"Progress updates are shown for each fix attempt\",\n    \"Final test validation reports are generated with success/failure statistics\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test execution for entire workspace or specific test files\",\n    \"Initiate automatic fixing of failing tests with configurable retry attempts\",\n    \"Receive structured test execution results with pass/fail counts per file\",\n    \"Get detailed test reports including failure messages and stack traces\",\n    \"Access test report summaries with overall statistics\",\n    \"Monitor fix attempt progress through logged messages\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or tests in a specific file and captures results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - array of test results per file\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with retry logic\",\n      \"inputs\": \"testFilePath (string), executionResult (TestExecutionResult), workspaceRoot (string), llmService (any), optional maxAttempts (number, default 3)\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"testResultTypes (TestExecutionResult, TestReport, TestReportSummary)\",\n    \"testPrompts (buildFixPrompt)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation workflow by running tests, identifying failures, and using LLM capabilities to automatically fix broken tests with intelligent retry logic. It solves the problem of manual test debugging and fixing by providing an automated validation and repair pipeline for generated or existing tests.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes test suites (Jest, Mocha, Pytest) and captures their results for analysis and reporting",
      "userVisibleActions": [
        "Runs tests for a specific file or all tests in the workspace",
        "Shows test execution progress with status updates",
        "Displays test results including passed, failed, and error counts",
        "Shows test execution duration for each test suite",
        "Reports detailed error messages and stack traces for failed tests",
        "Indicates when tests timeout or fail to execute"
      ],
      "developerVisibleActions": [
        "Calls runJest() to execute Jest tests with optional file parameter",
        "Calls runMocha() to execute Mocha tests with optional file parameter",
        "Calls runPytest() to execute Python tests with optional file parameter",
        "Receives TestExecutionResult[] containing pass/fail status, counts, duration, and error details",
        "Handles test execution errors and timeouts gracefully",
        "Works with workspace root path to locate test files",
        "Parses test framework output (JSON format) into structured results",
        "Provides detailed error information including test name, message, and stack trace"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Executes Jest test suite for a specific file or all tests",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runMocha",
          "desc": "Executes Mocha test suite for a specific file or all tests",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runPytest",
          "desc": "Executes Pytest test suite for a specific file or all tests",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "parseJestOutput",
          "desc": "Parses Jest JSON output into structured test results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parseMochaOutput",
          "desc": "Parses Mocha JSON output into structured test results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parsePytestOutput",
          "desc": "Parses Pytest JSON output into structured test results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "This service solves the problem of running different test frameworks (Jest, Mocha, Pytest) in a unified way and translating their diverse output formats into a consistent structured format that can be analyzed, reported, and acted upon. It abstracts away the complexity of executing shell commands, parsing framework-specific output, and handling errors.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest) and captures their results for analysis and reporting\",\n  \"userVisibleActions\": [\n    \"Runs tests for a specific file or all tests in the workspace\",\n    \"Shows test execution progress with status updates\",\n    \"Displays test results including passed, failed, and error counts\",\n    \"Shows test execution duration for each test suite\",\n    \"Reports detailed error messages and stack traces for failed tests\",\n    \"Indicates when tests timeout or fail to execute\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls runJest() to execute Jest tests with optional file parameter\",\n    \"Calls runMocha() to execute Mocha tests with optional file parameter\",\n    \"Calls runPytest() to execute Python tests with optional file parameter\",\n    \"Receives TestExecutionResult[] containing pass/fail status, counts, duration, and error details\",\n    \"Handles test execution errors and timeouts gracefully\",\n    \"Works with workspace root path to locate test files\",\n    \"Parses test framework output (JSON format) into structured results\",\n    \"Provides detailed error information including test name, message, and stack trace\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Pytest test suite for a specific file or all tests\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses Jest JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses Mocha JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses Pytest JSON output into structured test results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"This service solves the problem of running different test frameworks (Jest, Mocha, Pytest) in a unified way and translating their diverse output formats into a consistent structured format that can be analyzed, reported, and acted upon. It abstracts away the complexity of executing shell commands, parsing framework-specific output, and handling errors.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for organizing and tracking automated test generation for code functions",
      "userVisibleActions": [
        "View test generation progress through different phases (setup, planning, generation, validation, complete)",
        "See how many functions are testable out of total functions in the codebase",
        "Track which functions have tests generated and validated",
        "Monitor test generation failures with error details and retry attempts",
        "Understand function complexity and testing priority through grouped organization"
      ],
      "developerVisibleActions": [
        "Define test plans that organize functions into prioritized groups for systematic test generation",
        "Track test generation workflow state across multiple phases",
        "Specify function metadata including file location, line numbers, complexity, and dependencies",
        "Identify which functions require mocking based on external dependencies",
        "Monitor batch processing of test generation with real-time counts and timestamps",
        "Handle and record test generation failures with error tracking and retry logic"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to provide a structured type system for managing automated test generation workflows. It solves the problem of organizing and tracking the complex process of generating tests for multiple functions by defining clear phases, grouping strategies, function metadata, and failure tracking mechanisms. It ensures type safety when planning which functions to test, monitoring generation progress, and handling errors during automated test creation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for organizing and tracking automated test generation for code functions\",\n  \"userVisibleActions\": [\n    \"View test generation progress through different phases (setup, planning, generation, validation, complete)\",\n    \"See how many functions are testable out of total functions in the codebase\",\n    \"Track which functions have tests generated and validated\",\n    \"Monitor test generation failures with error details and retry attempts\",\n    \"Understand function complexity and testing priority through grouped organization\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define test plans that organize functions into prioritized groups for systematic test generation\",\n    \"Track test generation workflow state across multiple phases\",\n    \"Specify function metadata including file location, line numbers, complexity, and dependencies\",\n    \"Identify which functions require mocking based on external dependencies\",\n    \"Monitor batch processing of test generation with real-time counts and timestamps\",\n    \"Handle and record test generation failures with error tracking and retry logic\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a structured type system for managing automated test generation workflows. It solves the problem of organizing and tracking the complex process of generating tests for multiple functions by defining clear phases, grouping strategies, function metadata, and failure tracking mechanisms. It ensures type safety when planning which functions to test, monitoring generation progress, and handling errors during automated test creation.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test generation, validation, execution, and reporting results.",
      "userVisibleActions": [
        "View test execution status (pass/fail/error) for each test file",
        "See how many tests passed, failed, or encountered errors",
        "Review test execution duration and timing information",
        "Read error messages and stack traces for failed tests",
        "View test report summary with pass rates and file statistics",
        "Access recommendations for improving test quality",
        "See which test files were generated and which are passing"
      ],
      "developerVisibleActions": [
        "Define structured test generation results with imports, mocks, and test code",
        "Represent mock statements with explanations for clarity",
        "Handle test validation results with fixed code and remaining issues",
        "Track detailed test execution metrics including passed/failed/error counts",
        "Capture error details with test names, messages, and stack traces",
        "Generate comprehensive test reports with summaries and recommendations",
        "Structure test report summaries with pass rates and file counts"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a standardized type system for representing test-related data throughout the testing workflow, ensuring consistent structure for test generation output, validation feedback, execution results, and comprehensive reporting with metrics and recommendations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test generation, validation, execution, and reporting results.\",\n  \"userVisibleActions\": [\n    \"View test execution status (pass/fail/error) for each test file\",\n    \"See how many tests passed, failed, or encountered errors\",\n    \"Review test execution duration and timing information\",\n    \"Read error messages and stack traces for failed tests\",\n    \"View test report summary with pass rates and file statistics\",\n    \"Access recommendations for improving test quality\",\n    \"See which test files were generated and which are passing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structured test generation results with imports, mocks, and test code\",\n    \"Represent mock statements with explanations for clarity\",\n    \"Handle test validation results with fixed code and remaining issues\",\n    \"Track detailed test execution metrics including passed/failed/error counts\",\n    \"Capture error details with test names, messages, and stack traces\",\n    \"Generate comprehensive test reports with summaries and recommendations\",\n    \"Structure test report summaries with pass rates and file counts\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for representing test-related data throughout the testing workflow, ensuring consistent structure for test generation output, validation feedback, execution results, and comprehensive reporting with metrics and recommendations.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test setup and configuration management in a testing service",
      "userVisibleActions": [
        "User can set up test environments with specified languages and frameworks",
        "User receives feedback on test setup success or failure with created files and installed dependencies",
        "User can view which dependencies and configuration files are needed for testing",
        "User sees information about existing test environment components and what's missing"
      ],
      "developerVisibleActions": [
        "Developer defines test setup plans with language, framework, and dependencies",
        "Developer specifies configuration files with paths and content for test setup",
        "Developer checks test environment state including package.json, TypeScript config, and Jest config",
        "Developer receives structured execution results with success status, messages, and errors",
        "Developer defines mock requirements with type and reason for testing needs",
        "Developer tracks which dependencies are missing and which test frameworks exist"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to provide a type-safe contract for test setup operations, ensuring consistent structure when creating test environments, managing dependencies, generating configuration files, and reporting setup results across the testing service",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test setup and configuration management in a testing service\",\n  \"userVisibleActions\": [\n    \"User can set up test environments with specified languages and frameworks\",\n    \"User receives feedback on test setup success or failure with created files and installed dependencies\",\n    \"User can view which dependencies and configuration files are needed for testing\",\n    \"User sees information about existing test environment components and what's missing\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines test setup plans with language, framework, and dependencies\",\n    \"Developer specifies configuration files with paths and content for test setup\",\n    \"Developer checks test environment state including package.json, TypeScript config, and Jest config\",\n    \"Developer receives structured execution results with success status, messages, and errors\",\n    \"Developer defines mock requirements with type and reason for testing needs\",\n    \"Developer tracks which dependencies are missing and which test frameworks exist\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a type-safe contract for test setup operations, ensuring consistent structure when creating test environments, managing dependencies, generating configuration files, and reporting setup results across the testing service\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "Main extension entry point that activates and orchestrates all Code Analyzer features, commands, and UI components in VSCode",
      "userVisibleActions": [
        "Analyze code files to generate insights about behavior and dependencies",
        "View generated insights in a tree view sidebar",
        "Generate LLM-optimized prompts for AI code analysis",
        "Navigate to code locations from insights",
        "See real-time diagnostic warnings and errors in files",
        "Get status updates via status bar showing analysis progress",
        "Refresh analysis when files change automatically",
        "Export insights and analysis results",
        "Configure analysis settings through extension settings",
        "See insights organized by entry points, functions, and dependencies"
      ],
      "developerVisibleActions": [
        "Extension activates when VSCode starts or when code analysis commands are triggered",
        "Bootstrapper initializes all core components (analyzer, insight generator, LLM formatter, file watcher, etc.)",
        "Command handlers are registered for all user-triggerable actions",
        "File watcher monitors workspace for code changes and triggers re-analysis",
        "Cache system stores analysis results to avoid redundant processing",
        "Diagnostics provider surfaces code issues in the Problems panel",
        "Tree view provider displays structured insights in the sidebar",
        "Status bar updates to show current analysis state",
        "Error handler catches and displays user-friendly error messages",
        "Configuration manager loads and validates user settings",
        "Navigation handler allows jumping to code locations from insights",
        "Cleanup occurs on extension deactivation to dispose resources"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Initializes the extension when VSCode loads it, sets up all components, registers commands, and starts file watching",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "void"
        },
        {
          "name": "deactivate",
          "desc": "Cleans up resources when the extension is unloaded or disabled",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "ExtensionBootstrapper.initialize",
          "desc": "Creates and wires together all extension components (analyzer, generators, providers, handlers)",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "ExtensionComponents"
        },
        {
          "name": "CommandRegistry.registerAll",
          "desc": "Registers all user-facing commands with VSCode command palette",
          "inputs": "context, components, commandHandlers",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler"
      ],
      "intent": "This file exists to serve as the main entry point for the VSCode extension, orchestrating the initialization, lifecycle management, and coordination of all code analysis features. It solves the problem of bootstrapping a complex multi-component extension by centralizing activation logic, registering commands, and ensuring all parts work together cohesively to provide code analysis and AI-assisted insights to developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Main extension entry point that activates and orchestrates all Code Analyzer features, commands, and UI components in VSCode\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights about behavior and dependencies\",\n    \"View generated insights in a tree view sidebar\",\n    \"Generate LLM-optimized prompts for AI code analysis\",\n    \"Navigate to code locations from insights\",\n    \"See real-time diagnostic warnings and errors in files\",\n    \"Get status updates via status bar showing analysis progress\",\n    \"Refresh analysis when files change automatically\",\n    \"Export insights and analysis results\",\n    \"Configure analysis settings through extension settings\",\n    \"See insights organized by entry points, functions, and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or when code analysis commands are triggered\",\n    \"Bootstrapper initializes all core components (analyzer, insight generator, LLM formatter, file watcher, etc.)\",\n    \"Command handlers are registered for all user-triggerable actions\",\n    \"File watcher monitors workspace for code changes and triggers re-analysis\",\n    \"Cache system stores analysis results to avoid redundant processing\",\n    \"Diagnostics provider surfaces code issues in the Problems panel\",\n    \"Tree view provider displays structured insights in the sidebar\",\n    \"Status bar updates to show current analysis state\",\n    \"Error handler catches and displays user-friendly error messages\",\n    \"Configuration manager loads and validates user settings\",\n    \"Navigation handler allows jumping to code locations from insights\",\n    \"Cleanup occurs on extension deactivation to dispose resources\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension when VSCode loads it, sets up all components, registers commands, and starts file watching\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources when the extension is unloaded or disabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"ExtensionBootstrapper.initialize\",\n      \"desc\": \"Creates and wires together all extension components (analyzer, generators, providers, handlers)\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents\"\n    },\n    {\n      \"name\": \"CommandRegistry.registerAll\",\n      \"desc\": \"Registers all user-facing commands with VSCode command palette\",\n      \"inputs\": \"context, components, commandHandlers\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file exists to serve as the main entry point for the VSCode extension, orchestrating the initialization, lifecycle management, and coordination of all code analysis features. It solves the problem of bootstrapping a complex multi-component extension by centralizing activation logic, registering commands, and ensuring all parts work together cohesively to provide code analysis and AI-assisted insights to developers.\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and grep search functionality to enable LLM-powered code analysis with iterative file access and pattern matching",
      "userVisibleActions": [
        "Search for code patterns across multiple files using grep",
        "View file contents with line counts",
        "See organized file listings grouped by folder",
        "Get search results with line numbers and surrounding context",
        "Receive limited search results to avoid overwhelming output"
      ],
      "developerVisibleActions": [
        "Request specific files by path with optional reason for transparency",
        "Perform grep searches with optional file patterns (e.g., '*.ts') to filter search scope",
        "Set maximum result limits to control output size",
        "Process file access requests and grep requests through unified interface",
        "Receive structured responses with file metadata (path, lines, existence)",
        "Get grep matches with context lines before and after each match",
        "Track whether search results were truncated due to limits"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Organizes and formats a list of files grouped by their directory paths",
          "inputs": "Array of file objects with path, lines, and language properties",
          "outputs": "Formatted string showing files organized by folder with metadata"
        },
        {
          "name": "readFile",
          "desc": "Reads a file from the workspace and returns its content with metadata",
          "inputs": "File path relative to workspace root",
          "outputs": "FileResponse with content, line count, and existence status"
        },
        {
          "name": "grepFiles",
          "desc": "Searches for a pattern across files with optional filtering and result limiting",
          "inputs": "Search pattern, optional file pattern filter, optional max results limit",
          "outputs": "GrepResponse with matches, context lines, total count, and truncation flag"
        },
        {
          "name": "processRequest",
          "desc": "Handles both file read and grep requests through a unified interface",
          "inputs": "LLMRequest object (FileRequest or GrepRequest)",
          "outputs": "Either FileResponse or GrepResponse depending on request type"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to bridge the gap between LLM code analysis needs and file system access, allowing AI to iteratively explore codebases by reading specific files and searching for patterns without overwhelming the context window, enabling intelligent code understanding through targeted queries",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable LLM-powered code analysis with iterative file access and pattern matching\",\n  \"userVisibleActions\": [\n    \"Search for code patterns across multiple files using grep\",\n    \"View file contents with line counts\",\n    \"See organized file listings grouped by folder\",\n    \"Get search results with line numbers and surrounding context\",\n    \"Receive limited search results to avoid overwhelming output\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request specific files by path with optional reason for transparency\",\n    \"Perform grep searches with optional file patterns (e.g., '*.ts') to filter search scope\",\n    \"Set maximum result limits to control output size\",\n    \"Process file access requests and grep requests through unified interface\",\n    \"Receive structured responses with file metadata (path, lines, existence)\",\n    \"Get grep matches with context lines before and after each match\",\n    \"Track whether search results were truncated due to limits\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by their directory paths\",\n      \"inputs\": \"Array of file objects with path, lines, and language properties\",\n      \"outputs\": \"Formatted string showing files organized by folder with metadata\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its content with metadata\",\n      \"inputs\": \"File path relative to workspace root\",\n      \"outputs\": \"FileResponse with content, line count, and existence status\"\n    },\n    {\n      \"name\": \"grepFiles\",\n      \"desc\": \"Searches for a pattern across files with optional filtering and result limiting\",\n      \"inputs\": \"Search pattern, optional file pattern filter, optional max results limit\",\n      \"outputs\": \"GrepResponse with matches, context lines, total count, and truncation flag\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Handles both file read and grep requests through a unified interface\",\n      \"inputs\": \"LLMRequest object (FileRequest or GrepRequest)\",\n      \"outputs\": \"Either FileResponse or GrepResponse depending on request type\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM code analysis needs and file system access, allowing AI to iteratively explore codebases by reading specific files and searching for patterns without overwhelming the context window, enabling intelligent code understanding through targeted queries\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.",
      "userVisibleActions": [
        "View organized documentation showing what each file does from a user perspective",
        "See categorized actions for GUI, CLI, API, and CI/CD interfaces",
        "Access structured summaries of features and capabilities",
        "Review workflow integration examples and problems solved by the product"
      ],
      "developerVisibleActions": [
        "Define documentation structure using FileSummary, ModuleSummary, and EnhancedProductDocumentation interfaces",
        "Organize code files by role (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface)",
        "Document file purposes, user-visible actions, and developer-visible actions",
        "Structure module capabilities with endpoints, commands, and worker job flows",
        "Create product-level documentation with overview, architecture, and component diagrams"
      ],
      "keyFunctions": [],
      "dependencies": [
        "fs",
        "path",
        "./analyzer (CodeAnalysis, FileInfo types)"
      ],
      "intent": "This file exists to provide a standardized schema for documenting codebases at multiple levels of abstraction (file  module  product), enabling automated documentation generation that separates user-facing behavior from implementation details and organizes information by role and capability.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"View organized documentation showing what each file does from a user perspective\",\n    \"See categorized actions for GUI, CLI, API, and CI/CD interfaces\",\n    \"Access structured summaries of features and capabilities\",\n    \"Review workflow integration examples and problems solved by the product\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define documentation structure using FileSummary, ModuleSummary, and EnhancedProductDocumentation interfaces\",\n    \"Organize code files by role (CLI entrypoint, API route, Worker, GUI view, Core logic, Utility, Contract/interface)\",\n    \"Document file purposes, user-visible actions, and developer-visible actions\",\n    \"Structure module capabilities with endpoints, commands, and worker job flows\",\n    \"Create product-level documentation with overview, architecture, and component diagrams\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo types)\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for documenting codebases at multiple levels of abstraction (file  module  product), enabling automated documentation generation that separates user-facing behavior from implementation details and organizes information by role and capability.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file changes and triggers code analysis when files are saved in the workspace.",
      "userVisibleActions": [
        "Automatically analyzes code when a file is saved (if 'analyzeOnSave' setting is enabled)",
        "Displays code insights and diagnostics after file save",
        "Updates insights tree view with latest analysis results",
        "Shows analysis status in output channel"
      ],
      "developerVisibleActions": [
        "Watches document save events in VS Code workspace",
        "Triggers code analysis with configurable debounce delay to avoid excessive analysis",
        "Coordinates between CodeAnalyzer, InsightGenerator, DiagnosticsProvider, and InsightsTreeProvider",
        "Can be started and stopped programmatically to control when analysis occurs",
        "Prevents duplicate analysis when multiple files are saved rapidly",
        "Handles errors during analysis and logs them via ErrorHandler"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins watching for file save events and enables automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops watching file save events and cancels any pending analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save event and schedules analysis with debounce",
          "inputs": "document (TextDocument)",
          "outputs": "void"
        },
        {
          "name": "analyzeFile",
          "desc": "Performs code analysis on a file and updates all providers with results",
          "inputs": "document (TextDocument)",
          "outputs": "Promise<void>"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources and stops the file watcher",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "configurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of keeping code insights synchronized with the latest file changes without requiring manual analysis triggers. It acts as the orchestration layer that connects file system events to the analysis pipeline, ensuring users always see up-to-date insights while preventing performance issues through debouncing and duplicate analysis prevention.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes and triggers code analysis when files are saved in the workspace.\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when a file is saved (if 'analyzeOnSave' setting is enabled)\",\n    \"Displays code insights and diagnostics after file save\",\n    \"Updates insights tree view with latest analysis results\",\n    \"Shows analysis status in output channel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Watches document save events in VS Code workspace\",\n    \"Triggers code analysis with configurable debounce delay to avoid excessive analysis\",\n    \"Coordinates between CodeAnalyzer, InsightGenerator, DiagnosticsProvider, and InsightsTreeProvider\",\n    \"Can be started and stopped programmatically to control when analysis occurs\",\n    \"Prevents duplicate analysis when multiple files are saved rapidly\",\n    \"Handles errors during analysis and logs them via ErrorHandler\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching file save events and cancels any pending analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save event and schedules analysis with debounce\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Performs code analysis on a file and updates all providers with results\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources and stops the file watcher\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by monitoring when users save files. It solves the problem of keeping code insights synchronized with the latest file changes without requiring manual analysis triggers. It acts as the orchestration layer that connects file system events to the analysis pipeline, ensuring users always see up-to-date insights while preventing performance issues through debouncing and duplicate analysis prevention.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Caches file contents in memory to avoid redundant disk reads and improve performance across the extension",
      "userVisibleActions": [
        "File operations complete faster when accessing previously opened files",
        "Extension responds more quickly when analyzing or processing the same files multiple times",
        "Automatic detection of file changes ensures users always see current content"
      ],
      "developerVisibleActions": [
        "Retrieve file contents with automatic caching via getFile()",
        "Cache automatically invalidates when files are modified, created, or deleted",
        "LRU (Least Recently Used) eviction policy manages memory usage automatically",
        "File system watcher monitors changes and keeps cache synchronized",
        "Cache statistics track hits, misses, evictions, and memory usage",
        "Configurable maximum cache size and time-to-live (TTL) settings"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "constructor",
          "desc": "Initializes the cache with configurable size limit and TTL, sets up file system watcher",
          "inputs": "maxSize: number (default 500), ttl: number (default 5000ms)",
          "outputs": "FileCache instance"
        },
        {
          "name": "isStale",
          "desc": "Checks if cached entry has exceeded its time-to-live period",
          "inputs": "cached: CachedFile",
          "outputs": "boolean - true if stale"
        },
        {
          "name": "setupWatcher",
          "desc": "Creates file system watcher to automatically invalidate cache entries when files change",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "evictIfNeeded",
          "desc": "Removes least recently used cache entries when cache exceeds maximum size",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getFileHash",
          "desc": "Computes hash of file to detect content changes",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file hash"
        },
        {
          "name": "readFileFromDisk",
          "desc": "Reads file content directly from filesystem",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.",
      "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to avoid redundant disk reads and improve performance across the extension\",\n  \"userVisibleActions\": [\n    \"File operations complete faster when accessing previously opened files\",\n    \"Extension responds more quickly when analyzing or processing the same files multiple times\",\n    \"Automatic detection of file changes ensures users always see current content\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file contents with automatic caching via getFile()\",\n    \"Cache automatically invalidates when files are modified, created, or deleted\",\n    \"LRU (Least Recently Used) eviction policy manages memory usage automatically\",\n    \"File system watcher monitors changes and keeps cache synchronized\",\n    \"Cache statistics track hits, misses, evictions, and memory usage\",\n    \"Configurable maximum cache size and time-to-live (TTL) settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the cache with configurable size limit and TTL, sets up file system watcher\",\n      \"inputs\": \"maxSize: number (default 500), ttl: number (default 5000ms)\",\n      \"outputs\": \"FileCache instance\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Checks if cached entry has exceeded its time-to-live period\",\n      \"inputs\": \"cached: CachedFile\",\n      \"outputs\": \"boolean - true if stale\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Creates file system watcher to automatically invalidate cache entries when files change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used cache entries when cache exceeds maximum size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getFileHash\",\n      \"desc\": \"Computes hash of file to detect content changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file hash\"\n    },\n    {\n      \"name\": \"readFileFromDisk\",\n      \"desc\": \"Reads file content directly from filesystem\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling",
      "userVisibleActions": [
        "Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)",
        "Multiple files are processed simultaneously for faster performance",
        "File processing errors are handled gracefully without crashing the application"
      ],
      "developerVisibleActions": [
        "Developer calls processFiles() with an array of file paths and a custom processor function",
        "Files are automatically filtered based on configurable patterns before processing",
        "Each file's content is read and passed to the developer's processor function",
        "Results are collected and returned as an array in the same order as input files",
        "Developer can inject custom file filters and file readers for testing or specialized behavior",
        "Error context can be provided for detailed error tracking and debugging"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines if a file should be processed based on its path",
          "inputs": "filePath: string",
          "outputs": "boolean indicating if file should be processed"
        },
        {
          "name": "readFile",
          "desc": "Reads the content of a file asynchronously",
          "inputs": "filePath: string",
          "outputs": "Promise<string> containing file content"
        },
        {
          "name": "processFiles",
          "desc": "Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each",
          "inputs": "files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext",
          "outputs": "Promise<T[]> containing processed results for each file"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../utils/errorHandler"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)\",\n    \"Multiple files are processed simultaneously for faster performance\",\n    \"File processing errors are handled gracefully without crashing the application\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls processFiles() with an array of file paths and a custom processor function\",\n    \"Files are automatically filtered based on configurable patterns before processing\",\n    \"Each file's content is read and passed to the developer's processor function\",\n    \"Results are collected and returned as an array in the same order as input files\",\n    \"Developer can inject custom file filters and file readers for testing or specialized behavior\",\n    \"Error context can be provided for detailed error tracking and debugging\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads the content of a file asynchronously\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> containing file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext\",\n      \"outputs\": \"Promise<T[]> containing processed results for each file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages storage and retrieval of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory structure.",
      "userVisibleActions": [
        "Product documentation files are saved to .shadow/docs/product-docs-[timestamp]/ directory",
        "Architecture insights are saved to .shadow/insights/architecture-[timestamp]/ directory",
        "Analysis summaries are stored in timestamped run directories",
        "Each analysis run creates a new timestamped directory to preserve history",
        "Documentation is formatted and saved as markdown files organized by file path"
      ],
      "developerVisibleActions": [
        "Initialize product documentation runs to create storage directories",
        "Initialize architecture insights runs to create storage directories",
        "Save enhanced product documentation with markdown formatting",
        "Save architecture insights with metadata and analysis details",
        "Save analysis summaries with statistics and file counts",
        "Retrieve current run directories for ongoing analysis operations",
        "Reset run contexts when analysis completes or needs to restart",
        "Access formatted documentation through the documentation formatter"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Creates a new timestamped directory for storing product documentation results",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Creates a new timestamped directory for storing architecture insights results",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "saveProductDocs",
          "desc": "Persists enhanced product documentation to markdown files organized by file path",
          "inputs": "workspaceRoot: string, filePath: string, documentation: EnhancedProductDocumentation",
          "outputs": "void"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Persists architecture insights and analysis to JSON file with metadata",
          "inputs": "workspaceRoot: string, insights: LLMInsights",
          "outputs": "void"
        },
        {
          "name": "saveAnalysisSummary",
          "desc": "Saves analysis summary with file counts and statistics to timestamped storage",
          "inputs": "workspaceRoot: string, summary: object",
          "outputs": "void"
        },
        {
          "name": "getCurrentProductDocsRunDir",
          "desc": "Retrieves the current product documentation run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "getCurrentArchitectureInsightsRunDir",
          "desc": "Retrieves the current architecture insights run directory path",
          "inputs": "none",
          "outputs": "string | null"
        },
        {
          "name": "resetProductDocsRun",
          "desc": "Clears the current product documentation run context to allow new runs",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "resetArchitectureInsightsRun",
          "desc": "Clears the current architecture insights run context to allow new runs",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "fileDocumentation (EnhancedProductDocumentation)",
        "llmService (LLMInsights)",
        "domain/formatters/documentationFormatter",
        "storage/incrementalStorage"
      ],
      "intent": "Separates persistence concerns from AI analysis logic by providing a dedicated repository for storing analysis results in an organized, timestamped directory structure, enabling historical tracking of documentation and insights while keeping the file system operations isolated from the core analysis code.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages storage and retrieval of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory structure.\",\n  \"userVisibleActions\": [\n    \"Product documentation files are saved to .shadow/docs/product-docs-[timestamp]/ directory\",\n    \"Architecture insights are saved to .shadow/insights/architecture-[timestamp]/ directory\",\n    \"Analysis summaries are stored in timestamped run directories\",\n    \"Each analysis run creates a new timestamped directory to preserve history\",\n    \"Documentation is formatted and saved as markdown files organized by file path\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation runs to create storage directories\",\n    \"Initialize architecture insights runs to create storage directories\",\n    \"Save enhanced product documentation with markdown formatting\",\n    \"Save architecture insights with metadata and analysis details\",\n    \"Save analysis summaries with statistics and file counts\",\n    \"Retrieve current run directories for ongoing analysis operations\",\n    \"Reset run contexts when analysis completes or needs to restart\",\n    \"Access formatted documentation through the documentation formatter\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocs\",\n      \"desc\": \"Persists enhanced product documentation to markdown files organized by file path\",\n      \"inputs\": \"workspaceRoot: string, filePath: string, documentation: EnhancedProductDocumentation\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Persists architecture insights and analysis to JSON file with metadata\",\n      \"inputs\": \"workspaceRoot: string, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveAnalysisSummary\",\n      \"desc\": \"Saves analysis summary with file counts and statistics to timestamped storage\",\n      \"inputs\": \"workspaceRoot: string, summary: object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Retrieves the current product documentation run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Retrieves the current architecture insights run directory path\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product documentation run context to allow new runs\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context to allow new runs\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates persistence concerns from AI analysis logic by providing a dedicated repository for storing analysis results in an organized, timestamped directory structure, enabling historical tracking of documentation and insights while keeping the file system operations isolated from the core analysis code.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a centralized service for displaying progress notifications to users during long-running operations",
      "userVisibleActions": [
        "See progress notifications with titles and messages during operations",
        "Cancel ongoing operations if they are marked as cancellable",
        "View progress indicators in different locations (notification area, window, etc.)",
        "Track operation progress with incremental updates"
      ],
      "developerVisibleActions": [
        "Wrap any async operation with standardized progress reporting using withProgress method",
        "Pass either a simple string title or detailed options object for progress configuration",
        "Receive a ProgressReporter object to report incremental progress updates",
        "Control whether operations are cancellable and where progress is displayed",
        "Access cancellation token to check if user cancelled the operation"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying a progress notification to the user",
          "inputs": "options (title, cancellable flag, location) and async task function that receives a ProgressReporter",
          "outputs": "Promise that resolves to the task result"
        },
        {
          "name": "report (ProgressReporter)",
          "desc": "Updates the progress notification with a new message and optional increment value",
          "inputs": "message string and optional increment number",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This service exists to standardize and simplify progress reporting across the extension, reducing boilerplate code by wrapping VSCode's progress API with consistent defaults and a cleaner interface for developers to show operation progress to users",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for displaying progress notifications to users during long-running operations\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during operations\",\n    \"Cancel ongoing operations if they are marked as cancellable\",\n    \"View progress indicators in different locations (notification area, window, etc.)\",\n    \"Track operation progress with incremental updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any async operation with standardized progress reporting using withProgress method\",\n    \"Pass either a simple string title or detailed options object for progress configuration\",\n    \"Receive a ProgressReporter object to report incremental progress updates\",\n    \"Control whether operations are cancellable and where progress is displayed\",\n    \"Access cancellation token to check if user cancelled the operation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location) and async task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise that resolves to the task result\"\n    },\n    {\n      \"name\": \"report (ProgressReporter)\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment value\",\n      \"inputs\": \"message string and optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This service exists to standardize and simplify progress reporting across the extension, reducing boilerplate code by wrapping VSCode's progress API with consistent defaults and a cleaner interface for developers to show operation progress to users\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Generates actionable code quality insights and recommendations by analyzing code structure, complexity, and organization patterns.",
      "userVisibleActions": [
        "Receives warnings about files that are too large (over 500 lines)",
        "Gets alerts about orphaned files that aren't imported anywhere",
        "Sees suggestions to split large files into smaller modules",
        "Receives notifications about missing entry points in the project",
        "Gets warnings about potential circular dependencies between files",
        "Sees alerts about 'god objects' (files with too many responsibilities)",
        "Receives suggestions about dead code that may be unused",
        "Gets recommendations for better file organization",
        "Sees warnings about overly complex functions",
        "Views insights categorized by severity (error, warning, info)",
        "Reads specific suggestions with file paths and line numbers for each issue"
      ],
      "developerVisibleActions": [
        "Pass CodeAnalysis object to generate comprehensive insights across entire codebase",
        "Generate file-specific insights by providing analysis and file path",
        "Receive structured Insight objects with id, title, description, severity, category, file location, and actionable suggestions",
        "Access insights filtered by severity levels (error, warning, info)",
        "Use insights to identify code smells and architectural issues",
        "Get code snippets attached to relevant insights for context",
        "Integrate insights into code review workflows",
        "Track technical debt through categorized insight reports"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Analyzes entire codebase and produces a comprehensive list of code quality insights covering multiple categories",
          "inputs": "CodeAnalysis object containing file and function information",
          "outputs": "Array of Insight objects with recommendations"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Generates targeted insights for a specific file in the codebase",
          "inputs": "CodeAnalysis object and file path string",
          "outputs": "Array of Insight objects specific to that file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Identifies files exceeding recommended line count threshold",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about oversized files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Detects files that are not imported by any other file in the project",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about potentially unused files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Validates presence of required entry points in the project",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Identifies potential circular dependency patterns between files",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about circular dependencies"
        },
        {
          "name": "checkGodObjects",
          "desc": "Detects files with too many responsibilities or excessive complexity",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about god objects"
        },
        {
          "name": "checkDeadCode",
          "desc": "Identifies code that appears to be unused or unreachable",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about potential dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Evaluates project structure and file organization patterns",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about file organization"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Analyzes function complexity metrics to identify overly complex code",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about function complexity"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to transform raw code analysis data into meaningful, actionable recommendations that help developers improve code quality, maintainability, and architecture by identifying anti-patterns, code smells, and organizational issues.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates actionable code quality insights and recommendations by analyzing code structure, complexity, and organization patterns.\",\n  \"userVisibleActions\": [\n    \"Receives warnings about files that are too large (over 500 lines)\",\n    \"Gets alerts about orphaned files that aren't imported anywhere\",\n    \"Sees suggestions to split large files into smaller modules\",\n    \"Receives notifications about missing entry points in the project\",\n    \"Gets warnings about potential circular dependencies between files\",\n    \"Sees alerts about 'god objects' (files with too many responsibilities)\",\n    \"Receives suggestions about dead code that may be unused\",\n    \"Gets recommendations for better file organization\",\n    \"Sees warnings about overly complex functions\",\n    \"Views insights categorized by severity (error, warning, info)\",\n    \"Reads specific suggestions with file paths and line numbers for each issue\"\n  ],\n  \"developerVisibleActions\": [\n    \"Pass CodeAnalysis object to generate comprehensive insights across entire codebase\",\n    \"Generate file-specific insights by providing analysis and file path\",\n    \"Receive structured Insight objects with id, title, description, severity, category, file location, and actionable suggestions\",\n    \"Access insights filtered by severity levels (error, warning, info)\",\n    \"Use insights to identify code smells and architectural issues\",\n    \"Get code snippets attached to relevant insights for context\",\n    \"Integrate insights into code review workflows\",\n    \"Track technical debt through categorized insight reports\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and produces a comprehensive list of code quality insights covering multiple categories\",\n      \"inputs\": \"CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects with recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates targeted insights for a specific file in the codebase\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects specific to that file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count threshold\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Detects files that are not imported by any other file in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about potentially unused files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Validates presence of required entry points in the project\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Identifies potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Detects files with too many responsibilities or excessive complexity\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about god objects\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Identifies code that appears to be unused or unreachable\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about potential dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates project structure and file organization patterns\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about file organization\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity metrics to identify overly complex code\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about function complexity\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into meaningful, actionable recommendations that help developers improve code quality, maintainability, and architecture by identifying anti-patterns, code smells, and organizational issues.\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view GUI in VS Code that displays AI-generated insights, documentation, reports, and analysis results for the codebase",
      "userVisibleActions": [
        "View a tree structure showing code insights, documentation status, and analysis reports",
        "Click on 'Product Documentation' node to see documentation generation status and access generated docs",
        "Click on 'AI Insights' node to view AI-generated insights about the codebase",
        "Click on 'Unit Test Analysis' node to see test coverage and recommendations",
        "Click on 'Static Analysis' node to view code quality analysis results",
        "Open generated reports (Workspace Report, Product Documentation Report, Architecture Report, Unit Test Report) by clicking on them",
        "Refresh the tree view to update all insights and reports",
        "See timestamp labels showing when each analysis was last generated",
        "View status indicators (idle, generating, complete) for various analysis tasks",
        "Expand/collapse sections to navigate through different types of insights",
        "See individual insight items with titles, descriptions, and severity indicators"
      ],
      "developerVisibleActions": [
        "Tree view updates automatically when new insights are generated",
        "Persisted state maintains report paths and timestamps across VS Code sessions",
        "Integration with LLM service for AI-generated insights and analysis",
        "Tree items show icons and context values for command registration",
        "Report files are created in workspace .code-insights directory",
        "Tree provider fires change events to refresh the view when data updates",
        "Supports multiple report types: workspace, product docs, architecture, and unit tests",
        "Status tracking for asynchronous generation processes (idle/generating/complete)",
        "File system checks validate report existence before displaying in tree"
      ],
      "keyFunctions": [
        {
          "name": "getTreeItem",
          "desc": "Returns the visual representation of a tree node",
          "inputs": "element: TreeItem",
          "outputs": "TreeItem or Promise<TreeItem>"
        },
        {
          "name": "getChildren",
          "desc": "Returns child nodes for a given tree element to build the tree structure",
          "inputs": "element?: TreeItem",
          "outputs": "Promise<TreeItem[]>"
        },
        {
          "name": "updateInsights",
          "desc": "Updates the displayed insights list and refreshes the tree view",
          "inputs": "insights: Insight[]",
          "outputs": "void"
        },
        {
          "name": "updateLLMInsights",
          "desc": "Updates AI-generated insights and their generation status",
          "inputs": "llmInsights: LLMInsights | null, status: 'idle' | 'generating' | 'complete'",
          "outputs": "void"
        },
        {
          "name": "setReportPath",
          "desc": "Sets the file path for a generated report and updates the tree",
          "inputs": "reportPath: string | null",
          "outputs": "void"
        },
        {
          "name": "setProductDocsStatus",
          "desc": "Updates the status of product documentation generation",
          "inputs": "status: 'idle' | 'generating' | 'complete'",
          "outputs": "void"
        },
        {
          "name": "setAnalysisStatus",
          "desc": "Updates the status of static analysis completion",
          "inputs": "status: 'idle' | 'complete'",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a full refresh of the tree view display",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "loadPersistedState",
          "desc": "Loads previously saved report paths and timestamps from workspace storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "persistState",
          "desc": "Saves current report paths and timestamps to workspace storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "createRootItems",
          "desc": "Creates the top-level tree nodes (Product Docs, AI Insights, Unit Tests, Analysis)",
          "inputs": "none",
          "outputs": "TreeItem[]"
        },
        {
          "name": "createProductDocsChildren",
          "desc": "Creates child nodes showing product documentation status and reports",
          "inputs": "none",
          "outputs": "Promise<TreeItem[]>"
        },
        {
          "name": "createInsightsChildren",
          "desc": "Creates child nodes showing AI insights and workspace reports",
          "inputs": "none",
          "outputs": "Promise<TreeItem[]>"
        },
        {
          "name": "createUnitTestChildren",
          "desc": "Creates child nodes showing unit test analysis results",
          "inputs": "none",
          "outputs": "Promise<TreeItem[]>"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator",
        "./llmFormatter",
        "./llmService"
      ],
      "intent": "This file exists to provide a visual, hierarchical interface in VS Code's sidebar for users to access and navigate through various AI-generated code insights, documentation, test analysis, and reports. It solves the problem of organizing and presenting multiple types of code analysis results in an easily accessible tree structure with persistent state and real-time status updates.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view GUI in VS Code that displays AI-generated insights, documentation, reports, and analysis results for the codebase\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code insights, documentation status, and analysis reports\",\n    \"Click on 'Product Documentation' node to see documentation generation status and access generated docs\",\n    \"Click on 'AI Insights' node to view AI-generated insights about the codebase\",\n    \"Click on 'Unit Test Analysis' node to see test coverage and recommendations\",\n    \"Click on 'Static Analysis' node to view code quality analysis results\",\n    \"Open generated reports (Workspace Report, Product Documentation Report, Architecture Report, Unit Test Report) by clicking on them\",\n    \"Refresh the tree view to update all insights and reports\",\n    \"See timestamp labels showing when each analysis was last generated\",\n    \"View status indicators (idle, generating, complete) for various analysis tasks\",\n    \"Expand/collapse sections to navigate through different types of insights\",\n    \"See individual insight items with titles, descriptions, and severity indicators\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view updates automatically when new insights are generated\",\n    \"Persisted state maintains report paths and timestamps across VS Code sessions\",\n    \"Integration with LLM service for AI-generated insights and analysis\",\n    \"Tree items show icons and context values for command registration\",\n    \"Report files are created in workspace .code-insights directory\",\n    \"Tree provider fires change events to refresh the view when data updates\",\n    \"Supports multiple report types: workspace, product docs, architecture, and unit tests\",\n    \"Status tracking for asynchronous generation processes (idle/generating/complete)\",\n    \"File system checks validate report existence before displaying in tree\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the visual representation of a tree node\",\n      \"inputs\": \"element: TreeItem\",\n      \"outputs\": \"TreeItem or Promise<TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child nodes for a given tree element to build the tree structure\",\n      \"inputs\": \"element?: TreeItem\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights list and refreshes the tree view\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"updateLLMInsights\",\n      \"desc\": \"Updates AI-generated insights and their generation status\",\n      \"inputs\": \"llmInsights: LLMInsights | null, status: 'idle' | 'generating' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report and updates the tree\",\n      \"inputs\": \"reportPath: string | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the status of product documentation generation\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the status of static analysis completion\",\n      \"inputs\": \"status: 'idle' | 'complete'\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a full refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Loads previously saved report paths and timestamps from workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"persistState\",\n      \"desc\": \"Saves current report paths and timestamps to workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"createRootItems\",\n      \"desc\": \"Creates the top-level tree nodes (Product Docs, AI Insights, Unit Tests, Analysis)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"TreeItem[]\"\n    },\n    {\n      \"name\": \"createProductDocsChildren\",\n      \"desc\": \"Creates child nodes showing product documentation status and reports\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"createInsightsChildren\",\n      \"desc\": \"Creates child nodes showing AI insights and workspace reports\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    },\n    {\n      \"name\": \"createUnitTestChildren\",\n      \"desc\": \"Creates child nodes showing unit test analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<TreeItem[]>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual, hierarchical interface in VS Code's sidebar for users to access and navigate through various AI-generated code insights, documentation, test analysis, and reports. It solves the problem of organizing and presenting multiple types of code analysis results in an easily accessible tree structure with persistent state and real-time status updates.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VS Code to browse and navigate AI-generated architecture insights about the codebase",
      "userVisibleActions": [
        "View hierarchical tree of architecture insights in the sidebar",
        "Click on insights to navigate to corresponding files",
        "See architecture insights organized by file and section",
        "View documentation insights with descriptions",
        "Click on file items to open files in the editor",
        "Expand/collapse insight categories",
        "View insights automatically updated when files change",
        "See 'No insights available' message when no data exists"
      ],
      "developerVisibleActions": [
        "Tree view automatically refreshes when insights files are modified",
        "Insights are loaded from .shadow/insights.json file",
        "Purpose documentation loaded from .shadow/docs/purpose.json",
        "File system watchers monitor changes to insights and purpose files",
        "Tree view provides navigation to source files via file paths",
        "Insights are structured with parent-child relationships",
        "Can programmatically trigger tree refresh via refresh() method",
        "Supports collapsible tree items with different states"
      ],
      "keyFunctions": [
        {
          "name": "setInsights",
          "desc": "Updates the insights data and refreshes the tree view",
          "inputs": "LLMInsights object containing architecture insights",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a refresh of the tree view display",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the tree item representation for display in VS Code",
          "inputs": "InsightItem",
          "outputs": "vscode.TreeItem or Promise<vscode.TreeItem>"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given parent in the tree hierarchy",
          "inputs": "Optional InsightItem parent",
          "outputs": "Promise<InsightItem[]>"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Establishes file system watchers to auto-refresh when insights change",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file watchers and resources when view is closed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "llmService",
        "path",
        "fs",
        "fileWatcherService"
      ],
      "intent": "This file exists to provide a user-friendly tree view interface for browsing AI-generated architecture insights, making it easy to explore documentation about code structure, file purposes, and architectural decisions directly within VS Code's sidebar with automatic updates when insights change.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code to browse and navigate AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View hierarchical tree of architecture insights in the sidebar\",\n    \"Click on insights to navigate to corresponding files\",\n    \"See architecture insights organized by file and section\",\n    \"View documentation insights with descriptions\",\n    \"Click on file items to open files in the editor\",\n    \"Expand/collapse insight categories\",\n    \"View insights automatically updated when files change\",\n    \"See 'No insights available' message when no data exists\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when insights files are modified\",\n    \"Insights are loaded from .shadow/insights.json file\",\n    \"Purpose documentation loaded from .shadow/docs/purpose.json\",\n    \"File system watchers monitor changes to insights and purpose files\",\n    \"Tree view provides navigation to source files via file paths\",\n    \"Insights are structured with parent-child relationships\",\n    \"Can programmatically trigger tree refresh via refresh() method\",\n    \"Supports collapsible tree items with different states\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data and refreshes the tree view\",\n      \"inputs\": \"LLMInsights object containing architecture insights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the tree view display\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for display in VS Code\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"vscode.TreeItem or Promise<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given parent in the tree hierarchy\",\n      \"inputs\": \"Optional InsightItem parent\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Establishes file system watchers to auto-refresh when insights change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and resources when view is closed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmService\",\n    \"path\",\n    \"fs\",\n    \"fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide a user-friendly tree view interface for browsing AI-generated architecture insights, making it easy to explore documentation about code structure, file purposes, and architectural decisions directly within VS Code's sidebar with automatic updates when insights change.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different output formats optimized for various AI assistants and human readers.",
      "userVisibleActions": [
        "View architecture issues grouped by severity (Critical/Warnings/Informational)",
        "See issues formatted specifically for Cursor AI with actionable prompts",
        "See issues formatted for ChatGPT with structured analysis sections",
        "View compact summaries of issues by category",
        "Read generic formatted reports with detailed issue breakdowns",
        "See formatted suggestions asking for prioritization and refactoring help",
        "View architecture violations with file locations and suggested fixes"
      ],
      "developerVisibleActions": [
        "Choose between 4 output formats: cursor, chatgpt, compact, or generic",
        "Call formatInsights() with insights array and format preference",
        "Receive markdown-formatted output ready for AI assistant consumption",
        "Get insights automatically grouped by severity levels",
        "Obtain structured reports with severity indicators (, , )",
        "Generate format-specific prompts that guide AI assistant responses",
        "Produce outputs optimized for different AI assistant conversation styles"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Main entry point that routes insights to the appropriate formatter based on specified format",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "string - formatted markdown text"
        },
        {
          "name": "formatForCursor",
          "desc": "Formats insights optimized for Cursor AI with severity grouping and actionable prompts",
          "inputs": "insights: Insight[]",
          "outputs": "string - Cursor-optimized markdown"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Formats insights for ChatGPT with structured sections and conversation-style prompts",
          "inputs": "insights: Insight[]",
          "outputs": "string - ChatGPT-optimized markdown"
        },
        {
          "name": "formatCompact",
          "desc": "Creates a condensed summary of issues grouped by category without detailed formatting",
          "inputs": "insights: Insight[]",
          "outputs": "string - compact markdown summary"
        },
        {
          "name": "formatGeneric",
          "desc": "Produces a standard detailed report suitable for any AI assistant or human reader",
          "inputs": "insights: Insight[]",
          "outputs": "string - generic formatted markdown"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats individual insight with file location, description, and suggested action",
          "inputs": "insight: Insight",
          "outputs": "string - formatted insight block"
        },
        {
          "name": "formatInsightForChatGPT",
          "desc": "Formats individual insight with numbered structure and conversational tone",
          "inputs": "insight: Insight",
          "outputs": "string - formatted insight block"
        },
        {
          "name": "formatInsightCompact",
          "desc": "Formats individual insight as a single line with essential information",
          "inputs": "insight: Insight",
          "outputs": "string - one-line insight summary"
        },
        {
          "name": "formatInsightGeneric",
          "desc": "Formats individual insight with all details in a standard structure",
          "inputs": "insight: Insight",
          "outputs": "string - formatted insight block"
        }
      ],
      "dependencies": [
        "./insightGenerator (Insight type)"
      ],
      "intent": "Transforms raw code analysis insights into AI assistant-specific formats that maximize the effectiveness of automated code improvement suggestions by tailoring the presentation style to each AI's conversation patterns and capabilities.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output formats optimized for various AI assistants and human readers.\",\n  \"userVisibleActions\": [\n    \"View architecture issues grouped by severity (Critical/Warnings/Informational)\",\n    \"See issues formatted specifically for Cursor AI with actionable prompts\",\n    \"See issues formatted for ChatGPT with structured analysis sections\",\n    \"View compact summaries of issues by category\",\n    \"Read generic formatted reports with detailed issue breakdowns\",\n    \"See formatted suggestions asking for prioritization and refactoring help\",\n    \"View architecture violations with file locations and suggested fixes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Choose between 4 output formats: cursor, chatgpt, compact, or generic\",\n    \"Call formatInsights() with insights array and format preference\",\n    \"Receive markdown-formatted output ready for AI assistant consumption\",\n    \"Get insights automatically grouped by severity levels\",\n    \"Obtain structured reports with severity indicators (, , )\",\n    \"Generate format-specific prompts that guide AI assistant responses\",\n    \"Produce outputs optimized for different AI assistant conversation styles\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Main entry point that routes insights to the appropriate formatter based on specified format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"string - formatted markdown text\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Formats insights optimized for Cursor AI with severity grouping and actionable prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - Cursor-optimized markdown\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Formats insights for ChatGPT with structured sections and conversation-style prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - ChatGPT-optimized markdown\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates a condensed summary of issues grouped by category without detailed formatting\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - compact markdown summary\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Produces a standard detailed report suitable for any AI assistant or human reader\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"string - generic formatted markdown\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file location, description, and suggested action\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats individual insight with numbered structure and conversational tone\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats individual insight as a single line with essential information\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - one-line insight summary\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats individual insight with all details in a standard structure\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"string - formatted insight block\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator (Insight type)\"\n  ],\n  \"intent\": \"Transforms raw code analysis insights into AI assistant-specific formats that maximize the effectiveness of automated code improvement suggestions by tailoring the presentation style to each AI's conversation patterns and capabilities.\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Integrates LLM-powered analysis features into the VS Code extension, coordinating code analysis, documentation generation, and insights display.",
      "userVisibleActions": [
        "Generates AI-powered insights about codebase structure and behavior",
        "Creates comprehensive product documentation from code analysis",
        "Displays code analysis results in tree views and panels",
        "Shows entry points and navigation structure of the project",
        "Presents unit test coverage and organization",
        "Provides interactive insights viewer with AI-generated explanations",
        "Updates and refreshes documentation when code changes",
        "Shows status of analysis and documentation generation in output panel"
      ],
      "developerVisibleActions": [
        "Initialize LLM service with API key configuration",
        "Trigger code analysis on workspace or specific files",
        "Generate documentation for entire product or individual files",
        "Regenerate insights when code or analysis changes",
        "Access saved analysis results and cached documentation",
        "Configure LLM provider and model settings",
        "View logs and debug information in output channel",
        "Manage state of analysis, documentation, and insights across sessions",
        "Export and import analysis contexts for persistence"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Sets up the LLM service and registers configuration change listeners",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "generateInsights",
          "desc": "Generates AI-powered insights from code analysis context",
          "inputs": "AnalysisContext",
          "outputs": "Promise<LLMInsights>"
        },
        {
          "name": "generateDocumentation",
          "desc": "Creates comprehensive product documentation from analysis results",
          "inputs": "CodeAnalysis, workspace path",
          "outputs": "Promise<EnhancedProductDocumentation>"
        },
        {
          "name": "analyzeCode",
          "desc": "Performs code analysis on workspace or specific files",
          "inputs": "workspace path or file paths",
          "outputs": "Promise<CodeAnalysis>"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to storage",
          "inputs": "CodeAnalysis, workspace path",
          "outputs": "Promise<void>"
        },
        {
          "name": "loadSavedCodeAnalysis",
          "desc": "Retrieves previously saved code analysis from storage",
          "inputs": "workspace path",
          "outputs": "Promise<CodeAnalysis | null>"
        },
        {
          "name": "refreshViews",
          "desc": "Updates all tree views and panels with latest data",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms code analysis results into LLM-compatible context format",
          "inputs": "CodeAnalysis",
          "outputs": "AnalysisContext"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "./llmService",
        "./insightsTreeView",
        "./fileDocumentation",
        "./analyzer",
        "./productNavigator",
        "./analysisViewer",
        "./insightsViewer",
        "./unitTestsNavigator",
        "./logger",
        "./state/llmStateManager",
        "./context/analysisContextBuilder",
        "./domain/formatters/documentationFormatter",
        "./infrastructure/persistence/analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis and AI-powered features, orchestrating the flow from code scanning to insight generation to user-facing documentation and visualizations. It solves the problem of coordinating multiple complex operations (analysis, LLM processing, state management, UI updates) into a cohesive system that helps developers understand their codebase through AI assistance.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered analysis features into the VS Code extension, coordinating code analysis, documentation generation, and insights display.\",\n  \"userVisibleActions\": [\n    \"Generates AI-powered insights about codebase structure and behavior\",\n    \"Creates comprehensive product documentation from code analysis\",\n    \"Displays code analysis results in tree views and panels\",\n    \"Shows entry points and navigation structure of the project\",\n    \"Presents unit test coverage and organization\",\n    \"Provides interactive insights viewer with AI-generated explanations\",\n    \"Updates and refreshes documentation when code changes\",\n    \"Shows status of analysis and documentation generation in output panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service with API key configuration\",\n    \"Trigger code analysis on workspace or specific files\",\n    \"Generate documentation for entire product or individual files\",\n    \"Regenerate insights when code or analysis changes\",\n    \"Access saved analysis results and cached documentation\",\n    \"Configure LLM provider and model settings\",\n    \"View logs and debug information in output channel\",\n    \"Manage state of analysis, documentation, and insights across sessions\",\n    \"Export and import analysis contexts for persistence\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service and registers configuration change listeners\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates AI-powered insights from code analysis context\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Promise<LLMInsights>\"\n    },\n    {\n      \"name\": \"generateDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation from analysis results\",\n      \"inputs\": \"CodeAnalysis, workspace path\",\n      \"outputs\": \"Promise<EnhancedProductDocumentation>\"\n    },\n    {\n      \"name\": \"analyzeCode\",\n      \"desc\": \"Performs code analysis on workspace or specific files\",\n      \"inputs\": \"workspace path or file paths\",\n      \"outputs\": \"Promise<CodeAnalysis>\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to storage\",\n      \"inputs\": \"CodeAnalysis, workspace path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved code analysis from storage\",\n      \"inputs\": \"workspace path\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"refreshViews\",\n      \"desc\": \"Updates all tree views and panels with latest data\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis results into LLM-compatible context format\",\n      \"inputs\": \"CodeAnalysis\",\n      \"outputs\": \"AnalysisContext\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and AI-powered features, orchestrating the flow from code scanning to insight generation to user-facing documentation and visualizations. It solves the problem of coordinating multiple complex operations (analysis, LLM processing, state management, UI updates) into a cohesive system that helps developers understand their codebase through AI assistance.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure and validate AI-generated responses for code analysis tasks, ensuring consistent, parseable outputs without manual parsing.",
      "userVisibleActions": [
        "Receives structured product purpose analysis with clear sections for goals, architecture reasoning, and design decisions",
        "Gets organized issue reports with clear titles, descriptions, relevant files, and severity levels",
        "Views categorized code analysis results separated into user-facing vs developer-facing behavior",
        "Sees detailed function documentation with inputs, outputs, and behavioral descriptions",
        "Receives file classifications (Core Logic, Configuration, Testing, etc.) with clear purpose statements"
      ],
      "developerVisibleActions": [
        "Uses predefined schemas to request structured AI analysis of codebases",
        "Receives guaranteed valid JSON responses from Claude API without parsing errors",
        "Gets code behavior extracted as user-facing actions and developer-facing actions separately",
        "Obtains dependency lists and relationship mappings between files",
        "Receives categorized issues (Architecture, Documentation, Code Quality, etc.) with severity ratings",
        "Gets function signatures extracted with behavioral descriptions instead of implementation details"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to enforce consistent structure in AI-generated code analysis responses. It solves the problem of unreliable, unparseable AI outputs by defining strict JSON schemas that guarantee valid, structured data for product purpose analysis, issue detection, code behavior extraction, and documentation generation. It ensures the AI focuses on WHAT code does (user/developer perspective) rather than HOW it's implemented.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate AI-generated responses for code analysis tasks, ensuring consistent, parseable outputs without manual parsing.\",\n  \"userVisibleActions\": [\n    \"Receives structured product purpose analysis with clear sections for goals, architecture reasoning, and design decisions\",\n    \"Gets organized issue reports with clear titles, descriptions, relevant files, and severity levels\",\n    \"Views categorized code analysis results separated into user-facing vs developer-facing behavior\",\n    \"Sees detailed function documentation with inputs, outputs, and behavioral descriptions\",\n    \"Receives file classifications (Core Logic, Configuration, Testing, etc.) with clear purpose statements\"\n  ],\n  \"developerVisibleActions\": [\n    \"Uses predefined schemas to request structured AI analysis of codebases\",\n    \"Receives guaranteed valid JSON responses from Claude API without parsing errors\",\n    \"Gets code behavior extracted as user-facing actions and developer-facing actions separately\",\n    \"Obtains dependency lists and relationship mappings between files\",\n    \"Receives categorized issues (Architecture, Documentation, Code Quality, etc.) with severity ratings\",\n    \"Gets function signatures extracted with behavioral descriptions instead of implementation details\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to enforce consistent structure in AI-generated code analysis responses. It solves the problem of unreliable, unparseable AI outputs by defining strict JSON schemas that guarantee valid, structured data for product purpose analysis, issue detection, code behavior extraction, and documentation generation. It ensures the AI focuses on WHAT code does (user/developer perspective) rather than HOW it's implemented.\"\n}\n```"
    },
    {
      "file": "src/llmService.ts",
      "role": "Core Logic",
      "purpose": "Provides AI-powered code analysis services by coordinating with OpenAI/Claude to generate intelligent insights about code purpose, architecture, refactoring suggestions, and test plans.",
      "userVisibleActions": [
        "Generates explanations of what the codebase does and why it was built",
        "Provides intelligent refactoring suggestions for improving code quality",
        "Creates test plans showing what should be tested and why",
        "Explains the purpose and architecture of the entire product",
        "Generates comprehensive product documentation from code analysis",
        "Analyzes code complexity and suggests improvements",
        "Explains relationships between files and modules"
      ],
      "developerVisibleActions": [
        "Call AI service to analyze codebase and get product purpose analysis",
        "Request refactoring suggestions for specific functions or files",
        "Generate unit test plans based on code analysis",
        "Get insights about code quality, architecture patterns, and improvements",
        "Analyze file summaries to understand module structure",
        "Retrieve enhanced product documentation with AI-generated insights",
        "Process incremental analysis updates as code changes",
        "Configure which AI provider to use (OpenAI, Claude, or Gemini)",
        "Set custom API endpoints and model preferences",
        "Handle rate limiting and retry logic for AI requests automatically"
      ],
      "keyFunctions": [
        {
          "name": "analyzeProductPurpose",
          "desc": "Analyzes the entire codebase to determine what the product does and why it exists",
          "inputs": "context (file structure, imports, entry points), codeAnalysis (detailed code metrics)",
          "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, key features, and design decisions"
        },
        {
          "name": "generateProductDocumentation",
          "desc": "Creates comprehensive product documentation using AI analysis of code structure and patterns",
          "inputs": "fileSummaries (per-file analysis), moduleSummaries (module-level groupings), productPurpose (high-level purpose)",
          "outputs": "EnhancedProductDocumentation with overview, architecture, modules, features, and technical details"
        },
        {
          "name": "generateRefactoringSuggestion",
          "desc": "Provides AI-generated suggestions for improving code quality and structure",
          "inputs": "fileInfo (file metadata), functionMetadata (function details), codeContent (actual code)",
          "outputs": "Refactoring suggestions with severity, description, benefits, and implementation steps"
        },
        {
          "name": "generateUnitTestPlan",
          "desc": "Creates a test plan showing what should be tested and why based on code analysis",
          "inputs": "fileInfo, functionMetadata, codeContent, and existing test files",
          "outputs": "UnitTestPlan with test strategies, scenarios, coverage recommendations, and priority areas"
        },
        {
          "name": "getInsights",
          "desc": "Generates intelligent insights about code quality, patterns, and improvements",
          "inputs": "context (codebase structure), codeAnalysis (metrics), configuration (settings)",
          "outputs": "Array of insights categorized by type with descriptions and actionable recommendations"
        },
        {
          "name": "analyzeIncrementally",
          "desc": "Performs incremental analysis on changed files to provide fast, targeted insights",
          "inputs": "changedFiles (list of modified files), existingAnalysis (previous results)",
          "outputs": "Updated analysis results focusing only on changes"
        },
        {
          "name": "callLLM",
          "desc": "Internal method that handles communication with AI providers (OpenAI, Claude, Gemini)",
          "inputs": "prompt (question/task), schema (expected response format), options (provider settings)",
          "outputs": "AI-generated response parsed according to schema"
        }
      ],
      "dependencies": [
        "vscode",
        "./fileDocumentation",
        "./analyzer",
        "./analysis/enhancedAnalyzer",
        "./llmSchemas",
        "./fileAccessHelper",
        "./logger",
        "./config/configurationManager",
        "./ai/providers/providerFactory",
        "./ai/llmResponseParser",
        "./ai/llmRateLimiter",
        "./ai/llmRetryHandler",
        "./domain/prompts/promptBuilder",
        "./domain/services/incrementalAnalysisService",
        "./domain/prompts/refactoringPromptBuilder",
        "./analysis/functionAnalyzer"
      ],
      "intent": "This file exists to bridge the gap between static code analysis and intelligent insights by leveraging AI language models. It solves the problem of understanding large codebases by providing human-readable explanations of code purpose, architecture decisions, quality issues, and improvement opportunities. It abstracts away the complexity of working with multiple AI providers and handles concerns like rate limiting, retries, and response parsing, allowing the extension to provide consistent AI-powered features regardless of which provider the user chooses.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis services by coordinating with OpenAI/Claude to generate intelligent insights about code purpose, architecture, refactoring suggestions, and test plans.\",\n  \"userVisibleActions\": [\n    \"Generates explanations of what the codebase does and why it was built\",\n    \"Provides intelligent refactoring suggestions for improving code quality\",\n    \"Creates test plans showing what should be tested and why\",\n    \"Explains the purpose and architecture of the entire product\",\n    \"Generates comprehensive product documentation from code analysis\",\n    \"Analyzes code complexity and suggests improvements\",\n    \"Explains relationships between files and modules\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call AI service to analyze codebase and get product purpose analysis\",\n    \"Request refactoring suggestions for specific functions or files\",\n    \"Generate unit test plans based on code analysis\",\n    \"Get insights about code quality, architecture patterns, and improvements\",\n    \"Analyze file summaries to understand module structure\",\n    \"Retrieve enhanced product documentation with AI-generated insights\",\n    \"Process incremental analysis updates as code changes\",\n    \"Configure which AI provider to use (OpenAI, Claude, or Gemini)\",\n    \"Set custom API endpoints and model preferences\",\n    \"Handle rate limiting and retry logic for AI requests automatically\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine what the product does and why it exists\",\n      \"inputs\": \"context (file structure, imports, entry points), codeAnalysis (detailed code metrics)\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, key features, and design decisions\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation using AI analysis of code structure and patterns\",\n      \"inputs\": \"fileSummaries (per-file analysis), moduleSummaries (module-level groupings), productPurpose (high-level purpose)\",\n      \"outputs\": \"EnhancedProductDocumentation with overview, architecture, modules, features, and technical details\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestion\",\n      \"desc\": \"Provides AI-generated suggestions for improving code quality and structure\",\n      \"inputs\": \"fileInfo (file metadata), functionMetadata (function details), codeContent (actual code)\",\n      \"outputs\": \"Refactoring suggestions with severity, description, benefits, and implementation steps\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a test plan showing what should be tested and why based on code analysis\",\n      \"inputs\": \"fileInfo, functionMetadata, codeContent, and existing test files\",\n      \"outputs\": \"UnitTestPlan with test strategies, scenarios, coverage recommendations, and priority areas\"\n    },\n    {\n      \"name\": \"getInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and improvements\",\n      \"inputs\": \"context (codebase structure), codeAnalysis (metrics), configuration (settings)\",\n      \"outputs\": \"Array of insights categorized by type with descriptions and actionable recommendations\"\n    },\n    {\n      \"name\": \"analyzeIncrementally\",\n      \"desc\": \"Performs incremental analysis on changed files to provide fast, targeted insights\",\n      \"inputs\": \"changedFiles (list of modified files), existingAnalysis (previous results)\",\n      \"outputs\": \"Updated analysis results focusing only on changes\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Internal method that handles communication with AI providers (OpenAI, Claude, Gemini)\",\n      \"inputs\": \"prompt (question/task), schema (expected response format), options (provider settings)\",\n      \"outputs\": \"AI-generated response parsed according to schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between static code analysis and intelligent insights by leveraging AI language models. It solves the problem of understanding large codebases by providing human-readable explanations of code purpose, architecture decisions, quality issues, and improvement opportunities. It abstracts away the complexity of working with multiple AI providers and handles concerns like rate limiting, retries, and response parsing, allowing the extension to provide consistent AI-powered features regardless of which provider the user chooses.\"\n}\n```"
    },
    {
      "file": "src/logger.ts",
      "role": "Core Logic",
      "purpose": "Provides logging functionality to write timestamped messages to a log file in the workspace's .shadow/logs directory",
      "userVisibleActions": [
        "Log files are created in the .shadow/logs directory at the workspace root",
        "A shadow-watch.log file contains timestamped entries of extension activity",
        "Log entries show timestamps in ISO format for tracking when events occurred"
      ],
      "developerVisibleActions": [
        "Developers can call SWLogger.log() to write timestamped messages to the log file",
        "Developers can call SWLogger.section() to create visual section separators in the log",
        "Log messages automatically include ISO timestamp prefixes",
        "Logging failures are silently ignored (best-effort) to prevent extension crashes"
      ],
      "keyFunctions": [
        {
          "name": "log",
          "desc": "Writes a timestamped message to the shadow-watch.log file",
          "inputs": "message: string - The text to log",
          "outputs": "void - No return value"
        },
        {
          "name": "section",
          "desc": "Creates a visual section separator in the log with a title",
          "inputs": "title: string - The section title to display",
          "outputs": "void - No return value"
        },
        {
          "name": "getLogPath",
          "desc": "Determines the file path for the log file in the workspace",
          "inputs": "None",
          "outputs": "string | null - Path to log file or null if no workspace is open"
        },
        {
          "name": "ensureDir",
          "desc": "Creates a directory if it doesn't exist",
          "inputs": "dir: string - Directory path to create",
          "outputs": "void - No return value"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "vscode"
      ],
      "intent": "This file exists to provide centralized, timestamped logging for the Shadow Watch extension, allowing developers to track extension behavior and debug issues by writing activity to a persistent log file in the workspace",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality to write timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are created in the .shadow/logs directory at the workspace root\",\n    \"A shadow-watch.log file contains timestamped entries of extension activity\",\n    \"Log entries show timestamps in ISO format for tracking when events occurred\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can call SWLogger.log() to write timestamped messages to the log file\",\n    \"Developers can call SWLogger.section() to create visual section separators in the log\",\n    \"Log messages automatically include ISO timestamp prefixes\",\n    \"Logging failures are silently ignored (best-effort) to prevent extension crashes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - The text to log\",\n      \"outputs\": \"void - No return value\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a visual section separator in the log with a title\",\n      \"inputs\": \"title: string - The section title to display\",\n      \"outputs\": \"void - No return value\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the file path for the log file in the workspace\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string | null - Path to log file or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory if it doesn't exist\",\n      \"inputs\": \"dir: string - Directory path to create\",\n      \"outputs\": \"void - No return value\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide centralized, timestamped logging for the Shadow Watch extension, allowing developers to track extension behavior and debug issues by writing activity to a persistent log file in the workspace\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is an AI-powered VS Code extension that automatically analyzes codebases to generate human-readable documentation, architectural insights, and actionable code quality recommendations. Users interact with the extension through integrated sidebar panels that display code analysis results, quality metrics, test coverage information, and AI-generated documentation. The extension continuously monitors workspace files and updates its analysis when code changes, providing developers with real-time insights into code structure, complexity, dependencies, and potential issues.\\n\\nThe extension serves as an intelligent code understanding assistant that bridges the gap between raw source code and comprehensible documentation. It automatically identifies entry points, maps dependencies between files and functions, detects code smells like circular dependencies and orphaned files, and generates test coverage reports. Users can explore their codebase through multiple specialized views including hierarchical analysis trees, insights panels, and documentation browsers that make complex codebases easier to navigate and understand.\\n\\nShadow Watch integrates AI language models (OpenAI GPT or Anthropic Claude) to generate contextual documentation and refactoring recommendations. Users can trigger analysis on-demand or enable automatic analysis on file save, view generated insights directly in the VS Code Problems panel, export analysis results in formats optimized for different AI assistants, and navigate instantly from analysis results to the corresponding code locations. The extension maintains a persistent knowledge base of analysis results that improves over time and supports iterative AI-powered analysis workflows.\",\"whatItDoes\":[\"Automatically analyzes code structure and generates human-readable documentation explaining what code does from a user perspective\",\"Displays code quality metrics and complexity assessments in interactive sidebar tree views\",\"Identifies test coverage gaps showing which functions have tests and which need testing\",\"Detects code organization issues including large files, orphaned code, circular dependencies, and duplicate code\",\"Generates AI-powered refactoring recommendations with detailed migration guidance\",\"Creates automated test generation plans and executes tests with validation and auto-fixing capabilities\",\"Provides real-time diagnostics in the VS Code Problems panel showing code quality warnings and suggestions\",\"Enables instant navigation from analysis results to specific code locations in the editor\",\"Exports analysis results in formats optimized for ChatGPT, Cursor AI, and other AI assistants\",\"Monitors file changes and automatically refreshes analysis when code is modified\",\"Generates comprehensive product documentation describing application features and architecture\",\"Creates test plans prioritizing which functions need testing based on complexity and risk\"],\"userPerspective\":{\"gui\":[\"Interactive sidebar tree views displaying code analysis hierarchy with files, functions, and metrics\",\"Insights panel showing AI-generated recommendations categorized by type (quality, architecture, testing)\",\"Documentation browser for viewing generated product documentation and architecture insights\",\"Problems panel integration displaying code quality diagnostics with severity levels\",\"Status bar indicators showing analysis progress and current state\",\"Webview panels displaying detailed information about selected code elements with syntax highlighting\",\"Tree view navigation allowing direct jumps to code locations by clicking on analysis items\",\"Progress notifications during long-running analysis and test generation operations\",\"Configuration settings interface for enabling/disabling features and selecting AI providers\"],\"cli\":[],\"api\":[],\"cicd\":[]},\"workflowIntegration\":[\"Code review workflow: Developers review AI-generated insights before merging code changes to identify quality issues\",\"Documentation generation workflow: Automatically create and update product documentation when codebase changes\",\"Test-driven development workflow: Generate test plans and implement tests based on AI recommendations\",\"Refactoring workflow: Use AI-generated refactoring reports to safely restructure large files and improve code organization\",\"Onboarding workflow: New developers explore codebase through generated documentation and analysis views\",\"Technical debt management workflow: Track and prioritize code quality issues through diagnostics and insights panels\"],\"problemsSolved\":[\"Eliminates manual documentation effort by automatically generating human-readable explanations of code purpose\",\"Reduces time spent understanding unfamiliar codebases through AI-powered architectural insights\",\"Identifies hidden code quality issues that manual review might miss (circular dependencies, orphaned files, complexity hotspots)\",\"Accelerates test writing by automatically generating test plans and test code with validation\",\"Prevents technical debt accumulation by surfacing refactoring opportunities before files become unmaintainable\",\"Improves code navigation in large projects through structured analysis hierarchies and instant jump-to-definition\",\"Standardizes documentation format across projects through consistent AI-generated output\",\"Reduces cognitive load during code review by highlighting specific issues with actionable recommendations\"],\"architecture\":\"Shadow Watch follows a layered architecture with distinct separation between domain logic, infrastructure concerns, and presentation. The domain layer contains services for code analysis, AI integration, test generation, and insight creation. These services orchestrate workflows like analyzing code structure, generating documentation, planning tests, and creating refactoring recommendations. The infrastructure layer handles persistence, file system operations, caching, and external AI provider integration. The presentation layer consists of VS Code UI components including tree view providers, webview panels, diagnostics providers, and command handlers.\\n\\nThe extension uses an event-driven architecture where file system watchers detect code changes and trigger analysis pipelines. Analysis results flow through multiple stages: initial code parsing extracts structural information, AI services enrich this data with semantic understanding and recommendations, formatters transform results into human-readable documentation, and UI components display formatted results to users. A caching layer stores analysis results to avoid redundant processing and improve performance.\\n\\nAI integration follows a provider abstraction pattern allowing seamless switching between OpenAI and Anthropic Claude. The system implements rate limiting, retry logic with exponential backoff, and response parsing to ensure reliable AI interactions. Test generation uses an iterative workflow where the AI analyzes code, creates test plans, generates tests in small batches, executes them, captures results, and automatically fixes failures through multiple refinement cycles. All analysis results are persisted to a workspace directory structure enabling version history and cross-session continuity.\",\"titles\":[\"Code Analysis Engine\",\"AI-Powered Documentation Generator\",\"Test Generation System\",\"Insights and Recommendations Engine\",\"Code Quality Diagnostics\",\"Architecture Insights Viewer\",\"Analysis Tree Navigator\",\"Product Documentation Generator\",\"Refactoring Report Builder\",\"Test Plan Creator\",\"Test Execution and Validation\",\"File System Watcher\",\"Rate Limiter for AI Requests\",\"Response Parser for AI Outputs\",\"Configuration Manager\",\"Navigation Handler\",\"Progress Notification Service\",\"Analysis Context Builder\",\"Incremental Analysis Service\",\"Test Configuration Detector\"],\"descriptions\":[{\"title\":\"Code Analysis Engine\",\"description\":\"Scans source code files to extract structural information including functions, classes, dependencies, complexity metrics, and code relationships. Identifies entry points, maps call graphs, and detects patterns like circular dependencies and orphaned files.\",\"category\":\"component\"},{\"title\":\"AI-Powered Documentation Generator\",\"description\":\"Leverages language models to transform raw code structure into human-readable documentation explaining what code does from a user perspective. Generates product overviews, feature descriptions, and architectural summaries.\",\"category\":\"feature\"},{\"title\":\"Test Generation System\",\"description\":\"Creates comprehensive automated testing workflows including test environment detection, test plan creation, test code generation, execution, validation, and automatic fixing of failing tests. Supports multiple test frameworks like Jest, Mocha, pytest, and JUnit.\",\"category\":\"feature\"},{\"title\":\"Insights and Recommendations Engine\",\"description\":\"Analyzes code quality, complexity, organization, and structure to generate actionable recommendations for improvements. Identifies refactoring opportunities, test coverage gaps, and code smell patterns.\",\"category\":\"feature\"},{\"title\":\"Code Quality Diagnostics\",\"description\":\"Displays code quality issues, warnings, and suggestions directly in the VS Code Problems panel. Categorizes diagnostics by severity and provides navigation to problem locations.\",\"category\":\"feature\"},{\"title\":\"Architecture Insights Viewer\",\"description\":\"Interactive tree view for browsing AI-generated architectural analysis of the codebase. Shows module structure, component relationships, and system design patterns.\",\"category\":\"feature\"},{\"title\":\"Analysis Tree Navigator\",\"description\":\"Hierarchical view of code analysis results showing statistics, files, functions, and entry points. Enables users to explore code structure and navigate to specific code locations.\",\"category\":\"feature\"},{\"title\":\"Product Documentation Generator\",\"description\":\"Creates comprehensive product documentation describing application features, user workflows, problems solved, and technical architecture. Formats documentation as structured markdown with timestamped versions.\",\"category\":\"feature\"},{\"title\":\"Refactoring Report Builder\",\"description\":\"Generates detailed refactoring recommendations for large or complex files. Provides extraction plans, migration guidance, and step-by-step instructions for safely restructuring code.\",\"category\":\"feature\"},{\"title\":\"Test Plan Creator\",\"description\":\"Analyzes codebase to determine which functions need testing and creates prioritized test plans. Evaluates testability based on complexity, dependencies, and existing test coverage.\",\"category\":\"feature\"},{\"title\":\"Test Execution and Validation\",\"description\":\"Runs generated tests, captures results including pass/fail status and error messages, and automatically attempts to fix failing tests through iterative AI-powered refinement.\",\"category\":\"workflow\"},{\"title\":\"File System Watcher\",\"description\":\"Monitors workspace for file changes including creation, modification, and deletion. Triggers automatic re-analysis when files are saved if auto-analysis is enabled.\",\"category\":\"component\"},{\"title\":\"Rate Limiter for AI Requests\",\"description\":\"Enforces provider-specific API rate limits to prevent quota exhaustion. Automatically queues requests when approaching limits and throttles according to OpenAI (60 req/min) or Claude (50 req/min) constraints.\",\"category\":\"component\"},{\"title\":\"Response Parser for AI Outputs\",\"description\":\"Extracts structured data from AI-generated text responses. Handles both JSON and natural language outputs, providing fallback text parsing when structured data is unavailable.\",\"category\":\"component\"},{\"title\":\"Configuration Manager\",\"description\":\"Centralizes all extension settings including enable/disable controls, auto-analysis behavior, diagnostic display preferences, AI provider selection, and performance tuning parameters. Propagates configuration changes to dependent components in real-time.\",\"category\":\"component\"},{\"title\":\"Navigation Handler\",\"description\":\"Manages navigation between analysis results and source code locations. Opens files, positions editor view, highlights relevant code sections, and displays detailed information in webview panels.\",\"category\":\"component\"},{\"title\":\"Progress Notification Service\",\"description\":\"Displays progress indicators during long-running operations like analysis, test generation, and AI requests. Supports cancellation for interruptible operations.\",\"category\":\"component\"},{\"title\":\"Analysis Context Builder\",\"description\":\"Transforms code analysis results into structured format optimized for AI processing. Persists analysis data to workspace directory for reuse across sessions.\",\"category\":\"component\"},{\"title\":\"Incremental Analysis Service\",\"description\":\"Manages iterative AI analysis where the language model can progressively request additional files or grep searches until sufficient information is gathered for completion.\",\"category\":\"workflow\"},{\"title\":\"Test Configuration Detector\",\"description\":\"Automatically identifies test frameworks in use, validates configuration, and detects missing dependencies. Ensures generated tests can execute without manual setup.\",\"category\":\"component\"}],\"relevantFunctions\":[{\"name\":\"analyzeCodebase\",\"description\":\"Performs comprehensive code analysis across all workspace files, extracting functions, dependencies, complexity metrics, and structural patterns\",\"file\":\"src/analyzer.ts\",\"module\":\"analyzer\"},{\"name\":\"generateInsights\",\"description\":\"Creates actionable code quality insights by analyzing code structure, complexity, and organization patterns\",\"file\":\"src/insightGenerator.ts\",\"module\":\"insightGenerator\"},{\"name\":\"generateProductDocumentation\",\"description\":\"Leverages AI to create comprehensive product documentation from code analysis results\",\"file\":\"src/llmIntegration.ts\",\"module\":\"llmIntegration\"},{\"name\":\"generateArchitectureInsights\",\"description\":\"Uses AI to analyze codebase architecture and generate high-level architectural insights\",\"file\":\"src/llmIntegration.ts\",\"module\":\"llmIntegration\"},{\"name\":\"createTestPlan\",\"description\":\"Analyzes functions to determine testability and creates prioritized test generation plans\",\"file\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"module\":\"llmTestPlanningService\"},{\"name\":\"generateTests\",\"description\":\"Creates test code for functions using AI, executing tests in small batches with validation\",\"file\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"module\":\"llmTestGenerationService\"},{\"name\":\"validateTests\",\"description\":\"Executes generated tests, detects failures, and automatically fixes failing tests through iterative refinement\",\"file\":\"src/domain/services/testing/llmTestValidationService.ts\",\"module\":\"llmTestValidationService\"},{\"name\":\"navigateToLocation\",\"description\":\"Opens files in the editor and positions cursor at specific code locations from analysis results\",\"file\":\"src/domain/handlers/navigationHandler.ts\",\"module\":\"navigationHandler\"},{\"name\":\"buildPromptForAnalysis\",\"description\":\"Constructs specialized prompts that guide AI interactions for code analysis tasks\",\"file\":\"src/domain/prompts/promptBuilder.ts\",\"module\":\"promptBuilder\"},{\"name\":\"parseAnalysisResponse\",\"description\":\"Extracts structured data from AI text responses, handling both JSON and natural language outputs\",\"file\":\"src/ai/llmResponseParser.ts\",\"module\":\"llmResponseParser\"},{\"name\":\"enforceRateLimit\",\"description\":\"Throttles AI API requests to prevent quota exhaustion based on provider-specific limits\",\"file\":\"src/ai/llmRateLimiter.ts\",\"module\":\"llmRateLimiter\"},{\"name\":\"processFileChanges\",\"description\":\"Handles file system change events and triggers appropriate analysis updates\",\"file\":\"src/domain/services/fileWatcherService.ts\",\"module\":\"fileWatcherService\"}],\"relevantDataStructures\":[{\"name\":\"AnalysisResult\",\"description\":\"Represents complete code analysis output including file metrics, functions, dependencies, entry points, and code relationships\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FileAnalysis\",\"description\":\"Contains detailed analysis of a single file including functions, imports, exports, complexity metrics, and test mappings\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FunctionInfo\",\"description\":\"Describes a function including name, signature, location, complexity, dependencies, and behavioral metadata\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"CodeInsight\",\"description\":\"Represents an actionable code quality recommendation with severity, category, description, and affected locations\",\"type\":\"interface\",\"file\":\"src/insightGenerator.ts\"},{\"name\":\"ProductDocumentation\",\"description\":\"Structured product documentation including overview, features, user perspectives, architecture, and examples\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"TestPlan\",\"description\":\"Organized plan for test generation including functions to test, priorities, testability assessments, and generation strategy\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestResult\",\"description\":\"Results from test execution including pass/fail status, error messages, stack traces, and execution timing\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestSetupPlan\",\"description\":\"Configuration plan for test environment including framework detection, required dependencies, and setup instructions\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testSetupTypes.ts\"},{\"name\":\"AnalysisTreeItem\",\"description\":\"Tree view item representing a node in the analysis hierarchy for display in VS Code sidebar\",\"type\":\"class\",\"file\":\"src/analysisViewer.ts\"},{\"name\":\"InsightTreeItem\",\"description\":\"Tree view item representing an insight or recommendation for display in the insights panel\",\"type\":\"class\",\"file\":\"src/insightsTreeView.ts\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main entry point that initializes the extension and orchestrates all features when VS Code activates\",\"purpose\":\"Bootstraps all extension components including analyzers, tree views, diagnostics, file watchers, and command handlers\",\"role\":\"Entry point and orchestration\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Core analysis engine that scans code files to extract functions, dependencies, complexity metrics, and structural information\",\"purpose\":\"Performs comprehensive static code analysis across the workspace\",\"role\":\"Core analysis engine\"},{\"path\":\"src/insightGenerator.ts\",\"description\":\"Generates actionable code quality insights by analyzing patterns like complexity, large files, orphaned code, and circular dependencies\",\"purpose\":\"Creates recommendations for code improvements based on analysis results\",\"role\":\"Insight generation\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"Coordinates AI-powered features including documentation generation, architecture insights, and refactoring recommendations\",\"purpose\":\"Integrates language models into the analysis workflow for semantic understanding\",\"role\":\"AI integration orchestration\"},{\"path\":\"src/llmService.ts\",\"description\":\"Provides AI services for generating documentation, insights, test plans, and refactoring guidance using language models\",\"purpose\":\"Handles all interactions with AI providers for analysis enrichment\",\"role\":\"AI service layer\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Generates automated tests using AI in small batches with execution and validation\",\"purpose\":\"Creates test code for functions identified in test plans\",\"role\":\"Test generation workflow\"},{\"path\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"description\":\"Creates prioritized test plans by analyzing which functions need testing and determining test strategy\",\"purpose\":\"Plans test generation workflow based on complexity and coverage analysis\",\"role\":\"Test planning\"},{\"path\":\"src/analysisViewer.ts\",\"description\":\"Provides interactive tree view displaying analysis hierarchy including files, functions, and metrics\",\"purpose\":\"Enables users to explore code structure through visual tree navigation\",\"role\":\"UI component for analysis browsing\"},{\"path\":\"src/insightsTreeView.ts\",\"description\":\"Displays AI-generated insights, recommendations, and documentation in an interactive sidebar panel\",\"purpose\":\"Presents code quality insights and documentation to users\",\"role\":\"UI component for insights display\"},{\"path\":\"src/diagnosticsProvider.ts\",\"description\":\"Manages code quality diagnostics displayed in the VS Code Problems panel\",\"purpose\":\"Shows warnings and suggestions alongside native VS Code diagnostics\",\"role\":\"Diagnostics integration\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Handles navigation from analysis results to source code locations with highlighting and detailed information display\",\"purpose\":\"Enables instant jumps from analysis views to corresponding code\",\"role\":\"Navigation management\"},{\"path\":\"src/domain/prompts/promptBuilder.ts\",\"description\":\"Constructs specialized prompts for all AI-powered analysis tasks\",\"purpose\":\"Guides AI interactions to produce consistent, structured analysis results\",\"role\":\"Prompt engineering\"}],\"exampleInput\":{\"description\":\"Example analysis context passed to AI for generating product documentation, showing how code analysis results are structured for AI processing\",\"json\":\"{\\\"stats\\\":{\\\"totalFiles\\\":65,\\\"totalLines\\\":25156,\\\"averageComplexity\\\":8.3},\\\"entryPoints\\\":[{\\\"file\\\":\\\"src/extension.ts\\\",\\\"function\\\":\\\"activate\\\",\\\"type\\\":\\\"extension_entry\\\"}],\\\"files\\\":[{\\\"path\\\":\\\"src/analyzer.ts\\\",\\\"purpose\\\":\\\"Core code analysis engine\\\",\\\"exports\\\":[\\\"analyzeCodebase\\\",\\\"AnalysisResult\\\"],\\\"complexity\\\":12.4},{\\\"path\\\":\\\"src/llmService.ts\\\",\\\"purpose\\\":\\\"AI service integration\\\",\\\"exports\\\":[\\\"generateDocumentation\\\",\\\"createTestPlan\\\"],\\\"complexity\\\":15.7}],\\\"dependencies\\\":{\\\"src/analyzer.ts\\\":[\\\"typescript\\\",\\\"@typescript-eslint/parser\\\"],\\\"src/llmService.ts\\\":[\\\"openai\\\",\\\"@anthropic-ai/sdk\\\"]},\\\"insights\\\":[{\\\"type\\\":\\\"large_file\\\",\\\"severity\\\":\\\"warning\\\",\\\"file\\\":\\\"src/llmIntegration.ts\\\",\\\"message\\\":\\\"File has 2849 lines - consider refactoring\\\",\\\"recommendation\\\":\\\"Split into smaller modules\\\"}]}\"},\"exampleOutput\":{\"description\":\"Example product documentation output generated by AI from code analysis, showing the structured documentation format returned to users\",\"json\":\"{\\\"overview\\\":\\\"Shadow Watch is an AI-powered VS Code extension that automatically analyzes codebases to generate documentation and insights...\\\",\\\"whatItDoes\\\":[\\\"Automatically analyzes code structure\\\",\\\"Generates human-readable documentation\\\",\\\"Creates test plans and generates tests\\\"],\\\"userPerspective\\\":{\\\"gui\\\":[\\\"Interactive sidebar tree views\\\",\\\"Problems panel diagnostics\\\",\\\"Webview documentation browser\\\"],\\\"cli\\\":[],\\\"api\\\":[],\\\"cicd\\\":[]},\\\"architecture\\\":\\\"Shadow Watch follows a layered architecture with domain services, infrastructure components, and presentation layers...\\\",\\\"titles\\\":[\\\"Code Analysis Engine\\\",\\\"AI Documentation Generator\\\",\\\"Test Generation System\\\"],\\\"descriptions\\\":[{\\\"title\\\":\\\"Code Analysis Engine\\\",\\\"description\\\":\\\"Scans source code to extract structural information\\\",\\\"category\\\":\\\"component\\\"}],\\\"relevantFunctions\\\":[{\\\"name\\\":\\\"analyzeCodebase\\\",\\\"description\\\":\\\"Performs comprehensive code analysis\\\",\\\"file\\\":\\\"src/analyzer.ts\\\"}],\\\"relevantDataStructures\\\":[{\\\"name\\\":\\\"AnalysisResult\\\",\\\"description\\\":\\\"Complete code analysis output\\\",\\\"type\\\":\\\"interface\\\"}],\\\"relevantCodeFiles\\\":[{\\\"path\\\":\\\"src/extension.ts\\\",\\\"description\\\":\\\"Main entry point\\\",\\\"purpose\\\":\\\"Bootstraps extension\\\"}]}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-20T06:42:16.136Z",
    "generatedAtLocal": "11/19/2025, 10:42:16 PM",
    "runId": "product-docs-2025-11-20T06-26-15-844Z"
  }
}