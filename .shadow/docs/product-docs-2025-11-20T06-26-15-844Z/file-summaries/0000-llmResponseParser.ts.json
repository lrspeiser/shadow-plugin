{
  "file": "src/ai/llmResponseParser.ts",
  "role": "Core Logic",
  "purpose": "Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).",
  "userVisibleActions": [
    "Converts raw AI-generated text responses into organized documentation",
    "Extracts file purposes and actions from AI analysis",
    "Generates structured module and product documentation from AI responses",
    "Provides fallback text parsing when AI returns non-JSON responses"
  ],
  "developerVisibleActions": [
    "Call parseFileSummary() to convert LLM response into FileSummary object",
    "Call parseModuleSummary() to extract module-level documentation from LLM text",
    "Call parseInsights() to structure AI-generated insights about codebase",
    "Call parseProductDocumentation() to build comprehensive product docs from LLM output",
    "Call parsePurposeAnalysis() to extract product purpose analysis",
    "Handles both JSON and plain text LLM response formats automatically",
    "Returns typed TypeScript objects with fallback values for missing data"
  ],
  "keyFunctions": [
    {
      "name": "parseFileSummary",
      "desc": "Converts LLM response text into a FileSummary object with purpose, actions, and dependencies",
      "inputs": "content (LLM response text), filePath (string), role (string)",
      "outputs": "FileSummary object"
    },
    {
      "name": "parseModuleSummary",
      "desc": "Extracts module-level documentation including purpose, features, and structure from LLM response",
      "inputs": "content (LLM response text), moduleName (string)",
      "outputs": "ModuleSummary object"
    },
    {
      "name": "parseInsights",
      "desc": "Structures AI insights about the codebase into categories like architecture patterns and improvement areas",
      "inputs": "content (LLM response text), context (AnalysisContext)",
      "outputs": "LLMInsights object"
    },
    {
      "name": "parseProductDocumentation",
      "desc": "Builds comprehensive product documentation from LLM analysis including overview, features, and use cases",
      "inputs": "content (LLM response text)",
      "outputs": "EnhancedProductDocumentation object"
    },
    {
      "name": "parsePurposeAnalysis",
      "desc": "Extracts product purpose analysis including main purpose, target audience, and value proposition",
      "inputs": "content (LLM response text)",
      "outputs": "ProductPurposeAnalysis object"
    },
    {
      "name": "extractSection",
      "desc": "Helper that pulls out a specific labeled section from unstructured text",
      "inputs": "content (text), sectionName (string)",
      "outputs": "Extracted section text or empty string"
    },
    {
      "name": "extractListSection",
      "desc": "Helper that extracts bullet points or list items from a text section",
      "inputs": "content (text), sectionName (string)",
      "outputs": "Array of list items"
    }
  ],
  "dependencies": [
    "../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)",
    "../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)"
  ],
  "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.",
  "rawContent": "```json\n{\n  \"purpose\": \"Parses and extracts structured data from LLM text responses into typed objects for different analysis types (file summaries, module summaries, insights, and product documentation).\",\n  \"userVisibleActions\": [\n    \"Converts raw AI-generated text responses into organized documentation\",\n    \"Extracts file purposes and actions from AI analysis\",\n    \"Generates structured module and product documentation from AI responses\",\n    \"Provides fallback text parsing when AI returns non-JSON responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call parseFileSummary() to convert LLM response into FileSummary object\",\n    \"Call parseModuleSummary() to extract module-level documentation from LLM text\",\n    \"Call parseInsights() to structure AI-generated insights about codebase\",\n    \"Call parseProductDocumentation() to build comprehensive product docs from LLM output\",\n    \"Call parsePurposeAnalysis() to extract product purpose analysis\",\n    \"Handles both JSON and plain text LLM response formats automatically\",\n    \"Returns typed TypeScript objects with fallback values for missing data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object with purpose, actions, and dependencies\",\n      \"inputs\": \"content (LLM response text), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level documentation including purpose, features, and structure from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName (string)\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseInsights\",\n      \"desc\": \"Structures AI insights about the codebase into categories like architecture patterns and improvement areas\",\n      \"inputs\": \"content (LLM response text), context (AnalysisContext)\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductDocumentation\",\n      \"desc\": \"Builds comprehensive product documentation from LLM analysis including overview, features, and use cases\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"parsePurposeAnalysis\",\n      \"desc\": \"Extracts product purpose analysis including main purpose, target audience, and value proposition\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Helper that pulls out a specific labeled section from unstructured text\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Extracted section text or empty string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Helper that extracts bullet points or list items from a text section\",\n      \"inputs\": \"content (text), sectionName (string)\",\n      \"outputs\": \"Array of list items\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation (FileSummary, ModuleSummary, EnhancedProductDocumentation)\",\n    \"../llmService (LLMInsights, ProductPurposeAnalysis, AnalysisContext)\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript types needed by the application. It handles the unpredictability of AI responses by supporting both JSON and plain text formats, ensuring the rest of the application always receives properly typed data objects regardless of how the LLM formatted its response.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:26:45.409Z"
  }
}