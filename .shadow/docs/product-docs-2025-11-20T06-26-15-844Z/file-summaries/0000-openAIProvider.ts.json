{
  "file": "src/ai/providers/openAIProvider.ts",
  "role": "Core Logic",
  "purpose": "Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.",
  "userVisibleActions": [
    "Sends chat messages to OpenAI's GPT models and receives AI-generated responses",
    "Receives structured JSON responses from AI when requested",
    "Experiences timeout protection with 5-minute maximum wait time for responses",
    "Gets error messages when OpenAI API key is not configured"
  ],
  "developerVisibleActions": [
    "Configure OpenAI API key through configuration manager to enable the provider",
    "Send chat requests with custom system prompts, messages, and model selection",
    "Request structured JSON outputs with specific schemas",
    "Check if provider is properly configured before use",
    "Receive parsed JSON objects from AI responses",
    "Handle errors when API key is missing or requests fail",
    "Use default GPT-4o model or specify alternative OpenAI models"
  ],
  "keyFunctions": [
    {
      "name": "initialize",
      "desc": "Sets up OpenAI client with API key from configuration",
      "inputs": "None",
      "outputs": "void"
    },
    {
      "name": "isConfigured",
      "desc": "Checks if provider has valid API key and is ready to use",
      "inputs": "None",
      "outputs": "boolean indicating if configured"
    },
    {
      "name": "getName",
      "desc": "Returns provider identifier",
      "inputs": "None",
      "outputs": "string 'openai'"
    },
    {
      "name": "sendRequest",
      "desc": "Sends chat completion request to OpenAI and returns response",
      "inputs": "LLMRequestOptions (system prompt, messages, model, response format)",
      "outputs": "Promise<LLMResponse> with content and finish reason"
    },
    {
      "name": "sendStructuredOutputRequest",
      "desc": "Sends request expecting structured JSON response conforming to a schema",
      "inputs": "LLMRequestOptions with JSON schema",
      "outputs": "Promise<StructuredOutputResponse> with parsed JSON object"
    }
  ],
  "dependencies": [
    "openai",
    "ILLMProvider",
    "configurationManager",
    "jsonExtractor"
  ],
  "intent": "This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for sending chat requests and receiving AI-generated responses with support for structured JSON outputs.\",\n  \"userVisibleActions\": [\n    \"Sends chat messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Receives structured JSON responses from AI when requested\",\n    \"Experiences timeout protection with 5-minute maximum wait time for responses\",\n    \"Gets error messages when OpenAI API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure OpenAI API key through configuration manager to enable the provider\",\n    \"Send chat requests with custom system prompts, messages, and model selection\",\n    \"Request structured JSON outputs with specific schemas\",\n    \"Check if provider is properly configured before use\",\n    \"Receive parsed JSON objects from AI responses\",\n    \"Handle errors when API key is missing or requests fail\",\n    \"Use default GPT-4o model or specify alternative OpenAI models\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if provider has valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends chat completion request to OpenAI and returns response\",\n      \"inputs\": \"LLMRequestOptions (system prompt, messages, model, response format)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting structured JSON response conforming to a schema\",\n      \"inputs\": \"LLMRequestOptions with JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON object\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"ILLMProvider\",\n    \"configurationManager\",\n    \"jsonExtractor\"\n  ],\n  \"intent\": \"This file exists to integrate OpenAI's GPT models into the application, allowing developers to send chat requests and receive both free-form text and structured JSON responses. It solves the problem of needing a standardized interface to interact with OpenAI's API while handling configuration, timeouts, and JSON parsing automatically.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:27:37.467Z"
  }
}