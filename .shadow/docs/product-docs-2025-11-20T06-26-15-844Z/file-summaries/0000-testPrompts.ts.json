{
  "file": "src/domain/prompts/testPrompts.ts",
  "role": "Core Logic",
  "purpose": "Provides prompt templates for LLM-based automated test generation and test configuration setup",
  "userVisibleActions": [
    "Automatically generates test setup recommendations for the codebase",
    "Creates prioritized test plans identifying which functions need testing",
    "Generates actual test code with assertions and edge cases",
    "Analyzes codebase to determine optimal testing framework and dependencies"
  ],
  "developerVisibleActions": [
    "Call buildSetupPrompt() to get LLM prompt for test configuration analysis",
    "Call buildPlanningPrompt() to get LLM prompt for test strategy creation",
    "Call buildGenerationPrompt() to get LLM prompt for actual test code generation",
    "Provide workspace root, file lists, and function details as inputs",
    "Receive structured JSON responses with test setup configurations, test plans, or generated test code",
    "Pass in optional product documentation and architecture insights to improve test generation quality"
  ],
  "keyFunctions": [
    {
      "name": "buildSetupPrompt",
      "desc": "Creates prompt for LLM to analyze codebase and recommend test setup configuration",
      "inputs": "workspaceRoot (string), fileList (array), optional packageJsonContent (string)",
      "outputs": "Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files"
    },
    {
      "name": "buildPlanningPrompt",
      "desc": "Creates prompt for LLM to generate prioritized test plan for functions",
      "inputs": "context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights",
      "outputs": "Formatted prompt string requesting prioritized list of functions to test with complexity assessments"
    },
    {
      "name": "buildGenerationPrompt",
      "desc": "Creates prompt for LLM to generate actual test code for specific function",
      "inputs": "testableFunction (TestableFunction), framework (string), optional fileContext (string)",
      "outputs": "Formatted prompt string requesting complete test code with imports, mocks, and assertions"
    }
  ],
  "dependencies": [
    "../../analyzer",
    "../services/testing/types/testPlanTypes"
  ],
  "intent": "Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based automated test generation and test configuration setup\",\n  \"userVisibleActions\": [\n    \"Automatically generates test setup recommendations for the codebase\",\n    \"Creates prioritized test plans identifying which functions need testing\",\n    \"Generates actual test code with assertions and edge cases\",\n    \"Analyzes codebase to determine optimal testing framework and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() to get LLM prompt for test configuration analysis\",\n    \"Call buildPlanningPrompt() to get LLM prompt for test strategy creation\",\n    \"Call buildGenerationPrompt() to get LLM prompt for actual test code generation\",\n    \"Provide workspace root, file lists, and function details as inputs\",\n    \"Receive structured JSON responses with test setup configurations, test plans, or generated test code\",\n    \"Pass in optional product documentation and architecture insights to improve test generation quality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates prompt for LLM to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate prioritized test plan for functions\",\n      \"inputs\": \"context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted prompt string requesting prioritized list of functions to test with complexity assessments\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate actual test code for specific function\",\n      \"inputs\": \"testableFunction (TestableFunction), framework (string), optional fileContext (string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test code with imports, mocks, and assertions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:31:32.107Z"
  }
}