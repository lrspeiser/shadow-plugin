{
  "file": "src/domain/services/incrementalAnalysisService.ts",
  "role": "Core Logic",
  "purpose": "Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task",
  "userVisibleActions": [
    "AI progressively gathers more information about the codebase by requesting specific files",
    "AI performs grep searches to find relevant code patterns across the project",
    "Analysis completes after gathering sufficient information or reaching maximum iteration limit",
    "Receives additional context information formatted as markdown sections"
  ],
  "developerVisibleActions": [
    "Trigger incremental analysis that automatically handles LLM requests for files and grep searches",
    "Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)",
    "Control maximum number of analysis iterations to prevent infinite loops",
    "Receive structured results including all processed requests and conversation history",
    "Access shouldContinue flag to determine if analysis needs more iterations"
  ],
  "keyFunctions": [
    {
      "name": "processRequests",
      "desc": "Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages",
      "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation history)",
      "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
    },
    {
      "name": "iterativeAnalysis (implied by async iterator pattern)",
      "desc": "Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached",
      "inputs": "iteration callbacks, max iterations, initial result and messages",
      "outputs": "IterationResult containing final result, iteration count, all requests, and continuation status"
    }
  ],
  "dependencies": [
    "fileAccessHelper",
    "LLMRequest interface",
    "FileAccessHelper class"
  ],
  "intent": "Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress",
  "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative AI analysis sessions where the LLM can request additional file content or grep searches across multiple iterations until it has enough information to complete its task\",\n  \"userVisibleActions\": [\n    \"AI progressively gathers more information about the codebase by requesting specific files\",\n    \"AI performs grep searches to find relevant code patterns across the project\",\n    \"Analysis completes after gathering sufficient information or reaching maximum iteration limit\",\n    \"Receives additional context information formatted as markdown sections\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger incremental analysis that automatically handles LLM requests for files and grep searches\",\n    \"Monitor analysis progress through iteration callbacks (onIterationStart, onIterationComplete)\",\n    \"Control maximum number of analysis iterations to prevent infinite loops\",\n    \"Receive structured results including all processed requests and conversation history\",\n    \"Access shouldContinue flag to determine if analysis needs more iterations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM-requested file reads and grep searches, returning formatted additional information and updated conversation messages\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"iterativeAnalysis (implied by async iterator pattern)\",\n      \"desc\": \"Executes multiple analysis iterations, processing file/grep requests between each iteration until completion or max iterations reached\",\n      \"inputs\": \"iteration callbacks, max iterations, initial result and messages\",\n      \"outputs\": \"IterationResult containing final result, iteration count, all requests, and continuation status\"\n    }\n  ],\n  \"dependencies\": [\n    \"fileAccessHelper\",\n    \"LLMRequest interface\",\n    \"FileAccessHelper class\"\n  ],\n  \"intent\": \"Eliminates code duplication by centralizing the iterative LLM analysis pattern where AI agents can request additional files or perform grep searches during analysis, making the process more testable by converting while loops to async iterators and providing structured callbacks for monitoring progress\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:32:00.585Z"
  }
}