{
  "file": "src/ai/llmRetryHandler.ts",
  "role": "Core Logic",
  "purpose": "Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors",
  "userVisibleActions": [
    "Automatic retry when AI requests fail due to rate limits or temporary issues",
    "Delayed retry attempts that increase wait time between retries",
    "Transparent error recovery without user intervention for recoverable errors",
    "Final error display only after all retry attempts are exhausted"
  ],
  "developerVisibleActions": [
    "Configure maximum number of retry attempts for LLM requests",
    "Set initial delay and maximum delay between retries",
    "Define which error types should trigger automatic retries",
    "Receive callbacks on each retry attempt for logging or monitoring",
    "Execute any async LLM operation with automatic retry handling",
    "Get result with attempt count after successful retry",
    "Handle non-retryable errors immediately without retry attempts"
  ],
  "keyFunctions": [
    {
      "name": "executeWithRetry",
      "desc": "Executes an LLM operation with automatic retry on failure",
      "inputs": "operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)",
      "outputs": "Promise resolving to the operation result, or throws error after all retries exhausted"
    },
    {
      "name": "isRetryableError",
      "desc": "Determines if an error should trigger a retry attempt",
      "inputs": "error object, list of retryable error patterns",
      "outputs": "Boolean indicating whether the error is retryable"
    }
  ],
  "dependencies": [],
  "intent": "Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services",
  "rawContent": "```json\n{\n  \"purpose\": \"Handles automatic retry logic for LLM API requests with exponential backoff when requests fail due to rate limits, timeouts, or temporary errors\",\n  \"userVisibleActions\": [\n    \"Automatic retry when AI requests fail due to rate limits or temporary issues\",\n    \"Delayed retry attempts that increase wait time between retries\",\n    \"Transparent error recovery without user intervention for recoverable errors\",\n    \"Final error display only after all retry attempts are exhausted\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure maximum number of retry attempts for LLM requests\",\n    \"Set initial delay and maximum delay between retries\",\n    \"Define which error types should trigger automatic retries\",\n    \"Receive callbacks on each retry attempt for logging or monitoring\",\n    \"Execute any async LLM operation with automatic retry handling\",\n    \"Get result with attempt count after successful retry\",\n    \"Handle non-retryable errors immediately without retry attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an LLM operation with automatic retry on failure\",\n      \"inputs\": \"operation (async function to execute), options (retry configuration including maxRetries, delays, retryable error types, callback)\",\n      \"outputs\": \"Promise resolving to the operation result, or throws error after all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry attempt\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"Boolean indicating whether the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilient LLM API communication by automatically handling transient failures like rate limits, network issues, and temporary service outages, preventing user-facing errors for recoverable problems while using exponential backoff to avoid overwhelming services\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:26:56.760Z"
  }
}