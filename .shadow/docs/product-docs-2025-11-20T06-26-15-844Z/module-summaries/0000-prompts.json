{
  "module": "src/domain/prompts",
  "moduleType": "other",
  "capabilities": [
    "Generates structured prompts for AI-driven code analysis and architecture evaluation",
    "Creates prompts for automated documentation generation from source code",
    "Produces prompts for comprehensive test generation including setup, planning, and test code",
    "Builds prescriptive refactoring prompts with extraction plans and migration guidance",
    "Generates prompts for analyzing project structure, purpose, and target audience",
    "Creates prompts for module-level summaries and relationship mapping",
    "Provides templates for test framework setup and dependency recommendations"
  ],
  "summary": "This module serves as the prompt engineering layer that powers all AI-driven code analysis and generation features. It constructs specialized, structured prompts that guide LLM interactions for tasks like architecture analysis, documentation creation, test generation, and code refactoring. Each prompt is carefully crafted to extract specific insights from codebases or generate particular outputs.\n\nThe module supports three primary workflows: (1) Code Analysis - generating prompts to understand project architecture, file relationships, and module structure; (2) Documentation Generation - creating prompts that produce product documentation, API references, and code summaries from source files; (3) Test & Refactoring - building prompts for automated test generation with full test plans and actual test code, plus detailed refactoring recommendations with step-by-step migration instructions.\n\nUsers interact with this module indirectly through higher-level features that leverage these prompts. The prompts handle context injection, constraint specification, and output formatting requirements to ensure LLM responses are consistent, actionable, and tailored to specific code analysis needs. This centralized approach ensures all AI interactions maintain quality standards and produce results in expected formats.",
  "files": [
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.",
      "userVisibleActions": [
        "Generates AI prompts that analyze project architecture and structure",
        "Creates AI prompts for generating product documentation from code",
        "Produces AI prompts that determine product purpose and target audience",
        "Generates AI prompts for analyzing individual code files",
        "Creates AI prompts for summarizing code modules and their relationships",
        "Produces AI prompts for generating comprehensive test plans for code files",
        "Generates AI prompts for creating actual test code from test plans"
      ],
      "developerVisibleActions": [
        "Developer calls prompt builder methods to generate LLM prompts for different analysis tasks",
        "System constructs architecture analysis prompts by combining code analysis, product docs, and context",
        "System builds product documentation prompts from project context and file structure",
        "System generates file-specific analysis prompts including code content and role information",
        "System creates module rollup prompts aggregating file summaries within a module",
        "System produces product-level documentation prompts combining all summaries and analysis",
        "System generates test planning prompts with function metadata and existing test information",
        "System creates test code generation prompts with test plans and source code references",
        "All prompts include token budgets and structured output requirements for consistent LLM responses"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure",
          "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
          "outputs": "Formatted string prompt with architecture analysis instructions and context"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Creates a prompt for generating product-level documentation from code structure",
          "inputs": "context (AnalysisContext)",
          "outputs": "Formatted string prompt requesting product documentation generation"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Generates a prompt for determining product purpose, target audience, and value proposition",
          "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
          "outputs": "Formatted string prompt for product purpose analysis"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Creates a prompt for analyzing a single code file's behavior and purpose",
          "inputs": "file (FileInfo), content (string), role (string)",
          "outputs": "Formatted string prompt with file content and analysis instructions"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Generates a prompt for summarizing a module by aggregating its file summaries",
          "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
          "outputs": "Formatted string prompt for module-level summary generation"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Creates a comprehensive prompt for product-level documentation combining all analysis results",
          "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper",
          "outputs": "Formatted string prompt for complete product documentation"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Generates a prompt for creating a test plan for a specific file's functions",
          "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
          "outputs": "Formatted string prompt requesting structured test plan generation"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Creates a prompt for generating actual test code from a test plan item",
          "inputs": "testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)",
          "outputs": "Formatted string prompt with test plan and code context for test generation"
        }
      ],
      "dependencies": [
        "../../llmService (AnalysisContext, ProductPurposeAnalysis)",
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)",
        "../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)",
        "../../fileAccessHelper (FileAccessHelper)"
      ],
      "intent": "This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction service that generates structured prompts for all LLM-based code analysis tasks including architecture analysis, documentation generation, and test planning.\",\n  \"userVisibleActions\": [\n    \"Generates AI prompts that analyze project architecture and structure\",\n    \"Creates AI prompts for generating product documentation from code\",\n    \"Produces AI prompts that determine product purpose and target audience\",\n    \"Generates AI prompts for analyzing individual code files\",\n    \"Creates AI prompts for summarizing code modules and their relationships\",\n    \"Produces AI prompts for generating comprehensive test plans for code files\",\n    \"Generates AI prompts for creating actual test code from test plans\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls prompt builder methods to generate LLM prompts for different analysis tasks\",\n    \"System constructs architecture analysis prompts by combining code analysis, product docs, and context\",\n    \"System builds product documentation prompts from project context and file structure\",\n    \"System generates file-specific analysis prompts including code content and role information\",\n    \"System creates module rollup prompts aggregating file summaries within a module\",\n    \"System produces product-level documentation prompts combining all summaries and analysis\",\n    \"System generates test planning prompts with function metadata and existing test information\",\n    \"System creates test code generation prompts with test plans and source code references\",\n    \"All prompts include token budgets and structured output requirements for consistent LLM responses\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs a comprehensive prompt for LLM to analyze project architecture, patterns, and structure\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt with architecture analysis instructions and context\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Creates a prompt for generating product-level documentation from code structure\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt requesting product documentation generation\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Generates a prompt for determining product purpose, target audience, and value proposition\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for product purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Creates a prompt for analyzing a single code file's behavior and purpose\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted string prompt with file content and analysis instructions\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Generates a prompt for summarizing a module by aggregating its file summaries\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted string prompt for module-level summary generation\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for product-level documentation combining all analysis results\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for complete product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Generates a prompt for creating a test plan for a specific file's functions\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted string prompt requesting structured test plan generation\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Creates a prompt for generating actual test code from a test plan item\",\n      \"inputs\": \"testPlanItem (any), sourceCode (string), functionCode (string), language (string), testFramework (string)\",\n      \"outputs\": \"Formatted string prompt with test plan and code context for test generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService (AnalysisContext, ProductPurposeAnalysis)\",\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata, TestMapping)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation, FileSummary, ModuleSummary)\",\n    \"../../fileAccessHelper (FileAccessHelper)\"\n  ],\n  \"intent\": \"This file exists to eliminate prompt duplication across the codebase by centralizing all LLM prompt construction logic into a single reusable service. It solves the problem of inconsistent prompt formatting and makes it easier to maintain and update prompts used throughout the application's AI-powered code analysis features.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations showing which code should be extracted and where",
        "Gets step-by-step migration instructions for moving code between files",
        "Sees before-and-after code examples demonstrating proposed refactorings",
        "Views function dependency relationships to understand refactoring impacts",
        "Receives prescriptive guidance on how to organize code into better structures"
      ],
      "developerVisibleActions": [
        "Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions",
        "Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance",
        "Receives structured extraction plans showing which functions to move from source to target files",
        "Gets migration steps and code examples to execute the refactoring safely",
        "Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]",
          "outputs": "Formatted string prompt containing refactoring instructions and requirements"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Creates the foundation prompt with context, code analysis, and architectural insights",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
          "outputs": "Base prompt string"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Adds detailed function-level analysis including dependencies and responsibilities to the prompt",
          "inputs": "FunctionAnalysis[]",
          "outputs": "Formatted section describing function characteristics"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Specifies requirements for code extraction plans including target files and migration steps",
          "inputs": "None",
          "outputs": "Section detailing extraction plan requirements"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed, prescriptive prompts for generating AI-driven code refactoring reports with extraction plans and migration guidance.\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations showing which code should be extracted and where\",\n    \"Gets step-by-step migration instructions for moving code between files\",\n    \"Sees before-and-after code examples demonstrating proposed refactorings\",\n    \"Views function dependency relationships to understand refactoring impacts\",\n    \"Receives prescriptive guidance on how to organize code into better structures\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls buildDetailedRefactoringPrompt() with code analysis context to generate refactoring instructions\",\n    \"Provides function analyses, product documentation, and architecture insights to enrich refactoring guidance\",\n    \"Receives structured extraction plans showing which functions to move from source to target files\",\n    \"Gets migration steps and code examples to execute the refactoring safely\",\n    \"Uses function metadata (dependencies, dependents, responsibilities) to inform extraction decisions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Generates a comprehensive prompt for AI to create detailed refactoring reports with extraction plans\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis[]\",\n      \"outputs\": \"Formatted string prompt containing refactoring instructions and requirements\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundation prompt with context, code analysis, and architectural insights\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Adds detailed function-level analysis including dependencies and responsibilities to the prompt\",\n      \"inputs\": \"FunctionAnalysis[]\",\n      \"outputs\": \"Formatted section describing function characteristics\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Specifies requirements for code extraction plans including target files and migration steps\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Section detailing extraction plan requirements\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to construct sophisticated AI prompts that guide language models in generating actionable, detailed refactoring recommendations. It solves the problem of getting generic or vague refactoring advice by providing structured context about code dependencies, function responsibilities, and architectural patterns, ensuring the AI produces specific extraction plans with concrete migration steps and code examples.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt templates for LLM-based automated test generation and test configuration setup",
      "userVisibleActions": [
        "Automatically generates test setup recommendations for the codebase",
        "Creates prioritized test plans identifying which functions need testing",
        "Generates actual test code with assertions and edge cases",
        "Analyzes codebase to determine optimal testing framework and dependencies"
      ],
      "developerVisibleActions": [
        "Call buildSetupPrompt() to get LLM prompt for test configuration analysis",
        "Call buildPlanningPrompt() to get LLM prompt for test strategy creation",
        "Call buildGenerationPrompt() to get LLM prompt for actual test code generation",
        "Provide workspace root, file lists, and function details as inputs",
        "Receive structured JSON responses with test setup configurations, test plans, or generated test code",
        "Pass in optional product documentation and architecture insights to improve test generation quality"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates prompt for LLM to analyze codebase and recommend test setup configuration",
          "inputs": "workspaceRoot (string), fileList (array), optional packageJsonContent (string)",
          "outputs": "Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates prompt for LLM to generate prioritized test plan for functions",
          "inputs": "context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights",
          "outputs": "Formatted prompt string requesting prioritized list of functions to test with complexity assessments"
        },
        {
          "name": "buildGenerationPrompt",
          "desc": "Creates prompt for LLM to generate actual test code for specific function",
          "inputs": "testableFunction (TestableFunction), framework (string), optional fileContext (string)",
          "outputs": "Formatted prompt string requesting complete test code with imports, mocks, and assertions"
        }
      ],
      "dependencies": [
        "../../analyzer",
        "../services/testing/types/testPlanTypes"
      ],
      "intent": "Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based automated test generation and test configuration setup\",\n  \"userVisibleActions\": [\n    \"Automatically generates test setup recommendations for the codebase\",\n    \"Creates prioritized test plans identifying which functions need testing\",\n    \"Generates actual test code with assertions and edge cases\",\n    \"Analyzes codebase to determine optimal testing framework and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() to get LLM prompt for test configuration analysis\",\n    \"Call buildPlanningPrompt() to get LLM prompt for test strategy creation\",\n    \"Call buildGenerationPrompt() to get LLM prompt for actual test code generation\",\n    \"Provide workspace root, file lists, and function details as inputs\",\n    \"Receive structured JSON responses with test setup configurations, test plans, or generated test code\",\n    \"Pass in optional product documentation and architecture insights to improve test generation quality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates prompt for LLM to analyze codebase and recommend test setup configuration\",\n      \"inputs\": \"workspaceRoot (string), fileList (array), optional packageJsonContent (string)\",\n      \"outputs\": \"Formatted prompt string requesting language detection, framework recommendation, dependencies, and configuration files\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate prioritized test plan for functions\",\n      \"inputs\": \"context (AnalysisContext), functions (array), optional productDocs, optional architectureInsights\",\n      \"outputs\": \"Formatted prompt string requesting prioritized list of functions to test with complexity assessments\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates prompt for LLM to generate actual test code for specific function\",\n      \"inputs\": \"testableFunction (TestableFunction), framework (string), optional fileContext (string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test code with imports, mocks, and assertions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"Serves as the bridge between the test generation system and LLMs by providing structured, context-rich prompts that guide AI models to analyze codebases, create test strategies, and generate actual test code with appropriate frameworks, dependencies, and configurations\"\n}\n```"
    }
  ],
  "endpoints": [],
  "commands": [],
  "workers": [],
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:39:36.677Z"
  }
}