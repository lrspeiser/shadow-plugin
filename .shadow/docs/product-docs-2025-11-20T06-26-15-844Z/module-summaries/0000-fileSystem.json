{
  "module": "src/infrastructure/fileSystem",
  "moduleType": "other",
  "capabilities": [
    "Accelerates file operations through intelligent in-memory caching",
    "Automatically filters out non-source directories and files during processing",
    "Processes multiple files simultaneously for improved performance",
    "Detects file changes automatically to ensure content accuracy",
    "Handles file processing errors gracefully without disrupting workflows"
  ],
  "summary": "The fileSystem module provides high-performance file operations for the extension through intelligent caching and parallel processing. It ensures users experience fast, responsive file access by maintaining an in-memory cache that automatically detects and reflects file changes, eliminating redundant disk reads when analyzing or processing the same files multiple times.\n\nWhen working with multiple files, the module automatically filters out common non-source directories (node_modules, .git, dist, build, etc.) to focus on relevant source code. It processes files in parallel for maximum throughput while maintaining robust error handling that prevents individual file failures from disrupting entire operations. This results in faster analysis, smoother navigation, and more reliable file operations throughout the extension.\n\nThe module serves as the foundation for all file-based operations in the extension, providing a unified system that balances performance with accuracy. Users benefit from near-instantaneous access to previously opened files while always seeing current content, making workflows like code analysis, documentation generation, and multi-file operations significantly faster and more efficient.",
  "files": [
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Caches file contents in memory to avoid redundant disk reads and improve performance across the extension",
      "userVisibleActions": [
        "File operations complete faster when accessing previously opened files",
        "Extension responds more quickly when analyzing or processing the same files multiple times",
        "Automatic detection of file changes ensures users always see current content"
      ],
      "developerVisibleActions": [
        "Retrieve file contents with automatic caching via getFile()",
        "Cache automatically invalidates when files are modified, created, or deleted",
        "LRU (Least Recently Used) eviction policy manages memory usage automatically",
        "File system watcher monitors changes and keeps cache synchronized",
        "Cache statistics track hits, misses, evictions, and memory usage",
        "Configurable maximum cache size and time-to-live (TTL) settings"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "constructor",
          "desc": "Initializes the cache with configurable size limit and TTL, sets up file system watcher",
          "inputs": "maxSize: number (default 500), ttl: number (default 5000ms)",
          "outputs": "FileCache instance"
        },
        {
          "name": "isStale",
          "desc": "Checks if cached entry has exceeded its time-to-live period",
          "inputs": "cached: CachedFile",
          "outputs": "boolean - true if stale"
        },
        {
          "name": "setupWatcher",
          "desc": "Creates file system watcher to automatically invalidate cache entries when files change",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "evictIfNeeded",
          "desc": "Removes least recently used cache entries when cache exceeds maximum size",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getFileHash",
          "desc": "Computes hash of file to detect content changes",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file hash"
        },
        {
          "name": "readFileFromDisk",
          "desc": "Reads file content directly from filesystem",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.",
      "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to avoid redundant disk reads and improve performance across the extension\",\n  \"userVisibleActions\": [\n    \"File operations complete faster when accessing previously opened files\",\n    \"Extension responds more quickly when analyzing or processing the same files multiple times\",\n    \"Automatic detection of file changes ensures users always see current content\"\n  ],\n  \"developerVisibleActions\": [\n    \"Retrieve file contents with automatic caching via getFile()\",\n    \"Cache automatically invalidates when files are modified, created, or deleted\",\n    \"LRU (Least Recently Used) eviction policy manages memory usage automatically\",\n    \"File system watcher monitors changes and keeps cache synchronized\",\n    \"Cache statistics track hits, misses, evictions, and memory usage\",\n    \"Configurable maximum cache size and time-to-live (TTL) settings\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes the cache with configurable size limit and TTL, sets up file system watcher\",\n      \"inputs\": \"maxSize: number (default 500), ttl: number (default 5000ms)\",\n      \"outputs\": \"FileCache instance\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Checks if cached entry has exceeded its time-to-live period\",\n      \"inputs\": \"cached: CachedFile\",\n      \"outputs\": \"boolean - true if stale\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Creates file system watcher to automatically invalidate cache entries when files change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used cache entries when cache exceeds maximum size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getFileHash\",\n      \"desc\": \"Computes hash of file to detect content changes\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file hash\"\n    },\n    {\n      \"name\": \"readFileFromDisk\",\n      \"desc\": \"Reads file content directly from filesystem\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"Eliminates redundant file system reads by caching file contents, improving extension performance when multiple components need to access the same files. Maintains cache validity through automatic invalidation on file changes and TTL expiration.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling",
      "userVisibleActions": [
        "Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)",
        "Multiple files are processed simultaneously for faster performance",
        "File processing errors are handled gracefully without crashing the application"
      ],
      "developerVisibleActions": [
        "Developer calls processFiles() with an array of file paths and a custom processor function",
        "Files are automatically filtered based on configurable patterns before processing",
        "Each file's content is read and passed to the developer's processor function",
        "Results are collected and returned as an array in the same order as input files",
        "Developer can inject custom file filters and file readers for testing or specialized behavior",
        "Error context can be provided for detailed error tracking and debugging"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines if a file should be processed based on its path",
          "inputs": "filePath: string",
          "outputs": "boolean indicating if file should be processed"
        },
        {
          "name": "readFile",
          "desc": "Reads the content of a file asynchronously",
          "inputs": "filePath: string",
          "outputs": "Promise<string> containing file content"
        },
        {
          "name": "processFiles",
          "desc": "Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each",
          "inputs": "files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext",
          "outputs": "Promise<T[]> containing processed results for each file"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../utils/errorHandler"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with consistent error handling\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip common non-source directories (node_modules, .git, dist, build, etc.)\",\n    \"Multiple files are processed simultaneously for faster performance\",\n    \"File processing errors are handled gracefully without crashing the application\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls processFiles() with an array of file paths and a custom processor function\",\n    \"Files are automatically filtered based on configurable patterns before processing\",\n    \"Each file's content is read and passed to the developer's processor function\",\n    \"Results are collected and returned as an array in the same order as input files\",\n    \"Developer can inject custom file filters and file readers for testing or specialized behavior\",\n    \"Error context can be provided for detailed error tracking and debugging\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on its path\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean indicating if file should be processed\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads the content of a file asynchronously\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> containing file content\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel by filtering, reading, and applying a custom processor function to each\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, optional context: ErrorContext\",\n      \"outputs\": \"Promise<T[]> containing processed results for each file\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a single, consistent, and reusable abstraction for filtering files, reading their contents, and processing them in parallel with proper error handling\"\n}\n```"
    }
  ],
  "endpoints": [],
  "commands": [],
  "workers": [],
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T06:40:16.918Z"
  }
}