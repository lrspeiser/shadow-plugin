{
  "overview": "Shadow Watch is a VS Code extension that provides AI-powered code intelligence and automated documentation for software development teams. The extension analyzes codebases to understand their architecture, purpose, and potential issues, then generates comprehensive insights and documentation automatically. Users interact with Shadow Watch primarily through VS Code's sidebar panels and command palette, where they can trigger analysis, view results in interactive tree views, and navigate directly to relevant code sections. The extension connects to AI services (OpenAI GPT or Anthropic Claude) to generate intelligent insights about code quality, architecture patterns, testability, and documentation.\n\nThe extension serves as an intelligent assistant that continuously monitors your codebase and provides actionable feedback. When you save files, Shadow Watch can automatically re-analyze them and update insights in real-time. It identifies code quality issues like large files, orphaned code, circular dependencies, and god objects, presenting these as inline diagnostics directly in your editor with specific line numbers and remediation suggestions. The extension also generates product-level documentation that explains what your application does, how components interact, and what workflows it supports.\n\nShadow Watch streamlines multiple development workflows including code review, documentation creation, test planning, and refactoring. Users can generate comprehensive test plans with AI-recommended test cases, receive step-by-step refactoring guidance for complex code, and export analysis results as formatted reports. The extension caches results for 24 hours to ensure fast subsequent loads, and all insights can be formatted for different AI assistants (Cursor, ChatGPT) or exported as standalone HTML reports.",
  "whatItDoes": [
    "Analyzes codebases to identify code quality issues, architectural patterns, and potential improvements",
    "Generates comprehensive product documentation explaining what your application does and how it works",
    "Creates AI-powered test plans identifying which functions need testing and recommending test strategies",
    "Provides inline diagnostics showing code issues directly in your editor with specific locations and fixes",
    "Automatically generates unit tests for your code using AI analysis of function behavior",
    "Validates and auto-fixes failing tests by analyzing failures and regenerating corrected test code",
    "Detects entry points including main functions, CLI tools, and test files across your codebase",
    "Navigates you directly to functions, endpoints, and code sections when you click items in tree views",
    "Monitors file changes and automatically re-analyzes code when you save files",
    "Exports analysis results and documentation as formatted reports for sharing with your team",
    "Provides architecture insights explaining component relationships and design patterns in your code",
    "Generates refactoring recommendations with before/after code examples and migration steps",
    "Formats insights for specific AI assistants to improve code generation and review workflows"
  ],
  "userPerspective": {
    "gui": [
      "View code analysis results in an interactive tree structure showing files, functions, and dependencies",
      "See inline warnings and errors directly in your editor highlighting specific code issues",
      "Browse AI-generated insights about your codebase architecture in a dedicated sidebar panel",
      "Navigate product documentation organized by features, modules, and components",
      "Review test plans showing which functions need testing and why",
      "Monitor test generation progress with real-time status updates",
      "Click any code element to jump directly to its location in your editor",
      "Export analysis results and documentation as HTML reports",
      "Toggle analyze-on-save to automatically update insights when files change",
      "Switch between OpenAI and Claude AI providers through settings"
    ],
    "cli": [
      "Trigger codebase analysis through VS Code command palette",
      "Generate product documentation on-demand via commands",
      "Create test plans for your codebase using commands",
      "Run automated test generation for specific files or entire projects",
      "Clear cached analysis results to force fresh analysis",
      "Copy insights to clipboard for sharing or documentation",
      "Switch LLM providers between OpenAI and Claude"
    ],
    "api": [
      "Connect to OpenAI GPT models for AI-powered code analysis",
      "Integrate with Anthropic Claude for alternative AI analysis",
      "Submit code for analysis and receive structured insights",
      "Request file content or search patterns during iterative analysis",
      "Generate documentation in multiple formats optimized for different tools"
    ],
    "cicd": [
      "Integrate automated test generation into CI pipelines",
      "Export analysis results for build-time quality checks",
      "Generate documentation as part of release processes",
      "Validate test coverage and quality metrics"
    ]
  },
  "workflowIntegration": [
    "Code review workflow: Analyze code before review to identify issues and generate documentation for reviewers",
    "Documentation workflow: Automatically generate and maintain product documentation as code evolves",
    "Test-driven development: Generate test plans and test code to increase coverage systematically",
    "Refactoring workflow: Receive AI-guided refactoring recommendations with specific extraction plans",
    "Onboarding workflow: Help new developers understand codebase architecture through AI-generated insights",
    "Quality assurance workflow: Continuously monitor code quality with automatic analysis on save",
    "CI/CD integration: Generate tests and documentation as part of automated build pipelines",
    "Technical debt workflow: Identify and track code quality issues with prioritized remediation steps"
  ],
  "problemsSolved": [
    "Eliminates manual documentation creation by automatically generating comprehensive product and architecture documentation",
    "Reduces time spent understanding unfamiliar codebases by providing AI-powered architecture insights and navigation",
    "Increases test coverage by automatically generating test plans and test code for functions",
    "Saves code review time by automatically identifying quality issues before human review",
    "Prevents technical debt accumulation by continuously monitoring for code smells and anti-patterns",
    "Reduces onboarding time for new developers by providing clear documentation and architecture explanations",
    "Eliminates guesswork in refactoring by providing AI-analyzed extraction plans and migration steps",
    "Automates test maintenance by detecting and auto-fixing failing tests",
    "Prevents API rate limit issues when using AI services through intelligent throttling and retry logic",
    "Reduces context switching by providing all insights within VS Code without external tools"
  ],
  "architecture": "Shadow Watch follows a modular architecture organized around core capabilities: code analysis, AI integration, UI presentation, and persistence. The analysis engine parses code into abstract syntax trees to extract detailed metadata about functions, dependencies, complexity, and behavioral patterns. This structural analysis feeds into an AI integration layer that communicates with LLM providers (OpenAI or Claude) to generate intelligent insights about architecture, code quality, and documentation. The AI layer includes rate limiting, retry logic, and response parsing to ensure reliable operation even under challenging network conditions.\n\nThe UI layer consists of multiple tree view providers that present analysis results, insights, test plans, and documentation in VS Code's sidebar. A diagnostics provider surfaces code quality issues as inline editor warnings with specific line numbers and remediation suggestions. Navigation handlers enable users to jump directly from tree views to relevant code locations. All components communicate through a command registry and event system that coordinates user actions across the extension.\n\nPersistence and caching layers optimize performance by storing analysis results and AI-generated insights to disk, eliminating redundant processing. A file watcher monitors workspace changes and triggers automatic re-analysis when configured. Progress notifications keep users informed during long-running operations like test generation or comprehensive codebase analysis. The architecture supports iterative AI analysis where the system can request additional files or search results across multiple conversation rounds to build comprehensive understanding.",
  "titles": [
    "Code Analysis Engine",
    "AI Integration Layer",
    "Insights Viewer",
    "Product Navigator",
    "Unit Tests Navigator",
    "Analysis Viewer",
    "Reports Viewer",
    "Static Analysis Viewer",
    "Inline Diagnostics",
    "Rate Limiter",
    "Response Parser",
    "Retry Handler",
    "Test Generation Service",
    "Test Planning Service",
    "Test Setup Service",
    "Test Validation Service",
    "Test Execution Service",
    "Documentation Formatter",
    "Navigation Handler",
    "Prompt Builder",
    "File Watcher Service",
    "Incremental Analysis Service",
    "Configuration Manager",
    "Progress Service",
    "Cache Manager",
    "File Access Helper",
    "Architecture Insights",
    "Product Documentation",
    "Refactoring Recommendations",
    "Test Plans",
    "Code Quality Detection",
    "Entry Point Detection",
    "Dependency Analysis",
    "Function Analysis",
    "Module Analysis",
    "Enhanced Analyzer",
    "Function Analyzer",
    "LLM State Manager",
    "Incremental Storage",
    "Error Handler",
    "JSON Extractor",
    "Analysis Context Builder",
    "Analysis Result Repository",
    "File Cache",
    "File Processor",
    "Command Registry",
    "Extension Bootstrapper",
    "Refactoring Prompt Builder",
    "Test Prompts",
    "Test Configuration Service",
    "Analyze on Save",
    "Copy to Clipboard",
    "Clear Cache",
    "Switch LLM Provider",
    "Generate Test Plan",
    "Generate Tests",
    "Validate Tests",
    "Export Reports"
  ],
  "descriptions": [
    {
      "title": "Code Analysis Engine",
      "description": "Parses source code to extract comprehensive metadata about files, functions, dependencies, imports, exports, and entry points. Builds a complete picture of codebase structure and relationships.",
      "category": "component"
    },
    {
      "title": "AI Integration Layer",
      "description": "Manages communication with LLM providers (OpenAI, Claude) including rate limiting, retry logic, and response parsing. Ensures reliable AI operations even under challenging conditions.",
      "category": "component"
    },
    {
      "title": "Insights Viewer",
      "description": "Interactive tree view displaying AI-generated architecture insights, code quality issues, and recommendations. Users can browse insights and navigate to relevant code sections.",
      "category": "feature"
    },
    {
      "title": "Product Navigator",
      "description": "Tree view showing product-level documentation organized by features, modules, components, and workflows. Enables quick navigation to understand what the application does.",
      "category": "feature"
    },
    {
      "title": "Unit Tests Navigator",
      "description": "Displays test plans, test generation progress, and test results. Shows which functions are tested, test coverage, and validation status.",
      "category": "feature"
    },
    {
      "title": "Analysis Viewer",
      "description": "Tree view presenting code analysis results including file statistics, function lists, imports, exports, and entry points. Provides structural overview of the codebase.",
      "category": "feature"
    },
    {
      "title": "Reports Viewer",
      "description": "Displays generated reports including documentation, test reports, and analysis summaries. Enables export to HTML for sharing with teams.",
      "category": "feature"
    },
    {
      "title": "Inline Diagnostics",
      "description": "Shows code quality issues as warnings, errors, or info messages directly in the editor at specific line numbers. Each diagnostic includes description and recommended fix.",
      "category": "feature"
    },
    {
      "title": "Rate Limiter",
      "description": "Tracks and throttles LLM API requests to prevent rate limit errors. Manages separate limits for different providers (OpenAI, Claude) and adjusts throttling automatically.",
      "category": "component"
    },
    {
      "title": "Response Parser",
      "description": "Transforms raw LLM text responses into structured data objects. Extracts JSON from markdown code blocks, validates against schemas, and handles parsing errors gracefully.",
      "category": "component"
    },
    {
      "title": "Retry Handler",
      "description": "Implements exponential backoff retry logic for failed LLM requests. Automatically retries on rate limits, timeouts, and transient errors without user intervention.",
      "category": "component"
    },
    {
      "title": "Test Generation Service",
      "description": "Generates unit test code incrementally using AI analysis of function behavior. Processes functions in small batches and provides progress updates during generation.",
      "category": "feature"
    },
    {
      "title": "Test Planning Service",
      "description": "Analyzes codebase to identify testable functions and creates prioritized test plans. Recommends testing strategies based on code complexity and importance.",
      "category": "feature"
    },
    {
      "title": "Test Setup Service",
      "description": "Automatically detects test framework (Jest, Mocha, Vitest, Pytest), configuration files, and test directories. Identifies missing dependencies and setup requirements.",
      "category": "feature"
    },
    {
      "title": "Test Validation Service",
      "description": "Validates generated tests by executing them and analyzing failures. Automatically regenerates failing tests with AI-powered fixes until tests pass.",
      "category": "feature"
    },
    {
      "title": "Test Execution Service",
      "description": "Runs test suites and captures detailed results including pass/fail counts, error messages, and stack traces. Supports multiple test frameworks.",
      "category": "feature"
    },
    {
      "title": "Documentation Formatter",
      "description": "Converts structured documentation data into polished Markdown format. Organizes content into sections including overview, architecture, usage, and insights.",
      "category": "component"
    },
    {
      "title": "Navigation Handler",
      "description": "Handles user clicks on tree view items to open files and navigate to specific code locations. Positions cursor at target line and highlights relevant code.",
      "category": "component"
    },
    {
      "title": "Prompt Builder",
      "description": "Constructs detailed prompts for LLM analysis tasks including architecture analysis, documentation generation, and test planning. Includes relevant code context and instructions.",
      "category": "component"
    },
    {
      "title": "File Watcher Service",
      "description": "Monitors workspace for file changes and triggers automatic re-analysis when files are saved. Enables real-time insights updates as code evolves.",
      "category": "feature"
    },
    {
      "title": "Incremental Analysis Service",
      "description": "Manages iterative LLM analysis sessions where the system can request additional files or search results across multiple conversation rounds.",
      "category": "component"
    },
    {
      "title": "Configuration Manager",
      "description": "Manages all extension settings including LLM provider selection, API keys, analyze-on-save toggle, severity thresholds, and output formats. Notifies components when settings change.",
      "category": "component"
    },
    {
      "title": "Analyze on Save",
      "description": "Automatically triggers code analysis and insight generation whenever you save a file. Keeps insights synchronized with your latest code changes.",
      "category": "feature"
    },
    {
      "title": "Copy to Clipboard",
      "description": "Copies analysis results, insights, or documentation to clipboard in formats optimized for specific AI assistants (Cursor, ChatGPT, Generic, Compact).",
      "category": "feature"
    },
    {
      "title": "Clear Cache",
      "description": "Removes cached analysis results to force fresh analysis. Useful when you want to regenerate all insights from scratch.",
      "category": "feature"
    },
    {
      "title": "Switch LLM Provider",
      "description": "Changes the AI provider between OpenAI and Claude. Allows you to use different models for analysis and compare results.",
      "category": "feature"
    },
    {
      "title": "Generate Test Plan",
      "description": "Analyzes your codebase to create a comprehensive test plan identifying which functions need tests and recommending testing strategies.",
      "category": "workflow"
    },
    {
      "title": "Generate Tests",
      "description": "Automatically writes unit test code for your functions using AI analysis. Generates tests incrementally with progress tracking.",
      "category": "workflow"
    },
    {
      "title": "Validate Tests",
      "description": "Executes generated tests and automatically fixes failures by regenerating test code until all tests pass.",
      "category": "workflow"
    },
    {
      "title": "Export Reports",
      "description": "Exports analysis results, documentation, and test reports as formatted HTML files for sharing with your team or including in documentation.",
      "category": "feature"
    },
    {
      "title": "Architecture Insights",
      "description": "AI-generated explanations of your codebase architecture including component relationships, design patterns, and architectural decisions.",
      "category": "feature"
    },
    {
      "title": "Product Documentation",
      "description": "Automatically generated documentation explaining what your application does, key features, user workflows, and problems solved.",
      "category": "feature"
    },
    {
      "title": "Refactoring Recommendations",
      "description": "AI-analyzed suggestions for improving code structure with specific extraction plans, before/after examples, and migration steps.",
      "category": "feature"
    },
    {
      "title": "Code Quality Detection",
      "description": "Automatically identifies issues like large files, orphaned code, circular dependencies, god objects, and other code smells.",
      "category": "feature"
    },
    {
      "title": "Entry Point Detection",
      "description": "Finds and categorizes entry points in your codebase including main functions, CLI tools, test files, and application initialization code.",
      "category": "feature"
    },
    {
      "title": "Dependency Analysis",
      "description": "Maps import and export relationships across your codebase to understand module dependencies and coupling.",
      "category": "feature"
    },
    {
      "title": "Function Analysis",
      "description": "Extracts detailed metadata about functions including signatures, parameters, return types, complexity, side effects, and behavior patterns.",
      "category": "feature"
    },
    {
      "title": "Module Analysis",
      "description": "Groups related files into logical modules and analyzes module-level architecture, capabilities, and responsibilities.",
      "category": "feature"
    }
  ],
  "relevantFunctions": [
    {
      "name": "analyzeWorkspace",
      "description": "Triggers comprehensive codebase analysis including file parsing, dependency mapping, and quality detection",
      "module": "analyzer"
    },
    {
      "name": "generateProductDocumentation",
      "description": "Creates AI-powered product documentation explaining what the application does and how it works",
      "module": "llmIntegration"
    },
    {
      "name": "generateArchitectureInsights",
      "description": "Analyzes codebase structure to produce insights about architecture patterns, component relationships, and design decisions",
      "module": "llmService"
    },
    {
      "name": "generateTestPlan",
      "description": "Analyzes code to identify testable functions and creates prioritized test plans with recommended strategies",
      "module": "llmTestPlanningService"
    },
    {
      "name": "generateTests",
      "description": "Generates unit test code incrementally using AI analysis of function behavior and dependencies",
      "module": "llmTestGenerationService"
    },
    {
      "name": "validateTests",
      "description": "Executes tests and automatically regenerates failing tests with AI-powered fixes until they pass",
      "module": "llmTestValidationService"
    },
    {
      "name": "executeTests",
      "description": "Runs test suites (Jest, Pytest) and captures detailed execution results",
      "module": "testExecutionService"
    },
    {
      "name": "navigateToLocation",
      "description": "Opens files and positions cursor at specific line numbers when users click tree view items",
      "module": "navigationHandler"
    },
    {
      "name": "formatDocumentation",
      "description": "Converts structured documentation data into polished, human-readable Markdown format",
      "module": "documentationFormatter"
    },
    {
      "name": "parseResponse",
      "description": "Extracts and validates structured data from raw LLM text responses",
      "module": "llmResponseParser"
    },
    {
      "name": "throttleRequest",
      "description": "Manages rate limiting for LLM API requests to prevent service disruptions",
      "module": "llmRateLimiter"
    },
    {
      "name": "retryWithBackoff",
      "description": "Implements exponential backoff retry logic for failed LLM requests",
      "module": "llmRetryHandler"
    },
    {
      "name": "detectTestFramework",
      "description": "Automatically identifies test framework configuration and missing dependencies",
      "module": "testConfigurationService"
    },
    {
      "name": "buildPrompt",
      "description": "Constructs detailed prompts for LLM analysis tasks with relevant code context",
      "module": "promptBuilder"
    },
    {
      "name": "watchFiles",
      "description": "Monitors workspace for file changes and triggers automatic re-analysis",
      "module": "fileWatcherService"
    },
    {
      "name": "cacheResults",
      "description": "Stores analysis results to disk to improve performance on subsequent loads",
      "module": "cache"
    },
    {
      "name": "extractFunctionMetadata",
      "description": "Parses function AST to extract signatures, dependencies, branches, and behavior patterns",
      "module": "enhancedAnalyzer"
    },
    {
      "name": "detectCodeQualityIssues",
      "description": "Identifies large files, orphaned code, circular dependencies, and other quality issues",
      "module": "insightGenerator"
    },
    {
      "name": "findEntryPoints",
      "description": "Locates and categorizes entry points including main functions, CLI tools, and test files",
      "module": "analyzer"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "AnalysisResult",
      "description": "Complete codebase analysis including files, functions, dependencies, quality metrics, and entry points",
      "type": "interface"
    },
    {
      "name": "FileAnalysis",
      "description": "Detailed analysis of a single file including functions, imports, exports, and metadata",
      "type": "interface"
    },
    {
      "name": "FunctionInfo",
      "description": "Function metadata including signature, parameters, return type, complexity, and behavior",
      "type": "interface"
    },
    {
      "name": "ProductDocumentation",
      "description": "AI-generated product documentation including overview, features, architecture, and workflows",
      "type": "interface"
    },
    {
      "name": "ArchitectureInsight",
      "description": "AI-generated insight about code architecture, patterns, or design decisions",
      "type": "interface"
    },
    {
      "name": "TestPlan",
      "description": "Comprehensive test plan including function groups, priorities, and recommended strategies",
      "type": "interface"
    },
    {
      "name": "TestResult",
      "description": "Test execution results including pass/fail counts, errors, and validation status",
      "type": "interface"
    },
    {
      "name": "CodeQualityIssue",
      "description": "Detected code quality issue with severity, location, description, and recommended fix",
      "type": "interface"
    },
    {
      "name": "LLMRequest",
      "description": "Structured request to LLM provider including messages, model, temperature, and response format",
      "type": "interface"
    },
    {
      "name": "LLMResponse",
      "description": "Parsed response from LLM including generated content and token usage",
      "type": "interface"
    },
    {
      "name": "EntryPoint",
      "description": "Identified entry point with type (main, CLI, test), file location, and description",
      "type": "interface"
    },
    {
      "name": "DependencyGraph",
      "description": "Map of import/export relationships showing module dependencies",
      "type": "interface"
    },
    {
      "name": "FunctionAnalysisDetail",
      "description": "Deep function analysis including branches, state mutations, dependencies, and behavioral hints",
      "type": "interface"
    },
    {
      "name": "TestGenerationState",
      "description": "Current state of test generation workflow including progress, completed functions, and errors",
      "type": "interface"
    },
    {
      "name": "TestSetupConfig",
      "description": "Detected test environment configuration including framework, directories, and dependencies",
      "type": "interface"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Extension entry point that initializes all components and registers commands",
      "purpose": "Coordinates extension activation and lifecycle management",
      "role": "Main entry point"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Performs comprehensive codebase analysis including file parsing and dependency mapping",
      "purpose": "Extracts structural information and metadata from code",
      "role": "Core analysis engine"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "Manages AI-powered analysis features and documentation generation",
      "purpose": "Coordinates LLM-based insights and documentation workflows",
      "role": "AI integration coordinator"
    },
    {
      "path": "src/llmService.ts",
      "description": "Handles communication with LLM providers to generate insights",
      "purpose": "Sends prompts to AI services and processes responses",
      "role": "AI service interface"
    },
    {
      "path": "src/insightsTreeView.ts",
      "description": "Displays AI-generated insights in interactive tree view",
      "purpose": "Presents architecture insights and quality issues to users",
      "role": "Insights UI component"
    },
    {
      "path": "src/productNavigator.ts",
      "description": "Shows product documentation in navigable tree structure",
      "purpose": "Enables users to browse product features and architecture",
      "role": "Documentation UI component"
    },
    {
      "path": "src/unitTestsNavigator.ts",
      "description": "Displays test plans, generation progress, and test results",
      "purpose": "Provides visibility into testing workflow and status",
      "role": "Testing UI component"
    },
    {
      "path": "src/diagnosticsProvider.ts",
      "description": "Shows code quality issues as inline editor warnings",
      "purpose": "Surfaces problems directly in code at specific line numbers",
      "role": "Diagnostics provider"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Generates unit test code using AI analysis",
      "purpose": "Automates test creation for functions",
      "role": "Test generation service"
    },
    {
      "path": "src/domain/services/testing/llmTestPlanningService.ts",
      "description": "Creates AI-powered test plans identifying functions to test",
      "purpose": "Provides testing strategy and priorities",
      "role": "Test planning service"
    },
    {
      "path": "src/domain/services/testing/llmTestValidationService.ts",
      "description": "Validates and auto-fixes failing tests",
      "purpose": "Ensures generated tests work correctly",
      "role": "Test validation service"
    },
    {
      "path": "src/ai/llmRateLimiter.ts",
      "description": "Prevents rate limit errors with AI providers",
      "purpose": "Manages API request throttling",
      "role": "Rate limiting component"
    },
    {
      "path": "src/ai/llmRetryHandler.ts",
      "description": "Handles retry logic for failed AI requests",
      "purpose": "Ensures reliable AI operations",
      "role": "Retry logic component"
    },
    {
      "path": "src/ai/llmResponseParser.ts",
      "description": "Parses structured data from AI text responses",
      "purpose": "Transforms AI output into usable data structures",
      "role": "Response parsing component"
    },
    {
      "path": "src/domain/formatters/documentationFormatter.ts",
      "description": "Formats documentation as polished Markdown",
      "purpose": "Makes AI-generated content human-readable",
      "role": "Documentation formatter"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Handles navigation from tree views to code locations",
      "purpose": "Opens files and positions cursor when users click items",
      "role": "Navigation handler"
    },
    {
      "path": "src/domain/prompts/promptBuilder.ts",
      "description": "Constructs prompts for all LLM analysis tasks",
      "purpose": "Provides context and instructions to AI services",
      "role": "Prompt engineering component"
    },
    {
      "path": "src/config/configurationManager.ts",
      "description": "Manages all extension settings and preferences",
      "purpose": "Provides centralized configuration access",
      "role": "Configuration manager"
    },
    {
      "path": "src/domain/services/fileWatcherService.ts",
      "description": "Monitors workspace for file changes",
      "purpose": "Triggers automatic re-analysis on save",
      "role": "File monitoring service"
    }
  ],
  "exampleInput": {
    "description": "Example API request to generate architecture insights for a codebase, showing the structure of analysis data provided to the LLM",
    "json": "{\"analysisResult\":{\"files\":[{\"path\":\"src/server.ts\",\"functions\":[{\"name\":\"startServer\",\"signature\":\"startServer(port: number): Promise<void>\",\"complexity\":15,\"dependencies\":[\"express\",\"database\"]},{\"name\":\"handleRequest\",\"signature\":\"handleRequest(req: Request, res: Response): void\",\"complexity\":8,\"dependencies\":[\"validator\"]}],\"imports\":[\"express\",\"./database\",\"./validator\"],\"exports\":[\"startServer\"],\"loc\":250}],\"totalFiles\":45,\"totalLOC\":12500,\"entryPoints\":[{\"type\":\"main\",\"file\":\"src/server.ts\",\"function\":\"startServer\"}],\"modules\":[{\"name\":\"server\",\"files\":[\"src/server.ts\",\"src/routes.ts\"],\"capabilities\":[\"HTTP request handling\",\"API routing\"]}]},\"prompt\":\"Analyze this web server codebase and provide insights about its architecture, design patterns, and potential improvements.\"}"
  },
  "exampleOutput": {
    "description": "Example product documentation generated by the extension, showing the structured output format that users see",
    "json": "{\"overview\":\"This is a REST API server application that provides user authentication and data management services. It handles HTTP requests, manages database connections, and implements JWT-based authentication. Users interact with the API through HTTP endpoints to create accounts, login, and manage resources.\",\"whatItDoes\":[\"Provides RESTful API endpoints for user management\",\"Authenticates users with JWT tokens\",\"Stores and retrieves data from PostgreSQL database\",\"Validates incoming requests and sanitizes data\"],\"architecture\":\"The application follows a three-tier architecture with clear separation between HTTP handling, business logic, and data persistence. The server layer processes incoming requests and routes them to appropriate handlers. The service layer implements business logic and coordinates between different components. The data layer manages database connections and executes queries.\",\"titles\":[\"User Authentication\",\"Data Management\",\"Request Validation\",\"Database Connection Pool\"],\"descriptions\":[{\"title\":\"User Authentication\",\"description\":\"JWT-based authentication system that validates credentials and issues tokens for authenticated sessions\",\"category\":\"feature\"},{\"title\":\"Data Management\",\"description\":\"CRUD operations for resources with validation and authorization checks\",\"category\":\"feature\"}],\"relevantFunctions\":[{\"name\":\"startServer\",\"description\":\"Initializes HTTP server, connects to database, and begins listening for requests\",\"file\":\"src/server.ts\"},{\"name\":\"authenticateUser\",\"description\":\"Validates user credentials and generates JWT token\",\"file\":\"src/auth.ts\"}],\"insights\":{\"architecturePatterns\":[\"Three-tier architecture with clear separation of concerns\",\"Dependency injection for testability\"],\"qualityIssues\":[{\"severity\":\"warning\",\"description\":\"Large file detected\",\"file\":\"src/server.ts\",\"recommendation\":\"Consider splitting into smaller modules\"}]}}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Provides Jest testing framework configuration for the project",
        "Enables TypeScript-based unit testing with ts-jest transformation",
        "Supports code coverage reporting with configurable thresholds",
        "Facilitates module resolution and import path mapping for tests"
      ],
      "summary": "This module configures the Jest testing framework for the project, enabling developers to write and execute unit tests for TypeScript code. It serves as the foundation for the project's testing infrastructure by defining how tests are discovered, executed, and reported.\n\nThe configuration establishes TypeScript support through ts-jest, allowing tests to be written in TypeScript and automatically transformed during execution. It includes coverage reporting capabilities that track code quality metrics and can enforce coverage thresholds to maintain testing standards.\n\nDevelopers benefit from this configuration through streamlined test execution, consistent module resolution that mirrors the application's import paths, and comprehensive coverage reports that identify untested code. While this is a development-time configuration file with no runtime impact, it directly enables the quality assurance workflow that ensures code reliability and maintainability.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest testing framework for TypeScript unit tests with coverage reporting and module resolution settings",
          "userVisibleActions": [
            "No direct user-facing actions - this is a development configuration file"
          ],
          "developerVisibleActions": [
            "Run unit tests in TypeScript using Jest with 'npm test' or 'jest' command",
            "View test coverage reports in text, lcov, and HTML formats in the 'coverage' directory",
            "Write tests in __tests__ directories or files ending in .spec.ts or .test.ts",
            "See test results execute in Node.js environment with 10-second timeout per test",
            "Access mocked VSCode API during testing through automated module mapping"
          ],
          "keyFunctions": [
            {
              "name": "testMatch",
              "desc": "Identifies test files to run based on naming patterns",
              "inputs": "File path patterns",
              "outputs": "Array of test file paths matching **/__tests__/**/*.ts or **/*.spec.ts or **/*.test.ts"
            },
            {
              "name": "transform",
              "desc": "Converts TypeScript files to JavaScript for test execution",
              "inputs": "TypeScript files with .ts extension",
              "outputs": "Transpiled JavaScript with ES2020 target and CommonJS modules"
            },
            {
              "name": "collectCoverageFrom",
              "desc": "Specifies which source files to include in code coverage analysis",
              "inputs": "Source file patterns",
              "outputs": "Coverage metrics excluding test files, type definitions, test utilities, and mocks"
            },
            {
              "name": "moduleNameMapper",
              "desc": "Redirects VSCode module imports to mock implementation during tests",
              "inputs": "Module import requests for 'vscode'",
              "outputs": "Mock VSCode module from src/test/__mocks__/vscode.ts"
            }
          ],
          "dependencies": [
            "ts-jest",
            "jest",
            "node"
          ],
          "intent": "This file exists to provide a standardized Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to run unit tests with proper TypeScript compilation, module resolution, and code coverage tracking while mocking VSCode APIs",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript unit tests with coverage reporting and module resolution settings\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this is a development configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run unit tests in TypeScript using Jest with 'npm test' or 'jest' command\",\n    \"View test coverage reports in text, lcov, and HTML formats in the 'coverage' directory\",\n    \"Write tests in __tests__ directories or files ending in .spec.ts or .test.ts\",\n    \"See test results execute in Node.js environment with 10-second timeout per test\",\n    \"Access mocked VSCode API during testing through automated module mapping\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Identifies test files to run based on naming patterns\",\n      \"inputs\": \"File path patterns\",\n      \"outputs\": \"Array of test file paths matching **/__tests__/**/*.ts or **/*.spec.ts or **/*.test.ts\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Converts TypeScript files to JavaScript for test execution\",\n      \"inputs\": \"TypeScript files with .ts extension\",\n      \"outputs\": \"Transpiled JavaScript with ES2020 target and CommonJS modules\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which source files to include in code coverage analysis\",\n      \"inputs\": \"Source file patterns\",\n      \"outputs\": \"Coverage metrics excluding test files, type definitions, test utilities, and mocks\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Redirects VSCode module imports to mock implementation during tests\",\n      \"inputs\": \"Module import requests for 'vscode'\",\n      \"outputs\": \"Mock VSCode module from src/test/__mocks__/vscode.ts\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"node\"\n  ],\n  \"intent\": \"This file exists to provide a standardized Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to run unit tests with proper TypeScript compilation, module resolution, and code coverage tracking while mocking VSCode APIs\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Automatically manages API rate limits across different LLM providers (OpenAI, Claude) to prevent service disruptions",
        "Parses unstructured AI responses into organized, structured data for file summaries, module summaries, and product documentation",
        "Provides resilient AI operations with automatic retry logic and exponential backoff for handling temporary failures",
        "Intelligently throttles requests to stay within provider-specific rate limits",
        "Handles transient errors (rate limits, timeouts, network issues) transparently without user intervention"
      ],
      "summary": "The AI module provides robust infrastructure for interacting with Large Language Model (LLM) APIs in a reliable and efficient manner. It ensures that AI-powered code analysis and documentation generation operations run smoothly by managing the complexities of external API communication. When you request AI analysis of your code, this module works behind the scenes to coordinate API calls, handle errors gracefully, and deliver structured results.\n\nThe module implements three critical safeguards for AI operations: rate limiting prevents your requests from being rejected by exceeding API quotas, intelligent parsing transforms raw AI text responses into organized data structures that the application can use, and automatic retry logic ensures temporary failures don't interrupt your workflow. These components work together to provide a seamless experience where AI operations 'just work' even when dealing with rate limits, network hiccups, or service timeouts.\n\nFor users, this means more reliable AI-powered documentation and analysis. Instead of encountering errors when the AI service is busy or rate limits are reached, requests are automatically queued, throttled, or retried as needed. The structured parsing ensures that AI-generated insights about your code are consistently formatted and easy to consume, whether you're viewing file summaries, module overviews, or product-level documentation.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Prevents LLM API requests from exceeding rate limits by tracking and throttling requests per provider",
          "userVisibleActions": [
            "API requests are automatically throttled to prevent hitting rate limits",
            "Requests may be delayed or rejected when rate limits are approached",
            "Different LLM providers (OpenAI, Claude) have different rate limits applied"
          ],
          "developerVisibleActions": [
            "Configure custom rate limits for OpenAI and Claude providers",
            "Check if a request can be made before calling the API",
            "Record successful API requests to track usage against limits",
            "Get information about remaining requests available",
            "Wait for rate limit windows to reset when limits are reached"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes rate limiter with default limits (OpenAI: 60 req/min, Claude: 50 req/min)",
              "inputs": "none",
              "outputs": "RateLimiter instance"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limit configuration for a specific LLM provider",
              "inputs": "provider (openai or claude), config (maxRequests, windowMs)",
              "outputs": "void"
            },
            {
              "name": "canMakeRequest",
              "desc": "Checks if a new request can be made without exceeding rate limits",
              "inputs": "provider (openai or claude)",
              "outputs": "boolean - true if request is allowed"
            },
            {
              "name": "recordRequest",
              "desc": "Records a request timestamp to track usage against rate limits",
              "inputs": "provider (openai or claude)",
              "outputs": "void"
            }
          ],
          "dependencies": [],
          "intent": "Prevents API rate limit errors by tracking and enforcing request quotas per LLM provider, ensuring the application stays within API usage limits and avoids service disruptions or additional costs from exceeding quotas",
          "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding rate limits by tracking and throttling requests per provider\",\n  \"userVisibleActions\": [\n    \"API requests are automatically throttled to prevent hitting rate limits\",\n    \"Requests may be delayed or rejected when rate limits are approached\",\n    \"Different LLM providers (OpenAI, Claude) have different rate limits applied\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure custom rate limits for OpenAI and Claude providers\",\n    \"Check if a request can be made before calling the API\",\n    \"Record successful API requests to track usage against limits\",\n    \"Get information about remaining requests available\",\n    \"Wait for rate limit windows to reset when limits are reached\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits (OpenAI: 60 req/min, Claude: 50 req/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (openai or claude), config (maxRequests, windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request can be made without exceeding rate limits\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"boolean - true if request is allowed\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a request timestamp to track usage against rate limits\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Prevents API rate limit errors by tracking and enforcing request quotas per LLM provider, ensuring the application stays within API usage limits and avoids service disruptions or additional costs from exceeding quotas\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Parses LLM text responses into structured data objects for file summaries, module summaries, and product documentation",
          "userVisibleActions": [
            "Receives structured analysis results from AI that describe code files in plain language",
            "Gets organized information about what code files do from a user perspective",
            "Views parsed product documentation with user-facing features and benefits"
          ],
          "developerVisibleActions": [
            "Calls parser methods to convert raw LLM response text into typed TypeScript objects",
            "Handles JSON-formatted LLM responses or falls back to text parsing if JSON fails",
            "Extracts file summaries with purpose, actions, functions, and dependencies from LLM output",
            "Parses module summaries that group related files together",
            "Converts LLM insights into structured analysis data with themes and patterns",
            "Processes product purpose analysis from LLM responses",
            "Generates enhanced product documentation by parsing LLM-generated content",
            "Deals with parsing errors gracefully by falling back to text extraction methods"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into a FileSummary object with purpose, actions, and dependencies",
              "inputs": "content (LLM response text), filePath, role",
              "outputs": "FileSummary object"
            },
            {
              "name": "parseModuleSummary",
              "desc": "Extracts module-level summary information from LLM response",
              "inputs": "content (LLM response text), moduleName",
              "outputs": "ModuleSummary object"
            },
            {
              "name": "parseLLMInsights",
              "desc": "Parses LLM analysis into structured insights with themes and patterns",
              "inputs": "content (LLM response text), context",
              "outputs": "LLMInsights object"
            },
            {
              "name": "parseProductPurpose",
              "desc": "Extracts product purpose analysis from LLM response",
              "inputs": "content (LLM response text)",
              "outputs": "ProductPurposeAnalysis object"
            },
            {
              "name": "parseEnhancedProductDoc",
              "desc": "Generates enhanced product documentation from LLM response",
              "inputs": "content (LLM response text), existingDocs",
              "outputs": "EnhancedProductDocumentation object"
            },
            {
              "name": "extractSection",
              "desc": "Extracts a specific section of text from LLM response by section name",
              "inputs": "content, sectionName",
              "outputs": "Extracted text string"
            },
            {
              "name": "extractListSection",
              "desc": "Extracts a list/array of items from a section in LLM response",
              "inputs": "content, sectionName",
              "outputs": "Array of strings"
            }
          ],
          "dependencies": [
            "../fileDocumentation",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript objects the application needs. It solves the problem of reliably extracting meaningful data from AI-generated content, handling both JSON and plain text formats, and providing fallback mechanisms when parsing fails.",
          "rawContent": "```json\n{\n  \"purpose\": \"Parses LLM text responses into structured data objects for file summaries, module summaries, and product documentation\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis results from AI that describe code files in plain language\",\n    \"Gets organized information about what code files do from a user perspective\",\n    \"Views parsed product documentation with user-facing features and benefits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls parser methods to convert raw LLM response text into typed TypeScript objects\",\n    \"Handles JSON-formatted LLM responses or falls back to text parsing if JSON fails\",\n    \"Extracts file summaries with purpose, actions, functions, and dependencies from LLM output\",\n    \"Parses module summaries that group related files together\",\n    \"Converts LLM insights into structured analysis data with themes and patterns\",\n    \"Processes product purpose analysis from LLM responses\",\n    \"Generates enhanced product documentation by parsing LLM-generated content\",\n    \"Deals with parsing errors gracefully by falling back to text extraction methods\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object with purpose, actions, and dependencies\",\n      \"inputs\": \"content (LLM response text), filePath, role\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level summary information from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Parses LLM analysis into structured insights with themes and patterns\",\n      \"inputs\": \"content (LLM response text), context\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductPurpose\",\n      \"desc\": \"Extracts product purpose analysis from LLM response\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"parseEnhancedProductDoc\",\n      \"desc\": \"Generates enhanced product documentation from LLM response\",\n      \"inputs\": \"content (LLM response text), existingDocs\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a specific section of text from LLM response by section name\",\n      \"inputs\": \"content, sectionName\",\n      \"outputs\": \"Extracted text string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array of items from a section in LLM response\",\n      \"inputs\": \"content, sectionName\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript objects the application needs. It solves the problem of reliably extracting meaningful data from AI-generated content, handling both JSON and plain text formats, and providing fallback mechanisms when parsing fails.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles retry logic with exponential backoff for LLM API requests that fail due to rate limits, timeouts, or temporary errors",
          "userVisibleActions": [
            "When an AI operation fails temporarily, the system automatically retries the request instead of showing an immediate error",
            "Rate limit errors and network timeouts are handled gracefully with automatic retries",
            "Long-running AI operations have built-in resilience against temporary service disruptions"
          ],
          "developerVisibleActions": [
            "Wrap any LLM API call with retry logic to handle transient failures automatically",
            "Configure retry behavior including max attempts, delay intervals, and which errors to retry",
            "Receive callbacks when retries occur to track retry attempts and errors",
            "Non-retryable errors (like invalid API keys) fail immediately without wasting retries",
            "Get back results with metadata about how many attempts were needed"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an async operation with automatic retry on failure, using exponential backoff between attempts",
              "inputs": "operation function to execute, optional retry configuration (maxRetries, delays, retryable error types, onRetry callback)",
              "outputs": "The successful result of the operation, or throws the final error if all retries exhausted"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines whether an error should trigger a retry based on error type and message content",
              "inputs": "error object, list of retryable error patterns",
              "outputs": "boolean indicating if the error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Provides resilience for LLM API calls by automatically retrying failed requests due to temporary issues like rate limits, network problems, or service unavailability, preventing users from experiencing failures that could be resolved by waiting and retrying",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles retry logic with exponential backoff for LLM API requests that fail due to rate limits, timeouts, or temporary errors\",\n  \"userVisibleActions\": [\n    \"When an AI operation fails temporarily, the system automatically retries the request instead of showing an immediate error\",\n    \"Rate limit errors and network timeouts are handled gracefully with automatic retries\",\n    \"Long-running AI operations have built-in resilience against temporary service disruptions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic to handle transient failures automatically\",\n    \"Configure retry behavior including max attempts, delay intervals, and which errors to retry\",\n    \"Receive callbacks when retries occur to track retry attempts and errors\",\n    \"Non-retryable errors (like invalid API keys) fail immediately without wasting retries\",\n    \"Get back results with metadata about how many attempts were needed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry on failure, using exponential backoff between attempts\",\n      \"inputs\": \"operation function to execute, optional retry configuration (maxRetries, delays, retryable error types, onRetry callback)\",\n      \"outputs\": \"The successful result of the operation, or throws the final error if all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines whether an error should trigger a retry based on error type and message content\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating if the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API calls by automatically retrying failed requests due to temporary issues like rate limits, network problems, or service unavailability, preventing users from experiencing failures that could be resolved by waiting and retrying\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Connect to multiple AI providers (OpenAI GPT models and Anthropic Claude models) through a unified interface",
        "Automatically select and initialize the appropriate AI provider based on user configuration and available API keys",
        "Send conversational messages with full conversation history to AI models for context-aware responses",
        "Receive both plain text responses and structured JSON data from AI models",
        "Request file content or search patterns from AI models during conversations",
        "Validate API keys automatically before making requests to prevent errors",
        "Switch between different AI providers transparently without changing application behavior",
        "Configure provider-specific settings including model selection and API keys"
      ],
      "summary": "This module provides a unified AI provider abstraction layer that enables users to interact with multiple AI language models (OpenAI GPT and Anthropic Claude) through a single consistent interface. Users can configure their preferred AI provider and API key in the extension settings, and the module automatically handles provider initialization, API key validation, and request routing.\n\nThe module supports both conversational interactions with full message history and structured data requests. Users can send prompts to AI models and receive either natural language responses or formatted JSON data depending on their needs. The provider factory automatically selects the appropriate AI service based on user configuration and validates that required API keys are present before attempting connections.\n\nAll AI interactions flow through a standardized interface that abstracts away provider-specific implementation details. This allows users to switch between OpenAI and Claude seamlessly, with the application handling differences in API formats, authentication methods, and response structures. The module ensures consistent behavior regardless of which underlying AI provider is being used, while still allowing access to provider-specific features like different model variants (GPT-4, Claude Sonnet, Opus, Haiku).",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines the standard interface for integrating different AI language model providers (OpenAI, Claude, etc.) into the application",
          "userVisibleActions": [
            "User can interact with different AI providers (OpenAI, Claude, custom) transparently without knowing which one is being used",
            "User receives text responses from AI models",
            "User receives structured JSON data responses from AI models",
            "User can send messages with conversation history to AI models",
            "User can request file content or search patterns from AI models"
          ],
          "developerVisibleActions": [
            "Developer implements this interface to add new AI provider support",
            "Developer checks if a provider is properly configured before use",
            "Developer sends text-based requests to any AI provider using a unified format",
            "Developer sends structured JSON requests with optional schemas",
            "Developer receives parsed JSON responses with optional file/grep requests",
            "Developer configures model parameters (temperature, max tokens, response format)",
            "Developer builds conversation flows with system, user, and assistant messages",
            "Developer gets provider name for logging or display purposes"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Verifies if the AI provider has valid API keys and is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating if provider is ready"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a conversation to the AI model and receives a text response",
              "inputs": "LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)",
              "outputs": "Promise<LLMResponse> with content, finish reason, and model info"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a request expecting structured JSON output, optionally validated against a schema",
              "inputs": "LLMRequestOptions and optional schema",
              "outputs": "Promise<StructuredOutputResponse<T>> with parsed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the name identifier of the AI provider",
              "inputs": "none",
              "outputs": "string with provider name"
            }
          ],
          "dependencies": [],
          "intent": "This interface exists to provide a unified abstraction layer over multiple AI providers, allowing the application to switch between different LLM services (OpenAI, Anthropic Claude, custom providers) without changing application code. It solves the problem of vendor lock-in and enables flexible AI provider configuration while maintaining consistent behavior across the application.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the standard interface for integrating different AI language model providers (OpenAI, Claude, etc.) into the application\",\n  \"userVisibleActions\": [\n    \"User can interact with different AI providers (OpenAI, Claude, custom) transparently without knowing which one is being used\",\n    \"User receives text responses from AI models\",\n    \"User receives structured JSON data responses from AI models\",\n    \"User can send messages with conversation history to AI models\",\n    \"User can request file content or search patterns from AI models\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add new AI provider support\",\n    \"Developer checks if a provider is properly configured before use\",\n    \"Developer sends text-based requests to any AI provider using a unified format\",\n    \"Developer sends structured JSON requests with optional schemas\",\n    \"Developer receives parsed JSON responses with optional file/grep requests\",\n    \"Developer configures model parameters (temperature, max tokens, response format)\",\n    \"Developer builds conversation flows with system, user, and assistant messages\",\n    \"Developer gets provider name for logging or display purposes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Verifies if the AI provider has valid API keys and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is ready\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a conversation to the AI model and receives a text response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, and model info\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a request expecting structured JSON output, optionally validated against a schema\",\n      \"inputs\": \"LLMRequestOptions and optional schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> with parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the name identifier of the AI provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to provide a unified abstraction layer over multiple AI providers, allowing the application to switch between different LLM services (OpenAI, Anthropic Claude, custom providers) without changing application code. It solves the problem of vendor lock-in and enables flexible AI provider configuration while maintaining consistent behavior across the application.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with Anthropic's Claude AI models for generating text responses and structured outputs",
          "userVisibleActions": [
            "User can interact with Claude AI models through the extension",
            "User receives AI-generated responses from Claude models (Sonnet, Opus, Haiku)",
            "User can configure Claude API key in settings to enable Claude provider",
            "User sees error messages when Claude API key is not configured",
            "User experiences AI conversations with system prompts and message history"
          ],
          "developerVisibleActions": [
            "Developer can send text generation requests to Claude models",
            "Developer can request structured JSON outputs with automatic validation",
            "Developer can specify system prompts to guide Claude's behavior",
            "Developer can provide conversation history with user and assistant messages",
            "Developer receives parsed JSON responses from Claude with validation",
            "Developer can choose between different Claude model variants (Sonnet, Opus, Haiku)",
            "Developer gets automatic retry with fallback when JSON parsing fails",
            "Developer can set custom token limits and timeouts for requests"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is configured and provider is ready to use",
              "inputs": "none",
              "outputs": "boolean indicating if provider is configured"
            },
            {
              "name": "getName",
              "desc": "Returns the identifier name for this provider",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a text generation request to Claude and returns the response",
              "inputs": "LLMRequestOptions with model, messages, system prompt, max tokens",
              "outputs": "LLMResponse with generated text content and token usage"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Requests structured JSON output from Claude with validation and retry logic",
              "inputs": "LLMRequestOptions with JSON schema requirements",
              "outputs": "StructuredOutputResponse with parsed JSON data or validation error"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Claude client with API key from configuration",
              "inputs": "none (reads from config)",
              "outputs": "none (initializes internal client)"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to provide a standardized interface for integrating Anthropic's Claude AI models into the extension. It solves the problem of abstracting away Claude-specific API details, handling message format conversion, managing API authentication, parsing structured outputs, and providing consistent error handling for Claude interactions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for generating text responses and structured outputs\",\n  \"userVisibleActions\": [\n    \"User can interact with Claude AI models through the extension\",\n    \"User receives AI-generated responses from Claude models (Sonnet, Opus, Haiku)\",\n    \"User can configure Claude API key in settings to enable Claude provider\",\n    \"User sees error messages when Claude API key is not configured\",\n    \"User experiences AI conversations with system prompts and message history\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can send text generation requests to Claude models\",\n    \"Developer can request structured JSON outputs with automatic validation\",\n    \"Developer can specify system prompts to guide Claude's behavior\",\n    \"Developer can provide conversation history with user and assistant messages\",\n    \"Developer receives parsed JSON responses from Claude with validation\",\n    \"Developer can choose between different Claude model variants (Sonnet, Opus, Haiku)\",\n    \"Developer gets automatic retry with fallback when JSON parsing fails\",\n    \"Developer can set custom token limits and timeouts for requests\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name for this provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text generation request to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, system prompt, max tokens\",\n      \"outputs\": \"LLMResponse with generated text content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests structured JSON output from Claude with validation and retry logic\",\n      \"inputs\": \"LLMRequestOptions with JSON schema requirements\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data or validation error\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude client with API key from configuration\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"none (initializes internal client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to provide a standardized interface for integrating Anthropic's Claude AI models into the extension. It solves the problem of abstracting away Claude-specific API details, handling message format conversion, managing API authentication, parsing structured outputs, and providing consistent error handling for Claude interactions.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses",
          "userVisibleActions": [
            "User's prompts are sent to OpenAI's GPT models for AI-powered responses",
            "User receives AI-generated text responses based on their input",
            "User can get structured JSON responses when requesting specific data formats",
            "User experiences automatic API key validation before making requests"
          ],
          "developerVisibleActions": [
            "Developer configures OpenAI API key through configuration manager",
            "Developer sends chat completion requests with custom models, prompts, and messages",
            "Developer receives parsed JSON responses when using structured output format",
            "Developer gets error messages when API key is not configured or requests fail",
            "Developer can check if provider is properly configured before use",
            "Developer specifies system prompts, conversation history, and response format options"
          ],
          "keyFunctions": [
            {
              "name": "initialize",
              "desc": "Sets up the OpenAI client with API key from configuration",
              "inputs": "None (reads from config manager)",
              "outputs": "void (initializes client)"
            },
            {
              "name": "isConfigured",
              "desc": "Checks if the provider has a valid API key and is ready to use",
              "inputs": "None",
              "outputs": "boolean indicating configuration status"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "None",
              "outputs": "string 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a chat completion request to OpenAI with messages and optional system prompt",
              "inputs": "LLMRequestOptions (model, messages, systemPrompt, responseFormat)",
              "outputs": "Promise<LLMResponse> with content and finish reason"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Sends a request expecting structured JSON output and parses the response",
              "inputs": "LLMRequestOptions with expected JSON format",
              "outputs": "Promise<StructuredOutputResponse> with parsed JSON data"
            }
          ],
          "dependencies": [
            "openai",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses\",\n  \"userVisibleActions\": [\n    \"User's prompts are sent to OpenAI's GPT models for AI-powered responses\",\n    \"User receives AI-generated text responses based on their input\",\n    \"User can get structured JSON responses when requesting specific data formats\",\n    \"User experiences automatic API key validation before making requests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer configures OpenAI API key through configuration manager\",\n    \"Developer sends chat completion requests with custom models, prompts, and messages\",\n    \"Developer receives parsed JSON responses when using structured output format\",\n    \"Developer gets error messages when API key is not configured or requests fail\",\n    \"Developer can check if provider is properly configured before use\",\n    \"Developer specifies system prompts, conversation history, and response format options\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the OpenAI client with API key from configuration\",\n      \"inputs\": \"None (reads from config manager)\",\n      \"outputs\": \"void (initializes client)\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has a valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI with messages and optional system prompt\",\n      \"inputs\": \"LLMRequestOptions (model, messages, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends a request expecting structured JSON output and parses the response\",\n      \"inputs\": \"LLMRequestOptions with expected JSON format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Creates and manages AI provider instances (OpenAI or Claude) based on user configuration",
          "userVisibleActions": [
            "Automatically connects to the AI provider selected in settings (OpenAI or Claude)",
            "Only shows available AI providers that have valid API keys configured",
            "Uses the default AI provider from configuration when generating responses"
          ],
          "developerVisibleActions": [
            "Provides a centralized factory for getting AI provider instances",
            "Caches provider instances to avoid recreating them",
            "Exposes methods to check which providers are properly configured",
            "Returns the currently active provider based on user settings",
            "Throws error when requesting an unknown provider type"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns a specific AI provider instance (OpenAI or Claude)",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the AI provider that is currently active in user settings",
              "inputs": "none",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks if a provider has valid configuration (API key, etc.)",
              "inputs": "provider: 'openai' | 'claude'",
              "outputs": "boolean"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns list of all providers that have valid configuration",
              "inputs": "none",
              "outputs": "Array of provider names"
            }
          ],
          "dependencies": [
            "ILLMProvider",
            "OpenAIProvider",
            "AnthropicProvider",
            "configurationManager"
          ],
          "intent": "Provides a single point of control for creating and accessing AI providers, ensuring only one instance of each provider exists and automatically selecting the provider based on user configuration",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI provider instances (OpenAI or Claude) based on user configuration\",\n  \"userVisibleActions\": [\n    \"Automatically connects to the AI provider selected in settings (OpenAI or Claude)\",\n    \"Only shows available AI providers that have valid API keys configured\",\n    \"Uses the default AI provider from configuration when generating responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a centralized factory for getting AI provider instances\",\n    \"Caches provider instances to avoid recreating them\",\n    \"Exposes methods to check which providers are properly configured\",\n    \"Returns the currently active provider based on user settings\",\n    \"Throws error when requesting an unknown provider type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a specific AI provider instance (OpenAI or Claude)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently active in user settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a provider has valid configuration (API key, etc.)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all providers that have valid configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of provider names\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Provides a single point of control for creating and accessing AI providers, ensuring only one instance of each provider exists and automatically selecting the provider based on user configuration\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Deep code analysis through abstract syntax tree (AST) parsing to understand code structure and behavior",
        "Extraction of comprehensive function metadata including signatures, parameters, return types, and responsibilities",
        "Detection and analysis of conditional branches and code paths within functions",
        "Identification of function dependencies, both internal and external to the codebase",
        "Tracking of state mutations and variable modifications throughout function execution",
        "Recognition of behavioral patterns such as pure functions, async operations, and recursive calls",
        "Analysis of function complexity and side effects for refactoring decisions",
        "Generation of detailed function analysis reports for large files requiring refactoring"
      ],
      "summary": "The analysis module provides sophisticated code intelligence capabilities that help developers understand and improve their codebase. It performs deep structural analysis by parsing code into abstract syntax trees, extracting rich metadata about functions, their behaviors, dependencies, and complexity characteristics. Users receive comprehensive insights about how their functions operate, including what branches exist, what state changes occur, and what other parts of the codebase are involved.\n\nThis module is particularly valuable when working with large files that need refactoring. It automatically identifies functions that may benefit from being split or reorganized, providing detailed reports about each function's purpose, dependencies, and relationships within the codebase. The analysis includes behavioral hints that help developers quickly understand whether functions are pure, asynchronous, recursive, or have side effects.\n\nThe insights generated by this module enable data-driven refactoring decisions by highlighting code complexity, identifying tightly coupled components, and revealing functions that modify state or depend on external resources. Developers can use this information to improve code maintainability, reduce complexity, and make informed architectural decisions about their codebase structure.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Performs deep code analysis by parsing abstract syntax trees (AST) to extract detailed function metadata including branches, dependencies, state mutations, and behavioral patterns.",
          "userVisibleActions": [
            "Receives enhanced code intelligence about function behavior and complexity",
            "Gets insights about function dependencies and side effects",
            "Sees analysis of conditional branches and code paths within functions",
            "Receives information about state mutations and variable modifications",
            "Gets behavioral hints about function characteristics (pure, async, recursive, etc.)"
          ],
          "developerVisibleActions": [
            "Analyzes code files to extract detailed function metadata beyond basic information",
            "Parses TypeScript/JavaScript files using AST to understand code structure",
            "Extracts branch analysis showing conditional logic and code paths",
            "Profiles function dependencies and external module usage",
            "Detects state mutations and side effects in functions",
            "Generates behavioral hints indicating function patterns (pure functions, async operations, recursion)",
            "Falls back to regex-based analysis for non-TypeScript/JavaScript languages",
            "Provides test mapping suggestions based on function characteristics",
            "Returns comprehensive metadata including complexity metrics and dependency graphs"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes a code file and extracts enhanced metadata for all functions within it",
              "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
              "outputs": "Map<string, FunctionMetadata> containing detailed metadata for each function"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata",
              "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
              "outputs": "FunctionMetadata object with branch info, dependencies, mutations, and behavioral hints"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Provides fallback regex-based analysis for languages other than TypeScript/JavaScript",
              "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
              "outputs": "FunctionMetadata object with basic analysis data"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the source code content of a function based on line numbers",
              "inputs": "content (string), startLine (number), endLine (number)",
              "outputs": "String containing the function's source code"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer"
          ],
          "intent": "This file exists to provide deep, AST-level code analysis that goes beyond surface-level parsing. It solves the problem of understanding complex code behavior, dependencies, and patterns by analyzing the actual structure of code rather than just reading it as text. This enables intelligent features like dependency tracking, branch analysis, mutation detection, and behavioral pattern recognition for better code understanding and test generation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing abstract syntax trees (AST) to extract detailed function metadata including branches, dependencies, state mutations, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives enhanced code intelligence about function behavior and complexity\",\n    \"Gets insights about function dependencies and side effects\",\n    \"Sees analysis of conditional branches and code paths within functions\",\n    \"Receives information about state mutations and variable modifications\",\n    \"Gets behavioral hints about function characteristics (pure, async, recursive, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes code files to extract detailed function metadata beyond basic information\",\n    \"Parses TypeScript/JavaScript files using AST to understand code structure\",\n    \"Extracts branch analysis showing conditional logic and code paths\",\n    \"Profiles function dependencies and external module usage\",\n    \"Detects state mutations and side effects in functions\",\n    \"Generates behavioral hints indicating function patterns (pure functions, async operations, recursion)\",\n    \"Falls back to regex-based analysis for non-TypeScript/JavaScript languages\",\n    \"Provides test mapping suggestions based on function characteristics\",\n    \"Returns comprehensive metadata including complexity metrics and dependency graphs\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a code file and extracts enhanced metadata for all functions within it\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing detailed metadata for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata object with branch info, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for languages other than TypeScript/JavaScript\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata object with basic analysis data\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function based on line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide deep, AST-level code analysis that goes beyond surface-level parsing. It solves the problem of understanding complex code behavior, dependencies, and patterns by analyzing the actual structure of code rather than just reading it as text. This enables intelligent features like dependency tracking, branch analysis, mutation detection, and behavioral pattern recognition for better code understanding and test generation.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and responsibilities for generating refactoring reports.",
          "userVisibleActions": [
            "Identifies functions in large files that may need refactoring",
            "Generates detailed function analysis reports showing what each function does",
            "Highlights function dependencies and relationships within the codebase",
            "Provides function signature information for understanding code structure"
          ],
          "developerVisibleActions": [
            "Developer triggers function analysis on large files exceeding a threshold (default 500 lines)",
            "Receives structured FunctionAnalysis objects containing function metadata",
            "Gets function signatures, dependencies, dependents, and responsibilities extracted from TypeScript code",
            "Can access analyzed function data to build refactoring prompts and reports",
            "Sees warnings when function analysis fails for specific functions"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in files exceeding a size threshold and extracts detailed information",
              "inputs": "codeAnalysis (CodeAnalysis object), largeFileThreshold (optional number, default 500 lines)",
              "outputs": "Promise<FunctionAnalysis[]> - array of detailed function analyses"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs detailed analysis on a single function to extract its metadata and relationships",
              "inputs": "filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)",
              "outputs": "Promise<FunctionAnalysis | null> - detailed function analysis or null if analysis fails"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves the full file path for a given file in the code analysis",
              "inputs": "filePath (string), codeAnalysis (CodeAnalysis)",
              "outputs": "string - resolved full file path"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to provide deep analysis of functions within large code files to support refactoring efforts. It solves the problem of understanding complex function relationships, dependencies, and responsibilities when developers need to break down or refactor large files. It bridges the gap between basic code analysis and actionable refactoring insights by extracting function-level metadata that can be used to generate intelligent refactoring suggestions.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and responsibilities for generating refactoring reports.\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Generates detailed function analysis reports showing what each function does\",\n    \"Highlights function dependencies and relationships within the codebase\",\n    \"Provides function signature information for understanding code structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers function analysis on large files exceeding a threshold (default 500 lines)\",\n    \"Receives structured FunctionAnalysis objects containing function metadata\",\n    \"Gets function signatures, dependencies, dependents, and responsibilities extracted from TypeScript code\",\n    \"Can access analyzed function data to build refactoring prompts and reports\",\n    \"Sees warnings when function analysis fails for specific functions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files exceeding a size threshold and extracts detailed information\",\n      \"inputs\": \"codeAnalysis (CodeAnalysis object), largeFileThreshold (optional number, default 500 lines)\",\n      \"outputs\": \"Promise<FunctionAnalysis[]> - array of detailed function analyses\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function to extract its metadata and relationships\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"Promise<FunctionAnalysis | null> - detailed function analysis or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves the full file path for a given file in the code analysis\",\n      \"inputs\": \"filePath (string), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"string - resolved full file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions within large code files to support refactoring efforts. It solves the problem of understanding complex function relationships, dependencies, and responsibilities when developers need to break down or refactor large files. It bridges the gap between basic code analysis and actionable refactoring insights by extracting function-level metadata that can be used to generate intelligent refactoring suggestions.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "AI-powered code analysis and insights generation using LLM services (OpenAI/Claude)",
        "Automated code quality detection including large files, orphaned code, circular dependencies, and god objects",
        "Interactive tree-based visualization of code structure, analysis results, and insights",
        "Real-time inline diagnostics showing code issues directly in the editor",
        "Automated product documentation generation explaining codebase purpose and architecture",
        "File and module-level documentation with behavioral summaries",
        "Entry point detection for main functions, test files, and CLI tools",
        "Code search and file access capabilities for iterative LLM analysis",
        "Automatic file watching with on-save analysis triggering",
        "Persistent caching of analysis results for improved performance",
        "Export functionality for analysis results and documentation",
        "Unit test planning and coverage analysis",
        "Multiple LLM output formats optimized for different AI assistants"
      ],
      "summary": "The src module is a VS Code extension that provides comprehensive AI-powered code analysis and insights. It analyzes codebases to generate intelligent documentation, detect code quality issues, and provide actionable recommendations for improvement. The extension integrates LLM services (OpenAI and Claude) to understand code purpose, architecture patterns, and potential problems, presenting this information through interactive tree views and inline diagnostics.\n\nUsers interact with the extension primarily through VS Code's sidebar tree views and inline editor diagnostics. The extension automatically watches for file changes and can trigger analysis on save, providing real-time feedback. It generates multiple types of reports including product documentation, architecture insights, unit test plans, and static analysis results. All insights are presented with specific file locations, line numbers, and actionable suggestions for remediation.\n\nThe module supports iterative workflows where users can generate initial insights, navigate to problematic code sections, make changes, and automatically see updated analysis. Results are cached for 24 hours to improve performance on subsequent loads. The extension formats insights for different consumption methods - whether viewing in VS Code's tree views, exporting to HTML reports, or formatting for specific AI assistants like Cursor or ChatGPT.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VS Code that displays code analysis results including file statistics, functions, imports, and entry points.",
          "userVisibleActions": [
            "View a tree structure showing code analysis results organized by categories",
            "Browse file statistics (total files, lines of code, functions)",
            "Explore files grouped by directory in a hierarchical view",
            "See detailed information for each file including language, lines of code, and function count",
            "View list of all functions with their parameter counts and line numbers",
            "Browse import statements and dependencies for each file",
            "View entry points (main functions, test files, CLI tools) detected in the codebase",
            "Click on any item to navigate to the corresponding location in the source file",
            "See descriptive tooltips when hovering over items in the tree",
            "View 'No analysis available' message when analysis hasn't been run yet"
          ],
          "developerVisibleActions": [
            "Implements TreeDataProvider interface to render analysis results in VS Code sidebar",
            "Receives CodeAnalysis data structure and converts it into a navigable tree view",
            "Handles user clicks on tree items to open files at specific locations",
            "Provides refresh capability when new analysis results are available",
            "Groups files by directory structure for better organization",
            "Displays different icons and labels based on item type (file, function, import, etc.)",
            "Formats statistics and metrics for display (file counts, LOC, complexity)",
            "Creates clickable tree items with commands to navigate to source code locations"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the viewer with new analysis results and refreshes the tree view",
              "inputs": "CodeAnalysis object or null",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a refresh of the tree view to display updated data",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the tree item representation for VS Code to render",
              "inputs": "AnalysisItem element",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node to build the hierarchy",
              "inputs": "Optional AnalysisItem element (undefined for root)",
              "outputs": "Promise of AnalysisItem array"
            },
            {
              "name": "getRootItems",
              "desc": "Creates top-level tree items showing statistics, files, functions, and entry points categories",
              "inputs": "none",
              "outputs": "Array of AnalysisItem"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Generates tree items displaying code metrics like total files, LOC, and function counts",
              "inputs": "none",
              "outputs": "Array of AnalysisItem"
            },
            {
              "name": "getFilesItems",
              "desc": "Organizes files into directory groups for hierarchical browsing",
              "inputs": "none",
              "outputs": "Array of AnalysisItem representing directories and standalone files"
            },
            {
              "name": "getFileDetails",
              "desc": "Returns detailed information about a specific file including functions, imports, and exports",
              "inputs": "AnalysisItem representing a file",
              "outputs": "Promise of AnalysisItem array"
            },
            {
              "name": "getFunctionItems",
              "desc": "Creates tree items for all functions across the codebase with navigation links",
              "inputs": "none",
              "outputs": "Array of AnalysisItem"
            },
            {
              "name": "getEntryPointItems",
              "desc": "Lists detected entry points categorized by type (main, tests, CLI, etc.)",
              "inputs": "none",
              "outputs": "Array of AnalysisItem"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)"
          ],
          "intent": "This file exists to provide developers with a visual, interactive way to explore code analysis results within VS Code. It solves the problem of understanding large codebases by organizing analysis data into a browsable tree structure where users can quickly navigate to specific files, functions, or entry points, and understand code statistics and relationships at a glance.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays code analysis results including file statistics, functions, imports, and entry points.\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code analysis results organized by categories\",\n    \"Browse file statistics (total files, lines of code, functions)\",\n    \"Explore files grouped by directory in a hierarchical view\",\n    \"See detailed information for each file including language, lines of code, and function count\",\n    \"View list of all functions with their parameter counts and line numbers\",\n    \"Browse import statements and dependencies for each file\",\n    \"View entry points (main functions, test files, CLI tools) detected in the codebase\",\n    \"Click on any item to navigate to the corresponding location in the source file\",\n    \"See descriptive tooltips when hovering over items in the tree\",\n    \"View 'No analysis available' message when analysis hasn't been run yet\"\n  ],\n  \"developerVisibleActions\": [\n    \"Implements TreeDataProvider interface to render analysis results in VS Code sidebar\",\n    \"Receives CodeAnalysis data structure and converts it into a navigable tree view\",\n    \"Handles user clicks on tree items to open files at specific locations\",\n    \"Provides refresh capability when new analysis results are available\",\n    \"Groups files by directory structure for better organization\",\n    \"Displays different icons and labels based on item type (file, function, import, etc.)\",\n    \"Formats statistics and metrics for display (file counts, LOC, complexity)\",\n    \"Creates clickable tree items with commands to navigate to source code locations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the viewer with new analysis results and refreshes the tree view\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the tree view to display updated data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for VS Code to render\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node to build the hierarchy\",\n      \"inputs\": \"Optional AnalysisItem element (undefined for root)\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Creates top-level tree items showing statistics, files, functions, and entry points categories\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Generates tree items displaying code metrics like total files, LOC, and function counts\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes files into directory groups for hierarchical browsing\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem representing directories and standalone files\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information about a specific file including functions, imports, and exports\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getFunctionItems\",\n      \"desc\": \"Creates tree items for all functions across the codebase with navigation links\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getEntryPointItems\",\n      \"desc\": \"Lists detected entry points categorized by type (main, tests, CLI, etc.)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\"\n  ],\n  \"intent\": \"This file exists to provide developers with a visual, interactive way to explore code analysis results within VS Code. It solves the problem of understanding large codebases by organizing analysis data into a browsable tree structure where users can quickly navigate to specific files, functions, or entry points, and understand code statistics and relationships at a glance.\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Defines interfaces and structures for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
          "userVisibleActions": [
            "View total counts of files, lines, and functions in their codebase",
            "See which files are large and may need refactoring",
            "Identify orphaned files that aren't imported anywhere",
            "Discover entry points in the application",
            "Find duplicate code blocks across the codebase",
            "Understand function risk levels (high, medium, low)",
            "See which functions lack test coverage"
          ],
          "developerVisibleActions": [
            "Access structured analysis data through TypeScript interfaces",
            "Query file information including path, lines, size, and role",
            "Inspect function metadata including parameters, return types, and visibility",
            "Examine control flow branches (if, loops, try-catch) in functions",
            "Track dependencies (database, HTTP, filesystem, etc.) used by functions",
            "Analyze state mutations (assignments, modifications) in code",
            "Map test files to source files and functions",
            "Identify uncovered functions and lines in test coverage",
            "Find import relationships between files",
            "Use caching mechanism for performance optimization"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main analysis result container with file counts, function metadata, dependencies, and test coverage",
              "inputs": "N/A (interface)",
              "outputs": "Structured data including totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping"
            },
            {
              "name": "FunctionMetadata",
              "desc": "Detailed information about a function including parameters, branches, dependencies, and risk level",
              "inputs": "N/A (interface)",
              "outputs": "Function name, parameters with types, return type, visibility, branches, dependencies, state mutations, risk assessment"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source files and functions to their test coverage",
              "inputs": "N/A (interface)",
              "outputs": "Source-to-test file mappings, function-to-test mappings, list of uncovered functions"
            },
            {
              "name": "DependencyInfo",
              "desc": "Identifies external dependencies like databases, HTTP calls, filesystem operations",
              "inputs": "N/A (interface)",
              "outputs": "Dependency name, type (db/http/filesystem/etc), whether internal or external, line number"
            },
            {
              "name": "EntryPoint",
              "desc": "Identifies application entry points and their types",
              "inputs": "N/A (interface)",
              "outputs": "File path, entry point type (main/cli/api/config/test), function name, description"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache"
          ],
          "intent": "This file provides the type system and data structures for representing comprehensive code analysis results. It enables developers to work with structured information about code quality, test coverage, dependencies, and architectural patterns. The interfaces support both basic metrics (file counts, function counts) and advanced analysis (control flow branches, state mutations, risk assessment, duplicate detection) to help developers understand and improve their codebase.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines interfaces and structures for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View total counts of files, lines, and functions in their codebase\",\n    \"See which files are large and may need refactoring\",\n    \"Identify orphaned files that aren't imported anywhere\",\n    \"Discover entry points in the application\",\n    \"Find duplicate code blocks across the codebase\",\n    \"Understand function risk levels (high, medium, low)\",\n    \"See which functions lack test coverage\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access structured analysis data through TypeScript interfaces\",\n    \"Query file information including path, lines, size, and role\",\n    \"Inspect function metadata including parameters, return types, and visibility\",\n    \"Examine control flow branches (if, loops, try-catch) in functions\",\n    \"Track dependencies (database, HTTP, filesystem, etc.) used by functions\",\n    \"Analyze state mutations (assignments, modifications) in code\",\n    \"Map test files to source files and functions\",\n    \"Identify uncovered functions and lines in test coverage\",\n    \"Find import relationships between files\",\n    \"Use caching mechanism for performance optimization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main analysis result container with file counts, function metadata, dependencies, and test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Structured data including totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed information about a function including parameters, branches, dependencies, and risk level\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Function name, parameters with types, return type, visibility, branches, dependencies, state mutations, risk assessment\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Source-to-test file mappings, function-to-test mappings, list of uncovered functions\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Identifies external dependencies like databases, HTTP calls, filesystem operations\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Dependency name, type (db/http/filesystem/etc), whether internal or external, line number\"\n    },\n    {\n      \"name\": \"EntryPoint\",\n      \"desc\": \"Identifies application entry points and their types\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"File path, entry point type (main/cli/api/config/test), function name, description\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file provides the type system and data structures for representing comprehensive code analysis results. It enables developers to work with structured information about code quality, test coverage, dependencies, and architectural patterns. The interfaces support both basic metrics (file counts, function counts) and advanced analysis (control flow branches, state mutations, risk assessment, duplicate detection) to help developers understand and improve their codebase.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent caching of code analysis results to improve performance and avoid redundant analysis",
          "userVisibleActions": [
            "Faster project loading when reopening a workspace (analysis loads from cache instead of re-analyzing)",
            "Automatic cache expiration after 24 hours ensures fresh analysis",
            "Cache clearing capability to force fresh analysis when needed"
          ],
          "developerVisibleActions": [
            "Code analysis results are automatically saved to disk after initial analysis",
            "Cached analysis is retrieved on subsequent workspace opens if still valid",
            "Cache files are stored in a hidden .shadowwatch-cache directory",
            "Cache automatically invalidates after 24 hours to prevent stale data",
            "Cache can be manually cleared to force fresh analysis",
            "Cache keys are derived from workspace paths to isolate different projects"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes cache system with storage location and creates cache directory",
              "inputs": "storagePath: string - where to store cache files",
              "outputs": "AnalysisCache instance"
            },
            {
              "name": "get",
              "desc": "Retrieves cached analysis for a workspace if available and not expired",
              "inputs": "workspaceRoot: string - path to workspace",
              "outputs": "Promise<CodeAnalysis | null> - cached analysis or null if not found/expired"
            },
            {
              "name": "set",
              "desc": "Saves analysis results to cache with current timestamp",
              "inputs": "workspaceRoot: string, data: CodeAnalysis - workspace path and analysis to cache",
              "outputs": "Promise<void>"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis files from the cache directory",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "getCacheKey",
              "desc": "Generates a safe filesystem-compatible cache key from workspace path",
              "inputs": "workspaceRoot: string - workspace path",
              "outputs": "string - base64 encoded safe filename"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "Eliminates the need to re-analyze large codebases every time VSCode starts by persistently storing analysis results on disk with automatic expiration to balance performance and freshness",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent caching of code analysis results to improve performance and avoid redundant analysis\",\n  \"userVisibleActions\": [\n    \"Faster project loading when reopening a workspace (analysis loads from cache instead of re-analyzing)\",\n    \"Automatic cache expiration after 24 hours ensures fresh analysis\",\n    \"Cache clearing capability to force fresh analysis when needed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Code analysis results are automatically saved to disk after initial analysis\",\n    \"Cached analysis is retrieved on subsequent workspace opens if still valid\",\n    \"Cache files are stored in a hidden .shadowwatch-cache directory\",\n    \"Cache automatically invalidates after 24 hours to prevent stale data\",\n    \"Cache can be manually cleared to force fresh analysis\",\n    \"Cache keys are derived from workspace paths to isolate different projects\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache system with storage location and creates cache directory\",\n      \"inputs\": \"storagePath: string - where to store cache files\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis for a workspace if available and not expired\",\n      \"inputs\": \"workspaceRoot: string - path to workspace\",\n      \"outputs\": \"Promise<CodeAnalysis | null> - cached analysis or null if not found/expired\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis - workspace path and analysis to cache\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filesystem-compatible cache key from workspace path\",\n      \"inputs\": \"workspaceRoot: string - workspace path\",\n      \"outputs\": \"string - base64 encoded safe filename\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Eliminates the need to re-analyze large codebases every time VSCode starts by persistently storing analysis results on disk with automatic expiration to balance performance and freshness\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Manages and displays code insights as inline diagnostics (warnings, errors, info) in the VS Code editor",
          "userVisibleActions": [
            "Sees inline diagnostics (squiggly underlines) in code files where insights are detected",
            "Hovers over diagnostics to see insight descriptions and severity levels",
            "Views diagnostics in the Problems panel organized by file",
            "Sees diagnostics labeled as 'Shadow Watch' with unique insight IDs",
            "Diagnostics automatically clear and refresh when insights update"
          ],
          "developerVisibleActions": [
            "Creates a diagnostic collection named 'shadowWatch' for the extension",
            "Converts insight objects into VS Code diagnostic objects that appear in the editor",
            "Groups insights by file path and applies them to the correct documents",
            "Maps insight severity levels to VS Code diagnostic severities (Error, Warning, Information, Hint)",
            "Clears all diagnostics when requested or when disposing the provider",
            "Updates diagnostics for all files or specific files based on insight data"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Takes a list of insights and displays them as diagnostics across all affected files",
              "inputs": "Array of Insight objects",
              "outputs": "void (updates VS Code UI)"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostics for a specific file URI",
              "inputs": "VS Code URI and array of Insight objects",
              "outputs": "void (updates VS Code UI)"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostics from all files",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts a single insight into a VS Code diagnostic object",
              "inputs": "Insight object",
              "outputs": "VS Code Diagnostic object"
            },
            {
              "name": "getSeverity",
              "desc": "Maps insight severity to VS Code diagnostic severity level",
              "inputs": "Severity string from insight",
              "outputs": "VS Code DiagnosticSeverity enum"
            },
            {
              "name": "dispose",
              "desc": "Cleans up the diagnostic collection when extension deactivates",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "Provides a bridge between the extension's insight generation system and VS Code's native diagnostics UI, allowing code analysis results to be displayed as familiar inline problems that users see in their editor and Problems panel",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages and displays code insights as inline diagnostics (warnings, errors, info) in the VS Code editor\",\n  \"userVisibleActions\": [\n    \"Sees inline diagnostics (squiggly underlines) in code files where insights are detected\",\n    \"Hovers over diagnostics to see insight descriptions and severity levels\",\n    \"Views diagnostics in the Problems panel organized by file\",\n    \"Sees diagnostics labeled as 'Shadow Watch' with unique insight IDs\",\n    \"Diagnostics automatically clear and refresh when insights update\"\n  ],\n  \"developerVisibleActions\": [\n    \"Creates a diagnostic collection named 'shadowWatch' for the extension\",\n    \"Converts insight objects into VS Code diagnostic objects that appear in the editor\",\n    \"Groups insights by file path and applies them to the correct documents\",\n    \"Maps insight severity levels to VS Code diagnostic severities (Error, Warning, Information, Hint)\",\n    \"Clears all diagnostics when requested or when disposing the provider\",\n    \"Updates diagnostics for all files or specific files based on insight data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Takes a list of insights and displays them as diagnostics across all affected files\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void (updates VS Code UI)\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file URI\",\n      \"inputs\": \"VS Code URI and array of Insight objects\",\n      \"outputs\": \"void (updates VS Code UI)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from all files\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts a single insight into a VS Code diagnostic object\",\n      \"inputs\": \"Insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"getSeverity\",\n      \"desc\": \"Maps insight severity to VS Code diagnostic severity level\",\n      \"inputs\": \"Severity string from insight\",\n      \"outputs\": \"VS Code DiagnosticSeverity enum\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up the diagnostic collection when extension deactivates\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Provides a bridge between the extension's insight generation system and VS Code's native diagnostics UI, allowing code analysis results to be displayed as familiar inline problems that users see in their editor and Problems panel\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "Main extension entry point that initializes and coordinates all VS Code extension components, registers commands, and manages the extension lifecycle.",
          "userVisibleActions": [
            "Analyze code files to generate insights and behavior descriptions",
            "View code insights in a tree view sidebar",
            "Navigate through code structure and entry points",
            "Generate LLM-friendly summaries of code files",
            "See real-time diagnostics and warnings in the editor",
            "Export analysis results to files",
            "View context-aware code analysis in webview panels",
            "Get automatic cache updates when files change",
            "See status bar indicators for analysis progress",
            "Navigate to specific code elements from insights",
            "Analyze entire workspaces or individual files",
            "View product navigation structure"
          ],
          "developerVisibleActions": [
            "Extension activates when VS Code starts",
            "All components are initialized and wired together via bootstrapper",
            "Commands are registered for analyzing code, exporting results, and navigating insights",
            "File watcher monitors workspace changes and triggers re-analysis",
            "Cache stores analysis results for performance optimization",
            "Diagnostics are updated in real-time as code changes",
            "Tree view and webview panels are created and managed",
            "Status bar shows current analysis state",
            "Configuration changes trigger component updates",
            "Error handling captures and logs failures",
            "Extension deactivates and cleans up resources on shutdown"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Initializes the extension, sets up all components, registers commands, and starts file watching",
              "inputs": "vscode.ExtensionContext",
              "outputs": "void"
            },
            {
              "name": "deactivate",
              "desc": "Cleans up resources and stops all extension services when the extension is deactivated",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler",
            "./productNavigator"
          ],
          "intent": "This file serves as the central orchestration point for the VS Code extension, responsible for initializing all subsystems, wiring dependencies, registering user commands, and managing the complete extension lifecycle. It solves the problem of coordinating multiple independent components (analysis, insights, diagnostics, caching, UI) into a cohesive extension that provides code analysis and understanding capabilities to users.",
          "rawContent": "```json\n{\n  \"purpose\": \"Main extension entry point that initializes and coordinates all VS Code extension components, registers commands, and manages the extension lifecycle.\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights and behavior descriptions\",\n    \"View code insights in a tree view sidebar\",\n    \"Navigate through code structure and entry points\",\n    \"Generate LLM-friendly summaries of code files\",\n    \"See real-time diagnostics and warnings in the editor\",\n    \"Export analysis results to files\",\n    \"View context-aware code analysis in webview panels\",\n    \"Get automatic cache updates when files change\",\n    \"See status bar indicators for analysis progress\",\n    \"Navigate to specific code elements from insights\",\n    \"Analyze entire workspaces or individual files\",\n    \"View product navigation structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VS Code starts\",\n    \"All components are initialized and wired together via bootstrapper\",\n    \"Commands are registered for analyzing code, exporting results, and navigating insights\",\n    \"File watcher monitors workspace changes and triggers re-analysis\",\n    \"Cache stores analysis results for performance optimization\",\n    \"Diagnostics are updated in real-time as code changes\",\n    \"Tree view and webview panels are created and managed\",\n    \"Status bar shows current analysis state\",\n    \"Configuration changes trigger component updates\",\n    \"Error handling captures and logs failures\",\n    \"Extension deactivates and cleans up resources on shutdown\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, sets up all components, registers commands, and starts file watching\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources and stops all extension services when the extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file serves as the central orchestration point for the VS Code extension, responsible for initializing all subsystems, wiring dependencies, registering user commands, and managing the complete extension lifecycle. It solves the problem of coordinating multiple independent components (analysis, insights, diagnostics, caching, UI) into a cohesive extension that provides code analysis and understanding capabilities to users.\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and grep search functionality to enable iterative code analysis by LLMs within a workspace",
          "userVisibleActions": [
            "Users can request to read specific files by providing a file path",
            "Users can search for text patterns across multiple files using grep-like functionality",
            "Users receive file contents with line counts and existence status",
            "Users get search results showing matching lines with file locations and line numbers",
            "Users can see context lines before and after grep matches",
            "Users can limit search scope using file patterns (e.g., '*.ts', 'src/**/*.ts')",
            "Users can control maximum number of search results returned",
            "Users receive organized file listings grouped by folder"
          ],
          "developerVisibleActions": [
            "Developer creates FileRequest objects with file path and optional reason",
            "Developer creates GrepRequest objects with search pattern, optional file pattern, max results, and reason",
            "Developer receives FileResponse with file content, line count, and existence flag",
            "Developer receives GrepResponse with matches, total match count, and limited flag",
            "Developer gets structured grep matches with file path, line number, content, and optional context",
            "Developer can process file listings organized by directory structure",
            "Developer handles both successful file reads and missing file scenarios",
            "Developer works with workspace-relative paths through the FileAccessHelper instance"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Organizes and formats a list of files grouped by their containing folders",
              "inputs": "Array of file objects with path, optional lines, and optional language",
              "outputs": "String representation of files organized by folder structure"
            },
            {
              "name": "processRequest",
              "desc": "Processes either a file read request or grep search request and returns appropriate response",
              "inputs": "LLMRequest (FileRequest or GrepRequest)",
              "outputs": "FileResponse or GrepResponse depending on request type"
            },
            {
              "name": "readFile",
              "desc": "Reads a specific file from the workspace and returns its content with metadata",
              "inputs": "File path string",
              "outputs": "FileResponse with content, line count, and exists flag"
            },
            {
              "name": "grepSearch",
              "desc": "Searches for a text pattern across files with optional filtering and result limiting",
              "inputs": "GrepRequest with pattern, optional file pattern, max results, and reason",
              "outputs": "GrepResponse with matching lines, context, total count, and limited flag"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to enable LLMs to iteratively explore and analyze codebases by providing controlled file access and search capabilities, allowing LLMs to request specific files or search for patterns as needed during analysis rather than loading entire codebases upfront",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative code analysis by LLMs within a workspace\",\n  \"userVisibleActions\": [\n    \"Users can request to read specific files by providing a file path\",\n    \"Users can search for text patterns across multiple files using grep-like functionality\",\n    \"Users receive file contents with line counts and existence status\",\n    \"Users get search results showing matching lines with file locations and line numbers\",\n    \"Users can see context lines before and after grep matches\",\n    \"Users can limit search scope using file patterns (e.g., '*.ts', 'src/**/*.ts')\",\n    \"Users can control maximum number of search results returned\",\n    \"Users receive organized file listings grouped by folder\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates FileRequest objects with file path and optional reason\",\n    \"Developer creates GrepRequest objects with search pattern, optional file pattern, max results, and reason\",\n    \"Developer receives FileResponse with file content, line count, and existence flag\",\n    \"Developer receives GrepResponse with matches, total match count, and limited flag\",\n    \"Developer gets structured grep matches with file path, line number, content, and optional context\",\n    \"Developer can process file listings organized by directory structure\",\n    \"Developer handles both successful file reads and missing file scenarios\",\n    \"Developer works with workspace-relative paths through the FileAccessHelper instance\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by their containing folders\",\n      \"inputs\": \"Array of file objects with path, optional lines, and optional language\",\n      \"outputs\": \"String representation of files organized by folder structure\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Processes either a file read request or grep search request and returns appropriate response\",\n      \"inputs\": \"LLMRequest (FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a specific file from the workspace and returns its content with metadata\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"FileResponse with content, line count, and exists flag\"\n    },\n    {\n      \"name\": \"grepSearch\",\n      \"desc\": \"Searches for a text pattern across files with optional filtering and result limiting\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern, max results, and reason\",\n      \"outputs\": \"GrepResponse with matching lines, context, total count, and limited flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable LLMs to iteratively explore and analyze codebases by providing controlled file access and search capabilities, allowing LLMs to request specific files or search for patterns as needed during analysis rather than loading entire codebases upfront\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces and types for multi-level code documentation system (file  module  product  full aggregation)",
          "userVisibleActions": [
            "Users can view structured documentation showing what the product does from their perspective (GUI, CLI, API, CI/CD workflows)",
            "Users can see product capabilities organized by how they interact with the system",
            "Users can understand what problems the product solves and how it integrates into workflows"
          ],
          "developerVisibleActions": [
            "Developer defines file-level documentation structure including role, purpose, and user/developer visible actions",
            "Developer organizes files into module summaries with endpoints, commands, or workers",
            "Developer creates product-level documentation with overview, architecture diagrams, and workflow integration",
            "Developer structures documentation with titles, descriptions, and behavioral sections",
            "Developer aggregates all documentation levels into a complete reference document"
          ],
          "keyFunctions": [],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "Provides the type definitions and data structures for a hierarchical documentation system that captures what code does from user and developer perspectives across four levels: individual files, modules, product features, and complete product documentation. Enables documentation generation that focuses on behavior and outcomes rather than implementation details.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and types for multi-level code documentation system (file  module  product  full aggregation)\",\n  \"userVisibleActions\": [\n    \"Users can view structured documentation showing what the product does from their perspective (GUI, CLI, API, CI/CD workflows)\",\n    \"Users can see product capabilities organized by how they interact with the system\",\n    \"Users can understand what problems the product solves and how it integrates into workflows\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file-level documentation structure including role, purpose, and user/developer visible actions\",\n    \"Developer organizes files into module summaries with endpoints, commands, or workers\",\n    \"Developer creates product-level documentation with overview, architecture diagrams, and workflow integration\",\n    \"Developer structures documentation with titles, descriptions, and behavioral sections\",\n    \"Developer aggregates all documentation levels into a complete reference document\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Provides the type definitions and data structures for a hierarchical documentation system that captures what code does from user and developer perspectives across four levels: individual files, modules, product features, and complete product documentation. Enables documentation generation that focuses on behavior and outcomes rather than implementation details.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file saves in the workspace and automatically triggers code analysis when files are saved",
          "userVisibleActions": [
            "Automatically analyzes code when files are saved (if 'analyze on save' is enabled)",
            "Provides real-time feedback on code quality after saving",
            "Shows insights and diagnostics in the editor after file changes",
            "Batches multiple rapid saves together to avoid overwhelming the system",
            "Respects user's 'analyze on save' configuration setting"
          ],
          "developerVisibleActions": [
            "Starts and stops file watching based on configuration",
            "Debounces file save events to prevent excessive analysis",
            "Coordinates analysis workflow across analyzer, insight generator, diagnostics, and tree view",
            "Handles errors during file analysis gracefully",
            "Provides hooks for workspace-level analysis when files change",
            "Exposes status of whether watcher is active (isStarted)",
            "Allows testing by accepting FileWatcherService dependency injection"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins watching for file saves and enables automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops watching for file saves and disables automatic analysis",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save events by scheduling debounced analysis",
              "inputs": "document (TextDocument)",
              "outputs": "void"
            },
            {
              "name": "triggerAnalysis",
              "desc": "Executes the full analysis pipeline on a saved file",
              "inputs": "document (TextDocument)",
              "outputs": "Promise<void>"
            },
            {
              "name": "shouldAnalyzeDocument",
              "desc": "Determines if a document should be analyzed based on file type and configuration",
              "inputs": "document (TextDocument)",
              "outputs": "boolean"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources when the file watcher is no longer needed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "ConfigurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic, on-save code analysis functionality. It solves the problem of keeping code insights up-to-date without requiring manual user intervention. By watching file saves and intelligently debouncing analysis requests, it provides a responsive development experience that gives immediate feedback on code quality while avoiding performance issues from excessive analysis.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file saves in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when files are saved (if 'analyze on save' is enabled)\",\n    \"Provides real-time feedback on code quality after saving\",\n    \"Shows insights and diagnostics in the editor after file changes\",\n    \"Batches multiple rapid saves together to avoid overwhelming the system\",\n    \"Respects user's 'analyze on save' configuration setting\"\n  ],\n  \"developerVisibleActions\": [\n    \"Starts and stops file watching based on configuration\",\n    \"Debounces file save events to prevent excessive analysis\",\n    \"Coordinates analysis workflow across analyzer, insight generator, diagnostics, and tree view\",\n    \"Handles errors during file analysis gracefully\",\n    \"Provides hooks for workspace-level analysis when files change\",\n    \"Exposes status of whether watcher is active (isStarted)\",\n    \"Allows testing by accepting FileWatcherService dependency injection\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file saves and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file saves and disables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events by scheduling debounced analysis\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline on a saved file\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"shouldAnalyzeDocument\",\n      \"desc\": \"Determines if a document should be analyzed based on file type and configuration\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources when the file watcher is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, on-save code analysis functionality. It solves the problem of keeping code insights up-to-date without requiring manual user intervention. By watching file saves and intelligently debouncing analysis requests, it provides a responsive development experience that gives immediate feedback on code quality while avoiding performance issues from excessive analysis.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code to generate actionable insights about code quality, organization, and potential issues",
          "userVisibleActions": [
            "Receives warnings about large files exceeding 500 lines of code",
            "Gets notified about orphaned files with no imports or dependencies",
            "Sees alerts for missing entry points in the codebase",
            "Receives warnings about potential circular dependencies between files",
            "Gets notified about 'god objects' (overly complex files or classes)",
            "Sees suggestions for potential dead code that may not be used",
            "Receives recommendations about file organization and structure",
            "Gets warnings about overly complex functions",
            "Views insights categorized by severity (error, warning, info)",
            "Sees specific file locations and line numbers where issues occur",
            "Receives actionable suggestions for improving code quality",
            "Views code snippets highlighting problematic areas"
          ],
          "developerVisibleActions": [
            "Passes CodeAnalysis data to generate comprehensive insights for entire codebase",
            "Requests file-specific insights by providing a file path",
            "Receives structured Insight objects with id, title, description, severity, category, file location, line number, suggestion, and optional code snippet",
            "Gets insights filtered by severity levels (error, warning, info)",
            "Accesses categorized insights (Code Organization, Complexity, Dependencies, etc.)",
            "Integrates insight generation into code analysis workflows",
            "Uses insights to identify refactoring opportunities automatically",
            "Triggers different check methods for specific code quality concerns"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Generates all insights for an entire codebase analysis",
              "inputs": "analysis: CodeAnalysis object containing file and function information",
              "outputs": "Array of Insight objects describing code quality issues and recommendations"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Generates insights specific to a single file",
              "inputs": "analysis: CodeAnalysis object, filePath: string path to target file",
              "outputs": "Array of Insight objects relevant to the specified file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Identifies files exceeding recommended line count thresholds",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for oversized files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Detects files with no imports or dependencies",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for isolated files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Verifies presence of necessary entry point files",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Identifies potential circular dependency patterns",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for circular dependency risks"
            },
            {
              "name": "checkGodObjects",
              "desc": "Detects files or classes with excessive complexity or responsibility",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for overly complex components"
            },
            {
              "name": "checkDeadCode",
              "desc": "Identifies potential unused or unreachable code",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for potentially dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Evaluates file structure and organization patterns",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for organization improvements"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Analyzes function complexity metrics",
              "inputs": "analysis: CodeAnalysis object",
              "outputs": "Array of Insight objects for complex functions"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to transform raw code analysis data into actionable, prioritized insights that help developers identify code quality issues, architectural problems, and refactoring opportunities across their codebase",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code to generate actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"Receives warnings about large files exceeding 500 lines of code\",\n    \"Gets notified about orphaned files with no imports or dependencies\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Receives warnings about potential circular dependencies between files\",\n    \"Gets notified about 'god objects' (overly complex files or classes)\",\n    \"Sees suggestions for potential dead code that may not be used\",\n    \"Receives recommendations about file organization and structure\",\n    \"Gets warnings about overly complex functions\",\n    \"Views insights categorized by severity (error, warning, info)\",\n    \"Sees specific file locations and line numbers where issues occur\",\n    \"Receives actionable suggestions for improving code quality\",\n    \"Views code snippets highlighting problematic areas\"\n  ],\n  \"developerVisibleActions\": [\n    \"Passes CodeAnalysis data to generate comprehensive insights for entire codebase\",\n    \"Requests file-specific insights by providing a file path\",\n    \"Receives structured Insight objects with id, title, description, severity, category, file location, line number, suggestion, and optional code snippet\",\n    \"Gets insights filtered by severity levels (error, warning, info)\",\n    \"Accesses categorized insights (Code Organization, Complexity, Dependencies, etc.)\",\n    \"Integrates insight generation into code analysis workflows\",\n    \"Uses insights to identify refactoring opportunities automatically\",\n    \"Triggers different check methods for specific code quality concerns\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates all insights for an entire codebase analysis\",\n      \"inputs\": \"analysis: CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects describing code quality issues and recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates insights specific to a single file\",\n      \"inputs\": \"analysis: CodeAnalysis object, filePath: string path to target file\",\n      \"outputs\": \"Array of Insight objects relevant to the specified file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Detects files with no imports or dependencies\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies presence of necessary entry point files\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Identifies potential circular dependency patterns\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular dependency risks\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Detects files or classes with excessive complexity or responsibility\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for overly complex components\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Identifies potential unused or unreachable code\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potentially dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates file structure and organization patterns\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organization improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity metrics\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, prioritized insights that help developers identify code quality issues, architectural problems, and refactoring opportunities across their codebase\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view interface for displaying and managing AI-generated code insights, documentation, test reports, and analysis results in the VS Code sidebar.",
          "userVisibleActions": [
            "View code insights organized in a tree structure with categories like Product Docs, Unit Tests, and Analysis",
            "Click 'Generate Product Docs' to create AI-generated documentation for the codebase",
            "Click 'Generate Insights' to get AI-powered code analysis and suggestions",
            "Click 'Generate Unit Tests' to create automated test cases",
            "View timestamps showing when each report was last generated",
            "Open generated reports (HTML files) in the browser or editor",
            "Copy report file paths to clipboard",
            "Reveal report files in the file explorer",
            "See loading indicators while reports are being generated",
            "View different report types: workspace overview, product docs, architecture, unit tests, and static analysis",
            "Refresh the insights tree to see updated information",
            "Expand and collapse insight categories to organize information"
          ],
          "developerVisibleActions": [
            "Tree provider updates automatically when insights are generated or status changes",
            "Insights are persisted across VS Code sessions using context state",
            "Report file paths and timestamps are tracked and restored on extension reload",
            "Status indicators show whether generation is idle, in progress, or complete",
            "Integration with LLM services to generate content asynchronously",
            "Tree items are created dynamically based on available insights and reports",
            "File system checks verify report existence before displaying items",
            "Context menu actions are available based on item type (copy path, reveal in explorer, open in browser)",
            "Icons and decorations indicate status (loading spinner, checkmarks, etc.)"
          ],
          "keyFunctions": [
            {
              "name": "getTreeItem",
              "desc": "Converts internal data into tree items for VS Code's tree view display",
              "inputs": "TreeItem element",
              "outputs": "vscode.TreeItem with label, icon, and command"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for tree hierarchy, showing insights categories and individual reports",
              "inputs": "Optional parent TreeItem",
              "outputs": "Array of TreeItem children or null"
            },
            {
              "name": "updateInsights",
              "desc": "Updates the displayed insights and refreshes the tree view",
              "inputs": "Array of Insight objects",
              "outputs": "void"
            },
            {
              "name": "setProductDocsStatus",
              "desc": "Updates the generation status for product documentation and refreshes display",
              "inputs": "Status string (idle/generating/complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setInsightsStatus",
              "desc": "Updates the generation status for insights and refreshes display",
              "inputs": "Status string (idle/generating/complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setUnitTestStatus",
              "desc": "Updates the generation status for unit tests and refreshes display",
              "inputs": "Status string (idle/generating/complete) and optional timestamp",
              "outputs": "void"
            },
            {
              "name": "setReportPath",
              "desc": "Stores the file path for a generated report and updates display",
              "inputs": "File path string and report type, optional timestamp",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a complete refresh of the tree view display",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "loadPersistedState",
              "desc": "Restores saved timestamps and report paths from previous sessions",
              "inputs": "None",
              "outputs": "Promise<void>"
            },
            {
              "name": "setLLMService",
              "desc": "Configures the LLM service used for generating insights",
              "inputs": "LLMService instance",
              "outputs": "void"
            },
            {
              "name": "setLLMInsights",
              "desc": "Updates the LLM-generated insights data and refreshes display",
              "inputs": "LLMInsights object",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator",
            "./llmFormatter",
            "./llmService"
          ],
          "intent": "This file exists to provide a visual interface in VS Code's sidebar where users can view, manage, and interact with AI-generated code documentation, insights, and analysis reports. It solves the problem of presenting complex analysis results in an organized, accessible tree structure with actions to generate, view, and manage different types of code intelligence reports.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for displaying and managing AI-generated code insights, documentation, test reports, and analysis results in the VS Code sidebar.\",\n  \"userVisibleActions\": [\n    \"View code insights organized in a tree structure with categories like Product Docs, Unit Tests, and Analysis\",\n    \"Click 'Generate Product Docs' to create AI-generated documentation for the codebase\",\n    \"Click 'Generate Insights' to get AI-powered code analysis and suggestions\",\n    \"Click 'Generate Unit Tests' to create automated test cases\",\n    \"View timestamps showing when each report was last generated\",\n    \"Open generated reports (HTML files) in the browser or editor\",\n    \"Copy report file paths to clipboard\",\n    \"Reveal report files in the file explorer\",\n    \"See loading indicators while reports are being generated\",\n    \"View different report types: workspace overview, product docs, architecture, unit tests, and static analysis\",\n    \"Refresh the insights tree to see updated information\",\n    \"Expand and collapse insight categories to organize information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree provider updates automatically when insights are generated or status changes\",\n    \"Insights are persisted across VS Code sessions using context state\",\n    \"Report file paths and timestamps are tracked and restored on extension reload\",\n    \"Status indicators show whether generation is idle, in progress, or complete\",\n    \"Integration with LLM services to generate content asynchronously\",\n    \"Tree items are created dynamically based on available insights and reports\",\n    \"File system checks verify report existence before displaying items\",\n    \"Context menu actions are available based on item type (copy path, reveal in explorer, open in browser)\",\n    \"Icons and decorations indicate status (loading spinner, checkmarks, etc.)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts internal data into tree items for VS Code's tree view display\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem with label, icon, and command\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for tree hierarchy, showing insights categories and individual reports\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of TreeItem children or null\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the generation status for product documentation and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the generation status for insights and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the generation status for unit tests and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Stores the file path for a generated report and updates display\",\n      \"inputs\": \"File path string and report type, optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a complete refresh of the tree view display\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved timestamps and report paths from previous sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Configures the LLM service used for generating insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the LLM-generated insights data and refreshes display\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual interface in VS Code's sidebar where users can view, manage, and interact with AI-generated code documentation, insights, and analysis reports. It solves the problem of presenting complex analysis results in an organized, accessible tree structure with actions to generate, view, and manage different types of code intelligence reports.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view in VSCode for browsing and navigating AI-generated architecture insights about the codebase",
          "userVisibleActions": [
            "View hierarchical insights tree showing architecture, decisions, principles, patterns, and risks",
            "Navigate to specific code files by clicking on file references in insights",
            "See file paths and line numbers associated with insights",
            "Refresh insights view to see updated analysis results",
            "Expand/collapse insight categories and subcategories",
            "View purpose documentation and architectural decisions in tree structure"
          ],
          "developerVisibleActions": [
            "Tree view automatically refreshes when .shadow/docs/insights.json file changes",
            "Tree view automatically updates when purpose.md file is modified",
            "Can manually refresh the insights view via command",
            "Set custom insights data programmatically via setInsights method",
            "File watchers monitor .shadow directory for changes",
            "Click on items to navigate to referenced source files"
          ],
          "keyFunctions": [
            {
              "name": "refresh",
              "desc": "Reloads insights from the .shadow/docs/insights.json file and updates the tree view",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts insight data into displayable tree items with icons and navigation",
              "inputs": "InsightItem",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given parent in the tree hierarchy",
              "inputs": "InsightItem or undefined",
              "outputs": "Promise<InsightItem[]>"
            },
            {
              "name": "setInsights",
              "desc": "Updates the insights data and refreshes the tree view",
              "inputs": "LLMInsights object",
              "outputs": "void"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Creates file system watchers to auto-refresh when insights or purpose files change",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "handleItemClick",
              "desc": "Opens source code file at specific line when user clicks an insight item with file reference",
              "inputs": "InsightItem",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs",
            "LLMInsights from ./llmService",
            "FileWatcherService from ./domain/services/fileWatcherService"
          ],
          "intent": "This file exists to provide developers with an organized, browsable view of AI-generated architecture insights within VSCode. It solves the problem of making complex architecture analysis accessible and navigable, allowing developers to understand project structure, design decisions, and potential risks through a familiar tree-view interface with direct navigation to relevant code locations.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VSCode for browsing and navigating AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View hierarchical insights tree showing architecture, decisions, principles, patterns, and risks\",\n    \"Navigate to specific code files by clicking on file references in insights\",\n    \"See file paths and line numbers associated with insights\",\n    \"Refresh insights view to see updated analysis results\",\n    \"Expand/collapse insight categories and subcategories\",\n    \"View purpose documentation and architectural decisions in tree structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when .shadow/docs/insights.json file changes\",\n    \"Tree view automatically updates when purpose.md file is modified\",\n    \"Can manually refresh the insights view via command\",\n    \"Set custom insights data programmatically via setInsights method\",\n    \"File watchers monitor .shadow directory for changes\",\n    \"Click on items to navigate to referenced source files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from the .shadow/docs/insights.json file and updates the tree view\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts insight data into displayable tree items with icons and navigation\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given parent in the tree hierarchy\",\n      \"inputs\": \"InsightItem or undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data and refreshes the tree view\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers to auto-refresh when insights or purpose files change\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"handleItemClick\",\n      \"desc\": \"Opens source code file at specific line when user clicks an insight item with file reference\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"LLMInsights from ./llmService\",\n    \"FileWatcherService from ./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with an organized, browsable view of AI-generated architecture insights within VSCode. It solves the problem of making complex architecture analysis accessible and navigable, allowing developers to understand project structure, design decisions, and potential risks through a familiar tree-view interface with direct navigation to relevant code locations.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different presentation styles optimized for various AI assistants and human readers",
          "userVisibleActions": [
            "View architecture issues organized by severity (errors, warnings, info)",
            "See insights formatted for specific AI tools (Cursor, ChatGPT)",
            "Read compact summaries of code issues",
            "Review generic formatted reports of code problems",
            "Get actionable recommendations for fixing architecture issues",
            "See file locations and line numbers for each issue",
            "Understand impact and resolution suggestions for problems"
          ],
          "developerVisibleActions": [
            "Call formatInsights() to convert insight objects into formatted text reports",
            "Choose output format: 'cursor', 'chatgpt', 'compact', or 'generic'",
            "Receive markdown-formatted strings ready for display or AI consumption",
            "Get insights grouped by severity level automatically",
            "Obtain format-specific prompts and instructions for AI assistants",
            "Access structured reports with file paths, descriptions, and recommendations"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Converts insight objects into formatted text based on specified output format",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "Formatted string (markdown) tailored for the specified format"
            },
            {
              "name": "formatForCursor",
              "desc": "Creates Cursor AI-optimized report with severity grouping and action prompts",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string with sections for errors, warnings, info, and assistance requests"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Generates ChatGPT-friendly report with conversational tone and context",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string formatted for ChatGPT's interaction style"
            },
            {
              "name": "formatCompact",
              "desc": "Produces condensed summary showing only essential information",
              "inputs": "insights: Insight[]",
              "outputs": "Brief markdown string with counts and key issues"
            },
            {
              "name": "formatGeneric",
              "desc": "Creates standard format suitable for any AI assistant or human reader",
              "inputs": "insights: Insight[]",
              "outputs": "Generic markdown string with all insights listed sequentially"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats a single insight with full details for Cursor AI",
              "inputs": "insight: Insight",
              "outputs": "Formatted markdown string for one insight"
            },
            {
              "name": "formatInsightForChatGPT",
              "desc": "Formats a single insight optimized for ChatGPT interaction",
              "inputs": "insight: Insight",
              "outputs": "Formatted markdown string for one insight"
            },
            {
              "name": "formatInsightCompact",
              "desc": "Formats a single insight in condensed one-line format",
              "inputs": "insight: Insight",
              "outputs": "Brief string with essential insight information"
            },
            {
              "name": "formatInsightGeneric",
              "desc": "Formats a single insight in standard detailed format",
              "inputs": "insight: Insight",
              "outputs": "Generic formatted string for one insight"
            }
          ],
          "dependencies": [
            "./insightGenerator"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis data and AI-consumable formats, transforming technical insights into structured reports that different AI assistants (Cursor, ChatGPT) can understand and act upon, while also providing human-readable formats for developers to review code architecture issues",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different presentation styles optimized for various AI assistants and human readers\",\n  \"userVisibleActions\": [\n    \"View architecture issues organized by severity (errors, warnings, info)\",\n    \"See insights formatted for specific AI tools (Cursor, ChatGPT)\",\n    \"Read compact summaries of code issues\",\n    \"Review generic formatted reports of code problems\",\n    \"Get actionable recommendations for fixing architecture issues\",\n    \"See file locations and line numbers for each issue\",\n    \"Understand impact and resolution suggestions for problems\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatInsights() to convert insight objects into formatted text reports\",\n    \"Choose output format: 'cursor', 'chatgpt', 'compact', or 'generic'\",\n    \"Receive markdown-formatted strings ready for display or AI consumption\",\n    \"Get insights grouped by severity level automatically\",\n    \"Obtain format-specific prompts and instructions for AI assistants\",\n    \"Access structured reports with file paths, descriptions, and recommendations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Converts insight objects into formatted text based on specified output format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string (markdown) tailored for the specified format\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized report with severity grouping and action prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with sections for errors, warnings, info, and assistance requests\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Generates ChatGPT-friendly report with conversational tone and context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string formatted for ChatGPT's interaction style\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Produces condensed summary showing only essential information\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Brief markdown string with counts and key issues\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format suitable for any AI assistant or human reader\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown string with all insights listed sequentially\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats a single insight with full details for Cursor AI\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats a single insight optimized for ChatGPT interaction\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats a single insight in condensed one-line format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Brief string with essential insight information\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats a single insight in standard detailed format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Generic formatted string for one insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis data and AI-consumable formats, transforming technical insights into structured reports that different AI assistants (Cursor, ChatGPT) can understand and act upon, while also providing human-readable formats for developers to review code architecture issues\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Integrates LLM-powered analysis features with VS Code UI components and manages the lifecycle of code analysis, documentation generation, and insights display.",
          "userVisibleActions": [
            "View AI-generated code insights in a tree view sidebar",
            "Access product documentation with AI-enhanced descriptions",
            "Navigate codebase structure through AI-analyzed entry points",
            "View unit test analysis and coverage information",
            "See analysis results in dedicated viewer panels",
            "Refresh insights manually via command palette or UI buttons",
            "Configure LLM API keys through VS Code settings",
            "Export analysis results and documentation to files",
            "View loading indicators while AI analysis is in progress",
            "Receive notifications when analysis completes or encounters errors"
          ],
          "developerVisibleActions": [
            "Initialize LLM service that connects to AI providers (OpenAI, Anthropic, etc.)",
            "Trigger code analysis on workspace files to extract structure and behavior",
            "Generate product documentation from analyzed code automatically",
            "Load previously saved analysis results and insights from disk",
            "Register VS Code commands for analysis, documentation, and insights management",
            "Set up tree view providers for displaying insights, tests, and navigation",
            "Configure webview panels for rich HTML analysis visualization",
            "Handle configuration changes and API key updates reactively",
            "Manage state persistence across VS Code sessions",
            "Export analysis data in JSON format for external tools"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Sets up the LLM service and connects it to UI components with configuration change handlers",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "analyzeWorkspace",
              "desc": "Analyzes all code files in the workspace to extract structure, entry points, and behavior patterns",
              "inputs": "workspace folder path",
              "outputs": "CodeAnalysis object with insights"
            },
            {
              "name": "generateProductDocumentation",
              "desc": "Creates AI-enhanced documentation from code analysis results",
              "inputs": "CodeAnalysis object",
              "outputs": "EnhancedProductDocumentation object"
            },
            {
              "name": "loadSavedCodeAnalysis",
              "desc": "Retrieves previously saved analysis results from persistent storage",
              "inputs": "workspace identifier",
              "outputs": "CodeAnalysis object or null"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists analysis results to disk for later retrieval",
              "inputs": "CodeAnalysis object, workspace path",
              "outputs": "boolean success status"
            },
            {
              "name": "refreshInsights",
              "desc": "Re-runs AI analysis and updates all tree views and panels with latest insights",
              "inputs": "optional force refresh flag",
              "outputs": "Promise<void>"
            },
            {
              "name": "exportAnalysisResults",
              "desc": "Saves analysis data and documentation to user-specified file location",
              "inputs": "export format, file path",
              "outputs": "Promise<void>"
            },
            {
              "name": "registerCommands",
              "desc": "Registers all VS Code commands for triggering analysis, documentation, and insights features",
              "inputs": "VS Code extension context",
              "outputs": "Disposable array"
            },
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms code analysis results into LLM-compatible context format",
              "inputs": "CodeAnalysis object",
              "outputs": "AnalysisContext object"
            },
            {
              "name": "updateTreeProviders",
              "desc": "Refreshes all tree view providers with updated analysis data",
              "inputs": "analysis results",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "./llmService",
            "./insightsTreeView",
            "./fileDocumentation",
            "./analyzer",
            "./productNavigator",
            "./analysisViewer",
            "./insightsViewer",
            "./unitTestsNavigator",
            "./logger",
            "./state/llmStateManager",
            "./context/analysisContextBuilder",
            "./domain/formatters/documentationFormatter",
            "./infrastructure/persistence/analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis and user-facing AI insights by orchestrating LLM services, managing analysis lifecycle, coordinating multiple UI components (tree views, webviews, navigators), and providing a centralized integration layer that makes AI-powered code understanding accessible through VS Code's interface. It solves the problem of making complex AI analysis results consumable and actionable for developers working in their IDE.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered analysis features with VS Code UI components and manages the lifecycle of code analysis, documentation generation, and insights display.\",\n  \"userVisibleActions\": [\n    \"View AI-generated code insights in a tree view sidebar\",\n    \"Access product documentation with AI-enhanced descriptions\",\n    \"Navigate codebase structure through AI-analyzed entry points\",\n    \"View unit test analysis and coverage information\",\n    \"See analysis results in dedicated viewer panels\",\n    \"Refresh insights manually via command palette or UI buttons\",\n    \"Configure LLM API keys through VS Code settings\",\n    \"Export analysis results and documentation to files\",\n    \"View loading indicators while AI analysis is in progress\",\n    \"Receive notifications when analysis completes or encounters errors\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service that connects to AI providers (OpenAI, Anthropic, etc.)\",\n    \"Trigger code analysis on workspace files to extract structure and behavior\",\n    \"Generate product documentation from analyzed code automatically\",\n    \"Load previously saved analysis results and insights from disk\",\n    \"Register VS Code commands for analysis, documentation, and insights management\",\n    \"Set up tree view providers for displaying insights, tests, and navigation\",\n    \"Configure webview panels for rich HTML analysis visualization\",\n    \"Handle configuration changes and API key updates reactively\",\n    \"Manage state persistence across VS Code sessions\",\n    \"Export analysis data in JSON format for external tools\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service and connects it to UI components with configuration change handlers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes all code files in the workspace to extract structure, entry points, and behavior patterns\",\n      \"inputs\": \"workspace folder path\",\n      \"outputs\": \"CodeAnalysis object with insights\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates AI-enhanced documentation from code analysis results\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis results from persistent storage\",\n      \"inputs\": \"workspace identifier\",\n      \"outputs\": \"CodeAnalysis object or null\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to disk for later retrieval\",\n      \"inputs\": \"CodeAnalysis object, workspace path\",\n      \"outputs\": \"boolean success status\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Re-runs AI analysis and updates all tree views and panels with latest insights\",\n      \"inputs\": \"optional force refresh flag\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportAnalysisResults\",\n      \"desc\": \"Saves analysis data and documentation to user-specified file location\",\n      \"inputs\": \"export format, file path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VS Code commands for triggering analysis, documentation, and insights features\",\n      \"inputs\": \"VS Code extension context\",\n      \"outputs\": \"Disposable array\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis results into LLM-compatible context format\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"AnalysisContext object\"\n    },\n    {\n      \"name\": \"updateTreeProviders\",\n      \"desc\": \"Refreshes all tree view providers with updated analysis data\",\n      \"inputs\": \"analysis results\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and user-facing AI insights by orchestrating LLM services, managing analysis lifecycle, coordinating multiple UI components (tree views, webviews, navigators), and providing a centralized integration layer that makes AI-powered code understanding accessible through VS Code's interface. It solves the problem of making complex AI analysis results consumable and actionable for developers working in their IDE.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure and validate LLM responses for product analysis, code quality issues, behavior extraction, and documentation generation.",
          "userVisibleActions": [
            "Receives structured product purpose analysis explaining what the codebase does and why it's designed that way",
            "Gets organized lists of code quality issues with clear titles, descriptions, and severity levels",
            "Views extracted behavior information from code files in a consistent format",
            "Sees categorized file summaries organized by role (Core Logic, Configuration, etc.)",
            "Receives documentation generation plans with proposed file structures and content outlines"
          ],
          "developerVisibleActions": [
            "Uses schemas to guarantee valid, parseable LLM responses without manual parsing",
            "Ensures LLM outputs include required fields like productPurpose, architectureRationale, and userGoals",
            "Validates that code quality issues contain title, description, severity, and relevant files",
            "Enforces consistent structure for behavior extraction including purpose, actions, and intent",
            "Defines strict response formats for documentation planning with file paths and content sections"
          ],
          "keyFunctions": [
            {
              "name": "productPurposeAnalysisSchema",
              "desc": "Schema for analyzing product purpose and architecture decisions",
              "inputs": "None (schema definition)",
              "outputs": "Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
            },
            {
              "name": "codeQualityIssuesSchema",
              "desc": "Schema for identifying and documenting code quality issues",
              "inputs": "None (schema definition)",
              "outputs": "Object with issues array containing title, description, severity, relevantFiles, tags"
            },
            {
              "name": "behaviorExtractionSchema",
              "desc": "Schema for extracting user-facing and developer-facing behavior from code",
              "inputs": "None (schema definition)",
              "outputs": "Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent"
            },
            {
              "name": "fileCategorizationSchema",
              "desc": "Schema for categorizing files by role with summaries",
              "inputs": "None (schema definition)",
              "outputs": "Object with categorized file summaries by role (Core Logic, UI Components, Configuration, etc.)"
            },
            {
              "name": "documentationPlanSchema",
              "desc": "Schema for generating documentation plans with file structure and content",
              "inputs": "None (schema definition)",
              "outputs": "Object with overview, proposedFiles array, and nextSteps"
            }
          ],
          "dependencies": [],
          "intent": "Provides type-safe schema definitions that ensure Claude AI returns consistent, structured data for product analysis, code quality assessment, behavior extraction, and documentation generation, eliminating the need for fragile response parsing.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate LLM responses for product analysis, code quality issues, behavior extraction, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"Receives structured product purpose analysis explaining what the codebase does and why it's designed that way\",\n    \"Gets organized lists of code quality issues with clear titles, descriptions, and severity levels\",\n    \"Views extracted behavior information from code files in a consistent format\",\n    \"Sees categorized file summaries organized by role (Core Logic, Configuration, etc.)\",\n    \"Receives documentation generation plans with proposed file structures and content outlines\"\n  ],\n  \"developerVisibleActions\": [\n    \"Uses schemas to guarantee valid, parseable LLM responses without manual parsing\",\n    \"Ensures LLM outputs include required fields like productPurpose, architectureRationale, and userGoals\",\n    \"Validates that code quality issues contain title, description, severity, and relevant files\",\n    \"Enforces consistent structure for behavior extraction including purpose, actions, and intent\",\n    \"Defines strict response formats for documentation planning with file paths and content sections\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose and architecture decisions\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"codeQualityIssuesSchema\",\n      \"desc\": \"Schema for identifying and documenting code quality issues\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with issues array containing title, description, severity, relevantFiles, tags\"\n    },\n    {\n      \"name\": \"behaviorExtractionSchema\",\n      \"desc\": \"Schema for extracting user-facing and developer-facing behavior from code\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent\"\n    },\n    {\n      \"name\": \"fileCategorizationSchema\",\n      \"desc\": \"Schema for categorizing files by role with summaries\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with categorized file summaries by role (Core Logic, UI Components, Configuration, etc.)\"\n    },\n    {\n      \"name\": \"documentationPlanSchema\",\n      \"desc\": \"Schema for generating documentation plans with file structure and content\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with overview, proposedFiles array, and nextSteps\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides type-safe schema definitions that ensure Claude AI returns consistent, structured data for product analysis, code quality assessment, behavior extraction, and documentation generation, eliminating the need for fragile response parsing.\"\n}\n```"
        },
        {
          "file": "src/llmService.ts",
          "role": "Core Logic",
          "purpose": "Orchestrates AI-powered code analysis by calling OpenAI/Claude APIs to generate intelligent insights about codebases, including product purpose, architecture analysis, and refactoring suggestions.",
          "userVisibleActions": [
            "Generates comprehensive product documentation explaining what the codebase does and why",
            "Provides intelligent insights about code architecture and design patterns",
            "Analyzes product purpose and core value propositions from code structure",
            "Generates refactoring suggestions for improving code quality",
            "Creates unit test plans for functions and modules",
            "Detects entry points and orphaned files in the codebase",
            "Groups files by modules and analyzes module relationships"
          ],
          "developerVisibleActions": [
            "Calls LLM APIs (OpenAI/Claude) with structured prompts to analyze code",
            "Processes file summaries and module information into AI prompts",
            "Handles rate limiting and retries for API calls automatically",
            "Parses and validates LLM responses against defined schemas",
            "Provides incremental analysis for large codebases to avoid token limits",
            "Manages different LLM providers based on configuration settings",
            "Tracks analysis progress and budget constraints during execution",
            "Exposes methods for product purpose analysis, refactoring analysis, and documentation generation"
          ],
          "keyFunctions": [
            {
              "name": "analyzeProductPurpose",
              "desc": "Analyzes the entire codebase to determine what the product does and its architecture rationale",
              "inputs": "CodeAnalysis object containing file and function metadata",
              "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, and key insights"
            },
            {
              "name": "generateEnhancedProductDocumentation",
              "desc": "Creates comprehensive product documentation by analyzing file roles, modules, and relationships",
              "inputs": "Array of file paths and workspace root",
              "outputs": "EnhancedProductDocumentation with purpose, architecture, modules, and design patterns"
            },
            {
              "name": "generateLLMInsights",
              "desc": "Generates intelligent insights about code quality, patterns, and potential improvements",
              "inputs": "CodeAnalysis object and analysis context",
              "outputs": "Structured insights including quality metrics, patterns, and recommendations"
            },
            {
              "name": "generateRefactoringSuggestions",
              "desc": "Analyzes a function and provides AI-powered refactoring suggestions",
              "inputs": "Function metadata, file content, and surrounding context",
              "outputs": "Refactoring suggestions with rationale and proposed improvements"
            },
            {
              "name": "generateUnitTestPlan",
              "desc": "Creates a comprehensive unit test plan for a given function",
              "inputs": "Function analysis including code, dependencies, and context",
              "outputs": "Test plan with test cases, edge cases, and mocking strategies"
            },
            {
              "name": "callLLMWithRetry",
              "desc": "Makes API calls to LLM providers with automatic retry logic and rate limiting",
              "inputs": "Prompt text, schema for validation, and optional model preferences",
              "outputs": "Parsed and validated LLM response conforming to the specified schema"
            }
          ],
          "dependencies": [
            "vscode",
            "./fileDocumentation",
            "./analyzer",
            "./analysis/enhancedAnalyzer",
            "./llmSchemas",
            "./fileAccessHelper",
            "./logger",
            "./config/configurationManager",
            "./ai/providers/providerFactory",
            "./ai/llmResponseParser",
            "./ai/llmRateLimiter",
            "./ai/llmRetryHandler",
            "./domain/prompts/promptBuilder",
            "./domain/services/incrementalAnalysisService",
            "./domain/prompts/refactoringPromptBuilder",
            "./analysis/functionAnalyzer"
          ],
          "intent": "This file exists to bridge the gap between raw code analysis and human-understandable insights by leveraging LLM capabilities. It solves the problem of understanding large codebases by automatically generating documentation, detecting architectural patterns, and providing intelligent suggestions for improvements. It abstracts away the complexity of working with different AI providers and handles the challenges of token limits, rate limiting, and response parsing.",
          "rawContent": "```json\n{\n  \"purpose\": \"Orchestrates AI-powered code analysis by calling OpenAI/Claude APIs to generate intelligent insights about codebases, including product purpose, architecture analysis, and refactoring suggestions.\",\n  \"userVisibleActions\": [\n    \"Generates comprehensive product documentation explaining what the codebase does and why\",\n    \"Provides intelligent insights about code architecture and design patterns\",\n    \"Analyzes product purpose and core value propositions from code structure\",\n    \"Generates refactoring suggestions for improving code quality\",\n    \"Creates unit test plans for functions and modules\",\n    \"Detects entry points and orphaned files in the codebase\",\n    \"Groups files by modules and analyzes module relationships\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls LLM APIs (OpenAI/Claude) with structured prompts to analyze code\",\n    \"Processes file summaries and module information into AI prompts\",\n    \"Handles rate limiting and retries for API calls automatically\",\n    \"Parses and validates LLM responses against defined schemas\",\n    \"Provides incremental analysis for large codebases to avoid token limits\",\n    \"Manages different LLM providers based on configuration settings\",\n    \"Tracks analysis progress and budget constraints during execution\",\n    \"Exposes methods for product purpose analysis, refactoring analysis, and documentation generation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine what the product does and its architecture rationale\",\n      \"inputs\": \"CodeAnalysis object containing file and function metadata\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, and key insights\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation by analyzing file roles, modules, and relationships\",\n      \"inputs\": \"Array of file paths and workspace root\",\n      \"outputs\": \"EnhancedProductDocumentation with purpose, architecture, modules, and design patterns\"\n    },\n    {\n      \"name\": \"generateLLMInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and potential improvements\",\n      \"inputs\": \"CodeAnalysis object and analysis context\",\n      \"outputs\": \"Structured insights including quality metrics, patterns, and recommendations\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Analyzes a function and provides AI-powered refactoring suggestions\",\n      \"inputs\": \"Function metadata, file content, and surrounding context\",\n      \"outputs\": \"Refactoring suggestions with rationale and proposed improvements\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a comprehensive unit test plan for a given function\",\n      \"inputs\": \"Function analysis including code, dependencies, and context\",\n      \"outputs\": \"Test plan with test cases, edge cases, and mocking strategies\"\n    },\n    {\n      \"name\": \"callLLMWithRetry\",\n      \"desc\": \"Makes API calls to LLM providers with automatic retry logic and rate limiting\",\n      \"inputs\": \"Prompt text, schema for validation, and optional model preferences\",\n      \"outputs\": \"Parsed and validated LLM response conforming to the specified schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and human-understandable insights by leveraging LLM capabilities. It solves the problem of understanding large codebases by automatically generating documentation, detecting architectural patterns, and providing intelligent suggestions for improvements. It abstracts away the complexity of working with different AI providers and handles the challenges of token limits, rate limiting, and response parsing.\"\n}\n```"
        },
        {
          "file": "src/logger.ts",
          "role": "Core Logic",
          "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
          "userVisibleActions": [
            "Log files are automatically created in the .shadow/logs/ directory of the workspace",
            "All logged events are timestamped with ISO format timestamps",
            "Log messages are appended to shadow-watch.log file with date and time information"
          ],
          "developerVisibleActions": [
            "Developer calls SWLogger.log() to write timestamped messages to the log file",
            "Developer calls SWLogger.section() to create visual section separators in the log",
            "Logging automatically creates the .shadow/logs directory structure if it doesn't exist",
            "Logging fails silently if workspace is not available or file operations fail"
          ],
          "keyFunctions": [
            {
              "name": "log",
              "desc": "Writes a timestamped message to the shadow-watch.log file",
              "inputs": "message: string - the text to log",
              "outputs": "void - writes to file system, no return value"
            },
            {
              "name": "section",
              "desc": "Creates a visual section separator in the log with a title",
              "inputs": "title: string - the section heading",
              "outputs": "void - writes formatted section header to log"
            },
            {
              "name": "getLogPath",
              "desc": "Determines the full file path where logs should be written",
              "inputs": "none",
              "outputs": "string | null - path to log file or null if no workspace is open"
            },
            {
              "name": "ensureDir",
              "desc": "Creates a directory and parent directories if they don't exist",
              "inputs": "dir: string - directory path to create",
              "outputs": "void - creates directory structure"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "vscode"
          ],
          "intent": "Provides a centralized logging mechanism for the extension to track events and debugging information in a persistent file within the workspace, making it easier to diagnose issues and understand extension behavior over time",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are automatically created in the .shadow/logs/ directory of the workspace\",\n    \"All logged events are timestamped with ISO format timestamps\",\n    \"Log messages are appended to shadow-watch.log file with date and time information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls SWLogger.log() to write timestamped messages to the log file\",\n    \"Developer calls SWLogger.section() to create visual section separators in the log\",\n    \"Logging automatically creates the .shadow/logs directory structure if it doesn't exist\",\n    \"Logging fails silently if workspace is not available or file operations fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - the text to log\",\n      \"outputs\": \"void - writes to file system, no return value\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a visual section separator in the log with a title\",\n      \"inputs\": \"title: string - the section heading\",\n      \"outputs\": \"void - writes formatted section header to log\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the full file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - path to log file or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory and parent directories if they don't exist\",\n      \"inputs\": \"dir: string - directory path to create\",\n      \"outputs\": \"void - creates directory structure\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"Provides a centralized logging mechanism for the extension to track events and debugging information in a persistent file within the workspace, making it easier to diagnose issues and understand extension behavior over time\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadow-watch.analyzeCode",
          "description": "Triggers comprehensive code analysis of the workspace, generating insights and documentation"
        },
        {
          "command": "shadow-watch.generateInsights",
          "description": "Generates AI-powered code insights including quality issues, architecture analysis, and refactoring suggestions"
        },
        {
          "command": "shadow-watch.generateProductDocs",
          "description": "Creates AI-generated product documentation explaining what the codebase does and its purpose"
        },
        {
          "command": "shadow-watch.generateUnitTests",
          "description": "Generates unit test plans and test coverage analysis for functions and modules"
        },
        {
          "command": "shadow-watch.exportAnalysis",
          "description": "Exports analysis results and documentation to files in various formats"
        },
        {
          "command": "shadow-watch.refreshInsights",
          "description": "Refreshes the insights tree view to show updated analysis information"
        },
        {
          "command": "shadow-watch.clearCache",
          "description": "Clears the analysis cache to force fresh analysis on next run"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized management of all Shadow Watch extension settings and preferences",
        "Real-time configuration change notifications to keep UI and analysis components synchronized",
        "Control over extension activation state and analysis triggers",
        "Customizable analysis behavior including severity thresholds and output formats",
        "Flexible LLM provider configuration supporting multiple AI services",
        "Performance tuning through adjustable batch sizes and concurrency limits"
      ],
      "summary": "The config module serves as the central configuration hub for the Shadow Watch extension, managing all user preferences and settings. It provides a unified interface for controlling how the extension operates, from basic activation toggles to advanced LLM provider configurations. The module ensures that all components of the extension stay synchronized when users modify their settings through VS Code's settings UI.\n\nUsers can customize their experience by controlling when and how code analysis occurs. The module supports toggling analyze-on-save functionality, adjusting inline hint visibility, and setting minimum severity thresholds to filter which issues appear in the editor. For AI-powered analysis, users can select between different LLM providers (OpenAI or Claude), configure API credentials, and choose output formats that match their preferred workflow (Cursor, ChatGPT, Generic, or Compact).\n\nThe configuration system also enables performance optimization through adjustable parameters like batch size and concurrency limits. When users modify any setting, the module immediately propagates these changes throughout the extension, ensuring consistent behavior across all features. This reactive configuration management allows users to fine-tune Shadow Watch to match their development environment and coding style without requiring extension restarts.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes occur.",
          "userVisibleActions": [
            "User enables or disables Shadow Watch extension",
            "User toggles analyze-on-save functionality",
            "User shows or hides inline hints in the editor",
            "User configures which LLM provider to use (OpenAI or Claude)",
            "User selects output format for LLM results (Cursor, ChatGPT, Generic, or Compact)",
            "User sets minimum severity threshold for displayed issues (error, warning, or info)",
            "User configures API keys and endpoints for LLM services",
            "User adjusts analysis settings like batch size and concurrency limits"
          ],
          "developerVisibleActions": [
            "Developer accesses centralized configuration properties through type-safe getters",
            "Developer registers callbacks to respond when settings change",
            "Developer validates configuration to ensure required settings are present",
            "Developer queries specific configuration sections without directly accessing VSCode API",
            "Configuration automatically reloads when user modifies settings in VSCode preferences"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes configuration manager and sets up automatic configuration change detection",
              "inputs": "none",
              "outputs": "ConfigurationManager instance"
            },
            {
              "name": "onConfigurationChange",
              "desc": "Registers a callback function to be notified when any Shadow Watch configuration changes",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Unregisters a previously registered configuration change callback",
              "inputs": "callback function",
              "outputs": "void"
            },
            {
              "name": "enabled (getter)",
              "desc": "Returns whether Shadow Watch extension is currently enabled",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave (getter)",
              "desc": "Returns whether automatic analysis should run when files are saved",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "showInlineHints (getter)",
              "desc": "Returns whether inline hints should be displayed in the editor",
              "inputs": "none",
              "outputs": "boolean"
            },
            {
              "name": "llmProvider (getter)",
              "desc": "Returns the selected LLM provider (OpenAI or Claude)",
              "inputs": "none",
              "outputs": "LLMProvider type"
            },
            {
              "name": "llmFormat (getter)",
              "desc": "Returns the selected output format for LLM analysis results",
              "inputs": "none",
              "outputs": "LLMFormat type"
            },
            {
              "name": "severityThreshold (getter)",
              "desc": "Returns the minimum severity level for displaying issues",
              "inputs": "none",
              "outputs": "SeverityThreshold type"
            },
            {
              "name": "validate",
              "desc": "Checks if the current configuration is valid and returns any errors found",
              "inputs": "none",
              "outputs": "ConfigValidationResult with valid flag and error list"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to provide a single source of truth for all Shadow Watch configuration settings, eliminating the need for components to directly access VSCode's configuration API and ensuring type safety throughout the extension. It solves the problem of scattered configuration access and makes it easy to react to configuration changes across the entire extension.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes occur.\",\n  \"userVisibleActions\": [\n    \"User enables or disables Shadow Watch extension\",\n    \"User toggles analyze-on-save functionality\",\n    \"User shows or hides inline hints in the editor\",\n    \"User configures which LLM provider to use (OpenAI or Claude)\",\n    \"User selects output format for LLM results (Cursor, ChatGPT, Generic, or Compact)\",\n    \"User sets minimum severity threshold for displayed issues (error, warning, or info)\",\n    \"User configures API keys and endpoints for LLM services\",\n    \"User adjusts analysis settings like batch size and concurrency limits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer accesses centralized configuration properties through type-safe getters\",\n    \"Developer registers callbacks to respond when settings change\",\n    \"Developer validates configuration to ensure required settings are present\",\n    \"Developer queries specific configuration sections without directly accessing VSCode API\",\n    \"Configuration automatically reloads when user modifies settings in VSCode preferences\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes configuration manager and sets up automatic configuration change detection\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be notified when any Shadow Watch configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled (getter)\",\n      \"desc\": \"Returns whether Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave (getter)\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints (getter)\",\n      \"desc\": \"Returns whether inline hints should be displayed in the editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider (getter)\",\n      \"desc\": \"Returns the selected LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider type\"\n    },\n    {\n      \"name\": \"llmFormat (getter)\",\n      \"desc\": \"Returns the selected output format for LLM analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMFormat type\"\n    },\n    {\n      \"name\": \"severityThreshold (getter)\",\n      \"desc\": \"Returns the minimum severity level for displaying issues\",\n      \"inputs\": \"none\",\n      \"outputs\": \"SeverityThreshold type\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Checks if the current configuration is valid and returns any errors found\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult with valid flag and error list\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single source of truth for all Shadow Watch configuration settings, eliminating the need for components to directly access VSCode's configuration API and ensuring type safety throughout the extension. It solves the problem of scattered configuration access and makes it easy to react to configuration changes across the entire extension.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Automatically captures and structures code analysis results for LLM consumption",
        "Persists analysis snapshots to disk with timestamps for historical tracking",
        "Organizes analysis data including file statistics, entry points, and import relationships",
        "Provides a structured documentation format that can be referenced by LLMs during code generation and modification tasks",
        "Maintains a persistent record of codebase structure in the .shadow/docs directory"
      ],
      "summary": "The context module serves as the bridge between code analysis and LLM-based documentation. It takes raw analysis results from the codebase and transforms them into a structured, timestamped format optimized for language model consumption. This enables LLMs to better understand the codebase structure, dependencies, and relationships when generating or modifying code.\n\nAll analysis results are automatically saved to the .shadow/docs directory within the workspace, creating a persistent documentation layer. Each snapshot includes comprehensive file statistics, identified entry points, and detailed import relationship mappings. The timestamped nature of these snapshots allows developers and automated systems to track how the codebase structure evolves over time.\n\nThis module is essential for maintaining context awareness in AI-assisted development workflows. By providing a standardized format for code structure information, it ensures that LLMs have access to accurate, up-to-date information about the codebase when performing tasks like code generation, refactoring, or documentation creation.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis results into a structured format for LLM consumption and saves them to disk for documentation and future reference",
          "userVisibleActions": [
            "Code analysis results are automatically saved to the .shadow/docs directory in the workspace",
            "Analysis results include file statistics, entry points, and import relationships",
            "Analysis snapshots are timestamped for tracking when documentation was generated"
          ],
          "developerVisibleActions": [
            "Call convertCodeAnalysisToContext() to transform CodeAnalysis into AnalysisContext format suitable for LLM processing",
            "Call saveCodeAnalysis() to persist analysis results to .shadow/docs/code-analysis.json",
            "Analysis data is structured with metadata including generation timestamps",
            "Files are automatically organized into .shadow/docs directory structure"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms CodeAnalysis format into AnalysisContext format for LLM service consumption",
              "inputs": "analysis: CodeAnalysis object containing files, imports, entry points, and statistics",
              "outputs": "AnalysisContext object with formatted file data, imports, entry points, orphaned files, and code metrics"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis results to disk in JSON format with metadata",
              "inputs": "analysis: CodeAnalysis object to save",
              "outputs": "void (creates .shadow/docs/code-analysis.json file)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between code analysis results and LLM documentation generation by converting analysis data into a consumable format and persisting it for documentation purposes. It solves the problem of making codebase analysis results accessible to both AI services and developers, while maintaining a historical record of project structure over time.",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a structured format for LLM consumption and saves them to disk for documentation and future reference\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to the .shadow/docs directory in the workspace\",\n    \"Analysis results include file statistics, entry points, and import relationships\",\n    \"Analysis snapshots are timestamped for tracking when documentation was generated\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call convertCodeAnalysisToContext() to transform CodeAnalysis into AnalysisContext format suitable for LLM processing\",\n    \"Call saveCodeAnalysis() to persist analysis results to .shadow/docs/code-analysis.json\",\n    \"Analysis data is structured with metadata including generation timestamps\",\n    \"Files are automatically organized into .shadow/docs directory structure\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis format into AnalysisContext format for LLM service consumption\",\n      \"inputs\": \"analysis: CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file data, imports, entry points, orphaned files, and code metrics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk in JSON format with metadata\",\n      \"inputs\": \"analysis: CodeAnalysis object to save\",\n      \"outputs\": \"void (creates .shadow/docs/code-analysis.json file)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM documentation generation by converting analysis data into a consumable format and persisting it for documentation purposes. It solves the problem of making codebase analysis results accessible to both AI services and developers, while maintaining a historical record of project structure over time.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Registers and exposes all extension commands that users can trigger from the command palette, context menus, and UI controls",
        "Initializes the complete extension architecture including analyzers, viewers, tree providers, and status indicators",
        "Automatically monitors file changes and triggers re-analysis to keep code insights current",
        "Integrates all extension components into VS Code's UI including sidebar panels, status bar, and diagnostics",
        "Manages the lifecycle of all extension services from activation through runtime operations"
      ],
      "summary": "This module serves as the foundation and entry point for the entire VS Code extension, handling both command registration and component initialization. It wires together all the pieces users interact with - from the command palette actions to the sidebar tree views - and ensures they work cohesively.\n\nWhen the extension activates, this module establishes the complete user interface including the Insights viewer, Analysis panel, Product Navigator, Unit Tests view, and Reports viewer. It also sets up automatic file monitoring so that as developers edit code, the extension continuously re-analyzes and updates insights without manual intervention. The status bar displays real-time feedback about analysis progress and current state.\n\nUsers interact with this module's capabilities primarily through VS Code commands (accessible via command palette or context menus) that enable actions like analyzing the workspace, copying insights to clipboard, clearing cached data, switching LLM providers, and navigating through code structure. The module ensures all these commands are properly registered and connected to their underlying functionality, while also managing the visual feedback through diagnostics, tree views, and status indicators that appear throughout the VS Code interface.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers and manages all VS Code commands that users and developers can trigger in the extension",
          "userVisibleActions": [
            "Analyze entire workspace to get code insights",
            "Analyze currently open file",
            "Copy all insights to clipboard",
            "Copy insights for specific file",
            "Copy individual insight",
            "Clear cached analysis data",
            "Clear all extension data",
            "Open extension settings",
            "Open latest analysis report",
            "Open latest unit test report",
            "Switch between different LLM providers",
            "Copy menu structure",
            "View current provider status",
            "Navigate to product items in codebase",
            "Navigate to analysis items",
            "Show detailed information for product items",
            "Show detailed information for insights",
            "Show detailed information for unit test items"
          ],
          "developerVisibleActions": [
            "Command handlers are registered and bound to VS Code command palette",
            "All commands are centrally managed in one registry",
            "Extension components are wired to command handlers",
            "Commands integrate with code analyzer, insight generator, diagnostics provider, and LLM services",
            "Command execution triggers analysis workflows and UI updates",
            "Configuration manager controls command behavior"
          ],
          "keyFunctions": [
            {
              "name": "register",
              "desc": "Registers all extension commands with VS Code and creates command handlers",
              "inputs": "VS Code extension context and extension components",
              "outputs": "Command handlers object for all registered commands"
            },
            {
              "name": "CommandHandlers interface",
              "desc": "Defines all available command handler functions in the extension",
              "inputs": "Various - depends on specific command (workspace, files, items)",
              "outputs": "Promise<void> for async operations"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "Centralizes command registration logic to separate concerns from main extension activation, making all user-facing actions discoverable and maintainable in one place while wiring together various extension components to execute those actions",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers and manages all VS Code commands that users and developers can trigger in the extension\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to get code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file\",\n    \"Copy individual insight\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between different LLM providers\",\n    \"Copy menu structure\",\n    \"View current provider status\",\n    \"Navigate to product items in codebase\",\n    \"Navigate to analysis items\",\n    \"Show detailed information for product items\",\n    \"Show detailed information for insights\",\n    \"Show detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Command handlers are registered and bound to VS Code command palette\",\n    \"All commands are centrally managed in one registry\",\n    \"Extension components are wired to command handlers\",\n    \"Commands integrate with code analyzer, insight generator, diagnostics provider, and LLM services\",\n    \"Command execution triggers analysis workflows and UI updates\",\n    \"Configuration manager controls command behavior\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all extension commands with VS Code and creates command handlers\",\n      \"inputs\": \"VS Code extension context and extension components\",\n      \"outputs\": \"Command handlers object for all registered commands\"\n    },\n    {\n      \"name\": \"CommandHandlers interface\",\n      \"desc\": \"Defines all available command handler functions in the extension\",\n      \"inputs\": \"Various - depends on specific command (workspace, files, items)\",\n      \"outputs\": \"Promise<void> for async operations\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"Centralizes command registration logic to separate concerns from main extension activation, making all user-facing actions discoverable and maintainable in one place while wiring together various extension components to execute those actions\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Initializes and wires together all VS Code extension components during activation, setting up analyzers, viewers, providers, and event handlers",
          "userVisibleActions": [
            "Extension activates and displays status bar item showing analysis state",
            "Tree views appear in sidebar (Insights, Analysis, Product Navigator, Unit Tests, Reports)",
            "File changes trigger automatic re-analysis with visual feedback",
            "Diagnostics appear in Problems panel for code issues",
            "Status bar shows current analysis or generation status",
            "Reports viewer displays generated analysis reports",
            "Product Navigator shows navigable code structure",
            "Static analysis results appear in dedicated viewer"
          ],
          "developerVisibleActions": [
            "Extension registers all commands during activation",
            "Sets up file watchers for automatic analysis on code changes",
            "Initializes LLM integration for code analysis",
            "Creates and registers tree view providers for different views",
            "Establishes diagnostics collection for problem reporting",
            "Configures caching system for analysis results",
            "Wires event handlers for configuration changes",
            "Manages state across extension lifecycle"
          ],
          "keyFunctions": [
            {
              "name": "bootstrap",
              "desc": "Main entry point that initializes all extension components and returns them as a structured object",
              "inputs": "context: vscode.ExtensionContext (VS Code extension context)",
              "outputs": "ExtensionComponents (object containing all initialized extension components)"
            },
            {
              "name": "createAnalyzer",
              "desc": "Creates and configures the code analyzer component",
              "inputs": "context",
              "outputs": "CodeAnalyzer instance"
            },
            {
              "name": "createInsightGenerator",
              "desc": "Creates the insight generator for producing code insights",
              "inputs": "context",
              "outputs": "InsightGenerator instance"
            },
            {
              "name": "createFileWatcher",
              "desc": "Sets up file watching to detect code changes and trigger re-analysis",
              "inputs": "context, analyzer",
              "outputs": "FileWatcher instance"
            },
            {
              "name": "createTreeProviders",
              "desc": "Initializes all tree view providers for different UI panels",
              "inputs": "context, components",
              "outputs": "Object containing tree providers and tree views"
            },
            {
              "name": "createStatusBarItem",
              "desc": "Creates the status bar indicator showing extension state",
              "inputs": "none",
              "outputs": "vscode.StatusBarItem"
            },
            {
              "name": "registerCommands",
              "desc": "Registers all VS Code commands provided by the extension",
              "inputs": "context, components",
              "outputs": "void"
            },
            {
              "name": "setupEventHandlers",
              "desc": "Configures event listeners for configuration changes and other events",
              "inputs": "context, components",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "FileWatcher",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "llmIntegration",
            "ProductNavigatorProvider",
            "AnalysisViewerProvider",
            "InsightsViewerProvider",
            "StaticAnalysisViewerProvider",
            "UnitTestsNavigatorProvider",
            "configurationManager",
            "ErrorHandler",
            "FileWatcherService",
            "ReportsViewer",
            "ReportsTreeProvider",
            "llmStateManager"
          ],
          "intent": "This file exists to separate and centralize the complex initialization logic required when the VS Code extension activates. It solves the problem of managing dependencies between multiple components, ensuring they are created in the correct order, properly wired together, and all UI elements, commands, and event handlers are registered. This modular approach makes the extension's activation process maintainable and testable by extracting it from the main extension.ts file.",
          "rawContent": "```json\n{\n  \"purpose\": \"Initializes and wires together all VS Code extension components during activation, setting up analyzers, viewers, providers, and event handlers\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis state\",\n    \"Tree views appear in sidebar (Insights, Analysis, Product Navigator, Unit Tests, Reports)\",\n    \"File changes trigger automatic re-analysis with visual feedback\",\n    \"Diagnostics appear in Problems panel for code issues\",\n    \"Status bar shows current analysis or generation status\",\n    \"Reports viewer displays generated analysis reports\",\n    \"Product Navigator shows navigable code structure\",\n    \"Static analysis results appear in dedicated viewer\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension registers all commands during activation\",\n    \"Sets up file watchers for automatic analysis on code changes\",\n    \"Initializes LLM integration for code analysis\",\n    \"Creates and registers tree view providers for different views\",\n    \"Establishes diagnostics collection for problem reporting\",\n    \"Configures caching system for analysis results\",\n    \"Wires event handlers for configuration changes\",\n    \"Manages state across extension lifecycle\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components and returns them as a structured object\",\n      \"inputs\": \"context: vscode.ExtensionContext (VS Code extension context)\",\n      \"outputs\": \"ExtensionComponents (object containing all initialized extension components)\"\n    },\n    {\n      \"name\": \"createAnalyzer\",\n      \"desc\": \"Creates and configures the code analyzer component\",\n      \"inputs\": \"context\",\n      \"outputs\": \"CodeAnalyzer instance\"\n    },\n    {\n      \"name\": \"createInsightGenerator\",\n      \"desc\": \"Creates the insight generator for producing code insights\",\n      \"inputs\": \"context\",\n      \"outputs\": \"InsightGenerator instance\"\n    },\n    {\n      \"name\": \"createFileWatcher\",\n      \"desc\": \"Sets up file watching to detect code changes and trigger re-analysis\",\n      \"inputs\": \"context, analyzer\",\n      \"outputs\": \"FileWatcher instance\"\n    },\n    {\n      \"name\": \"createTreeProviders\",\n      \"desc\": \"Initializes all tree view providers for different UI panels\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"Object containing tree providers and tree views\"\n    },\n    {\n      \"name\": \"createStatusBarItem\",\n      \"desc\": \"Creates the status bar indicator showing extension state\",\n      \"inputs\": \"none\",\n      \"outputs\": \"vscode.StatusBarItem\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VS Code commands provided by the extension\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupEventHandlers\",\n      \"desc\": \"Configures event listeners for configuration changes and other events\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"This file exists to separate and centralize the complex initialization logic required when the VS Code extension activates. It solves the problem of managing dependencies between multiple components, ensuring they are created in the correct order, properly wired together, and all UI elements, commands, and event handlers are registered. This modular approach makes the extension's activation process maintainable and testable by extracting it from the main extension.ts file.\"\n}\n```"
        }
      ],
      "commands": [
        {
          "command": "extension.analyzeWorkspace",
          "description": "Analyze entire workspace to generate comprehensive code insights across all files"
        },
        {
          "command": "extension.analyzeCurrentFile",
          "description": "Analyze only the currently open file for focused insights"
        },
        {
          "command": "extension.copyAllInsights",
          "description": "Copy all generated insights to clipboard for sharing or documentation"
        },
        {
          "command": "extension.copyInsightsForFile",
          "description": "Copy insights for a specific file to clipboard"
        },
        {
          "command": "extension.copyInsight",
          "description": "Copy an individual insight item to clipboard"
        },
        {
          "command": "extension.clearCache",
          "description": "Clear cached analysis data to force fresh analysis"
        },
        {
          "command": "extension.clearAllData",
          "description": "Clear all extension data including cache and settings"
        },
        {
          "command": "extension.openSettings",
          "description": "Open extension configuration settings"
        },
        {
          "command": "extension.openLatestReport",
          "description": "View the most recent analysis report"
        },
        {
          "command": "extension.openLatestUnitTestReport",
          "description": "View the most recent unit test report"
        },
        {
          "command": "extension.switchProvider",
          "description": "Switch between different LLM providers (OpenAI, Anthropic, etc.)"
        },
        {
          "command": "extension.copyMenuStructure",
          "description": "Copy the menu structure to clipboard"
        },
        {
          "command": "extension.showProviderStatus",
          "description": "Display current LLM provider configuration and status"
        },
        {
          "command": "extension.navigateToProductItem",
          "description": "Navigate to a specific product item in the codebase"
        },
        {
          "command": "extension.navigateToAnalysisItem",
          "description": "Navigate to a specific analysis item"
        },
        {
          "command": "extension.showProductItemDetails",
          "description": "Show detailed information panel for a product item"
        },
        {
          "command": "extension.showInsightDetails",
          "description": "Show detailed information panel for an insight"
        },
        {
          "command": "extension.showUnitTestDetails",
          "description": "Show detailed information panel for a unit test item"
        }
      ]
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Format product documentation into human-readable Markdown with organized sections",
        "Generate timestamped documentation exports for version tracking",
        "Structure AI-generated insights into accessible, readable formats",
        "Organize usage information by interface type (GUI, CLI, API)",
        "Present technical architecture and design patterns in clear sections",
        "Format integration details and dependency information",
        "Display code quality assessments and improvement suggestions"
      ],
      "summary": "The formatters module transforms raw product documentation and AI-generated insights into polished, human-readable Markdown format. It takes structured data about a codebase and converts it into comprehensive documentation that users can easily read, understand, and export.\n\nUsers interact with this module when viewing generated documentation in their editor or exporting it to files. The module automatically organizes content into logical sections including product overviews, usage instructions segmented by interface type, technical architecture details, and AI insights. Each document includes a timestamp for version tracking and follows a consistent formatting structure.\n\nThe primary workflow involves receiving structured documentation data, applying formatting rules to create well-organized Markdown sections, and outputting the result for display or export. This enables users to quickly access professional-quality documentation about their codebase without manual formatting effort.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and AI insights into human-readable Markdown format for display and export.",
          "userVisibleActions": [
            "View generated product documentation in Markdown format with timestamp",
            "See structured sections including Product Overview, What It Does, and User Perspective",
            "Read GUI, CLI, and API usage information organized by interface type",
            "View technical architecture documentation with structure and patterns",
            "See integration details and external dependencies",
            "Review AI-generated insights about the codebase in organized sections",
            "Read architecture overview with quality assessment",
            "See design patterns, security considerations, and scalability notes",
            "View suggested improvements and optimization opportunities",
            "Export documentation as formatted Markdown files"
          ],
          "developerVisibleActions": [
            "Call formatEnhancedDocsAsMarkdown() to convert product documentation objects to Markdown",
            "Call formatInsightsAsMarkdown() to convert AI insights objects to Markdown",
            "Pass EnhancedProductDocumentation objects to get formatted output",
            "Pass LLMInsights objects to get structured analysis output",
            "Receive Markdown strings that can be displayed or saved to files",
            "Generate timestamped documentation with both UTC and local time",
            "Create consistent documentation structure across different data types"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation object into formatted Markdown with sections for overview, features, user perspective, architecture, and integrations",
              "inputs": "EnhancedProductDocumentation object containing product details",
              "outputs": "Markdown-formatted string with hierarchical documentation structure"
            },
            {
              "name": "formatInsightsAsMarkdown",
              "desc": "Converts AI-generated insights into formatted Markdown with sections for architecture, design patterns, security, scalability, and improvements",
              "inputs": "LLMInsights object containing AI analysis results",
              "outputs": "Markdown-formatted string with structured insights and recommendations"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "This file exists to separate documentation formatting logic from business logic, providing a dedicated formatter that converts structured data objects into human-readable Markdown documentation with consistent formatting, timestamps, and hierarchical organization for both product documentation and AI insights.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and AI insights into human-readable Markdown format for display and export.\",\n  \"userVisibleActions\": [\n    \"View generated product documentation in Markdown format with timestamp\",\n    \"See structured sections including Product Overview, What It Does, and User Perspective\",\n    \"Read GUI, CLI, and API usage information organized by interface type\",\n    \"View technical architecture documentation with structure and patterns\",\n    \"See integration details and external dependencies\",\n    \"Review AI-generated insights about the codebase in organized sections\",\n    \"Read architecture overview with quality assessment\",\n    \"See design patterns, security considerations, and scalability notes\",\n    \"View suggested improvements and optimization opportunities\",\n    \"Export documentation as formatted Markdown files\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert product documentation objects to Markdown\",\n    \"Call formatInsightsAsMarkdown() to convert AI insights objects to Markdown\",\n    \"Pass EnhancedProductDocumentation objects to get formatted output\",\n    \"Pass LLMInsights objects to get structured analysis output\",\n    \"Receive Markdown strings that can be displayed or saved to files\",\n    \"Generate timestamped documentation with both UTC and local time\",\n    \"Create consistent documentation structure across different data types\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown with sections for overview, features, user perspective, architecture, and integrations\",\n      \"inputs\": \"EnhancedProductDocumentation object containing product details\",\n      \"outputs\": \"Markdown-formatted string with hierarchical documentation structure\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts AI-generated insights into formatted Markdown with sections for architecture, design patterns, security, scalability, and improvements\",\n      \"inputs\": \"LLMInsights object containing AI analysis results\",\n      \"outputs\": \"Markdown-formatted string with structured insights and recommendations\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting logic from business logic, providing a dedicated formatter that converts structured data objects into human-readable Markdown documentation with consistent formatting, timestamps, and hierarchical organization for both product documentation and AI insights.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate to specific files in the codebase by clicking navigator items",
        "Jump to and highlight function definitions within files",
        "Navigate to API endpoint implementations in the code",
        "Navigate to application entry points with automatic cursor positioning",
        "Preview code details and locations for selected items",
        "Open files at specific line numbers with cursor positioning",
        "Receive error notifications when navigation fails"
      ],
      "summary": "The Navigation Handler module enables seamless code navigation throughout the codebase from the product navigator and analysis viewer interfaces. Users can click on various code elements (files, functions, endpoints, entry points) to instantly open and position their cursor at the exact location in the editor.\n\nThis module orchestrates the complete navigation workflow: when a user selects an item in the navigator, the handler opens the corresponding file in the editor, positions the cursor at the relevant line number, and highlights the target code element. It supports navigation to multiple code artifact types including standalone files, function definitions, API endpoint implementations, and application entry points. The handler provides visual feedback through code previews and displays helpful error messages when files cannot be located or opened, ensuring users always understand the navigation outcome.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation to files, functions, endpoints, and other code locations when users interact with the product navigator and analysis viewer.",
          "userVisibleActions": [
            "Opens files in the editor when clicking on file items in the navigator",
            "Jumps to specific functions within files and highlights the function location",
            "Navigates to API endpoints and displays their location in code",
            "Shows error messages when files cannot be opened or locations cannot be found",
            "Displays code previews and details for selected items",
            "Navigates to entry points and highlights their definitions",
            "Opens and positions cursor at specific line numbers in files"
          ],
          "developerVisibleActions": [
            "Resolves relative and absolute file paths within the workspace",
            "Searches for function definitions within opened documents",
            "Handles navigation from ProductNavItem and AnalysisItem structures",
            "Manages editor focus and cursor positioning after navigation",
            "Converts between different item types (product items, analysis items, entry points)",
            "Provides error handling and user feedback for failed navigation attempts",
            "Supports navigation to various item types: files, functions, endpoints, classes, methods"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Navigates to a product navigation item (file, function, endpoint)",
              "inputs": "ProductNavItem containing file path, function name, and type information",
              "outputs": "Promise<void> - opens document and positions cursor"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to an analysis viewer item",
              "inputs": "AnalysisItem with file and location details",
              "outputs": "Promise<void> - opens document at specified location"
            },
            {
              "name": "navigateToEntryPoint",
              "desc": "Navigates to an entry point definition",
              "inputs": "EntryPoint with file path and position information",
              "outputs": "Promise<void> - opens file and highlights entry point"
            },
            {
              "name": "showItemDetails",
              "desc": "Displays detailed information about a selected item",
              "inputs": "Item object with metadata and description",
              "outputs": "void - shows details panel or quick pick with information"
            },
            {
              "name": "findFunctionInDocument",
              "desc": "Searches for a function definition within an open document",
              "inputs": "TextDocument and function name string",
              "outputs": "Position or Range where function is located, or undefined if not found"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "productNavigator",
            "analysisViewer",
            "analyzer"
          ],
          "intent": "Separates navigation concerns from the main extension code, providing a centralized handler for all file and code location navigation triggered by user interactions with the product navigator and analysis viewer trees. Solves the problem of scattered navigation logic by consolidating it into a single, testable module.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations when users interact with the product navigator and analysis viewer.\",\n  \"userVisibleActions\": [\n    \"Opens files in the editor when clicking on file items in the navigator\",\n    \"Jumps to specific functions within files and highlights the function location\",\n    \"Navigates to API endpoints and displays their location in code\",\n    \"Shows error messages when files cannot be opened or locations cannot be found\",\n    \"Displays code previews and details for selected items\",\n    \"Navigates to entry points and highlights their definitions\",\n    \"Opens and positions cursor at specific line numbers in files\"\n  ],\n  \"developerVisibleActions\": [\n    \"Resolves relative and absolute file paths within the workspace\",\n    \"Searches for function definitions within opened documents\",\n    \"Handles navigation from ProductNavItem and AnalysisItem structures\",\n    \"Manages editor focus and cursor positioning after navigation\",\n    \"Converts between different item types (product items, analysis items, entry points)\",\n    \"Provides error handling and user feedback for failed navigation attempts\",\n    \"Supports navigation to various item types: files, functions, endpoints, classes, methods\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, endpoint)\",\n      \"inputs\": \"ProductNavItem containing file path, function name, and type information\",\n      \"outputs\": \"Promise<void> - opens document and positions cursor\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis viewer item\",\n      \"inputs\": \"AnalysisItem with file and location details\",\n      \"outputs\": \"Promise<void> - opens document at specified location\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point definition\",\n      \"inputs\": \"EntryPoint with file path and position information\",\n      \"outputs\": \"Promise<void> - opens file and highlights entry point\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a selected item\",\n      \"inputs\": \"Item object with metadata and description\",\n      \"outputs\": \"void - shows details panel or quick pick with information\"\n    },\n    {\n      \"name\": \"findFunctionInDocument\",\n      \"desc\": \"Searches for a function definition within an open document\",\n      \"inputs\": \"TextDocument and function name string\",\n      \"outputs\": \"Position or Range where function is located, or undefined if not found\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"analyzer\"\n  ],\n  \"intent\": \"Separates navigation concerns from the main extension code, providing a centralized handler for all file and code location navigation triggered by user interactions with the product navigator and analysis viewer trees. Solves the problem of scattered navigation logic by consolidating it into a single, testable module.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Generate structured prompts for LLM-based architecture analysis of codebases",
        "Create prompts for automated documentation generation from code analysis",
        "Build prompts for comprehensive test planning and test code generation",
        "Generate detailed refactoring recommendations with extraction plans and migration steps",
        "Produce context-aware prompts that help LLMs understand code purpose and dependencies",
        "Create test setup configuration prompts based on codebase characteristics",
        "Generate prioritized test plans with coverage targets and test case specifications"
      ],
      "summary": "The prompts module serves as the central prompt engineering layer that enables high-quality AI-powered code analysis, documentation, testing, and refactoring capabilities. It provides standardized prompt templates and builders that structure requests to LLMs for various software development tasks, ensuring consistent and contextually-rich AI responses across the application.\n\nUsers interact with this module indirectly through features like architecture analysis, documentation generation, test creation, and refactoring suggestions. When a user requests any of these capabilities, the module constructs detailed prompts that include relevant code context, dependency information, and specific instructions to guide the LLM toward producing actionable results. For refactoring tasks, the module generates prompts that yield step-by-step migration plans with before/after code examples, while for testing, it creates prompts that produce complete test suites with proper setup, assertions, and edge case coverage.\n\nThe module supports a workflow where raw codebase data is transformed into structured prompts that maximize LLM understanding and output quality. This includes providing function-level analysis context, dependency mappings, architecture patterns, and specific formatting requirements. The result is more accurate architecture insights, better quality documentation, more comprehensive test coverage recommendations, and practical refactoring guidance that developers can immediately apply to improve their codebase.",
      "files": [
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Centralized prompt construction system that builds structured prompts for all LLM analysis tasks including architecture analysis, documentation generation, test planning, and code generation.",
          "userVisibleActions": [
            "Receives more accurate and consistent AI-generated architecture analysis",
            "Gets better quality product documentation from AI analysis",
            "Obtains more relevant test plans and test code generation",
            "Experiences improved AI understanding of code context and purpose"
          ],
          "developerVisibleActions": [
            "Provides standardized interface for building prompts across all LLM operations",
            "Constructs architecture analysis prompts with code context and documentation",
            "Generates prompts for product documentation and purpose analysis",
            "Creates prompts for file-level code analysis with role information",
            "Builds module rollup prompts for aggregating file summaries",
            "Produces product-level summary prompts combining multiple analysis layers",
            "Generates test planning prompts per file with function metadata",
            "Creates test code generation prompts with source and function context",
            "Eliminates duplicate prompt construction logic across the codebase",
            "Ensures consistent prompt structure and quality across all AI interactions"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Constructs prompt for analyzing codebase architecture",
              "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Builds prompt for generating product documentation",
              "inputs": "context (AnalysisContext)",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Creates prompt for analyzing product purpose and goals",
              "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Generates prompt for analyzing individual code files",
              "inputs": "file (FileInfo), content (string), role (string)",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Constructs prompt for rolling up file summaries into module summaries",
              "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Builds comprehensive prompt for product-level analysis",
              "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Creates prompt for generating test plans for specific files",
              "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
              "outputs": "Formatted string prompt for LLM"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Generates prompt for creating actual test code",
              "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
              "outputs": "Formatted string prompt for LLM"
            }
          ],
          "dependencies": [
            "../../llmService",
            "../../analyzer",
            "../../fileDocumentation",
            "../../fileAccessHelper"
          ],
          "intent": "This file solves the problem of duplicate and inconsistent prompt construction scattered across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent quality and structure for AI interactions while making prompts easier to maintain and improve.",
          "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction system that builds structured prompts for all LLM analysis tasks including architecture analysis, documentation generation, test planning, and code generation.\",\n  \"userVisibleActions\": [\n    \"Receives more accurate and consistent AI-generated architecture analysis\",\n    \"Gets better quality product documentation from AI analysis\",\n    \"Obtains more relevant test plans and test code generation\",\n    \"Experiences improved AI understanding of code context and purpose\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides standardized interface for building prompts across all LLM operations\",\n    \"Constructs architecture analysis prompts with code context and documentation\",\n    \"Generates prompts for product documentation and purpose analysis\",\n    \"Creates prompts for file-level code analysis with role information\",\n    \"Builds module rollup prompts for aggregating file summaries\",\n    \"Produces product-level summary prompts combining multiple analysis layers\",\n    \"Generates test planning prompts per file with function metadata\",\n    \"Creates test code generation prompts with source and function context\",\n    \"Eliminates duplicate prompt construction logic across the codebase\",\n    \"Ensures consistent prompt structure and quality across all AI interactions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs prompt for analyzing codebase architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Builds prompt for generating product documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates prompt for analyzing product purpose and goals\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Generates prompt for analyzing individual code files\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs prompt for rolling up file summaries into module summaries\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Builds comprehensive prompt for product-level analysis\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates prompt for generating test plans for specific files\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates prompt for creating actual test code\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file solves the problem of duplicate and inconsistent prompt construction scattered across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent quality and structure for AI interactions while making prompts easier to maintain and improve.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Builds detailed refactoring prompts with extraction plans and migration steps for LLM-based code refactoring analysis",
          "userVisibleActions": [
            "Receives detailed refactoring recommendations with specific code extraction suggestions",
            "Gets step-by-step migration instructions for moving code between files",
            "Views before/after code examples showing proposed refactoring changes",
            "Sees function-level analysis explaining what each function does and its dependencies"
          ],
          "developerVisibleActions": [
            "Generates comprehensive refactoring prompts that include code analysis context and product documentation",
            "Creates extraction plans showing which functions should be moved from source to target files",
            "Produces function analysis reports detailing responsibilities, dependencies, and call relationships",
            "Builds structured prompts with specific requirements for code extraction and migration",
            "Combines architecture insights with code analysis to guide refactoring decisions",
            "Generates migration steps and code examples to illustrate refactoring approach"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Creates a comprehensive refactoring prompt combining code analysis, product docs, architecture insights, and function analysis",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array",
              "outputs": "Formatted string prompt for LLM refactoring analysis"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Constructs the foundational prompt text with context and code analysis information",
              "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
              "outputs": "Base prompt string"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Generates a detailed section analyzing functions including their dependencies and responsibilities",
              "inputs": "Array of FunctionAnalysis objects",
              "outputs": "Formatted function analysis text"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Creates detailed requirements for code extraction including migration steps and examples",
              "inputs": "None",
              "outputs": "Extraction requirements text"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
            "../../llmService (AnalysisContext, LLMInsights)",
            "../../fileDocumentation (EnhancedProductDocumentation)"
          ],
          "intent": "This file exists to generate structured, prescriptive refactoring instructions for LLMs by combining code analysis data, function relationships, and documentation context into comprehensive prompts that guide the AI to produce actionable refactoring recommendations with specific extraction plans and migration steps",
          "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed refactoring prompts with extraction plans and migration steps for LLM-based code refactoring analysis\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with specific code extraction suggestions\",\n    \"Gets step-by-step migration instructions for moving code between files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Sees function-level analysis explaining what each function does and its dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Generates comprehensive refactoring prompts that include code analysis context and product documentation\",\n    \"Creates extraction plans showing which functions should be moved from source to target files\",\n    \"Produces function analysis reports detailing responsibilities, dependencies, and call relationships\",\n    \"Builds structured prompts with specific requirements for code extraction and migration\",\n    \"Combines architecture insights with code analysis to guide refactoring decisions\",\n    \"Generates migration steps and code examples to illustrate refactoring approach\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive refactoring prompt combining code analysis, product docs, architecture insights, and function analysis\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array\",\n      \"outputs\": \"Formatted string prompt for LLM refactoring analysis\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational prompt text with context and code analysis information\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Generates a detailed section analyzing functions including their dependencies and responsibilities\",\n      \"inputs\": \"Array of FunctionAnalysis objects\",\n      \"outputs\": \"Formatted function analysis text\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Creates detailed requirements for code extraction including migration steps and examples\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Extraction requirements text\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to generate structured, prescriptive refactoring instructions for LLMs by combining code analysis data, function relationships, and documentation context into comprehensive prompts that guide the AI to produce actionable refactoring recommendations with specific extraction plans and migration steps\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides prompt templates for LLM-based test generation, including setup configuration, test planning, and test case creation.",
          "userVisibleActions": [
            "Generates test setup recommendations based on codebase analysis",
            "Creates prioritized test plans with coverage targets",
            "Generates test cases for specific functions with assertions and edge cases",
            "Produces test suites organized by file with proper imports and setup"
          ],
          "developerVisibleActions": [
            "Call buildSetupPrompt() with workspace root and file list to get test framework recommendations",
            "Call buildPlanningPrompt() with code analysis and functions to generate test strategy",
            "Call buildImplementationPrompt() with testable functions to generate actual test code",
            "Call buildSuitePrompt() to organize generated tests into structured test suites",
            "Receive JSON-formatted responses with testing framework, dependencies, and configuration",
            "Get prioritized function lists with testing recommendations and risk assessments",
            "Obtain complete test implementations with describe/it blocks and assertions"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Creates a prompt for LLM to analyze codebase and recommend test framework setup",
              "inputs": "workspaceRoot (string), fileList (string[]), packageJsonContent (optional string)",
              "outputs": "Formatted prompt string requesting JSON with language, framework, dependencies, and configuration"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Creates a prompt for LLM to generate a prioritized test plan based on code analysis",
              "inputs": "context (CodeAnalysis), functions (any[]), productDocs (optional), architectureInsights (optional)",
              "outputs": "Formatted prompt string requesting JSON with prioritized functions, risk scores, and test recommendations"
            },
            {
              "name": "buildImplementationPrompt",
              "desc": "Creates a prompt for LLM to generate actual test code for specific functions",
              "inputs": "testableFunction (TestableFunction), projectContext (string), testingFramework (string)",
              "outputs": "Formatted prompt string requesting JSON array of test cases with code, descriptions, and assertions"
            },
            {
              "name": "buildSuitePrompt",
              "desc": "Creates a prompt for LLM to organize generated tests into structured test suites",
              "inputs": "filePath (string), testCases (string[]), imports (string[]), setupCode (optional string)",
              "outputs": "Formatted prompt string requesting complete test file with proper structure and organization"
            }
          ],
          "dependencies": [
            "../../analyzer",
            "../services/testing/types/testPlanTypes"
          ],
          "intent": "This file exists to provide standardized, detailed prompt templates that guide LLMs to generate high-quality test code, configurations, and strategies. It solves the problem of consistent, structured communication with AI models for test generation by providing context-rich prompts that result in actionable, properly formatted test outputs including framework setup, test planning, and implementation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based test generation, including setup configuration, test planning, and test case creation.\",\n  \"userVisibleActions\": [\n    \"Generates test setup recommendations based on codebase analysis\",\n    \"Creates prioritized test plans with coverage targets\",\n    \"Generates test cases for specific functions with assertions and edge cases\",\n    \"Produces test suites organized by file with proper imports and setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace root and file list to get test framework recommendations\",\n    \"Call buildPlanningPrompt() with code analysis and functions to generate test strategy\",\n    \"Call buildImplementationPrompt() with testable functions to generate actual test code\",\n    \"Call buildSuitePrompt() to organize generated tests into structured test suites\",\n    \"Receive JSON-formatted responses with testing framework, dependencies, and configuration\",\n    \"Get prioritized function lists with testing recommendations and risk assessments\",\n    \"Obtain complete test implementations with describe/it blocks and assertions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt for LLM to analyze codebase and recommend test framework setup\",\n      \"inputs\": \"workspaceRoot (string), fileList (string[]), packageJsonContent (optional string)\",\n      \"outputs\": \"Formatted prompt string requesting JSON with language, framework, dependencies, and configuration\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt for LLM to generate a prioritized test plan based on code analysis\",\n      \"inputs\": \"context (CodeAnalysis), functions (any[]), productDocs (optional), architectureInsights (optional)\",\n      \"outputs\": \"Formatted prompt string requesting JSON with prioritized functions, risk scores, and test recommendations\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Creates a prompt for LLM to generate actual test code for specific functions\",\n      \"inputs\": \"testableFunction (TestableFunction), projectContext (string), testingFramework (string)\",\n      \"outputs\": \"Formatted prompt string requesting JSON array of test cases with code, descriptions, and assertions\"\n    },\n    {\n      \"name\": \"buildSuitePrompt\",\n      \"desc\": \"Creates a prompt for LLM to organize generated tests into structured test suites\",\n      \"inputs\": \"filePath (string), testCases (string[]), imports (string[]), setupCode (optional string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test file with proper structure and organization\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"This file exists to provide standardized, detailed prompt templates that guide LLMs to generate high-quality test code, configurations, and strategies. It solves the problem of consistent, structured communication with AI models for test generation by providing context-rich prompts that result in actionable, properly formatted test outputs including framework setup, test planning, and implementation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatic file system monitoring and change detection across the workspace",
        "Real-time updates when project files are created, modified, or deleted",
        "Iterative LLM analysis sessions that can request additional context across multiple rounds",
        "Automatic test framework detection and configuration validation",
        "Missing test dependency identification without manual configuration",
        "Intelligent file and search result fetching during analysis iterations"
      ],
      "summary": "The services module provides core infrastructure services that enhance the extension's responsiveness and intelligence. It enables automatic monitoring of workspace changes, ensuring that features like product documentation and insights stay synchronized with the actual codebase without requiring manual refresh actions.\n\nThe module supports advanced iterative analysis workflows where AI-powered features can request additional files or search results across multiple conversation rounds, automatically fetching context up to a maximum number of iterations. This enables more thorough and context-aware analysis without overwhelming the system.\n\nFor testing capabilities, the module automatically detects test frameworks (Jest, Mocha, Vitest, Pytest) from project configuration files and identifies missing dependencies or setup issues. This eliminates the need for manual test configuration and helps users quickly understand what's required to get their test environment working properly.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides centralized file system watching functionality to monitor and react to file changes across the workspace",
          "userVisibleActions": [
            "Automatically detects when files are created, modified, or deleted in the workspace",
            "Updates features in real-time when relevant files change (e.g., product files, insights)",
            "Responds to file save events to trigger automatic refreshes or updates"
          ],
          "developerVisibleActions": [
            "Register watchers for specific file patterns (e.g., *.json, *.md) with custom handlers",
            "Handle file creation, modification, and deletion events separately",
            "Filter watched files using ignore patterns to exclude unwanted files",
            "Subscribe to document save events with custom handlers",
            "Dispose watchers when no longer needed to free resources",
            "Track multiple handlers for the same file pattern without creating duplicate watchers"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Registers a file system watcher for a specific pattern and calls the handler when matching files change",
              "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (watch types and ignore patterns)",
              "outputs": "Disposable object to unregister the watcher"
            },
            {
              "name": "onDocumentSave",
              "desc": "Registers a handler to be called whenever a text document is saved",
              "inputs": "id (string), handler (callback function accepting TextDocument)",
              "outputs": "Disposable object to unregister the handler"
            },
            {
              "name": "unwatch",
              "desc": "Removes a specific watcher by ID and cleans up resources if no other handlers exist",
              "inputs": "id (string)",
              "outputs": "void"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all watchers and handlers, freeing system resources",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "shouldIgnore",
              "desc": "Determines if a file path should be ignored based on configured patterns",
              "inputs": "filePath (string), ignorePatterns (array of glob patterns)",
              "outputs": "boolean indicating whether to ignore the file"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to consolidate duplicate file watching logic that was scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It provides a single, reusable service for monitoring file system changes, eliminating code duplication and ensuring consistent file watching behavior throughout the extension. It solves the problem of managing multiple file watchers efficiently while allowing different parts of the extension to react to file changes independently.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides centralized file system watching functionality to monitor and react to file changes across the workspace\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created, modified, or deleted in the workspace\",\n    \"Updates features in real-time when relevant files change (e.g., product files, insights)\",\n    \"Responds to file save events to trigger automatic refreshes or updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register watchers for specific file patterns (e.g., *.json, *.md) with custom handlers\",\n    \"Handle file creation, modification, and deletion events separately\",\n    \"Filter watched files using ignore patterns to exclude unwanted files\",\n    \"Subscribe to document save events with custom handlers\",\n    \"Dispose watchers when no longer needed to free resources\",\n    \"Track multiple handlers for the same file pattern without creating duplicate watchers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file system watcher for a specific pattern and calls the handler when matching files change\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (watch types and ignore patterns)\",\n      \"outputs\": \"Disposable object to unregister the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever a text document is saved\",\n      \"inputs\": \"id (string), handler (callback function accepting TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific watcher by ID and cleans up resources if no other handlers exist\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers, freeing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file path should be ignored based on configured patterns\",\n      \"inputs\": \"filePath (string), ignorePatterns (array of glob patterns)\",\n      \"outputs\": \"boolean indicating whether to ignore the file\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate duplicate file watching logic that was scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It provides a single, reusable service for monitoring file system changes, eliminating code duplication and ensuring consistent file watching behavior throughout the extension. It solves the problem of managing multiple file watchers efficiently while allowing different parts of the extension to react to file changes independently.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative analysis sessions where an LLM can request additional files or search results across multiple rounds of conversation.",
          "userVisibleActions": [
            "LLM analysis continues across multiple iterations when it needs more information",
            "Analysis automatically fetches requested files and grep search results",
            "Analysis stops after reaching maximum iterations or when LLM signals completion",
            "Up to 5 file/grep requests are processed per iteration to prevent overload"
          ],
          "developerVisibleActions": [
            "Developer initiates iterative analysis with custom callbacks for iteration start and completion",
            "Service processes LLM requests for file reads and grep searches automatically",
            "Developer receives structured iteration results including the final result, iteration count, and all requests made",
            "Service maintains conversation history by appending assistant and user messages",
            "Developer can configure maximum iterations to control analysis depth"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes up to 5 file read and grep search requests from the LLM, returning formatted results",
              "inputs": "requests (array of LLMRequest), currentResult (any analysis result), messages (conversation history)",
              "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
            },
            {
              "name": "async *iterateAnalysis",
              "desc": "Iterates through analysis rounds, yielding results after each iteration until completion or max iterations reached",
              "inputs": "currentResult (initial analysis), iteration (starting iteration number), maxIterations (limit), callbacks (optional iteration hooks)",
              "outputs": "AsyncGenerator yielding IterationResult objects with result, iteration count, requests, and continuation flag"
            }
          ],
          "dependencies": [
            "FileAccessHelper",
            "LLMRequest types from fileAccessHelper module"
          ],
          "intent": "Eliminates code duplication and improves testability by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM can request additional context through file reads and grep searches.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative analysis sessions where an LLM can request additional files or search results across multiple rounds of conversation.\",\n  \"userVisibleActions\": [\n    \"LLM analysis continues across multiple iterations when it needs more information\",\n    \"Analysis automatically fetches requested files and grep search results\",\n    \"Analysis stops after reaching maximum iterations or when LLM signals completion\",\n    \"Up to 5 file/grep requests are processed per iteration to prevent overload\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer initiates iterative analysis with custom callbacks for iteration start and completion\",\n    \"Service processes LLM requests for file reads and grep searches automatically\",\n    \"Developer receives structured iteration results including the final result, iteration count, and all requests made\",\n    \"Service maintains conversation history by appending assistant and user messages\",\n    \"Developer can configure maximum iterations to control analysis depth\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes up to 5 file read and grep search requests from the LLM, returning formatted results\",\n      \"inputs\": \"requests (array of LLMRequest), currentResult (any analysis result), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"async *iterateAnalysis\",\n      \"desc\": \"Iterates through analysis rounds, yielding results after each iteration until completion or max iterations reached\",\n      \"inputs\": \"currentResult (initial analysis), iteration (starting iteration number), maxIterations (limit), callbacks (optional iteration hooks)\",\n      \"outputs\": \"AsyncGenerator yielding IterationResult objects with result, iteration count, requests, and continuation flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest types from fileAccessHelper module\"\n  ],\n  \"intent\": \"Eliminates code duplication and improves testability by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM can request additional context through file reads and grep searches.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects test framework configuration (Jest, Mocha, Vitest, Pytest) and identifies missing dependencies or setup requirements without manual user configuration",
          "userVisibleActions": [
            "Test framework is automatically detected from project files",
            "Missing test dependencies are identified and reported",
            "Configuration issues are detected and surfaced",
            "Setup requirements are automatically checked",
            "Test configuration status is displayed"
          ],
          "developerVisibleActions": [
            "Service scans workspace for package.json and test configuration files",
            "Detects which test framework is being used (Jest, Mocha, Vitest, Pytest)",
            "Identifies missing dependencies required for testing",
            "Returns configuration status with framework, dependencies, and setup requirements",
            "Provides actionable setup steps when configuration is incomplete"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Scans workspace to determine which test framework is configured and what dependencies are missing",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "SWLogger"
          ],
          "intent": "Eliminates manual test configuration setup by automatically detecting the test framework being used in a project, checking if all required dependencies are installed, and identifying what setup steps are needed to ensure generated tests will work immediately without user intervention",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration (Jest, Mocha, Vitest, Pytest) and identifies missing dependencies or setup requirements without manual user configuration\",\n  \"userVisibleActions\": [\n    \"Test framework is automatically detected from project files\",\n    \"Missing test dependencies are identified and reported\",\n    \"Configuration issues are detected and surfaced\",\n    \"Setup requirements are automatically checked\",\n    \"Test configuration status is displayed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service scans workspace for package.json and test configuration files\",\n    \"Detects which test framework is being used (Jest, Mocha, Vitest, Pytest)\",\n    \"Identifies missing dependencies required for testing\",\n    \"Returns configuration status with framework, dependencies, and setup requirements\",\n    \"Provides actionable setup steps when configuration is incomplete\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Scans workspace to determine which test framework is configured and what dependencies are missing\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration setup by automatically detecting the test framework being used in a project, checking if all required dependencies are installed, and identifying what setup steps are needed to ensure generated tests will work immediately without user intervention\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automatically analyze codebases to identify testable functions and create prioritized test plans",
        "Generate unit tests incrementally using AI, creating test code for functions in small batches",
        "Detect and configure test environments including frameworks, directories, and configuration files",
        "Execute test suites (Jest, Pytest) and capture detailed results with pass/fail statistics",
        "Automatically validate and fix failing tests using AI-powered analysis and code regeneration",
        "Provide real-time progress updates during test generation, execution, and validation",
        "Save test plans and recommendations to the workspace for future reference"
      ],
      "summary": "This module provides comprehensive AI-powered test automation capabilities for software projects. It enables users to automatically generate, execute, and maintain unit tests without manual intervention. The workflow begins with test planning, where the system analyzes code to identify testable functions and prioritize them based on complexity and importance. Users receive a detailed test plan showing which functions need testing and strategic recommendations based on their codebase architecture.\n\nOnce planning is complete, the module can automatically generate test code using AI, processing functions in small batches and providing progress updates throughout the generation process. The system intelligently detects the project's test environment, including programming language, testing framework (Jest, Pytest), and configuration files, ensuring generated tests match the project's conventions. After generation, tests are automatically executed with detailed reporting of passed, failed, and error counts.\n\nThe module includes a self-healing capability that automatically validates and fixes failing tests. When tests fail, the system uses AI analysis to understand the failure and regenerate corrected test code, repeating this process until tests pass or a maximum number of attempts is reached. Users receive comprehensive reports throughout the entire lifecycle, from initial planning through final validation, with all progress, results, and recommendations displayed in real-time. Test plans and configurations are persisted in the .skyway/testing directory for ongoing reference and iteration.",
      "files": [
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates test code incrementally in small batches using an LLM service to create tests for testable functions",
          "userVisibleActions": [
            "Progress updates shown while tests are being generated for each function",
            "Test generation results displayed for batches of functions",
            "Error messages shown if test generation fails for specific functions"
          ],
          "developerVisibleActions": [
            "Triggers batch generation of tests for multiple functions at once",
            "Receives progress callbacks with current function being tested and completion percentage",
            "Gets back a map of test generation results keyed by function name",
            "Can provide custom progress handlers to track generation status",
            "Accesses generated test code and execution results for each function"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for multiple functions in a batch, processing them one at a time with progress tracking",
              "inputs": "functions array, workspace root path, LLM service instance, optional progress callback",
              "outputs": "Map of function names to TestGenerationResult objects"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Extracts the source code for a specific function from the workspace",
              "inputs": "TestableFunction object, workspace root path",
              "outputs": "Source code string for the function"
            },
            {
              "name": "buildGenerationPrompt",
              "desc": "Creates an LLM prompt for generating tests based on function details and existing code",
              "inputs": "function object, source code, test framework type, existing mock code",
              "outputs": "Formatted prompt string for the LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestableFunction",
            "TestGenerationState",
            "TestGenerationResult",
            "buildGenerationPrompt",
            "TestExecutionService",
            "SWLogger"
          ],
          "intent": "This file exists to orchestrate the automated generation of unit tests using an LLM in manageable batches, allowing developers to generate test suites for multiple functions incrementally with progress tracking and result collection, solving the problem of manually writing repetitive test code.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates test code incrementally in small batches using an LLM service to create tests for testable functions\",\n  \"userVisibleActions\": [\n    \"Progress updates shown while tests are being generated for each function\",\n    \"Test generation results displayed for batches of functions\",\n    \"Error messages shown if test generation fails for specific functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers batch generation of tests for multiple functions at once\",\n    \"Receives progress callbacks with current function being tested and completion percentage\",\n    \"Gets back a map of test generation results keyed by function name\",\n    \"Can provide custom progress handlers to track generation status\",\n    \"Accesses generated test code and execution results for each function\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, processing them one at a time with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Extracts the source code for a specific function from the workspace\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates an LLM prompt for generating tests based on function details and existing code\",\n      \"inputs\": \"function object, source code, test framework type, existing mock code\",\n      \"outputs\": \"Formatted prompt string for the LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to orchestrate the automated generation of unit tests using an LLM in manageable batches, allowing developers to generate test suites for multiple functions incrementally with progress tracking and result collection, solving the problem of manually writing repetitive test code.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Creates AI-powered test plans by analyzing code functions and prioritizing them for testing based on complexity and importance",
          "userVisibleActions": [
            "Receives a prioritized test plan showing which functions need testing",
            "Sees analysis of how many functions are testable vs total functions",
            "Gets test strategy recommendations based on code complexity and architecture",
            "Views saved test plans in the .skyway/testing directory"
          ],
          "developerVisibleActions": [
            "Calls analyzeFunctions() to extract function metadata from code analysis",
            "Invokes createTestPlan() to generate an AI-powered test strategy",
            "Saves test plans to disk using saveTestPlan() for future reference",
            "Receives structured TestPlan objects containing function groups and priorities",
            "Gets logging output showing progress of test plan creation",
            "Can provide product documentation and architecture insights to improve test planning"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts and structures function metadata from code analysis results",
              "inputs": "codeAnalysis object containing function information",
              "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
            },
            {
              "name": "createTestPlan",
              "desc": "Generates a prioritized test plan using AI by analyzing functions and context",
              "inputs": "CodeAnalysis context, functions array, LLM service, optional product docs and architecture insights",
              "outputs": "TestPlan object containing function groups, testable function count, and testing strategy"
            },
            {
              "name": "saveTestPlan",
              "desc": "Persists the generated test plan to disk in JSON format",
              "inputs": "TestPlan object and output directory path",
              "outputs": "File path where test plan was saved"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestPlan and TestableFunction types",
            "testPrompts (buildPlanningPrompt)",
            "CodeAnalysis from analyzer",
            "SWLogger"
          ],
          "intent": "This file exists to automate test planning by leveraging AI to analyze code complexity, function relationships, and architecture to determine which functions should be tested and in what priority order, eliminating manual test planning effort and ensuring critical code paths are tested first",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates AI-powered test plans by analyzing code functions and prioritizing them for testing based on complexity and importance\",\n  \"userVisibleActions\": [\n    \"Receives a prioritized test plan showing which functions need testing\",\n    \"Sees analysis of how many functions are testable vs total functions\",\n    \"Gets test strategy recommendations based on code complexity and architecture\",\n    \"Views saved test plans in the .skyway/testing directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis\",\n    \"Invokes createTestPlan() to generate an AI-powered test strategy\",\n    \"Saves test plans to disk using saveTestPlan() for future reference\",\n    \"Receives structured TestPlan objects containing function groups and priorities\",\n    \"Gets logging output showing progress of test plan creation\",\n    \"Can provide product documentation and architecture insights to improve test planning\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and structures function metadata from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing function information\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan using AI by analyzing functions and context\",\n      \"inputs\": \"CodeAnalysis context, functions array, LLM service, optional product docs and architecture insights\",\n      \"outputs\": \"TestPlan object containing function groups, testable function count, and testing strategy\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to disk in JSON format\",\n      \"inputs\": \"TestPlan object and output directory path\",\n      \"outputs\": \"File path where test plan was saved\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestPlan and TestableFunction types\",\n    \"testPrompts (buildPlanningPrompt)\",\n    \"CodeAnalysis from analyzer\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate test planning by leveraging AI to analyze code complexity, function relationships, and architecture to determine which functions should be tested and in what priority order, eliminating manual test planning effort and ensuring critical code paths are tested first\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects the test environment and configuration in a workspace to prepare for generating unit tests",
          "userVisibleActions": [
            "Analyzes workspace to determine programming language and testing framework",
            "Detects existing test configuration files (package.json, jest.config.js, tsconfig.json)",
            "Identifies test directories and file patterns in the project",
            "Generates test setup recommendations based on detected environment",
            "Reports whether test environment is properly configured or needs setup"
          ],
          "developerVisibleActions": [
            "Scans workspace directory structure to identify project type",
            "Counts files by extension to determine primary programming language",
            "Checks for presence of configuration files (package.json, jest.config, tsconfig)",
            "Reads and parses package.json to detect testing frameworks (Jest, Mocha, Vitest, etc.)",
            "Identifies existing test directories (UnitTests, tests, __tests__, spec)",
            "Returns structured test environment information including language, framework, and configuration status",
            "Provides setup plan when test environment is incomplete or missing"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Analyzes workspace to determine programming language, testing framework, and configuration status",
              "inputs": "workspaceRoot (string path to workspace)",
              "outputs": "TestEnvironment object containing language, framework, config files, and test directories"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively collects all files in workspace directory for analysis",
              "inputs": "directory path (string)",
              "outputs": "Array of file paths (string[])"
            },
            {
              "name": "buildSetupPrompt",
              "desc": "Creates LLM prompt for generating test setup configuration based on detected environment",
              "inputs": "TestEnvironment object",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "testSetupTypes",
            "testPrompts",
            "SWLogger"
          ],
          "intent": "This file exists to solve the problem of automatically setting up test environments for different programming languages and frameworks. It eliminates manual configuration by detecting what testing tools are available, what language the project uses, and what configuration is needed to enable automated unit test generation. This is Phase 1 of the test setup process, focusing on environment detection and configuration generation before actual test file creation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects the test environment and configuration in a workspace to prepare for generating unit tests\",\n  \"userVisibleActions\": [\n    \"Analyzes workspace to determine programming language and testing framework\",\n    \"Detects existing test configuration files (package.json, jest.config.js, tsconfig.json)\",\n    \"Identifies test directories and file patterns in the project\",\n    \"Generates test setup recommendations based on detected environment\",\n    \"Reports whether test environment is properly configured or needs setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace directory structure to identify project type\",\n    \"Counts files by extension to determine primary programming language\",\n    \"Checks for presence of configuration files (package.json, jest.config, tsconfig)\",\n    \"Reads and parses package.json to detect testing frameworks (Jest, Mocha, Vitest, etc.)\",\n    \"Identifies existing test directories (UnitTests, tests, __tests__, spec)\",\n    \"Returns structured test environment information including language, framework, and configuration status\",\n    \"Provides setup plan when test environment is incomplete or missing\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to determine programming language, testing framework, and configuration status\",\n      \"inputs\": \"workspaceRoot (string path to workspace)\",\n      \"outputs\": \"TestEnvironment object containing language, framework, config files, and test directories\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively collects all files in workspace directory for analysis\",\n      \"inputs\": \"directory path (string)\",\n      \"outputs\": \"Array of file paths (string[])\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates LLM prompt for generating test setup configuration based on detected environment\",\n      \"inputs\": \"TestEnvironment object\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to solve the problem of automatically setting up test environments for different programming languages and frameworks. It eliminates manual configuration by detecting what testing tools are available, what language the project uses, and what configuration is needed to enable automated unit test generation. This is Phase 1 of the test setup process, focusing on environment detection and configuration generation before actual test file creation.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates and automatically fixes failing tests using LLM-powered analysis and code generation",
          "userVisibleActions": [
            "Tests are automatically run and results are displayed showing passed/failed counts",
            "Failing tests are automatically analyzed and fixed without manual intervention",
            "Test validation progress is logged showing attempt numbers and success/failure status",
            "Final test report is generated showing overall test health and remaining failures"
          ],
          "developerVisibleActions": [
            "Developer triggers test validation which runs Jest tests and captures results",
            "Developer receives structured test execution results with pass/fail counts per test file",
            "Developer can specify a single test file or run all tests in workspace",
            "Developer gets iterative fix attempts (up to 3 by default) for each failing test",
            "Developer receives a comprehensive test report with summary statistics",
            "Developer sees logged progress for test execution and fix attempts"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or a specific test file and returns aggregated results",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]> - array of test results with pass/fail counts"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to automatically fix a failing test using LLM with multiple retry attempts",
              "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts?: number",
              "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}> - fix outcome"
            },
            {
              "name": "validateAndFix",
              "desc": "Orchestrates the complete test validation and auto-fix workflow for all failing tests",
              "inputs": "workspaceRoot: string, llmService: any, testFile?: string, maxAttempts?: number",
              "outputs": "Promise<TestReport> - comprehensive report of test execution and fix attempts"
            },
            {
              "name": "generateTestReport",
              "desc": "Creates a structured summary report of all test results and fix outcomes",
              "inputs": "results: TestExecutionResult[], fixes: Map<string, {success: boolean, attempts: number}>",
              "outputs": "TestReport - formatted report with statistics and per-file details"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "TestExecutionResult, TestReport, TestReportSummary (types)",
            "buildFixPrompt (prompts)",
            "SWLogger"
          ],
          "intent": "This file exists to automate the test validation and fixing workflow by running tests, detecting failures, and using LLM to intelligently repair broken tests. It solves the problem of manual test maintenance by providing automated analysis and fixes for failing tests, reducing developer time spent debugging test failures.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates and automatically fixes failing tests using LLM-powered analysis and code generation\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and results are displayed showing passed/failed counts\",\n    \"Failing tests are automatically analyzed and fixed without manual intervention\",\n    \"Test validation progress is logged showing attempt numbers and success/failure status\",\n    \"Final test report is generated showing overall test health and remaining failures\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test validation which runs Jest tests and captures results\",\n    \"Developer receives structured test execution results with pass/fail counts per test file\",\n    \"Developer can specify a single test file or run all tests in workspace\",\n    \"Developer gets iterative fix attempts (up to 3 by default) for each failing test\",\n    \"Developer receives a comprehensive test report with summary statistics\",\n    \"Developer sees logged progress for test execution and fix attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns aggregated results\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - array of test results with pass/fail counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with multiple retry attempts\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts?: number\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}> - fix outcome\"\n    },\n    {\n      \"name\": \"validateAndFix\",\n      \"desc\": \"Orchestrates the complete test validation and auto-fix workflow for all failing tests\",\n      \"inputs\": \"workspaceRoot: string, llmService: any, testFile?: string, maxAttempts?: number\",\n      \"outputs\": \"Promise<TestReport> - comprehensive report of test execution and fix attempts\"\n    },\n    {\n      \"name\": \"generateTestReport\",\n      \"desc\": \"Creates a structured summary report of all test results and fix outcomes\",\n      \"inputs\": \"results: TestExecutionResult[], fixes: Map<string, {success: boolean, attempts: number}>\",\n      \"outputs\": \"TestReport - formatted report with statistics and per-file details\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult, TestReport, TestReportSummary (types)\",\n    \"buildFixPrompt (prompts)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation and fixing workflow by running tests, detecting failures, and using LLM to intelligently repair broken tests. It solves the problem of manual test maintenance by providing automated analysis and fixes for failing tests, reducing developer time spent debugging test failures.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes test suites (Jest, Pytest) and captures their results for display to users and developers",
          "userVisibleActions": [
            "Tests run when user triggers test execution",
            "Test results appear showing passed, failed, and error counts",
            "Test execution status displays (running, success, error)",
            "Individual test failures show with error messages and stack traces",
            "Test execution progress shows duration/timing information"
          ],
          "developerVisibleActions": [
            "Triggers Jest tests for specific files or entire test suite",
            "Triggers Pytest tests for specific files or entire test suite",
            "Parses test framework output to extract structured results",
            "Handles test execution errors and timeouts",
            "Returns standardized test results regardless of testing framework",
            "Provides detailed error information including stack traces"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Executes Jest tests and returns structured results",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> containing test outcomes"
            },
            {
              "name": "runPytest",
              "desc": "Executes Pytest tests and returns structured results",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Promise<TestExecutionResult[]> containing test outcomes"
            },
            {
              "name": "parseJestOutput",
              "desc": "Converts Jest JSON output into standardized test result format",
              "inputs": "stdout (string), stderr (string)",
              "outputs": "TestExecutionResult[] with parsed test data"
            },
            {
              "name": "parsePytestOutput",
              "desc": "Converts Pytest JSON output into standardized test result format",
              "inputs": "stdout (string), stderr (string)",
              "outputs": "TestExecutionResult[] with parsed test data"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "Provides a unified interface for executing different testing frameworks (Jest for JavaScript/TypeScript, Pytest for Python) and normalizing their outputs into a consistent format that can be displayed to users and processed by other services, handling execution failures gracefully and providing detailed error information.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Pytest) and captures their results for display to users and developers\",\n  \"userVisibleActions\": [\n    \"Tests run when user triggers test execution\",\n    \"Test results appear showing passed, failed, and error counts\",\n    \"Test execution status displays (running, success, error)\",\n    \"Individual test failures show with error messages and stack traces\",\n    \"Test execution progress shows duration/timing information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers Jest tests for specific files or entire test suite\",\n    \"Triggers Pytest tests for specific files or entire test suite\",\n    \"Parses test framework output to extract structured results\",\n    \"Handles test execution errors and timeouts\",\n    \"Returns standardized test results regardless of testing framework\",\n    \"Provides detailed error information including stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests and returns structured results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Pytest tests and returns structured results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Converts Jest JSON output into standardized test result format\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test data\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Converts Pytest JSON output into standardized test result format\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test data\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for executing different testing frameworks (Jest for JavaScript/TypeScript, Pytest for Python) and normalizing their outputs into a consistent format that can be displayed to users and processed by other services, handling execution failures gracefully and providing detailed error information.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Track test generation workflow through multiple phases (setup, planning, generation, validation, complete)",
        "Monitor test plan creation with function grouping and validation state tracking",
        "View comprehensive test execution results with pass/fail/error statistics",
        "Access detailed test reports with summary metrics and pass rates",
        "Receive actionable recommendations for improving test quality",
        "Review test setup configuration including framework, dependencies, and config files",
        "Track test setup execution results including file creation and dependency installation",
        "Monitor existing test environment detection (package.json, tsconfig, jest config, test directories)",
        "View error details with test names, error messages, and stack traces",
        "Track test failure retry attempts and error recovery"
      ],
      "summary": "This module provides comprehensive type definitions for the entire test generation and execution lifecycle. It defines the data structures that enable users to track test workflows from initial setup through planning, generation, validation, and completion. Users can monitor which functions are being tested, view their validation status, and track progress through each phase of the testing process.\n\nThe module supports detailed visibility into test execution results, providing statistics on passed, failed, and errored tests along with actionable recommendations for improvement. Users receive structured feedback about their test environment setup, including information about testing frameworks, required dependencies, configuration files, and existing test infrastructure. Error handling capabilities allow users to review detailed failure information including stack traces and retry attempts, enabling effective debugging and test quality improvement.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test planning and generation workflow, including test plans, function grouping, and generation state tracking.",
          "userVisibleActions": [
            "View test generation progress through phases (setup, planning, generation, validation, complete)",
            "See how many functions are being tested and their validation status",
            "Track test failures with error messages and retry attempts"
          ],
          "developerVisibleActions": [
            "Structure test plans with function groups organized by priority",
            "Track testable functions with metadata (complexity, dependencies, mocking requirements)",
            "Monitor test generation state across different phases",
            "Access function details including file location, line numbers, parameters, and return types",
            "Handle test failures with function name, error details, and attempt count"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a strongly-typed contract for the test planning and generation service, ensuring consistent data structures when creating test plans, tracking generation progress, identifying testable functions, and managing test failures across the automated testing workflow.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test planning and generation workflow, including test plans, function grouping, and generation state tracking.\",\n  \"userVisibleActions\": [\n    \"View test generation progress through phases (setup, planning, generation, validation, complete)\",\n    \"See how many functions are being tested and their validation status\",\n    \"Track test failures with error messages and retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Structure test plans with function groups organized by priority\",\n    \"Track testable functions with metadata (complexity, dependencies, mocking requirements)\",\n    \"Monitor test generation state across different phases\",\n    \"Access function details including file location, line numbers, parameters, and return types\",\n    \"Handle test failures with function name, error details, and attempt count\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for the test planning and generation service, ensuring consistent data structures when creating test plans, tracking generation progress, identifying testable functions, and managing test failures across the automated testing workflow.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type interfaces for test generation, validation, execution results, and reporting structures in the testing service.",
          "userVisibleActions": [
            "View test execution results showing passed/failed/error counts",
            "See test reports with summary statistics and pass rates",
            "Read recommendations for improving test quality",
            "Review error details including test names, error messages, and stack traces"
          ],
          "developerVisibleActions": [
            "Use TestGenerationResult to structure generated test files with imports, mocks, and test code",
            "Access TestValidationResult to check if tests pass, fail, or have errors with explanations",
            "Retrieve TestExecutionResult to get test run statistics including duration and error details",
            "Generate TestReport with overall summary, individual results, and recommendations",
            "Work with MockStatement to understand what code is being mocked and why",
            "Access setup and teardown code for test configuration"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "This file exists to provide a standardized type system for the entire testing workflow - from generating tests with mocks and setup code, through validating and executing them, to producing comprehensive reports. It ensures type safety and consistent data structures across test generation, validation, execution, and reporting phases.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type interfaces for test generation, validation, execution results, and reporting structures in the testing service.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed/failed/error counts\",\n    \"See test reports with summary statistics and pass rates\",\n    \"Read recommendations for improving test quality\",\n    \"Review error details including test names, error messages, and stack traces\"\n  ],\n  \"developerVisibleActions\": [\n    \"Use TestGenerationResult to structure generated test files with imports, mocks, and test code\",\n    \"Access TestValidationResult to check if tests pass, fail, or have errors with explanations\",\n    \"Retrieve TestExecutionResult to get test run statistics including duration and error details\",\n    \"Generate TestReport with overall summary, individual results, and recommendations\",\n    \"Work with MockStatement to understand what code is being mocked and why\",\n    \"Access setup and teardown code for test configuration\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a standardized type system for the entire testing workflow - from generating tests with mocks and setup code, through validating and executing them, to producing comprehensive reports. It ensures type safety and consistent data structures across test generation, validation, execution, and reporting phases.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service",
          "userVisibleActions": [
            "User receives information about test setup plans including testing framework, dependencies, and configuration files",
            "User sees results of test setup execution including created files and installed dependencies",
            "User is notified of errors during test setup process",
            "User gets feedback about existing test environment (package.json, tsconfig, jest config, test directories)"
          ],
          "developerVisibleActions": [
            "Developer uses TestSetupPlan to structure test configuration recommendations",
            "Developer uses TestEnvironment to detect existing test infrastructure",
            "Developer uses SetupExecutionResult to communicate setup success/failure and changes made",
            "Developer defines dependencies with version and dev/prod distinction",
            "Developer specifies mock requirements with type and reasoning",
            "Developer creates configuration files with path and content"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides type safety and structure for the test setup service by defining interfaces that represent test configuration plans, environment analysis, setup execution results, and related components like dependencies, config files, and mock requirements",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including testing framework, dependencies, and configuration files\",\n    \"User sees results of test setup execution including created files and installed dependencies\",\n    \"User is notified of errors during test setup process\",\n    \"User gets feedback about existing test environment (package.json, tsconfig, jest config, test directories)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan to structure test configuration recommendations\",\n    \"Developer uses TestEnvironment to detect existing test infrastructure\",\n    \"Developer uses SetupExecutionResult to communicate setup success/failure and changes made\",\n    \"Developer defines dependencies with version and dev/prod distinction\",\n    \"Developer specifies mock requirements with type and reasoning\",\n    \"Developer creates configuration files with path and content\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for the test setup service by defining interfaces that represent test configuration plans, environment analysis, setup execution results, and related components like dependencies, config files, and mock requirements\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Automatically caches file contents to speed up repeated file access across the extension",
        "Intelligently detects when files change on disk and refreshes cached content automatically",
        "Filters out unwanted directories and files (node_modules, .git, dist, build, etc.) from file operations",
        "Processes multiple files in parallel for faster bulk operations",
        "Handles file processing errors gracefully without disrupting the extension"
      ],
      "summary": "This module provides a high-performance file system layer that optimizes how the extension reads and processes files. It caches file contents in memory so that when the same file is accessed multiple times, subsequent reads are nearly instantaneous. The cache automatically invalidates when files are modified on disk, ensuring users always see up-to-date content without manual intervention.\n\nThe module includes intelligent filtering that automatically excludes common non-source directories like node_modules, .git, dist, build, coverage, and IDE configuration folders. This prevents the extension from wasting time processing files that users typically don't want to analyze. When working with multiple files, the module processes them in parallel to maximize performance and reduce wait times.\n\nUsers experience faster extension responses when navigating code, analyzing projects, or performing bulk operations. The combination of caching and parallel processing means that repetitive tasks complete quickly, while the automatic cache invalidation ensures data accuracy. Error handling is built-in, so individual file failures don't crash the entire operation.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Optimizes file system operations by caching file contents to reduce redundant reads across multiple components",
          "userVisibleActions": [
            "Files load faster when accessed multiple times within a short period",
            "Extension responds more quickly when working with the same files repeatedly",
            "Automatic detection when files change on disk to ensure fresh content is always available"
          ],
          "developerVisibleActions": [
            "Cache automatically retrieves and stores file contents on first access",
            "Cache invalidates entries when files are modified, deleted, or become stale",
            "LRU eviction policy automatically removes old entries when cache reaches size limit",
            "File system watcher monitors for external file changes and updates cache accordingly",
            "Cache statistics track hits, misses, and evictions for performance monitoring"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
              "inputs": "filePath: string",
              "outputs": "Promise<string> - file content"
            },
            {
              "name": "invalidate",
              "desc": "Removes a specific file from the cache, forcing fresh read on next access",
              "inputs": "filePath: string",
              "outputs": "void"
            },
            {
              "name": "clear",
              "desc": "Removes all cached files and resets cache statistics",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getStats",
              "desc": "Returns cache performance statistics including hits, misses, evictions, and size",
              "inputs": "none",
              "outputs": "CacheStats object"
            },
            {
              "name": "dispose",
              "desc": "Cleans up resources including file system watcher when cache is no longer needed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "This file exists to improve extension performance by eliminating redundant file system reads. When multiple components need to access the same files repeatedly, the cache serves content from memory instead of disk, reducing I/O operations and improving responsiveness. It solves the problem of slow file access patterns common in analysis and refactoring operations where the same files are read multiple times in quick succession.",
          "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant reads across multiple components\",\n  \"userVisibleActions\": [\n    \"Files load faster when accessed multiple times within a short period\",\n    \"Extension responds more quickly when working with the same files repeatedly\",\n    \"Automatic detection when files change on disk to ensure fresh content is always available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Cache automatically retrieves and stores file contents on first access\",\n    \"Cache invalidates entries when files are modified, deleted, or become stale\",\n    \"LRU eviction policy automatically removes old entries when cache reaches size limit\",\n    \"File system watcher monitors for external file changes and updates cache accordingly\",\n    \"Cache statistics track hits, misses, and evictions for performance monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing fresh read on next access\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached files and resets cache statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance statistics including hits, misses, evictions, and size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources including file system watcher when cache is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by eliminating redundant file system reads. When multiple components need to access the same files repeatedly, the cache serves content from memory instead of disk, reducing I/O operations and improving responsiveness. It solves the problem of slow file access patterns common in analysis and refactoring operations where the same files are read multiple times in quick succession.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with error handling",
          "userVisibleActions": [
            "Files matching skip patterns (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea) are automatically excluded from processing",
            "Multiple files are processed simultaneously for faster results",
            "Errors during file processing are handled gracefully without crashing the application"
          ],
          "developerVisibleActions": [
            "Developer calls processFiles() with an array of file paths and a custom processing function",
            "Files are automatically filtered using configurable filter patterns before processing",
            "Each file's content is read and passed to the developer's processing function",
            "Results from all processed files are collected and returned as an array",
            "Custom file filters and readers can be injected to override default behavior",
            "Error context can be provided to track where processing failures occur"
          ],
          "keyFunctions": [
            {
              "name": "shouldProcess",
              "desc": "Determines whether a file path should be processed based on filter patterns",
              "inputs": "filePath: string",
              "outputs": "boolean (true if file should be processed)"
            },
            {
              "name": "readFile",
              "desc": "Reads the content of a file as UTF-8 text",
              "inputs": "filePath: string",
              "outputs": "Promise<string> (file content)"
            },
            {
              "name": "processFiles",
              "desc": "Filters, reads, and processes multiple files in parallel using a custom processor function",
              "inputs": "files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext",
              "outputs": "Promise<T[]> (array of processed results)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "../../utils/errorHandler"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a centralized, configurable, and reusable file processing pipeline that handles filtering, reading, parallel processing, and error handling in one place",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with error handling\",\n  \"userVisibleActions\": [\n    \"Files matching skip patterns (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea) are automatically excluded from processing\",\n    \"Multiple files are processed simultaneously for faster results\",\n    \"Errors during file processing are handled gracefully without crashing the application\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls processFiles() with an array of file paths and a custom processing function\",\n    \"Files are automatically filtered using configurable filter patterns before processing\",\n    \"Each file's content is read and passed to the developer's processing function\",\n    \"Results from all processed files are collected and returned as an array\",\n    \"Custom file filters and readers can be injected to override default behavior\",\n    \"Error context can be provided to track where processing failures occur\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines whether a file path should be processed based on filter patterns\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean (true if file should be processed)\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads the content of a file as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> (file content)\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Filters, reads, and processes multiple files in parallel using a custom processor function\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> (array of processed results)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a centralized, configurable, and reusable file processing pipeline that handles filtering, reading, parallel processing, and error handling in one place\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Persistent storage of AI-generated product documentation in the workspace",
        "Archival of architecture insights and analysis results with timestamps",
        "Generation of consolidated summary files combining multiple analyses",
        "Incremental documentation updates with version tracking",
        "Organized storage structure in .shadow directory for all analysis artifacts"
      ],
      "summary": "The persistence module provides comprehensive storage and retrieval capabilities for all AI-generated analysis results within the workspace. It manages the lifecycle of documentation artifacts by saving them to an organized .shadow directory structure, ensuring that product documentation, architecture insights, and summaries are preserved with proper timestamps and versioning.\n\nUsers benefit from automatic persistence of their analysis sessions, with documentation saved to .shadow/docs and insights stored in .shadow/insights, each in timestamped subdirectories. The module handles both incremental updates and full documentation consolidation, allowing teams to track how their understanding of the codebase evolves over time.\n\nThe module creates consolidated summary files that combine results from multiple analyses, making it easy to review comprehensive findings at a glance. All stored artifacts maintain their timestamps, enabling users to trace the history of their documentation efforts and compare different analysis iterations.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages persistence and storage of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory",
          "userVisibleActions": [
            "Product documentation is saved to timestamped directories in .shadow/docs",
            "Architecture insights are saved to timestamped directories in .shadow/insights",
            "Summary files are created combining all analysis results",
            "Incremental documentation updates are stored with timestamps",
            "Consolidated documentation files are generated from multiple analyses"
          ],
          "developerVisibleActions": [
            "Initialize product documentation run to create storage directories",
            "Initialize architecture insights run to create storage directories",
            "Save enhanced product documentation with formatted output",
            "Save architecture insights with formatted output",
            "Save summary files combining product docs and insights",
            "Store documentation updates incrementally with timestamps",
            "Retrieve latest documentation from storage",
            "Get consolidated documentation from all runs",
            "Finalize runs by creating summary files"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Creates a new timestamped directory for storing product documentation results",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Creates a new timestamped directory for storing architecture insights results",
              "inputs": "workspaceRoot: string",
              "outputs": "string (path to run directory)"
            },
            {
              "name": "saveProductDocs",
              "desc": "Saves enhanced product documentation to the current run directory",
              "inputs": "workspaceRoot: string, docs: EnhancedProductDocumentation",
              "outputs": "void"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Saves architecture insights to the current run directory",
              "inputs": "workspaceRoot: string, insights: LLMInsights",
              "outputs": "void"
            },
            {
              "name": "saveSummary",
              "desc": "Creates a summary file combining product docs and architecture insights",
              "inputs": "workspaceRoot: string, productDocs: EnhancedProductDocumentation, insights: LLMInsights",
              "outputs": "void"
            },
            {
              "name": "finalizeProductDocsRun",
              "desc": "Completes the product docs run by creating final summary files",
              "inputs": "workspaceRoot: string",
              "outputs": "void"
            },
            {
              "name": "finalizeArchitectureInsightsRun",
              "desc": "Completes the architecture insights run by creating final summary files",
              "inputs": "workspaceRoot: string",
              "outputs": "void"
            },
            {
              "name": "storeDocumentationUpdate",
              "desc": "Saves incremental documentation updates with timestamps",
              "inputs": "workspaceRoot: string, filePath: string, documentation: any",
              "outputs": "Promise<void>"
            },
            {
              "name": "getLatestDocumentation",
              "desc": "Retrieves the most recent documentation for a file",
              "inputs": "workspaceRoot: string, filePath: string",
              "outputs": "Promise<any | null>"
            },
            {
              "name": "getConsolidatedDocumentation",
              "desc": "Gets all documentation from all timestamped runs",
              "inputs": "workspaceRoot: string",
              "outputs": "Promise<Record<string, any>>"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "fileDocumentation (EnhancedProductDocumentation)",
            "llmService (LLMInsights)",
            "domain/formatters/documentationFormatter",
            "storage/incrementalStorage"
          ],
          "intent": "Separates persistence concerns from LLM integration by providing a dedicated repository for storing and retrieving all AI-generated analysis results, enabling organized storage with timestamps, incremental updates, and consolidated views of documentation across multiple analysis runs",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistence and storage of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory\",\n  \"userVisibleActions\": [\n    \"Product documentation is saved to timestamped directories in .shadow/docs\",\n    \"Architecture insights are saved to timestamped directories in .shadow/insights\",\n    \"Summary files are created combining all analysis results\",\n    \"Incremental documentation updates are stored with timestamps\",\n    \"Consolidated documentation files are generated from multiple analyses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation run to create storage directories\",\n    \"Initialize architecture insights run to create storage directories\",\n    \"Save enhanced product documentation with formatted output\",\n    \"Save architecture insights with formatted output\",\n    \"Save summary files combining product docs and insights\",\n    \"Store documentation updates incrementally with timestamps\",\n    \"Retrieve latest documentation from storage\",\n    \"Get consolidated documentation from all runs\",\n    \"Finalize runs by creating summary files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocs\",\n      \"desc\": \"Saves enhanced product documentation to the current run directory\",\n      \"inputs\": \"workspaceRoot: string, docs: EnhancedProductDocumentation\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights to the current run directory\",\n      \"inputs\": \"workspaceRoot: string, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Creates a summary file combining product docs and architecture insights\",\n      \"inputs\": \"workspaceRoot: string, productDocs: EnhancedProductDocumentation, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeProductDocsRun\",\n      \"desc\": \"Completes the product docs run by creating final summary files\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeArchitectureInsightsRun\",\n      \"desc\": \"Completes the architecture insights run by creating final summary files\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"storeDocumentationUpdate\",\n      \"desc\": \"Saves incremental documentation updates with timestamps\",\n      \"inputs\": \"workspaceRoot: string, filePath: string, documentation: any\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getLatestDocumentation\",\n      \"desc\": \"Retrieves the most recent documentation for a file\",\n      \"inputs\": \"workspaceRoot: string, filePath: string\",\n      \"outputs\": \"Promise<any | null>\"\n    },\n    {\n      \"name\": \"getConsolidatedDocumentation\",\n      \"desc\": \"Gets all documentation from all timestamped runs\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Promise<Record<string, any>>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates persistence concerns from LLM integration by providing a dedicated repository for storing and retrieving all AI-generated analysis results, enabling organized storage with timestamps, incremental updates, and consolidated views of documentation across multiple analysis runs\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display standardized progress notifications during long-running operations",
        "Show real-time progress updates with titles and status messages",
        "Allow users to cancel ongoing operations through the notification interface",
        "Track incremental progress across different UI locations (notification area, status bar)",
        "Provide consistent progress feedback across all application operations"
      ],
      "summary": "The infrastructure module provides a centralized progress notification service that keeps users informed during long-running operations. It delivers a consistent user experience by displaying progress indicators with customizable titles, status messages, and cancel functionality.\n\nUsers interact with this module passively through progress notifications that appear automatically when operations begin. The service displays real-time updates showing the current status of tasks, and users can cancel operations at any time using the cancel button in the notification. Progress can be tracked visually in multiple locations including the notification area and status bar, ensuring users always know when the application is working on their behalf.\n\nThis module serves as the foundation for all progress-related UI feedback in the application, standardizing how operations communicate their status to users and enabling a predictable, user-friendly experience across different features and workflows.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations",
          "userVisibleActions": [
            "See progress notifications with titles and status messages during operations",
            "Cancel ongoing operations via cancel button in progress notification",
            "Track progress of operations with incremental updates",
            "View progress indicators in different locations (notification area, status bar, etc.)"
          ],
          "developerVisibleActions": [
            "Wrap async operations with standardized progress reporting",
            "Display titled progress notifications with customizable messages",
            "Configure progress location (notification, window, etc.)",
            "Enable or disable cancellation for operations",
            "Report progress updates with optional increment values",
            "Access cancellation token to handle user cancellation requests",
            "Use simple string title or full options object for flexibility"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying a progress notification to the user",
              "inputs": "options (title, cancellable flag, location), task function that receives a progress reporter",
              "outputs": "Result of the executed task"
            },
            {
              "name": "report",
              "desc": "Updates the progress notification with a new message and optional progress increment",
              "inputs": "message string, optional increment number",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "Eliminates boilerplate code for progress reporting by providing a consistent, reusable wrapper around VSCode's progress API, ensuring all long-running operations display uniform progress notifications to users",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and status messages during operations\",\n    \"Cancel ongoing operations via cancel button in progress notification\",\n    \"Track progress of operations with incremental updates\",\n    \"View progress indicators in different locations (notification area, status bar, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async operations with standardized progress reporting\",\n    \"Display titled progress notifications with customizable messages\",\n    \"Configure progress location (notification, window, etc.)\",\n    \"Enable or disable cancellation for operations\",\n    \"Report progress updates with optional increment values\",\n    \"Access cancellation token to handle user cancellation requests\",\n    \"Use simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location), task function that receives a progress reporter\",\n      \"outputs\": \"Result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress notification with a new message and optional progress increment\",\n      \"inputs\": \"message string, optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Eliminates boilerplate code for progress reporting by providing a consistent, reusable wrapper around VSCode's progress API, ensuring all long-running operations display uniform progress notifications to users\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest testing framework for TypeScript unit tests with coverage reporting and module resolution settings",
      "userVisibleActions": [
        "No direct user-facing actions - this is a development configuration file"
      ],
      "developerVisibleActions": [
        "Run unit tests in TypeScript using Jest with 'npm test' or 'jest' command",
        "View test coverage reports in text, lcov, and HTML formats in the 'coverage' directory",
        "Write tests in __tests__ directories or files ending in .spec.ts or .test.ts",
        "See test results execute in Node.js environment with 10-second timeout per test",
        "Access mocked VSCode API during testing through automated module mapping"
      ],
      "keyFunctions": [
        {
          "name": "testMatch",
          "desc": "Identifies test files to run based on naming patterns",
          "inputs": "File path patterns",
          "outputs": "Array of test file paths matching **/__tests__/**/*.ts or **/*.spec.ts or **/*.test.ts"
        },
        {
          "name": "transform",
          "desc": "Converts TypeScript files to JavaScript for test execution",
          "inputs": "TypeScript files with .ts extension",
          "outputs": "Transpiled JavaScript with ES2020 target and CommonJS modules"
        },
        {
          "name": "collectCoverageFrom",
          "desc": "Specifies which source files to include in code coverage analysis",
          "inputs": "Source file patterns",
          "outputs": "Coverage metrics excluding test files, type definitions, test utilities, and mocks"
        },
        {
          "name": "moduleNameMapper",
          "desc": "Redirects VSCode module imports to mock implementation during tests",
          "inputs": "Module import requests for 'vscode'",
          "outputs": "Mock VSCode module from src/test/__mocks__/vscode.ts"
        }
      ],
      "dependencies": [
        "ts-jest",
        "jest",
        "node"
      ],
      "intent": "This file exists to provide a standardized Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to run unit tests with proper TypeScript compilation, module resolution, and code coverage tracking while mocking VSCode APIs",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript unit tests with coverage reporting and module resolution settings\",\n  \"userVisibleActions\": [\n    \"No direct user-facing actions - this is a development configuration file\"\n  ],\n  \"developerVisibleActions\": [\n    \"Run unit tests in TypeScript using Jest with 'npm test' or 'jest' command\",\n    \"View test coverage reports in text, lcov, and HTML formats in the 'coverage' directory\",\n    \"Write tests in __tests__ directories or files ending in .spec.ts or .test.ts\",\n    \"See test results execute in Node.js environment with 10-second timeout per test\",\n    \"Access mocked VSCode API during testing through automated module mapping\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"testMatch\",\n      \"desc\": \"Identifies test files to run based on naming patterns\",\n      \"inputs\": \"File path patterns\",\n      \"outputs\": \"Array of test file paths matching **/__tests__/**/*.ts or **/*.spec.ts or **/*.test.ts\"\n    },\n    {\n      \"name\": \"transform\",\n      \"desc\": \"Converts TypeScript files to JavaScript for test execution\",\n      \"inputs\": \"TypeScript files with .ts extension\",\n      \"outputs\": \"Transpiled JavaScript with ES2020 target and CommonJS modules\"\n    },\n    {\n      \"name\": \"collectCoverageFrom\",\n      \"desc\": \"Specifies which source files to include in code coverage analysis\",\n      \"inputs\": \"Source file patterns\",\n      \"outputs\": \"Coverage metrics excluding test files, type definitions, test utilities, and mocks\"\n    },\n    {\n      \"name\": \"moduleNameMapper\",\n      \"desc\": \"Redirects VSCode module imports to mock implementation during tests\",\n      \"inputs\": \"Module import requests for 'vscode'\",\n      \"outputs\": \"Mock VSCode module from src/test/__mocks__/vscode.ts\"\n    }\n  ],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"node\"\n  ],\n  \"intent\": \"This file exists to provide a standardized Jest testing configuration for a TypeScript-based VSCode extension, enabling developers to run unit tests with proper TypeScript compilation, module resolution, and code coverage tracking while mocking VSCode APIs\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Prevents LLM API requests from exceeding rate limits by tracking and throttling requests per provider",
      "userVisibleActions": [
        "API requests are automatically throttled to prevent hitting rate limits",
        "Requests may be delayed or rejected when rate limits are approached",
        "Different LLM providers (OpenAI, Claude) have different rate limits applied"
      ],
      "developerVisibleActions": [
        "Configure custom rate limits for OpenAI and Claude providers",
        "Check if a request can be made before calling the API",
        "Record successful API requests to track usage against limits",
        "Get information about remaining requests available",
        "Wait for rate limit windows to reset when limits are reached"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes rate limiter with default limits (OpenAI: 60 req/min, Claude: 50 req/min)",
          "inputs": "none",
          "outputs": "RateLimiter instance"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limit configuration for a specific LLM provider",
          "inputs": "provider (openai or claude), config (maxRequests, windowMs)",
          "outputs": "void"
        },
        {
          "name": "canMakeRequest",
          "desc": "Checks if a new request can be made without exceeding rate limits",
          "inputs": "provider (openai or claude)",
          "outputs": "boolean - true if request is allowed"
        },
        {
          "name": "recordRequest",
          "desc": "Records a request timestamp to track usage against rate limits",
          "inputs": "provider (openai or claude)",
          "outputs": "void"
        }
      ],
      "dependencies": [],
      "intent": "Prevents API rate limit errors by tracking and enforcing request quotas per LLM provider, ensuring the application stays within API usage limits and avoids service disruptions or additional costs from exceeding quotas",
      "rawContent": "```json\n{\n  \"purpose\": \"Prevents LLM API requests from exceeding rate limits by tracking and throttling requests per provider\",\n  \"userVisibleActions\": [\n    \"API requests are automatically throttled to prevent hitting rate limits\",\n    \"Requests may be delayed or rejected when rate limits are approached\",\n    \"Different LLM providers (OpenAI, Claude) have different rate limits applied\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure custom rate limits for OpenAI and Claude providers\",\n    \"Check if a request can be made before calling the API\",\n    \"Record successful API requests to track usage against limits\",\n    \"Get information about remaining requests available\",\n    \"Wait for rate limit windows to reset when limits are reached\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes rate limiter with default limits (OpenAI: 60 req/min, Claude: 50 req/min)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"RateLimiter instance\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limit configuration for a specific LLM provider\",\n      \"inputs\": \"provider (openai or claude), config (maxRequests, windowMs)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if a new request can be made without exceeding rate limits\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"boolean - true if request is allowed\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records a request timestamp to track usage against rate limits\",\n      \"inputs\": \"provider (openai or claude)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Prevents API rate limit errors by tracking and enforcing request quotas per LLM provider, ensuring the application stays within API usage limits and avoids service disruptions or additional costs from exceeding quotas\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Parses LLM text responses into structured data objects for file summaries, module summaries, and product documentation",
      "userVisibleActions": [
        "Receives structured analysis results from AI that describe code files in plain language",
        "Gets organized information about what code files do from a user perspective",
        "Views parsed product documentation with user-facing features and benefits"
      ],
      "developerVisibleActions": [
        "Calls parser methods to convert raw LLM response text into typed TypeScript objects",
        "Handles JSON-formatted LLM responses or falls back to text parsing if JSON fails",
        "Extracts file summaries with purpose, actions, functions, and dependencies from LLM output",
        "Parses module summaries that group related files together",
        "Converts LLM insights into structured analysis data with themes and patterns",
        "Processes product purpose analysis from LLM responses",
        "Generates enhanced product documentation by parsing LLM-generated content",
        "Deals with parsing errors gracefully by falling back to text extraction methods"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into a FileSummary object with purpose, actions, and dependencies",
          "inputs": "content (LLM response text), filePath, role",
          "outputs": "FileSummary object"
        },
        {
          "name": "parseModuleSummary",
          "desc": "Extracts module-level summary information from LLM response",
          "inputs": "content (LLM response text), moduleName",
          "outputs": "ModuleSummary object"
        },
        {
          "name": "parseLLMInsights",
          "desc": "Parses LLM analysis into structured insights with themes and patterns",
          "inputs": "content (LLM response text), context",
          "outputs": "LLMInsights object"
        },
        {
          "name": "parseProductPurpose",
          "desc": "Extracts product purpose analysis from LLM response",
          "inputs": "content (LLM response text)",
          "outputs": "ProductPurposeAnalysis object"
        },
        {
          "name": "parseEnhancedProductDoc",
          "desc": "Generates enhanced product documentation from LLM response",
          "inputs": "content (LLM response text), existingDocs",
          "outputs": "EnhancedProductDocumentation object"
        },
        {
          "name": "extractSection",
          "desc": "Extracts a specific section of text from LLM response by section name",
          "inputs": "content, sectionName",
          "outputs": "Extracted text string"
        },
        {
          "name": "extractListSection",
          "desc": "Extracts a list/array of items from a section in LLM response",
          "inputs": "content, sectionName",
          "outputs": "Array of strings"
        }
      ],
      "dependencies": [
        "../fileDocumentation",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript objects the application needs. It solves the problem of reliably extracting meaningful data from AI-generated content, handling both JSON and plain text formats, and providing fallback mechanisms when parsing fails.",
      "rawContent": "```json\n{\n  \"purpose\": \"Parses LLM text responses into structured data objects for file summaries, module summaries, and product documentation\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis results from AI that describe code files in plain language\",\n    \"Gets organized information about what code files do from a user perspective\",\n    \"Views parsed product documentation with user-facing features and benefits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls parser methods to convert raw LLM response text into typed TypeScript objects\",\n    \"Handles JSON-formatted LLM responses or falls back to text parsing if JSON fails\",\n    \"Extracts file summaries with purpose, actions, functions, and dependencies from LLM output\",\n    \"Parses module summaries that group related files together\",\n    \"Converts LLM insights into structured analysis data with themes and patterns\",\n    \"Processes product purpose analysis from LLM responses\",\n    \"Generates enhanced product documentation by parsing LLM-generated content\",\n    \"Deals with parsing errors gracefully by falling back to text extraction methods\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object with purpose, actions, and dependencies\",\n      \"inputs\": \"content (LLM response text), filePath, role\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"parseModuleSummary\",\n      \"desc\": \"Extracts module-level summary information from LLM response\",\n      \"inputs\": \"content (LLM response text), moduleName\",\n      \"outputs\": \"ModuleSummary object\"\n    },\n    {\n      \"name\": \"parseLLMInsights\",\n      \"desc\": \"Parses LLM analysis into structured insights with themes and patterns\",\n      \"inputs\": \"content (LLM response text), context\",\n      \"outputs\": \"LLMInsights object\"\n    },\n    {\n      \"name\": \"parseProductPurpose\",\n      \"desc\": \"Extracts product purpose analysis from LLM response\",\n      \"inputs\": \"content (LLM response text)\",\n      \"outputs\": \"ProductPurposeAnalysis object\"\n    },\n    {\n      \"name\": \"parseEnhancedProductDoc\",\n      \"desc\": \"Generates enhanced product documentation from LLM response\",\n      \"inputs\": \"content (LLM response text), existingDocs\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a specific section of text from LLM response by section name\",\n      \"inputs\": \"content, sectionName\",\n      \"outputs\": \"Extracted text string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array of items from a section in LLM response\",\n      \"inputs\": \"content, sectionName\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between unstructured LLM text responses and the structured TypeScript objects the application needs. It solves the problem of reliably extracting meaningful data from AI-generated content, handling both JSON and plain text formats, and providing fallback mechanisms when parsing fails.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles retry logic with exponential backoff for LLM API requests that fail due to rate limits, timeouts, or temporary errors",
      "userVisibleActions": [
        "When an AI operation fails temporarily, the system automatically retries the request instead of showing an immediate error",
        "Rate limit errors and network timeouts are handled gracefully with automatic retries",
        "Long-running AI operations have built-in resilience against temporary service disruptions"
      ],
      "developerVisibleActions": [
        "Wrap any LLM API call with retry logic to handle transient failures automatically",
        "Configure retry behavior including max attempts, delay intervals, and which errors to retry",
        "Receive callbacks when retries occur to track retry attempts and errors",
        "Non-retryable errors (like invalid API keys) fail immediately without wasting retries",
        "Get back results with metadata about how many attempts were needed"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an async operation with automatic retry on failure, using exponential backoff between attempts",
          "inputs": "operation function to execute, optional retry configuration (maxRetries, delays, retryable error types, onRetry callback)",
          "outputs": "The successful result of the operation, or throws the final error if all retries exhausted"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines whether an error should trigger a retry based on error type and message content",
          "inputs": "error object, list of retryable error patterns",
          "outputs": "boolean indicating if the error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Provides resilience for LLM API calls by automatically retrying failed requests due to temporary issues like rate limits, network problems, or service unavailability, preventing users from experiencing failures that could be resolved by waiting and retrying",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles retry logic with exponential backoff for LLM API requests that fail due to rate limits, timeouts, or temporary errors\",\n  \"userVisibleActions\": [\n    \"When an AI operation fails temporarily, the system automatically retries the request instead of showing an immediate error\",\n    \"Rate limit errors and network timeouts are handled gracefully with automatic retries\",\n    \"Long-running AI operations have built-in resilience against temporary service disruptions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap any LLM API call with retry logic to handle transient failures automatically\",\n    \"Configure retry behavior including max attempts, delay intervals, and which errors to retry\",\n    \"Receive callbacks when retries occur to track retry attempts and errors\",\n    \"Non-retryable errors (like invalid API keys) fail immediately without wasting retries\",\n    \"Get back results with metadata about how many attempts were needed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry on failure, using exponential backoff between attempts\",\n      \"inputs\": \"operation function to execute, optional retry configuration (maxRetries, delays, retryable error types, onRetry callback)\",\n      \"outputs\": \"The successful result of the operation, or throws the final error if all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines whether an error should trigger a retry based on error type and message content\",\n      \"inputs\": \"error object, list of retryable error patterns\",\n      \"outputs\": \"boolean indicating if the error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides resilience for LLM API calls by automatically retrying failed requests due to temporary issues like rate limits, network problems, or service unavailability, preventing users from experiencing failures that could be resolved by waiting and retrying\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines the standard interface for integrating different AI language model providers (OpenAI, Claude, etc.) into the application",
      "userVisibleActions": [
        "User can interact with different AI providers (OpenAI, Claude, custom) transparently without knowing which one is being used",
        "User receives text responses from AI models",
        "User receives structured JSON data responses from AI models",
        "User can send messages with conversation history to AI models",
        "User can request file content or search patterns from AI models"
      ],
      "developerVisibleActions": [
        "Developer implements this interface to add new AI provider support",
        "Developer checks if a provider is properly configured before use",
        "Developer sends text-based requests to any AI provider using a unified format",
        "Developer sends structured JSON requests with optional schemas",
        "Developer receives parsed JSON responses with optional file/grep requests",
        "Developer configures model parameters (temperature, max tokens, response format)",
        "Developer builds conversation flows with system, user, and assistant messages",
        "Developer gets provider name for logging or display purposes"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Verifies if the AI provider has valid API keys and is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating if provider is ready"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a conversation to the AI model and receives a text response",
          "inputs": "LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)",
          "outputs": "Promise<LLMResponse> with content, finish reason, and model info"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a request expecting structured JSON output, optionally validated against a schema",
          "inputs": "LLMRequestOptions and optional schema",
          "outputs": "Promise<StructuredOutputResponse<T>> with parsed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the name identifier of the AI provider",
          "inputs": "none",
          "outputs": "string with provider name"
        }
      ],
      "dependencies": [],
      "intent": "This interface exists to provide a unified abstraction layer over multiple AI providers, allowing the application to switch between different LLM services (OpenAI, Anthropic Claude, custom providers) without changing application code. It solves the problem of vendor lock-in and enables flexible AI provider configuration while maintaining consistent behavior across the application.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the standard interface for integrating different AI language model providers (OpenAI, Claude, etc.) into the application\",\n  \"userVisibleActions\": [\n    \"User can interact with different AI providers (OpenAI, Claude, custom) transparently without knowing which one is being used\",\n    \"User receives text responses from AI models\",\n    \"User receives structured JSON data responses from AI models\",\n    \"User can send messages with conversation history to AI models\",\n    \"User can request file content or search patterns from AI models\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add new AI provider support\",\n    \"Developer checks if a provider is properly configured before use\",\n    \"Developer sends text-based requests to any AI provider using a unified format\",\n    \"Developer sends structured JSON requests with optional schemas\",\n    \"Developer receives parsed JSON responses with optional file/grep requests\",\n    \"Developer configures model parameters (temperature, max tokens, response format)\",\n    \"Developer builds conversation flows with system, user, and assistant messages\",\n    \"Developer gets provider name for logging or display purposes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Verifies if the AI provider has valid API keys and is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is ready\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a conversation to the AI model and receives a text response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, and model info\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a request expecting structured JSON output, optionally validated against a schema\",\n      \"inputs\": \"LLMRequestOptions and optional schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> with parsed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the name identifier of the AI provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string with provider name\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to provide a unified abstraction layer over multiple AI providers, allowing the application to switch between different LLM services (OpenAI, Anthropic Claude, custom providers) without changing application code. It solves the problem of vendor lock-in and enables flexible AI provider configuration while maintaining consistent behavior across the application.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with Anthropic's Claude AI models for generating text responses and structured outputs",
      "userVisibleActions": [
        "User can interact with Claude AI models through the extension",
        "User receives AI-generated responses from Claude models (Sonnet, Opus, Haiku)",
        "User can configure Claude API key in settings to enable Claude provider",
        "User sees error messages when Claude API key is not configured",
        "User experiences AI conversations with system prompts and message history"
      ],
      "developerVisibleActions": [
        "Developer can send text generation requests to Claude models",
        "Developer can request structured JSON outputs with automatic validation",
        "Developer can specify system prompts to guide Claude's behavior",
        "Developer can provide conversation history with user and assistant messages",
        "Developer receives parsed JSON responses from Claude with validation",
        "Developer can choose between different Claude model variants (Sonnet, Opus, Haiku)",
        "Developer gets automatic retry with fallback when JSON parsing fails",
        "Developer can set custom token limits and timeouts for requests"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is configured and provider is ready to use",
          "inputs": "none",
          "outputs": "boolean indicating if provider is configured"
        },
        {
          "name": "getName",
          "desc": "Returns the identifier name for this provider",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a text generation request to Claude and returns the response",
          "inputs": "LLMRequestOptions with model, messages, system prompt, max tokens",
          "outputs": "LLMResponse with generated text content and token usage"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Requests structured JSON output from Claude with validation and retry logic",
          "inputs": "LLMRequestOptions with JSON schema requirements",
          "outputs": "StructuredOutputResponse with parsed JSON data or validation error"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Claude client with API key from configuration",
          "inputs": "none (reads from config)",
          "outputs": "none (initializes internal client)"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to provide a standardized interface for integrating Anthropic's Claude AI models into the extension. It solves the problem of abstracting away Claude-specific API details, handling message format conversion, managing API authentication, parsing structured outputs, and providing consistent error handling for Claude interactions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for generating text responses and structured outputs\",\n  \"userVisibleActions\": [\n    \"User can interact with Claude AI models through the extension\",\n    \"User receives AI-generated responses from Claude models (Sonnet, Opus, Haiku)\",\n    \"User can configure Claude API key in settings to enable Claude provider\",\n    \"User sees error messages when Claude API key is not configured\",\n    \"User experiences AI conversations with system prompts and message history\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer can send text generation requests to Claude models\",\n    \"Developer can request structured JSON outputs with automatic validation\",\n    \"Developer can specify system prompts to guide Claude's behavior\",\n    \"Developer can provide conversation history with user and assistant messages\",\n    \"Developer receives parsed JSON responses from Claude with validation\",\n    \"Developer can choose between different Claude model variants (Sonnet, Opus, Haiku)\",\n    \"Developer gets automatic retry with fallback when JSON parsing fails\",\n    \"Developer can set custom token limits and timeouts for requests\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is configured and provider is ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the identifier name for this provider\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a text generation request to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, system prompt, max tokens\",\n      \"outputs\": \"LLMResponse with generated text content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Requests structured JSON output from Claude with validation and retry logic\",\n      \"inputs\": \"LLMRequestOptions with JSON schema requirements\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data or validation error\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude client with API key from configuration\",\n      \"inputs\": \"none (reads from config)\",\n      \"outputs\": \"none (initializes internal client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to provide a standardized interface for integrating Anthropic's Claude AI models into the extension. It solves the problem of abstracting away Claude-specific API details, handling message format conversion, managing API authentication, parsing structured outputs, and providing consistent error handling for Claude interactions.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses",
      "userVisibleActions": [
        "User's prompts are sent to OpenAI's GPT models for AI-powered responses",
        "User receives AI-generated text responses based on their input",
        "User can get structured JSON responses when requesting specific data formats",
        "User experiences automatic API key validation before making requests"
      ],
      "developerVisibleActions": [
        "Developer configures OpenAI API key through configuration manager",
        "Developer sends chat completion requests with custom models, prompts, and messages",
        "Developer receives parsed JSON responses when using structured output format",
        "Developer gets error messages when API key is not configured or requests fail",
        "Developer can check if provider is properly configured before use",
        "Developer specifies system prompts, conversation history, and response format options"
      ],
      "keyFunctions": [
        {
          "name": "initialize",
          "desc": "Sets up the OpenAI client with API key from configuration",
          "inputs": "None (reads from config manager)",
          "outputs": "void (initializes client)"
        },
        {
          "name": "isConfigured",
          "desc": "Checks if the provider has a valid API key and is ready to use",
          "inputs": "None",
          "outputs": "boolean indicating configuration status"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "None",
          "outputs": "string 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a chat completion request to OpenAI with messages and optional system prompt",
          "inputs": "LLMRequestOptions (model, messages, systemPrompt, responseFormat)",
          "outputs": "Promise<LLMResponse> with content and finish reason"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Sends a request expecting structured JSON output and parses the response",
          "inputs": "LLMRequestOptions with expected JSON format",
          "outputs": "Promise<StructuredOutputResponse> with parsed JSON data"
        }
      ],
      "dependencies": [
        "openai",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses\",\n  \"userVisibleActions\": [\n    \"User's prompts are sent to OpenAI's GPT models for AI-powered responses\",\n    \"User receives AI-generated text responses based on their input\",\n    \"User can get structured JSON responses when requesting specific data formats\",\n    \"User experiences automatic API key validation before making requests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer configures OpenAI API key through configuration manager\",\n    \"Developer sends chat completion requests with custom models, prompts, and messages\",\n    \"Developer receives parsed JSON responses when using structured output format\",\n    \"Developer gets error messages when API key is not configured or requests fail\",\n    \"Developer can check if provider is properly configured before use\",\n    \"Developer specifies system prompts, conversation history, and response format options\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the OpenAI client with API key from configuration\",\n      \"inputs\": \"None (reads from config manager)\",\n      \"outputs\": \"void (initializes client)\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has a valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI with messages and optional system prompt\",\n      \"inputs\": \"LLMRequestOptions (model, messages, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends a request expecting structured JSON output and parses the response\",\n      \"inputs\": \"LLMRequestOptions with expected JSON format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Creates and manages AI provider instances (OpenAI or Claude) based on user configuration",
      "userVisibleActions": [
        "Automatically connects to the AI provider selected in settings (OpenAI or Claude)",
        "Only shows available AI providers that have valid API keys configured",
        "Uses the default AI provider from configuration when generating responses"
      ],
      "developerVisibleActions": [
        "Provides a centralized factory for getting AI provider instances",
        "Caches provider instances to avoid recreating them",
        "Exposes methods to check which providers are properly configured",
        "Returns the currently active provider based on user settings",
        "Throws error when requesting an unknown provider type"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns a specific AI provider instance (OpenAI or Claude)",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the AI provider that is currently active in user settings",
          "inputs": "none",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks if a provider has valid configuration (API key, etc.)",
          "inputs": "provider: 'openai' | 'claude'",
          "outputs": "boolean"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns list of all providers that have valid configuration",
          "inputs": "none",
          "outputs": "Array of provider names"
        }
      ],
      "dependencies": [
        "ILLMProvider",
        "OpenAIProvider",
        "AnthropicProvider",
        "configurationManager"
      ],
      "intent": "Provides a single point of control for creating and accessing AI providers, ensuring only one instance of each provider exists and automatically selecting the provider based on user configuration",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates and manages AI provider instances (OpenAI or Claude) based on user configuration\",\n  \"userVisibleActions\": [\n    \"Automatically connects to the AI provider selected in settings (OpenAI or Claude)\",\n    \"Only shows available AI providers that have valid API keys configured\",\n    \"Uses the default AI provider from configuration when generating responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a centralized factory for getting AI provider instances\",\n    \"Caches provider instances to avoid recreating them\",\n    \"Exposes methods to check which providers are properly configured\",\n    \"Returns the currently active provider based on user settings\",\n    \"Throws error when requesting an unknown provider type\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns a specific AI provider instance (OpenAI or Claude)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently active in user settings\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a provider has valid configuration (API key, etc.)\",\n      \"inputs\": \"provider: 'openai' | 'claude'\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns list of all providers that have valid configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of provider names\"\n    }\n  ],\n  \"dependencies\": [\n    \"ILLMProvider\",\n    \"OpenAIProvider\",\n    \"AnthropicProvider\",\n    \"configurationManager\"\n  ],\n  \"intent\": \"Provides a single point of control for creating and accessing AI providers, ensuring only one instance of each provider exists and automatically selecting the provider based on user configuration\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Performs deep code analysis by parsing abstract syntax trees (AST) to extract detailed function metadata including branches, dependencies, state mutations, and behavioral patterns.",
      "userVisibleActions": [
        "Receives enhanced code intelligence about function behavior and complexity",
        "Gets insights about function dependencies and side effects",
        "Sees analysis of conditional branches and code paths within functions",
        "Receives information about state mutations and variable modifications",
        "Gets behavioral hints about function characteristics (pure, async, recursive, etc.)"
      ],
      "developerVisibleActions": [
        "Analyzes code files to extract detailed function metadata beyond basic information",
        "Parses TypeScript/JavaScript files using AST to understand code structure",
        "Extracts branch analysis showing conditional logic and code paths",
        "Profiles function dependencies and external module usage",
        "Detects state mutations and side effects in functions",
        "Generates behavioral hints indicating function patterns (pure functions, async operations, recursion)",
        "Falls back to regex-based analysis for non-TypeScript/JavaScript languages",
        "Provides test mapping suggestions based on function characteristics",
        "Returns comprehensive metadata including complexity metrics and dependency graphs"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes a code file and extracts enhanced metadata for all functions within it",
          "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
          "outputs": "Map<string, FunctionMetadata> containing detailed metadata for each function"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata",
          "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
          "outputs": "FunctionMetadata object with branch info, dependencies, mutations, and behavioral hints"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Provides fallback regex-based analysis for languages other than TypeScript/JavaScript",
          "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
          "outputs": "FunctionMetadata object with basic analysis data"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the source code content of a function based on line numbers",
          "inputs": "content (string), startLine (number), endLine (number)",
          "outputs": "String containing the function's source code"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer"
      ],
      "intent": "This file exists to provide deep, AST-level code analysis that goes beyond surface-level parsing. It solves the problem of understanding complex code behavior, dependencies, and patterns by analyzing the actual structure of code rather than just reading it as text. This enables intelligent features like dependency tracking, branch analysis, mutation detection, and behavioral pattern recognition for better code understanding and test generation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Performs deep code analysis by parsing abstract syntax trees (AST) to extract detailed function metadata including branches, dependencies, state mutations, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives enhanced code intelligence about function behavior and complexity\",\n    \"Gets insights about function dependencies and side effects\",\n    \"Sees analysis of conditional branches and code paths within functions\",\n    \"Receives information about state mutations and variable modifications\",\n    \"Gets behavioral hints about function characteristics (pure, async, recursive, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes code files to extract detailed function metadata beyond basic information\",\n    \"Parses TypeScript/JavaScript files using AST to understand code structure\",\n    \"Extracts branch analysis showing conditional logic and code paths\",\n    \"Profiles function dependencies and external module usage\",\n    \"Detects state mutations and side effects in functions\",\n    \"Generates behavioral hints indicating function patterns (pure functions, async operations, recursion)\",\n    \"Falls back to regex-based analysis for non-TypeScript/JavaScript languages\",\n    \"Provides test mapping suggestions based on function characteristics\",\n    \"Returns comprehensive metadata including complexity metrics and dependency graphs\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a code file and extracts enhanced metadata for all functions within it\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing detailed metadata for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis on TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata object with branch info, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for languages other than TypeScript/JavaScript\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata object with basic analysis data\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function based on line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide deep, AST-level code analysis that goes beyond surface-level parsing. It solves the problem of understanding complex code behavior, dependencies, and patterns by analyzing the actual structure of code rather than just reading it as text. This enables intelligent features like dependency tracking, branch analysis, mutation detection, and behavioral pattern recognition for better code understanding and test generation.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and responsibilities for generating refactoring reports.",
      "userVisibleActions": [
        "Identifies functions in large files that may need refactoring",
        "Generates detailed function analysis reports showing what each function does",
        "Highlights function dependencies and relationships within the codebase",
        "Provides function signature information for understanding code structure"
      ],
      "developerVisibleActions": [
        "Developer triggers function analysis on large files exceeding a threshold (default 500 lines)",
        "Receives structured FunctionAnalysis objects containing function metadata",
        "Gets function signatures, dependencies, dependents, and responsibilities extracted from TypeScript code",
        "Can access analyzed function data to build refactoring prompts and reports",
        "Sees warnings when function analysis fails for specific functions"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in files exceeding a size threshold and extracts detailed information",
          "inputs": "codeAnalysis (CodeAnalysis object), largeFileThreshold (optional number, default 500 lines)",
          "outputs": "Promise<FunctionAnalysis[]> - array of detailed function analyses"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs detailed analysis on a single function to extract its metadata and relationships",
          "inputs": "filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)",
          "outputs": "Promise<FunctionAnalysis | null> - detailed function analysis or null if analysis fails"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves the full file path for a given file in the code analysis",
          "inputs": "filePath (string), codeAnalysis (CodeAnalysis)",
          "outputs": "string - resolved full file path"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to provide deep analysis of functions within large code files to support refactoring efforts. It solves the problem of understanding complex function relationships, dependencies, and responsibilities when developers need to break down or refactor large files. It bridges the gap between basic code analysis and actionable refactoring insights by extracting function-level metadata that can be used to generate intelligent refactoring suggestions.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and responsibilities for generating refactoring reports.\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Generates detailed function analysis reports showing what each function does\",\n    \"Highlights function dependencies and relationships within the codebase\",\n    \"Provides function signature information for understanding code structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers function analysis on large files exceeding a threshold (default 500 lines)\",\n    \"Receives structured FunctionAnalysis objects containing function metadata\",\n    \"Gets function signatures, dependencies, dependents, and responsibilities extracted from TypeScript code\",\n    \"Can access analyzed function data to build refactoring prompts and reports\",\n    \"Sees warnings when function analysis fails for specific functions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files exceeding a size threshold and extracts detailed information\",\n      \"inputs\": \"codeAnalysis (CodeAnalysis object), largeFileThreshold (optional number, default 500 lines)\",\n      \"outputs\": \"Promise<FunctionAnalysis[]> - array of detailed function analyses\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis on a single function to extract its metadata and relationships\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"Promise<FunctionAnalysis | null> - detailed function analysis or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves the full file path for a given file in the code analysis\",\n      \"inputs\": \"filePath (string), codeAnalysis (CodeAnalysis)\",\n      \"outputs\": \"string - resolved full file path\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions within large code files to support refactoring efforts. It solves the problem of understanding complex function relationships, dependencies, and responsibilities when developers need to break down or refactor large files. It bridges the gap between basic code analysis and actionable refactoring insights by extracting function-level metadata that can be used to generate intelligent refactoring suggestions.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VS Code that displays code analysis results including file statistics, functions, imports, and entry points.",
      "userVisibleActions": [
        "View a tree structure showing code analysis results organized by categories",
        "Browse file statistics (total files, lines of code, functions)",
        "Explore files grouped by directory in a hierarchical view",
        "See detailed information for each file including language, lines of code, and function count",
        "View list of all functions with their parameter counts and line numbers",
        "Browse import statements and dependencies for each file",
        "View entry points (main functions, test files, CLI tools) detected in the codebase",
        "Click on any item to navigate to the corresponding location in the source file",
        "See descriptive tooltips when hovering over items in the tree",
        "View 'No analysis available' message when analysis hasn't been run yet"
      ],
      "developerVisibleActions": [
        "Implements TreeDataProvider interface to render analysis results in VS Code sidebar",
        "Receives CodeAnalysis data structure and converts it into a navigable tree view",
        "Handles user clicks on tree items to open files at specific locations",
        "Provides refresh capability when new analysis results are available",
        "Groups files by directory structure for better organization",
        "Displays different icons and labels based on item type (file, function, import, etc.)",
        "Formats statistics and metrics for display (file counts, LOC, complexity)",
        "Creates clickable tree items with commands to navigate to source code locations"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the viewer with new analysis results and refreshes the tree view",
          "inputs": "CodeAnalysis object or null",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a refresh of the tree view to display updated data",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the tree item representation for VS Code to render",
          "inputs": "AnalysisItem element",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node to build the hierarchy",
          "inputs": "Optional AnalysisItem element (undefined for root)",
          "outputs": "Promise of AnalysisItem array"
        },
        {
          "name": "getRootItems",
          "desc": "Creates top-level tree items showing statistics, files, functions, and entry points categories",
          "inputs": "none",
          "outputs": "Array of AnalysisItem"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Generates tree items displaying code metrics like total files, LOC, and function counts",
          "inputs": "none",
          "outputs": "Array of AnalysisItem"
        },
        {
          "name": "getFilesItems",
          "desc": "Organizes files into directory groups for hierarchical browsing",
          "inputs": "none",
          "outputs": "Array of AnalysisItem representing directories and standalone files"
        },
        {
          "name": "getFileDetails",
          "desc": "Returns detailed information about a specific file including functions, imports, and exports",
          "inputs": "AnalysisItem representing a file",
          "outputs": "Promise of AnalysisItem array"
        },
        {
          "name": "getFunctionItems",
          "desc": "Creates tree items for all functions across the codebase with navigation links",
          "inputs": "none",
          "outputs": "Array of AnalysisItem"
        },
        {
          "name": "getEntryPointItems",
          "desc": "Lists detected entry points categorized by type (main, tests, CLI, etc.)",
          "inputs": "none",
          "outputs": "Array of AnalysisItem"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)"
      ],
      "intent": "This file exists to provide developers with a visual, interactive way to explore code analysis results within VS Code. It solves the problem of understanding large codebases by organizing analysis data into a browsable tree structure where users can quickly navigate to specific files, functions, or entry points, and understand code statistics and relationships at a glance.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VS Code that displays code analysis results including file statistics, functions, imports, and entry points.\",\n  \"userVisibleActions\": [\n    \"View a tree structure showing code analysis results organized by categories\",\n    \"Browse file statistics (total files, lines of code, functions)\",\n    \"Explore files grouped by directory in a hierarchical view\",\n    \"See detailed information for each file including language, lines of code, and function count\",\n    \"View list of all functions with their parameter counts and line numbers\",\n    \"Browse import statements and dependencies for each file\",\n    \"View entry points (main functions, test files, CLI tools) detected in the codebase\",\n    \"Click on any item to navigate to the corresponding location in the source file\",\n    \"See descriptive tooltips when hovering over items in the tree\",\n    \"View 'No analysis available' message when analysis hasn't been run yet\"\n  ],\n  \"developerVisibleActions\": [\n    \"Implements TreeDataProvider interface to render analysis results in VS Code sidebar\",\n    \"Receives CodeAnalysis data structure and converts it into a navigable tree view\",\n    \"Handles user clicks on tree items to open files at specific locations\",\n    \"Provides refresh capability when new analysis results are available\",\n    \"Groups files by directory structure for better organization\",\n    \"Displays different icons and labels based on item type (file, function, import, etc.)\",\n    \"Formats statistics and metrics for display (file counts, LOC, complexity)\",\n    \"Creates clickable tree items with commands to navigate to source code locations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the viewer with new analysis results and refreshes the tree view\",\n      \"inputs\": \"CodeAnalysis object or null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the tree view to display updated data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the tree item representation for VS Code to render\",\n      \"inputs\": \"AnalysisItem element\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node to build the hierarchy\",\n      \"inputs\": \"Optional AnalysisItem element (undefined for root)\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Creates top-level tree items showing statistics, files, functions, and entry points categories\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Generates tree items displaying code metrics like total files, LOC, and function counts\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Organizes files into directory groups for hierarchical browsing\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem representing directories and standalone files\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information about a specific file including functions, imports, and exports\",\n      \"inputs\": \"AnalysisItem representing a file\",\n      \"outputs\": \"Promise of AnalysisItem array\"\n    },\n    {\n      \"name\": \"getFunctionItems\",\n      \"desc\": \"Creates tree items for all functions across the codebase with navigation links\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    },\n    {\n      \"name\": \"getEntryPointItems\",\n      \"desc\": \"Lists detected entry points categorized by type (main, tests, CLI, etc.)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of AnalysisItem\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\"\n  ],\n  \"intent\": \"This file exists to provide developers with a visual, interactive way to explore code analysis results within VS Code. It solves the problem of understanding large codebases by organizing analysis data into a browsable tree structure where users can quickly navigate to specific files, functions, or entry points, and understand code statistics and relationships at a glance.\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Defines interfaces and structures for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.",
      "userVisibleActions": [
        "View total counts of files, lines, and functions in their codebase",
        "See which files are large and may need refactoring",
        "Identify orphaned files that aren't imported anywhere",
        "Discover entry points in the application",
        "Find duplicate code blocks across the codebase",
        "Understand function risk levels (high, medium, low)",
        "See which functions lack test coverage"
      ],
      "developerVisibleActions": [
        "Access structured analysis data through TypeScript interfaces",
        "Query file information including path, lines, size, and role",
        "Inspect function metadata including parameters, return types, and visibility",
        "Examine control flow branches (if, loops, try-catch) in functions",
        "Track dependencies (database, HTTP, filesystem, etc.) used by functions",
        "Analyze state mutations (assignments, modifications) in code",
        "Map test files to source files and functions",
        "Identify uncovered functions and lines in test coverage",
        "Find import relationships between files",
        "Use caching mechanism for performance optimization"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main analysis result container with file counts, function metadata, dependencies, and test coverage",
          "inputs": "N/A (interface)",
          "outputs": "Structured data including totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping"
        },
        {
          "name": "FunctionMetadata",
          "desc": "Detailed information about a function including parameters, branches, dependencies, and risk level",
          "inputs": "N/A (interface)",
          "outputs": "Function name, parameters with types, return type, visibility, branches, dependencies, state mutations, risk assessment"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source files and functions to their test coverage",
          "inputs": "N/A (interface)",
          "outputs": "Source-to-test file mappings, function-to-test mappings, list of uncovered functions"
        },
        {
          "name": "DependencyInfo",
          "desc": "Identifies external dependencies like databases, HTTP calls, filesystem operations",
          "inputs": "N/A (interface)",
          "outputs": "Dependency name, type (db/http/filesystem/etc), whether internal or external, line number"
        },
        {
          "name": "EntryPoint",
          "desc": "Identifies application entry points and their types",
          "inputs": "N/A (interface)",
          "outputs": "File path, entry point type (main/cli/api/config/test), function name, description"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache"
      ],
      "intent": "This file provides the type system and data structures for representing comprehensive code analysis results. It enables developers to work with structured information about code quality, test coverage, dependencies, and architectural patterns. The interfaces support both basic metrics (file counts, function counts) and advanced analysis (control flow branches, state mutations, risk assessment, duplicate detection) to help developers understand and improve their codebase.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines interfaces and structures for code analysis results, including file metadata, function information, dependencies, test mappings, and code quality metrics.\",\n  \"userVisibleActions\": [\n    \"View total counts of files, lines, and functions in their codebase\",\n    \"See which files are large and may need refactoring\",\n    \"Identify orphaned files that aren't imported anywhere\",\n    \"Discover entry points in the application\",\n    \"Find duplicate code blocks across the codebase\",\n    \"Understand function risk levels (high, medium, low)\",\n    \"See which functions lack test coverage\"\n  ],\n  \"developerVisibleActions\": [\n    \"Access structured analysis data through TypeScript interfaces\",\n    \"Query file information including path, lines, size, and role\",\n    \"Inspect function metadata including parameters, return types, and visibility\",\n    \"Examine control flow branches (if, loops, try-catch) in functions\",\n    \"Track dependencies (database, HTTP, filesystem, etc.) used by functions\",\n    \"Analyze state mutations (assignments, modifications) in code\",\n    \"Map test files to source files and functions\",\n    \"Identify uncovered functions and lines in test coverage\",\n    \"Find import relationships between files\",\n    \"Use caching mechanism for performance optimization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main analysis result container with file counts, function metadata, dependencies, and test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Structured data including totalFiles, totalLines, functions, imports, orphanedFiles, duplicates, testMapping\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Detailed information about a function including parameters, branches, dependencies, and risk level\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Function name, parameters with types, return type, visibility, branches, dependencies, state mutations, risk assessment\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source files and functions to their test coverage\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Source-to-test file mappings, function-to-test mappings, list of uncovered functions\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Identifies external dependencies like databases, HTTP calls, filesystem operations\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"Dependency name, type (db/http/filesystem/etc), whether internal or external, line number\"\n    },\n    {\n      \"name\": \"EntryPoint\",\n      \"desc\": \"Identifies application entry points and their types\",\n      \"inputs\": \"N/A (interface)\",\n      \"outputs\": \"File path, entry point type (main/cli/api/config/test), function name, description\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file provides the type system and data structures for representing comprehensive code analysis results. It enables developers to work with structured information about code quality, test coverage, dependencies, and architectural patterns. The interfaces support both basic metrics (file counts, function counts) and advanced analysis (control flow branches, state mutations, risk assessment, duplicate detection) to help developers understand and improve their codebase.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent caching of code analysis results to improve performance and avoid redundant analysis",
      "userVisibleActions": [
        "Faster project loading when reopening a workspace (analysis loads from cache instead of re-analyzing)",
        "Automatic cache expiration after 24 hours ensures fresh analysis",
        "Cache clearing capability to force fresh analysis when needed"
      ],
      "developerVisibleActions": [
        "Code analysis results are automatically saved to disk after initial analysis",
        "Cached analysis is retrieved on subsequent workspace opens if still valid",
        "Cache files are stored in a hidden .shadowwatch-cache directory",
        "Cache automatically invalidates after 24 hours to prevent stale data",
        "Cache can be manually cleared to force fresh analysis",
        "Cache keys are derived from workspace paths to isolate different projects"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes cache system with storage location and creates cache directory",
          "inputs": "storagePath: string - where to store cache files",
          "outputs": "AnalysisCache instance"
        },
        {
          "name": "get",
          "desc": "Retrieves cached analysis for a workspace if available and not expired",
          "inputs": "workspaceRoot: string - path to workspace",
          "outputs": "Promise<CodeAnalysis | null> - cached analysis or null if not found/expired"
        },
        {
          "name": "set",
          "desc": "Saves analysis results to cache with current timestamp",
          "inputs": "workspaceRoot: string, data: CodeAnalysis - workspace path and analysis to cache",
          "outputs": "Promise<void>"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis files from the cache directory",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "getCacheKey",
          "desc": "Generates a safe filesystem-compatible cache key from workspace path",
          "inputs": "workspaceRoot: string - workspace path",
          "outputs": "string - base64 encoded safe filename"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "Eliminates the need to re-analyze large codebases every time VSCode starts by persistently storing analysis results on disk with automatic expiration to balance performance and freshness",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent caching of code analysis results to improve performance and avoid redundant analysis\",\n  \"userVisibleActions\": [\n    \"Faster project loading when reopening a workspace (analysis loads from cache instead of re-analyzing)\",\n    \"Automatic cache expiration after 24 hours ensures fresh analysis\",\n    \"Cache clearing capability to force fresh analysis when needed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Code analysis results are automatically saved to disk after initial analysis\",\n    \"Cached analysis is retrieved on subsequent workspace opens if still valid\",\n    \"Cache files are stored in a hidden .shadowwatch-cache directory\",\n    \"Cache automatically invalidates after 24 hours to prevent stale data\",\n    \"Cache can be manually cleared to force fresh analysis\",\n    \"Cache keys are derived from workspace paths to isolate different projects\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache system with storage location and creates cache directory\",\n      \"inputs\": \"storagePath: string - where to store cache files\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis for a workspace if available and not expired\",\n      \"inputs\": \"workspaceRoot: string - path to workspace\",\n      \"outputs\": \"Promise<CodeAnalysis | null> - cached analysis or null if not found/expired\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with current timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis - workspace path and analysis to cache\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis files from the cache directory\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filesystem-compatible cache key from workspace path\",\n      \"inputs\": \"workspaceRoot: string - workspace path\",\n      \"outputs\": \"string - base64 encoded safe filename\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Eliminates the need to re-analyze large codebases every time VSCode starts by persistently storing analysis results on disk with automatic expiration to balance performance and freshness\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes occur.",
      "userVisibleActions": [
        "User enables or disables Shadow Watch extension",
        "User toggles analyze-on-save functionality",
        "User shows or hides inline hints in the editor",
        "User configures which LLM provider to use (OpenAI or Claude)",
        "User selects output format for LLM results (Cursor, ChatGPT, Generic, or Compact)",
        "User sets minimum severity threshold for displayed issues (error, warning, or info)",
        "User configures API keys and endpoints for LLM services",
        "User adjusts analysis settings like batch size and concurrency limits"
      ],
      "developerVisibleActions": [
        "Developer accesses centralized configuration properties through type-safe getters",
        "Developer registers callbacks to respond when settings change",
        "Developer validates configuration to ensure required settings are present",
        "Developer queries specific configuration sections without directly accessing VSCode API",
        "Configuration automatically reloads when user modifies settings in VSCode preferences"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes configuration manager and sets up automatic configuration change detection",
          "inputs": "none",
          "outputs": "ConfigurationManager instance"
        },
        {
          "name": "onConfigurationChange",
          "desc": "Registers a callback function to be notified when any Shadow Watch configuration changes",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Unregisters a previously registered configuration change callback",
          "inputs": "callback function",
          "outputs": "void"
        },
        {
          "name": "enabled (getter)",
          "desc": "Returns whether Shadow Watch extension is currently enabled",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave (getter)",
          "desc": "Returns whether automatic analysis should run when files are saved",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "showInlineHints (getter)",
          "desc": "Returns whether inline hints should be displayed in the editor",
          "inputs": "none",
          "outputs": "boolean"
        },
        {
          "name": "llmProvider (getter)",
          "desc": "Returns the selected LLM provider (OpenAI or Claude)",
          "inputs": "none",
          "outputs": "LLMProvider type"
        },
        {
          "name": "llmFormat (getter)",
          "desc": "Returns the selected output format for LLM analysis results",
          "inputs": "none",
          "outputs": "LLMFormat type"
        },
        {
          "name": "severityThreshold (getter)",
          "desc": "Returns the minimum severity level for displaying issues",
          "inputs": "none",
          "outputs": "SeverityThreshold type"
        },
        {
          "name": "validate",
          "desc": "Checks if the current configuration is valid and returns any errors found",
          "inputs": "none",
          "outputs": "ConfigValidationResult with valid flag and error list"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to provide a single source of truth for all Shadow Watch configuration settings, eliminating the need for components to directly access VSCode's configuration API and ensuring type safety throughout the extension. It solves the problem of scattered configuration access and makes it easy to react to configuration changes across the entire extension.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes occur.\",\n  \"userVisibleActions\": [\n    \"User enables or disables Shadow Watch extension\",\n    \"User toggles analyze-on-save functionality\",\n    \"User shows or hides inline hints in the editor\",\n    \"User configures which LLM provider to use (OpenAI or Claude)\",\n    \"User selects output format for LLM results (Cursor, ChatGPT, Generic, or Compact)\",\n    \"User sets minimum severity threshold for displayed issues (error, warning, or info)\",\n    \"User configures API keys and endpoints for LLM services\",\n    \"User adjusts analysis settings like batch size and concurrency limits\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer accesses centralized configuration properties through type-safe getters\",\n    \"Developer registers callbacks to respond when settings change\",\n    \"Developer validates configuration to ensure required settings are present\",\n    \"Developer queries specific configuration sections without directly accessing VSCode API\",\n    \"Configuration automatically reloads when user modifies settings in VSCode preferences\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes configuration manager and sets up automatic configuration change detection\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigurationManager instance\"\n    },\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be notified when any Shadow Watch configuration changes\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback function\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled (getter)\",\n      \"desc\": \"Returns whether Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave (getter)\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints (getter)\",\n      \"desc\": \"Returns whether inline hints should be displayed in the editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"llmProvider (getter)\",\n      \"desc\": \"Returns the selected LLM provider (OpenAI or Claude)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMProvider type\"\n    },\n    {\n      \"name\": \"llmFormat (getter)\",\n      \"desc\": \"Returns the selected output format for LLM analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"LLMFormat type\"\n    },\n    {\n      \"name\": \"severityThreshold (getter)\",\n      \"desc\": \"Returns the minimum severity level for displaying issues\",\n      \"inputs\": \"none\",\n      \"outputs\": \"SeverityThreshold type\"\n    },\n    {\n      \"name\": \"validate\",\n      \"desc\": \"Checks if the current configuration is valid and returns any errors found\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ConfigValidationResult with valid flag and error list\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single source of truth for all Shadow Watch configuration settings, eliminating the need for components to directly access VSCode's configuration API and ensuring type safety throughout the extension. It solves the problem of scattered configuration access and makes it easy to react to configuration changes across the entire extension.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis results into a structured format for LLM consumption and saves them to disk for documentation and future reference",
      "userVisibleActions": [
        "Code analysis results are automatically saved to the .shadow/docs directory in the workspace",
        "Analysis results include file statistics, entry points, and import relationships",
        "Analysis snapshots are timestamped for tracking when documentation was generated"
      ],
      "developerVisibleActions": [
        "Call convertCodeAnalysisToContext() to transform CodeAnalysis into AnalysisContext format suitable for LLM processing",
        "Call saveCodeAnalysis() to persist analysis results to .shadow/docs/code-analysis.json",
        "Analysis data is structured with metadata including generation timestamps",
        "Files are automatically organized into .shadow/docs directory structure"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms CodeAnalysis format into AnalysisContext format for LLM service consumption",
          "inputs": "analysis: CodeAnalysis object containing files, imports, entry points, and statistics",
          "outputs": "AnalysisContext object with formatted file data, imports, entry points, orphaned files, and code metrics"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis results to disk in JSON format with metadata",
          "inputs": "analysis: CodeAnalysis object to save",
          "outputs": "void (creates .shadow/docs/code-analysis.json file)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between code analysis results and LLM documentation generation by converting analysis data into a consumable format and persisting it for documentation purposes. It solves the problem of making codebase analysis results accessible to both AI services and developers, while maintaining a historical record of project structure over time.",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis results into a structured format for LLM consumption and saves them to disk for documentation and future reference\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to the .shadow/docs directory in the workspace\",\n    \"Analysis results include file statistics, entry points, and import relationships\",\n    \"Analysis snapshots are timestamped for tracking when documentation was generated\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call convertCodeAnalysisToContext() to transform CodeAnalysis into AnalysisContext format suitable for LLM processing\",\n    \"Call saveCodeAnalysis() to persist analysis results to .shadow/docs/code-analysis.json\",\n    \"Analysis data is structured with metadata including generation timestamps\",\n    \"Files are automatically organized into .shadow/docs directory structure\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis format into AnalysisContext format for LLM service consumption\",\n      \"inputs\": \"analysis: CodeAnalysis object containing files, imports, entry points, and statistics\",\n      \"outputs\": \"AnalysisContext object with formatted file data, imports, entry points, orphaned files, and code metrics\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis results to disk in JSON format with metadata\",\n      \"inputs\": \"analysis: CodeAnalysis object to save\",\n      \"outputs\": \"void (creates .shadow/docs/code-analysis.json file)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis results and LLM documentation generation by converting analysis data into a consumable format and persisting it for documentation purposes. It solves the problem of making codebase analysis results accessible to both AI services and developers, while maintaining a historical record of project structure over time.\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Manages and displays code insights as inline diagnostics (warnings, errors, info) in the VS Code editor",
      "userVisibleActions": [
        "Sees inline diagnostics (squiggly underlines) in code files where insights are detected",
        "Hovers over diagnostics to see insight descriptions and severity levels",
        "Views diagnostics in the Problems panel organized by file",
        "Sees diagnostics labeled as 'Shadow Watch' with unique insight IDs",
        "Diagnostics automatically clear and refresh when insights update"
      ],
      "developerVisibleActions": [
        "Creates a diagnostic collection named 'shadowWatch' for the extension",
        "Converts insight objects into VS Code diagnostic objects that appear in the editor",
        "Groups insights by file path and applies them to the correct documents",
        "Maps insight severity levels to VS Code diagnostic severities (Error, Warning, Information, Hint)",
        "Clears all diagnostics when requested or when disposing the provider",
        "Updates diagnostics for all files or specific files based on insight data"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Takes a list of insights and displays them as diagnostics across all affected files",
          "inputs": "Array of Insight objects",
          "outputs": "void (updates VS Code UI)"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostics for a specific file URI",
          "inputs": "VS Code URI and array of Insight objects",
          "outputs": "void (updates VS Code UI)"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostics from all files",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts a single insight into a VS Code diagnostic object",
          "inputs": "Insight object",
          "outputs": "VS Code Diagnostic object"
        },
        {
          "name": "getSeverity",
          "desc": "Maps insight severity to VS Code diagnostic severity level",
          "inputs": "Severity string from insight",
          "outputs": "VS Code DiagnosticSeverity enum"
        },
        {
          "name": "dispose",
          "desc": "Cleans up the diagnostic collection when extension deactivates",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "Provides a bridge between the extension's insight generation system and VS Code's native diagnostics UI, allowing code analysis results to be displayed as familiar inline problems that users see in their editor and Problems panel",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages and displays code insights as inline diagnostics (warnings, errors, info) in the VS Code editor\",\n  \"userVisibleActions\": [\n    \"Sees inline diagnostics (squiggly underlines) in code files where insights are detected\",\n    \"Hovers over diagnostics to see insight descriptions and severity levels\",\n    \"Views diagnostics in the Problems panel organized by file\",\n    \"Sees diagnostics labeled as 'Shadow Watch' with unique insight IDs\",\n    \"Diagnostics automatically clear and refresh when insights update\"\n  ],\n  \"developerVisibleActions\": [\n    \"Creates a diagnostic collection named 'shadowWatch' for the extension\",\n    \"Converts insight objects into VS Code diagnostic objects that appear in the editor\",\n    \"Groups insights by file path and applies them to the correct documents\",\n    \"Maps insight severity levels to VS Code diagnostic severities (Error, Warning, Information, Hint)\",\n    \"Clears all diagnostics when requested or when disposing the provider\",\n    \"Updates diagnostics for all files or specific files based on insight data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Takes a list of insights and displays them as diagnostics across all affected files\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void (updates VS Code UI)\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a specific file URI\",\n      \"inputs\": \"VS Code URI and array of Insight objects\",\n      \"outputs\": \"void (updates VS Code UI)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from all files\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts a single insight into a VS Code diagnostic object\",\n      \"inputs\": \"Insight object\",\n      \"outputs\": \"VS Code Diagnostic object\"\n    },\n    {\n      \"name\": \"getSeverity\",\n      \"desc\": \"Maps insight severity to VS Code diagnostic severity level\",\n      \"inputs\": \"Severity string from insight\",\n      \"outputs\": \"VS Code DiagnosticSeverity enum\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up the diagnostic collection when extension deactivates\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Provides a bridge between the extension's insight generation system and VS Code's native diagnostics UI, allowing code analysis results to be displayed as familiar inline problems that users see in their editor and Problems panel\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers and manages all VS Code commands that users and developers can trigger in the extension",
      "userVisibleActions": [
        "Analyze entire workspace to get code insights",
        "Analyze currently open file",
        "Copy all insights to clipboard",
        "Copy insights for specific file",
        "Copy individual insight",
        "Clear cached analysis data",
        "Clear all extension data",
        "Open extension settings",
        "Open latest analysis report",
        "Open latest unit test report",
        "Switch between different LLM providers",
        "Copy menu structure",
        "View current provider status",
        "Navigate to product items in codebase",
        "Navigate to analysis items",
        "Show detailed information for product items",
        "Show detailed information for insights",
        "Show detailed information for unit test items"
      ],
      "developerVisibleActions": [
        "Command handlers are registered and bound to VS Code command palette",
        "All commands are centrally managed in one registry",
        "Extension components are wired to command handlers",
        "Commands integrate with code analyzer, insight generator, diagnostics provider, and LLM services",
        "Command execution triggers analysis workflows and UI updates",
        "Configuration manager controls command behavior"
      ],
      "keyFunctions": [
        {
          "name": "register",
          "desc": "Registers all extension commands with VS Code and creates command handlers",
          "inputs": "VS Code extension context and extension components",
          "outputs": "Command handlers object for all registered commands"
        },
        {
          "name": "CommandHandlers interface",
          "desc": "Defines all available command handler functions in the extension",
          "inputs": "Various - depends on specific command (workspace, files, items)",
          "outputs": "Promise<void> for async operations"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "Centralizes command registration logic to separate concerns from main extension activation, making all user-facing actions discoverable and maintainable in one place while wiring together various extension components to execute those actions",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers and manages all VS Code commands that users and developers can trigger in the extension\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace to get code insights\",\n    \"Analyze currently open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy insights for specific file\",\n    \"Copy individual insight\",\n    \"Clear cached analysis data\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"Open latest analysis report\",\n    \"Open latest unit test report\",\n    \"Switch between different LLM providers\",\n    \"Copy menu structure\",\n    \"View current provider status\",\n    \"Navigate to product items in codebase\",\n    \"Navigate to analysis items\",\n    \"Show detailed information for product items\",\n    \"Show detailed information for insights\",\n    \"Show detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Command handlers are registered and bound to VS Code command palette\",\n    \"All commands are centrally managed in one registry\",\n    \"Extension components are wired to command handlers\",\n    \"Commands integrate with code analyzer, insight generator, diagnostics provider, and LLM services\",\n    \"Command execution triggers analysis workflows and UI updates\",\n    \"Configuration manager controls command behavior\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all extension commands with VS Code and creates command handlers\",\n      \"inputs\": \"VS Code extension context and extension components\",\n      \"outputs\": \"Command handlers object for all registered commands\"\n    },\n    {\n      \"name\": \"CommandHandlers interface\",\n      \"desc\": \"Defines all available command handler functions in the extension\",\n      \"inputs\": \"Various - depends on specific command (workspace, files, items)\",\n      \"outputs\": \"Promise<void> for async operations\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"Centralizes command registration logic to separate concerns from main extension activation, making all user-facing actions discoverable and maintainable in one place while wiring together various extension components to execute those actions\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Initializes and wires together all VS Code extension components during activation, setting up analyzers, viewers, providers, and event handlers",
      "userVisibleActions": [
        "Extension activates and displays status bar item showing analysis state",
        "Tree views appear in sidebar (Insights, Analysis, Product Navigator, Unit Tests, Reports)",
        "File changes trigger automatic re-analysis with visual feedback",
        "Diagnostics appear in Problems panel for code issues",
        "Status bar shows current analysis or generation status",
        "Reports viewer displays generated analysis reports",
        "Product Navigator shows navigable code structure",
        "Static analysis results appear in dedicated viewer"
      ],
      "developerVisibleActions": [
        "Extension registers all commands during activation",
        "Sets up file watchers for automatic analysis on code changes",
        "Initializes LLM integration for code analysis",
        "Creates and registers tree view providers for different views",
        "Establishes diagnostics collection for problem reporting",
        "Configures caching system for analysis results",
        "Wires event handlers for configuration changes",
        "Manages state across extension lifecycle"
      ],
      "keyFunctions": [
        {
          "name": "bootstrap",
          "desc": "Main entry point that initializes all extension components and returns them as a structured object",
          "inputs": "context: vscode.ExtensionContext (VS Code extension context)",
          "outputs": "ExtensionComponents (object containing all initialized extension components)"
        },
        {
          "name": "createAnalyzer",
          "desc": "Creates and configures the code analyzer component",
          "inputs": "context",
          "outputs": "CodeAnalyzer instance"
        },
        {
          "name": "createInsightGenerator",
          "desc": "Creates the insight generator for producing code insights",
          "inputs": "context",
          "outputs": "InsightGenerator instance"
        },
        {
          "name": "createFileWatcher",
          "desc": "Sets up file watching to detect code changes and trigger re-analysis",
          "inputs": "context, analyzer",
          "outputs": "FileWatcher instance"
        },
        {
          "name": "createTreeProviders",
          "desc": "Initializes all tree view providers for different UI panels",
          "inputs": "context, components",
          "outputs": "Object containing tree providers and tree views"
        },
        {
          "name": "createStatusBarItem",
          "desc": "Creates the status bar indicator showing extension state",
          "inputs": "none",
          "outputs": "vscode.StatusBarItem"
        },
        {
          "name": "registerCommands",
          "desc": "Registers all VS Code commands provided by the extension",
          "inputs": "context, components",
          "outputs": "void"
        },
        {
          "name": "setupEventHandlers",
          "desc": "Configures event listeners for configuration changes and other events",
          "inputs": "context, components",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "FileWatcher",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "llmIntegration",
        "ProductNavigatorProvider",
        "AnalysisViewerProvider",
        "InsightsViewerProvider",
        "StaticAnalysisViewerProvider",
        "UnitTestsNavigatorProvider",
        "configurationManager",
        "ErrorHandler",
        "FileWatcherService",
        "ReportsViewer",
        "ReportsTreeProvider",
        "llmStateManager"
      ],
      "intent": "This file exists to separate and centralize the complex initialization logic required when the VS Code extension activates. It solves the problem of managing dependencies between multiple components, ensuring they are created in the correct order, properly wired together, and all UI elements, commands, and event handlers are registered. This modular approach makes the extension's activation process maintainable and testable by extracting it from the main extension.ts file.",
      "rawContent": "```json\n{\n  \"purpose\": \"Initializes and wires together all VS Code extension components during activation, setting up analyzers, viewers, providers, and event handlers\",\n  \"userVisibleActions\": [\n    \"Extension activates and displays status bar item showing analysis state\",\n    \"Tree views appear in sidebar (Insights, Analysis, Product Navigator, Unit Tests, Reports)\",\n    \"File changes trigger automatic re-analysis with visual feedback\",\n    \"Diagnostics appear in Problems panel for code issues\",\n    \"Status bar shows current analysis or generation status\",\n    \"Reports viewer displays generated analysis reports\",\n    \"Product Navigator shows navigable code structure\",\n    \"Static analysis results appear in dedicated viewer\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension registers all commands during activation\",\n    \"Sets up file watchers for automatic analysis on code changes\",\n    \"Initializes LLM integration for code analysis\",\n    \"Creates and registers tree view providers for different views\",\n    \"Establishes diagnostics collection for problem reporting\",\n    \"Configures caching system for analysis results\",\n    \"Wires event handlers for configuration changes\",\n    \"Manages state across extension lifecycle\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"bootstrap\",\n      \"desc\": \"Main entry point that initializes all extension components and returns them as a structured object\",\n      \"inputs\": \"context: vscode.ExtensionContext (VS Code extension context)\",\n      \"outputs\": \"ExtensionComponents (object containing all initialized extension components)\"\n    },\n    {\n      \"name\": \"createAnalyzer\",\n      \"desc\": \"Creates and configures the code analyzer component\",\n      \"inputs\": \"context\",\n      \"outputs\": \"CodeAnalyzer instance\"\n    },\n    {\n      \"name\": \"createInsightGenerator\",\n      \"desc\": \"Creates the insight generator for producing code insights\",\n      \"inputs\": \"context\",\n      \"outputs\": \"InsightGenerator instance\"\n    },\n    {\n      \"name\": \"createFileWatcher\",\n      \"desc\": \"Sets up file watching to detect code changes and trigger re-analysis\",\n      \"inputs\": \"context, analyzer\",\n      \"outputs\": \"FileWatcher instance\"\n    },\n    {\n      \"name\": \"createTreeProviders\",\n      \"desc\": \"Initializes all tree view providers for different UI panels\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"Object containing tree providers and tree views\"\n    },\n    {\n      \"name\": \"createStatusBarItem\",\n      \"desc\": \"Creates the status bar indicator showing extension state\",\n      \"inputs\": \"none\",\n      \"outputs\": \"vscode.StatusBarItem\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VS Code commands provided by the extension\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupEventHandlers\",\n      \"desc\": \"Configures event listeners for configuration changes and other events\",\n      \"inputs\": \"context, components\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"FileWatcher\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"llmIntegration\",\n    \"ProductNavigatorProvider\",\n    \"AnalysisViewerProvider\",\n    \"InsightsViewerProvider\",\n    \"StaticAnalysisViewerProvider\",\n    \"UnitTestsNavigatorProvider\",\n    \"configurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\",\n    \"ReportsViewer\",\n    \"ReportsTreeProvider\",\n    \"llmStateManager\"\n  ],\n  \"intent\": \"This file exists to separate and centralize the complex initialization logic required when the VS Code extension activates. It solves the problem of managing dependencies between multiple components, ensuring they are created in the correct order, properly wired together, and all UI elements, commands, and event handlers are registered. This modular approach makes the extension's activation process maintainable and testable by extracting it from the main extension.ts file.\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and AI insights into human-readable Markdown format for display and export.",
      "userVisibleActions": [
        "View generated product documentation in Markdown format with timestamp",
        "See structured sections including Product Overview, What It Does, and User Perspective",
        "Read GUI, CLI, and API usage information organized by interface type",
        "View technical architecture documentation with structure and patterns",
        "See integration details and external dependencies",
        "Review AI-generated insights about the codebase in organized sections",
        "Read architecture overview with quality assessment",
        "See design patterns, security considerations, and scalability notes",
        "View suggested improvements and optimization opportunities",
        "Export documentation as formatted Markdown files"
      ],
      "developerVisibleActions": [
        "Call formatEnhancedDocsAsMarkdown() to convert product documentation objects to Markdown",
        "Call formatInsightsAsMarkdown() to convert AI insights objects to Markdown",
        "Pass EnhancedProductDocumentation objects to get formatted output",
        "Pass LLMInsights objects to get structured analysis output",
        "Receive Markdown strings that can be displayed or saved to files",
        "Generate timestamped documentation with both UTC and local time",
        "Create consistent documentation structure across different data types"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation object into formatted Markdown with sections for overview, features, user perspective, architecture, and integrations",
          "inputs": "EnhancedProductDocumentation object containing product details",
          "outputs": "Markdown-formatted string with hierarchical documentation structure"
        },
        {
          "name": "formatInsightsAsMarkdown",
          "desc": "Converts AI-generated insights into formatted Markdown with sections for architecture, design patterns, security, scalability, and improvements",
          "inputs": "LLMInsights object containing AI analysis results",
          "outputs": "Markdown-formatted string with structured insights and recommendations"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "This file exists to separate documentation formatting logic from business logic, providing a dedicated formatter that converts structured data objects into human-readable Markdown documentation with consistent formatting, timestamps, and hierarchical organization for both product documentation and AI insights.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and AI insights into human-readable Markdown format for display and export.\",\n  \"userVisibleActions\": [\n    \"View generated product documentation in Markdown format with timestamp\",\n    \"See structured sections including Product Overview, What It Does, and User Perspective\",\n    \"Read GUI, CLI, and API usage information organized by interface type\",\n    \"View technical architecture documentation with structure and patterns\",\n    \"See integration details and external dependencies\",\n    \"Review AI-generated insights about the codebase in organized sections\",\n    \"Read architecture overview with quality assessment\",\n    \"See design patterns, security considerations, and scalability notes\",\n    \"View suggested improvements and optimization opportunities\",\n    \"Export documentation as formatted Markdown files\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatEnhancedDocsAsMarkdown() to convert product documentation objects to Markdown\",\n    \"Call formatInsightsAsMarkdown() to convert AI insights objects to Markdown\",\n    \"Pass EnhancedProductDocumentation objects to get formatted output\",\n    \"Pass LLMInsights objects to get structured analysis output\",\n    \"Receive Markdown strings that can be displayed or saved to files\",\n    \"Generate timestamped documentation with both UTC and local time\",\n    \"Create consistent documentation structure across different data types\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into formatted Markdown with sections for overview, features, user perspective, architecture, and integrations\",\n      \"inputs\": \"EnhancedProductDocumentation object containing product details\",\n      \"outputs\": \"Markdown-formatted string with hierarchical documentation structure\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts AI-generated insights into formatted Markdown with sections for architecture, design patterns, security, scalability, and improvements\",\n      \"inputs\": \"LLMInsights object containing AI analysis results\",\n      \"outputs\": \"Markdown-formatted string with structured insights and recommendations\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"This file exists to separate documentation formatting logic from business logic, providing a dedicated formatter that converts structured data objects into human-readable Markdown documentation with consistent formatting, timestamps, and hierarchical organization for both product documentation and AI insights.\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation to files, functions, endpoints, and other code locations when users interact with the product navigator and analysis viewer.",
      "userVisibleActions": [
        "Opens files in the editor when clicking on file items in the navigator",
        "Jumps to specific functions within files and highlights the function location",
        "Navigates to API endpoints and displays their location in code",
        "Shows error messages when files cannot be opened or locations cannot be found",
        "Displays code previews and details for selected items",
        "Navigates to entry points and highlights their definitions",
        "Opens and positions cursor at specific line numbers in files"
      ],
      "developerVisibleActions": [
        "Resolves relative and absolute file paths within the workspace",
        "Searches for function definitions within opened documents",
        "Handles navigation from ProductNavItem and AnalysisItem structures",
        "Manages editor focus and cursor positioning after navigation",
        "Converts between different item types (product items, analysis items, entry points)",
        "Provides error handling and user feedback for failed navigation attempts",
        "Supports navigation to various item types: files, functions, endpoints, classes, methods"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Navigates to a product navigation item (file, function, endpoint)",
          "inputs": "ProductNavItem containing file path, function name, and type information",
          "outputs": "Promise<void> - opens document and positions cursor"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to an analysis viewer item",
          "inputs": "AnalysisItem with file and location details",
          "outputs": "Promise<void> - opens document at specified location"
        },
        {
          "name": "navigateToEntryPoint",
          "desc": "Navigates to an entry point definition",
          "inputs": "EntryPoint with file path and position information",
          "outputs": "Promise<void> - opens file and highlights entry point"
        },
        {
          "name": "showItemDetails",
          "desc": "Displays detailed information about a selected item",
          "inputs": "Item object with metadata and description",
          "outputs": "void - shows details panel or quick pick with information"
        },
        {
          "name": "findFunctionInDocument",
          "desc": "Searches for a function definition within an open document",
          "inputs": "TextDocument and function name string",
          "outputs": "Position or Range where function is located, or undefined if not found"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "productNavigator",
        "analysisViewer",
        "analyzer"
      ],
      "intent": "Separates navigation concerns from the main extension code, providing a centralized handler for all file and code location navigation triggered by user interactions with the product navigator and analysis viewer trees. Solves the problem of scattered navigation logic by consolidating it into a single, testable module.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations when users interact with the product navigator and analysis viewer.\",\n  \"userVisibleActions\": [\n    \"Opens files in the editor when clicking on file items in the navigator\",\n    \"Jumps to specific functions within files and highlights the function location\",\n    \"Navigates to API endpoints and displays their location in code\",\n    \"Shows error messages when files cannot be opened or locations cannot be found\",\n    \"Displays code previews and details for selected items\",\n    \"Navigates to entry points and highlights their definitions\",\n    \"Opens and positions cursor at specific line numbers in files\"\n  ],\n  \"developerVisibleActions\": [\n    \"Resolves relative and absolute file paths within the workspace\",\n    \"Searches for function definitions within opened documents\",\n    \"Handles navigation from ProductNavItem and AnalysisItem structures\",\n    \"Manages editor focus and cursor positioning after navigation\",\n    \"Converts between different item types (product items, analysis items, entry points)\",\n    \"Provides error handling and user feedback for failed navigation attempts\",\n    \"Supports navigation to various item types: files, functions, endpoints, classes, methods\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Navigates to a product navigation item (file, function, endpoint)\",\n      \"inputs\": \"ProductNavItem containing file path, function name, and type information\",\n      \"outputs\": \"Promise<void> - opens document and positions cursor\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to an analysis viewer item\",\n      \"inputs\": \"AnalysisItem with file and location details\",\n      \"outputs\": \"Promise<void> - opens document at specified location\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Navigates to an entry point definition\",\n      \"inputs\": \"EntryPoint with file path and position information\",\n      \"outputs\": \"Promise<void> - opens file and highlights entry point\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a selected item\",\n      \"inputs\": \"Item object with metadata and description\",\n      \"outputs\": \"void - shows details panel or quick pick with information\"\n    },\n    {\n      \"name\": \"findFunctionInDocument\",\n      \"desc\": \"Searches for a function definition within an open document\",\n      \"inputs\": \"TextDocument and function name string\",\n      \"outputs\": \"Position or Range where function is located, or undefined if not found\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"analyzer\"\n  ],\n  \"intent\": \"Separates navigation concerns from the main extension code, providing a centralized handler for all file and code location navigation triggered by user interactions with the product navigator and analysis viewer trees. Solves the problem of scattered navigation logic by consolidating it into a single, testable module.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralized prompt construction system that builds structured prompts for all LLM analysis tasks including architecture analysis, documentation generation, test planning, and code generation.",
      "userVisibleActions": [
        "Receives more accurate and consistent AI-generated architecture analysis",
        "Gets better quality product documentation from AI analysis",
        "Obtains more relevant test plans and test code generation",
        "Experiences improved AI understanding of code context and purpose"
      ],
      "developerVisibleActions": [
        "Provides standardized interface for building prompts across all LLM operations",
        "Constructs architecture analysis prompts with code context and documentation",
        "Generates prompts for product documentation and purpose analysis",
        "Creates prompts for file-level code analysis with role information",
        "Builds module rollup prompts for aggregating file summaries",
        "Produces product-level summary prompts combining multiple analysis layers",
        "Generates test planning prompts per file with function metadata",
        "Creates test code generation prompts with source and function context",
        "Eliminates duplicate prompt construction logic across the codebase",
        "Ensures consistent prompt structure and quality across all AI interactions"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Constructs prompt for analyzing codebase architecture",
          "inputs": "context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Builds prompt for generating product documentation",
          "inputs": "context (AnalysisContext)",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Creates prompt for analyzing product purpose and goals",
          "inputs": "productDocs (EnhancedProductDocumentation), context (AnalysisContext)",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Generates prompt for analyzing individual code files",
          "inputs": "file (FileInfo), content (string), role (string)",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Constructs prompt for rolling up file summaries into module summaries",
          "inputs": "modulePath (string), moduleType (string), files (FileSummary[])",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Builds comprehensive prompt for product-level analysis",
          "inputs": "fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Creates prompt for generating test plans for specific files",
          "inputs": "filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary",
          "outputs": "Formatted string prompt for LLM"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Generates prompt for creating actual test code",
          "inputs": "testPlanItem, sourceCode, functionCode, language, testFramework",
          "outputs": "Formatted string prompt for LLM"
        }
      ],
      "dependencies": [
        "../../llmService",
        "../../analyzer",
        "../../fileDocumentation",
        "../../fileAccessHelper"
      ],
      "intent": "This file solves the problem of duplicate and inconsistent prompt construction scattered across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent quality and structure for AI interactions while making prompts easier to maintain and improve.",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralized prompt construction system that builds structured prompts for all LLM analysis tasks including architecture analysis, documentation generation, test planning, and code generation.\",\n  \"userVisibleActions\": [\n    \"Receives more accurate and consistent AI-generated architecture analysis\",\n    \"Gets better quality product documentation from AI analysis\",\n    \"Obtains more relevant test plans and test code generation\",\n    \"Experiences improved AI understanding of code context and purpose\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides standardized interface for building prompts across all LLM operations\",\n    \"Constructs architecture analysis prompts with code context and documentation\",\n    \"Generates prompts for product documentation and purpose analysis\",\n    \"Creates prompts for file-level code analysis with role information\",\n    \"Builds module rollup prompts for aggregating file summaries\",\n    \"Produces product-level summary prompts combining multiple analysis layers\",\n    \"Generates test planning prompts per file with function metadata\",\n    \"Creates test code generation prompts with source and function context\",\n    \"Eliminates duplicate prompt construction logic across the codebase\",\n    \"Ensures consistent prompt structure and quality across all AI interactions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Constructs prompt for analyzing codebase architecture\",\n      \"inputs\": \"context (AnalysisContext), optional codeAnalysis, productDocs, productPurposeAnalysis, fileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Builds prompt for generating product documentation\",\n      \"inputs\": \"context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates prompt for analyzing product purpose and goals\",\n      \"inputs\": \"productDocs (EnhancedProductDocumentation), context (AnalysisContext)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Generates prompt for analyzing individual code files\",\n      \"inputs\": \"file (FileInfo), content (string), role (string)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Constructs prompt for rolling up file summaries into module summaries\",\n      \"inputs\": \"modulePath (string), moduleType (string), files (FileSummary[])\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Builds comprehensive prompt for product-level analysis\",\n      \"inputs\": \"fileSummaries (FileSummary[]), moduleSummaries (ModuleSummary[]), analysis (CodeAnalysis), fileAccessHelper (FileAccessHelper)\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates prompt for generating test plans for specific files\",\n      \"inputs\": \"filePath, fileContent, functionMetadata, existingTests, language, testFramework, optional projectSummary\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates prompt for creating actual test code\",\n      \"inputs\": \"testPlanItem, sourceCode, functionCode, language, testFramework\",\n      \"outputs\": \"Formatted string prompt for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file solves the problem of duplicate and inconsistent prompt construction scattered across the codebase by centralizing all LLM prompt building logic in one place, ensuring consistent quality and structure for AI interactions while making prompts easier to maintain and improve.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Builds detailed refactoring prompts with extraction plans and migration steps for LLM-based code refactoring analysis",
      "userVisibleActions": [
        "Receives detailed refactoring recommendations with specific code extraction suggestions",
        "Gets step-by-step migration instructions for moving code between files",
        "Views before/after code examples showing proposed refactoring changes",
        "Sees function-level analysis explaining what each function does and its dependencies"
      ],
      "developerVisibleActions": [
        "Generates comprehensive refactoring prompts that include code analysis context and product documentation",
        "Creates extraction plans showing which functions should be moved from source to target files",
        "Produces function analysis reports detailing responsibilities, dependencies, and call relationships",
        "Builds structured prompts with specific requirements for code extraction and migration",
        "Combines architecture insights with code analysis to guide refactoring decisions",
        "Generates migration steps and code examples to illustrate refactoring approach"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Creates a comprehensive refactoring prompt combining code analysis, product docs, architecture insights, and function analysis",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array",
          "outputs": "Formatted string prompt for LLM refactoring analysis"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Constructs the foundational prompt text with context and code analysis information",
          "inputs": "AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights",
          "outputs": "Base prompt string"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Generates a detailed section analyzing functions including their dependencies and responsibilities",
          "inputs": "Array of FunctionAnalysis objects",
          "outputs": "Formatted function analysis text"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Creates detailed requirements for code extraction including migration steps and examples",
          "inputs": "None",
          "outputs": "Extraction requirements text"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to generate structured, prescriptive refactoring instructions for LLMs by combining code analysis data, function relationships, and documentation context into comprehensive prompts that guide the AI to produce actionable refactoring recommendations with specific extraction plans and migration steps",
      "rawContent": "```json\n{\n  \"purpose\": \"Builds detailed refactoring prompts with extraction plans and migration steps for LLM-based code refactoring analysis\",\n  \"userVisibleActions\": [\n    \"Receives detailed refactoring recommendations with specific code extraction suggestions\",\n    \"Gets step-by-step migration instructions for moving code between files\",\n    \"Views before/after code examples showing proposed refactoring changes\",\n    \"Sees function-level analysis explaining what each function does and its dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Generates comprehensive refactoring prompts that include code analysis context and product documentation\",\n    \"Creates extraction plans showing which functions should be moved from source to target files\",\n    \"Produces function analysis reports detailing responsibilities, dependencies, and call relationships\",\n    \"Builds structured prompts with specific requirements for code extraction and migration\",\n    \"Combines architecture insights with code analysis to guide refactoring decisions\",\n    \"Generates migration steps and code examples to illustrate refactoring approach\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive refactoring prompt combining code analysis, product docs, architecture insights, and function analysis\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights, optional FunctionAnalysis array\",\n      \"outputs\": \"Formatted string prompt for LLM refactoring analysis\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Constructs the foundational prompt text with context and code analysis information\",\n      \"inputs\": \"AnalysisContext, CodeAnalysis, optional EnhancedProductDocumentation, optional LLMInsights\",\n      \"outputs\": \"Base prompt string\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Generates a detailed section analyzing functions including their dependencies and responsibilities\",\n      \"inputs\": \"Array of FunctionAnalysis objects\",\n      \"outputs\": \"Formatted function analysis text\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Creates detailed requirements for code extraction including migration steps and examples\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Extraction requirements text\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to generate structured, prescriptive refactoring instructions for LLMs by combining code analysis data, function relationships, and documentation context into comprehensive prompts that guide the AI to produce actionable refactoring recommendations with specific extraction plans and migration steps\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides prompt templates for LLM-based test generation, including setup configuration, test planning, and test case creation.",
      "userVisibleActions": [
        "Generates test setup recommendations based on codebase analysis",
        "Creates prioritized test plans with coverage targets",
        "Generates test cases for specific functions with assertions and edge cases",
        "Produces test suites organized by file with proper imports and setup"
      ],
      "developerVisibleActions": [
        "Call buildSetupPrompt() with workspace root and file list to get test framework recommendations",
        "Call buildPlanningPrompt() with code analysis and functions to generate test strategy",
        "Call buildImplementationPrompt() with testable functions to generate actual test code",
        "Call buildSuitePrompt() to organize generated tests into structured test suites",
        "Receive JSON-formatted responses with testing framework, dependencies, and configuration",
        "Get prioritized function lists with testing recommendations and risk assessments",
        "Obtain complete test implementations with describe/it blocks and assertions"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Creates a prompt for LLM to analyze codebase and recommend test framework setup",
          "inputs": "workspaceRoot (string), fileList (string[]), packageJsonContent (optional string)",
          "outputs": "Formatted prompt string requesting JSON with language, framework, dependencies, and configuration"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates a prompt for LLM to generate a prioritized test plan based on code analysis",
          "inputs": "context (CodeAnalysis), functions (any[]), productDocs (optional), architectureInsights (optional)",
          "outputs": "Formatted prompt string requesting JSON with prioritized functions, risk scores, and test recommendations"
        },
        {
          "name": "buildImplementationPrompt",
          "desc": "Creates a prompt for LLM to generate actual test code for specific functions",
          "inputs": "testableFunction (TestableFunction), projectContext (string), testingFramework (string)",
          "outputs": "Formatted prompt string requesting JSON array of test cases with code, descriptions, and assertions"
        },
        {
          "name": "buildSuitePrompt",
          "desc": "Creates a prompt for LLM to organize generated tests into structured test suites",
          "inputs": "filePath (string), testCases (string[]), imports (string[]), setupCode (optional string)",
          "outputs": "Formatted prompt string requesting complete test file with proper structure and organization"
        }
      ],
      "dependencies": [
        "../../analyzer",
        "../services/testing/types/testPlanTypes"
      ],
      "intent": "This file exists to provide standardized, detailed prompt templates that guide LLMs to generate high-quality test code, configurations, and strategies. It solves the problem of consistent, structured communication with AI models for test generation by providing context-rich prompts that result in actionable, properly formatted test outputs including framework setup, test planning, and implementation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides prompt templates for LLM-based test generation, including setup configuration, test planning, and test case creation.\",\n  \"userVisibleActions\": [\n    \"Generates test setup recommendations based on codebase analysis\",\n    \"Creates prioritized test plans with coverage targets\",\n    \"Generates test cases for specific functions with assertions and edge cases\",\n    \"Produces test suites organized by file with proper imports and setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace root and file list to get test framework recommendations\",\n    \"Call buildPlanningPrompt() with code analysis and functions to generate test strategy\",\n    \"Call buildImplementationPrompt() with testable functions to generate actual test code\",\n    \"Call buildSuitePrompt() to organize generated tests into structured test suites\",\n    \"Receive JSON-formatted responses with testing framework, dependencies, and configuration\",\n    \"Get prioritized function lists with testing recommendations and risk assessments\",\n    \"Obtain complete test implementations with describe/it blocks and assertions\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates a prompt for LLM to analyze codebase and recommend test framework setup\",\n      \"inputs\": \"workspaceRoot (string), fileList (string[]), packageJsonContent (optional string)\",\n      \"outputs\": \"Formatted prompt string requesting JSON with language, framework, dependencies, and configuration\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates a prompt for LLM to generate a prioritized test plan based on code analysis\",\n      \"inputs\": \"context (CodeAnalysis), functions (any[]), productDocs (optional), architectureInsights (optional)\",\n      \"outputs\": \"Formatted prompt string requesting JSON with prioritized functions, risk scores, and test recommendations\"\n    },\n    {\n      \"name\": \"buildImplementationPrompt\",\n      \"desc\": \"Creates a prompt for LLM to generate actual test code for specific functions\",\n      \"inputs\": \"testableFunction (TestableFunction), projectContext (string), testingFramework (string)\",\n      \"outputs\": \"Formatted prompt string requesting JSON array of test cases with code, descriptions, and assertions\"\n    },\n    {\n      \"name\": \"buildSuitePrompt\",\n      \"desc\": \"Creates a prompt for LLM to organize generated tests into structured test suites\",\n      \"inputs\": \"filePath (string), testCases (string[]), imports (string[]), setupCode (optional string)\",\n      \"outputs\": \"Formatted prompt string requesting complete test file with proper structure and organization\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer\",\n    \"../services/testing/types/testPlanTypes\"\n  ],\n  \"intent\": \"This file exists to provide standardized, detailed prompt templates that guide LLMs to generate high-quality test code, configurations, and strategies. It solves the problem of consistent, structured communication with AI models for test generation by providing context-rich prompts that result in actionable, properly formatted test outputs including framework setup, test planning, and implementation.\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides centralized file system watching functionality to monitor and react to file changes across the workspace",
      "userVisibleActions": [
        "Automatically detects when files are created, modified, or deleted in the workspace",
        "Updates features in real-time when relevant files change (e.g., product files, insights)",
        "Responds to file save events to trigger automatic refreshes or updates"
      ],
      "developerVisibleActions": [
        "Register watchers for specific file patterns (e.g., *.json, *.md) with custom handlers",
        "Handle file creation, modification, and deletion events separately",
        "Filter watched files using ignore patterns to exclude unwanted files",
        "Subscribe to document save events with custom handlers",
        "Dispose watchers when no longer needed to free resources",
        "Track multiple handlers for the same file pattern without creating duplicate watchers"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Registers a file system watcher for a specific pattern and calls the handler when matching files change",
          "inputs": "id (string), pattern (file glob or relative pattern), handler (callback function), options (watch types and ignore patterns)",
          "outputs": "Disposable object to unregister the watcher"
        },
        {
          "name": "onDocumentSave",
          "desc": "Registers a handler to be called whenever a text document is saved",
          "inputs": "id (string), handler (callback function accepting TextDocument)",
          "outputs": "Disposable object to unregister the handler"
        },
        {
          "name": "unwatch",
          "desc": "Removes a specific watcher by ID and cleans up resources if no other handlers exist",
          "inputs": "id (string)",
          "outputs": "void"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all watchers and handlers, freeing system resources",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "shouldIgnore",
          "desc": "Determines if a file path should be ignored based on configured patterns",
          "inputs": "filePath (string), ignorePatterns (array of glob patterns)",
          "outputs": "boolean indicating whether to ignore the file"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to consolidate duplicate file watching logic that was scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It provides a single, reusable service for monitoring file system changes, eliminating code duplication and ensuring consistent file watching behavior throughout the extension. It solves the problem of managing multiple file watchers efficiently while allowing different parts of the extension to react to file changes independently.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides centralized file system watching functionality to monitor and react to file changes across the workspace\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created, modified, or deleted in the workspace\",\n    \"Updates features in real-time when relevant files change (e.g., product files, insights)\",\n    \"Responds to file save events to trigger automatic refreshes or updates\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register watchers for specific file patterns (e.g., *.json, *.md) with custom handlers\",\n    \"Handle file creation, modification, and deletion events separately\",\n    \"Filter watched files using ignore patterns to exclude unwanted files\",\n    \"Subscribe to document save events with custom handlers\",\n    \"Dispose watchers when no longer needed to free resources\",\n    \"Track multiple handlers for the same file pattern without creating duplicate watchers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file system watcher for a specific pattern and calls the handler when matching files change\",\n      \"inputs\": \"id (string), pattern (file glob or relative pattern), handler (callback function), options (watch types and ignore patterns)\",\n      \"outputs\": \"Disposable object to unregister the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever a text document is saved\",\n      \"inputs\": \"id (string), handler (callback function accepting TextDocument)\",\n      \"outputs\": \"Disposable object to unregister the handler\"\n    },\n    {\n      \"name\": \"unwatch\",\n      \"desc\": \"Removes a specific watcher by ID and cleans up resources if no other handlers exist\",\n      \"inputs\": \"id (string)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all watchers and handlers, freeing system resources\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file path should be ignored based on configured patterns\",\n      \"inputs\": \"filePath (string), ignorePatterns (array of glob patterns)\",\n      \"outputs\": \"boolean indicating whether to ignore the file\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to consolidate duplicate file watching logic that was scattered across multiple files (fileWatcher.ts, productNavigator.ts, insightsViewer.ts). It provides a single, reusable service for monitoring file system changes, eliminating code duplication and ensuring consistent file watching behavior throughout the extension. It solves the problem of managing multiple file watchers efficiently while allowing different parts of the extension to react to file changes independently.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative analysis sessions where an LLM can request additional files or search results across multiple rounds of conversation.",
      "userVisibleActions": [
        "LLM analysis continues across multiple iterations when it needs more information",
        "Analysis automatically fetches requested files and grep search results",
        "Analysis stops after reaching maximum iterations or when LLM signals completion",
        "Up to 5 file/grep requests are processed per iteration to prevent overload"
      ],
      "developerVisibleActions": [
        "Developer initiates iterative analysis with custom callbacks for iteration start and completion",
        "Service processes LLM requests for file reads and grep searches automatically",
        "Developer receives structured iteration results including the final result, iteration count, and all requests made",
        "Service maintains conversation history by appending assistant and user messages",
        "Developer can configure maximum iterations to control analysis depth"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes up to 5 file read and grep search requests from the LLM, returning formatted results",
          "inputs": "requests (array of LLMRequest), currentResult (any analysis result), messages (conversation history)",
          "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
        },
        {
          "name": "async *iterateAnalysis",
          "desc": "Iterates through analysis rounds, yielding results after each iteration until completion or max iterations reached",
          "inputs": "currentResult (initial analysis), iteration (starting iteration number), maxIterations (limit), callbacks (optional iteration hooks)",
          "outputs": "AsyncGenerator yielding IterationResult objects with result, iteration count, requests, and continuation flag"
        }
      ],
      "dependencies": [
        "FileAccessHelper",
        "LLMRequest types from fileAccessHelper module"
      ],
      "intent": "Eliminates code duplication and improves testability by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM can request additional context through file reads and grep searches.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative analysis sessions where an LLM can request additional files or search results across multiple rounds of conversation.\",\n  \"userVisibleActions\": [\n    \"LLM analysis continues across multiple iterations when it needs more information\",\n    \"Analysis automatically fetches requested files and grep search results\",\n    \"Analysis stops after reaching maximum iterations or when LLM signals completion\",\n    \"Up to 5 file/grep requests are processed per iteration to prevent overload\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer initiates iterative analysis with custom callbacks for iteration start and completion\",\n    \"Service processes LLM requests for file reads and grep searches automatically\",\n    \"Developer receives structured iteration results including the final result, iteration count, and all requests made\",\n    \"Service maintains conversation history by appending assistant and user messages\",\n    \"Developer can configure maximum iterations to control analysis depth\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes up to 5 file read and grep search requests from the LLM, returning formatted results\",\n      \"inputs\": \"requests (array of LLMRequest), currentResult (any analysis result), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"async *iterateAnalysis\",\n      \"desc\": \"Iterates through analysis rounds, yielding results after each iteration until completion or max iterations reached\",\n      \"inputs\": \"currentResult (initial analysis), iteration (starting iteration number), maxIterations (limit), callbacks (optional iteration hooks)\",\n      \"outputs\": \"AsyncGenerator yielding IterationResult objects with result, iteration count, requests, and continuation flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest types from fileAccessHelper module\"\n  ],\n  \"intent\": \"Eliminates code duplication and improves testability by extracting iterative LLM analysis logic into a dedicated service that handles multi-round conversations where the LLM can request additional context through file reads and grep searches.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects test framework configuration (Jest, Mocha, Vitest, Pytest) and identifies missing dependencies or setup requirements without manual user configuration",
      "userVisibleActions": [
        "Test framework is automatically detected from project files",
        "Missing test dependencies are identified and reported",
        "Configuration issues are detected and surfaced",
        "Setup requirements are automatically checked",
        "Test configuration status is displayed"
      ],
      "developerVisibleActions": [
        "Service scans workspace for package.json and test configuration files",
        "Detects which test framework is being used (Jest, Mocha, Vitest, Pytest)",
        "Identifies missing dependencies required for testing",
        "Returns configuration status with framework, dependencies, and setup requirements",
        "Provides actionable setup steps when configuration is incomplete"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Scans workspace to determine which test framework is configured and what dependencies are missing",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "SWLogger"
      ],
      "intent": "Eliminates manual test configuration setup by automatically detecting the test framework being used in a project, checking if all required dependencies are installed, and identifying what setup steps are needed to ensure generated tests will work immediately without user intervention",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration (Jest, Mocha, Vitest, Pytest) and identifies missing dependencies or setup requirements without manual user configuration\",\n  \"userVisibleActions\": [\n    \"Test framework is automatically detected from project files\",\n    \"Missing test dependencies are identified and reported\",\n    \"Configuration issues are detected and surfaced\",\n    \"Setup requirements are automatically checked\",\n    \"Test configuration status is displayed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service scans workspace for package.json and test configuration files\",\n    \"Detects which test framework is being used (Jest, Mocha, Vitest, Pytest)\",\n    \"Identifies missing dependencies required for testing\",\n    \"Returns configuration status with framework, dependencies, and setup requirements\",\n    \"Provides actionable setup steps when configuration is incomplete\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Scans workspace to determine which test framework is configured and what dependencies are missing\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestConfigStatus object containing framework type, configuration state, missing dependencies, and required setup actions\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates manual test configuration setup by automatically detecting the test framework being used in a project, checking if all required dependencies are installed, and identifying what setup steps are needed to ensure generated tests will work immediately without user intervention\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates test code incrementally in small batches using an LLM service to create tests for testable functions",
      "userVisibleActions": [
        "Progress updates shown while tests are being generated for each function",
        "Test generation results displayed for batches of functions",
        "Error messages shown if test generation fails for specific functions"
      ],
      "developerVisibleActions": [
        "Triggers batch generation of tests for multiple functions at once",
        "Receives progress callbacks with current function being tested and completion percentage",
        "Gets back a map of test generation results keyed by function name",
        "Can provide custom progress handlers to track generation status",
        "Accesses generated test code and execution results for each function"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for multiple functions in a batch, processing them one at a time with progress tracking",
          "inputs": "functions array, workspace root path, LLM service instance, optional progress callback",
          "outputs": "Map of function names to TestGenerationResult objects"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Extracts the source code for a specific function from the workspace",
          "inputs": "TestableFunction object, workspace root path",
          "outputs": "Source code string for the function"
        },
        {
          "name": "buildGenerationPrompt",
          "desc": "Creates an LLM prompt for generating tests based on function details and existing code",
          "inputs": "function object, source code, test framework type, existing mock code",
          "outputs": "Formatted prompt string for the LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestableFunction",
        "TestGenerationState",
        "TestGenerationResult",
        "buildGenerationPrompt",
        "TestExecutionService",
        "SWLogger"
      ],
      "intent": "This file exists to orchestrate the automated generation of unit tests using an LLM in manageable batches, allowing developers to generate test suites for multiple functions incrementally with progress tracking and result collection, solving the problem of manually writing repetitive test code.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates test code incrementally in small batches using an LLM service to create tests for testable functions\",\n  \"userVisibleActions\": [\n    \"Progress updates shown while tests are being generated for each function\",\n    \"Test generation results displayed for batches of functions\",\n    \"Error messages shown if test generation fails for specific functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers batch generation of tests for multiple functions at once\",\n    \"Receives progress callbacks with current function being tested and completion percentage\",\n    \"Gets back a map of test generation results keyed by function name\",\n    \"Can provide custom progress handlers to track generation status\",\n    \"Accesses generated test code and execution results for each function\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, processing them one at a time with progress tracking\",\n      \"inputs\": \"functions array, workspace root path, LLM service instance, optional progress callback\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Extracts the source code for a specific function from the workspace\",\n      \"inputs\": \"TestableFunction object, workspace root path\",\n      \"outputs\": \"Source code string for the function\"\n    },\n    {\n      \"name\": \"buildGenerationPrompt\",\n      \"desc\": \"Creates an LLM prompt for generating tests based on function details and existing code\",\n      \"inputs\": \"function object, source code, test framework type, existing mock code\",\n      \"outputs\": \"Formatted prompt string for the LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestableFunction\",\n    \"TestGenerationState\",\n    \"TestGenerationResult\",\n    \"buildGenerationPrompt\",\n    \"TestExecutionService\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to orchestrate the automated generation of unit tests using an LLM in manageable batches, allowing developers to generate test suites for multiple functions incrementally with progress tracking and result collection, solving the problem of manually writing repetitive test code.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Creates AI-powered test plans by analyzing code functions and prioritizing them for testing based on complexity and importance",
      "userVisibleActions": [
        "Receives a prioritized test plan showing which functions need testing",
        "Sees analysis of how many functions are testable vs total functions",
        "Gets test strategy recommendations based on code complexity and architecture",
        "Views saved test plans in the .skyway/testing directory"
      ],
      "developerVisibleActions": [
        "Calls analyzeFunctions() to extract function metadata from code analysis",
        "Invokes createTestPlan() to generate an AI-powered test strategy",
        "Saves test plans to disk using saveTestPlan() for future reference",
        "Receives structured TestPlan objects containing function groups and priorities",
        "Gets logging output showing progress of test plan creation",
        "Can provide product documentation and architecture insights to improve test planning"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts and structures function metadata from code analysis results",
          "inputs": "codeAnalysis object containing function information",
          "outputs": "Array of function objects with name, file, lines, complexity, parameters, and return type"
        },
        {
          "name": "createTestPlan",
          "desc": "Generates a prioritized test plan using AI by analyzing functions and context",
          "inputs": "CodeAnalysis context, functions array, LLM service, optional product docs and architecture insights",
          "outputs": "TestPlan object containing function groups, testable function count, and testing strategy"
        },
        {
          "name": "saveTestPlan",
          "desc": "Persists the generated test plan to disk in JSON format",
          "inputs": "TestPlan object and output directory path",
          "outputs": "File path where test plan was saved"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestPlan and TestableFunction types",
        "testPrompts (buildPlanningPrompt)",
        "CodeAnalysis from analyzer",
        "SWLogger"
      ],
      "intent": "This file exists to automate test planning by leveraging AI to analyze code complexity, function relationships, and architecture to determine which functions should be tested and in what priority order, eliminating manual test planning effort and ensuring critical code paths are tested first",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates AI-powered test plans by analyzing code functions and prioritizing them for testing based on complexity and importance\",\n  \"userVisibleActions\": [\n    \"Receives a prioritized test plan showing which functions need testing\",\n    \"Sees analysis of how many functions are testable vs total functions\",\n    \"Gets test strategy recommendations based on code complexity and architecture\",\n    \"Views saved test plans in the .skyway/testing directory\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis\",\n    \"Invokes createTestPlan() to generate an AI-powered test strategy\",\n    \"Saves test plans to disk using saveTestPlan() for future reference\",\n    \"Receives structured TestPlan objects containing function groups and priorities\",\n    \"Gets logging output showing progress of test plan creation\",\n    \"Can provide product documentation and architecture insights to improve test planning\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and structures function metadata from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing function information\",\n      \"outputs\": \"Array of function objects with name, file, lines, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan using AI by analyzing functions and context\",\n      \"inputs\": \"CodeAnalysis context, functions array, LLM service, optional product docs and architecture insights\",\n      \"outputs\": \"TestPlan object containing function groups, testable function count, and testing strategy\"\n    },\n    {\n      \"name\": \"saveTestPlan\",\n      \"desc\": \"Persists the generated test plan to disk in JSON format\",\n      \"inputs\": \"TestPlan object and output directory path\",\n      \"outputs\": \"File path where test plan was saved\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestPlan and TestableFunction types\",\n    \"testPrompts (buildPlanningPrompt)\",\n    \"CodeAnalysis from analyzer\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate test planning by leveraging AI to analyze code complexity, function relationships, and architecture to determine which functions should be tested and in what priority order, eliminating manual test planning effort and ensuring critical code paths are tested first\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects the test environment and configuration in a workspace to prepare for generating unit tests",
      "userVisibleActions": [
        "Analyzes workspace to determine programming language and testing framework",
        "Detects existing test configuration files (package.json, jest.config.js, tsconfig.json)",
        "Identifies test directories and file patterns in the project",
        "Generates test setup recommendations based on detected environment",
        "Reports whether test environment is properly configured or needs setup"
      ],
      "developerVisibleActions": [
        "Scans workspace directory structure to identify project type",
        "Counts files by extension to determine primary programming language",
        "Checks for presence of configuration files (package.json, jest.config, tsconfig)",
        "Reads and parses package.json to detect testing frameworks (Jest, Mocha, Vitest, etc.)",
        "Identifies existing test directories (UnitTests, tests, __tests__, spec)",
        "Returns structured test environment information including language, framework, and configuration status",
        "Provides setup plan when test environment is incomplete or missing"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Analyzes workspace to determine programming language, testing framework, and configuration status",
          "inputs": "workspaceRoot (string path to workspace)",
          "outputs": "TestEnvironment object containing language, framework, config files, and test directories"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively collects all files in workspace directory for analysis",
          "inputs": "directory path (string)",
          "outputs": "Array of file paths (string[])"
        },
        {
          "name": "buildSetupPrompt",
          "desc": "Creates LLM prompt for generating test setup configuration based on detected environment",
          "inputs": "TestEnvironment object",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "testSetupTypes",
        "testPrompts",
        "SWLogger"
      ],
      "intent": "This file exists to solve the problem of automatically setting up test environments for different programming languages and frameworks. It eliminates manual configuration by detecting what testing tools are available, what language the project uses, and what configuration is needed to enable automated unit test generation. This is Phase 1 of the test setup process, focusing on environment detection and configuration generation before actual test file creation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects the test environment and configuration in a workspace to prepare for generating unit tests\",\n  \"userVisibleActions\": [\n    \"Analyzes workspace to determine programming language and testing framework\",\n    \"Detects existing test configuration files (package.json, jest.config.js, tsconfig.json)\",\n    \"Identifies test directories and file patterns in the project\",\n    \"Generates test setup recommendations based on detected environment\",\n    \"Reports whether test environment is properly configured or needs setup\"\n  ],\n  \"developerVisibleActions\": [\n    \"Scans workspace directory structure to identify project type\",\n    \"Counts files by extension to determine primary programming language\",\n    \"Checks for presence of configuration files (package.json, jest.config, tsconfig)\",\n    \"Reads and parses package.json to detect testing frameworks (Jest, Mocha, Vitest, etc.)\",\n    \"Identifies existing test directories (UnitTests, tests, __tests__, spec)\",\n    \"Returns structured test environment information including language, framework, and configuration status\",\n    \"Provides setup plan when test environment is incomplete or missing\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to determine programming language, testing framework, and configuration status\",\n      \"inputs\": \"workspaceRoot (string path to workspace)\",\n      \"outputs\": \"TestEnvironment object containing language, framework, config files, and test directories\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively collects all files in workspace directory for analysis\",\n      \"inputs\": \"directory path (string)\",\n      \"outputs\": \"Array of file paths (string[])\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Creates LLM prompt for generating test setup configuration based on detected environment\",\n      \"inputs\": \"TestEnvironment object\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"testSetupTypes\",\n    \"testPrompts\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to solve the problem of automatically setting up test environments for different programming languages and frameworks. It eliminates manual configuration by detecting what testing tools are available, what language the project uses, and what configuration is needed to enable automated unit test generation. This is Phase 1 of the test setup process, focusing on environment detection and configuration generation before actual test file creation.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates and automatically fixes failing tests using LLM-powered analysis and code generation",
      "userVisibleActions": [
        "Tests are automatically run and results are displayed showing passed/failed counts",
        "Failing tests are automatically analyzed and fixed without manual intervention",
        "Test validation progress is logged showing attempt numbers and success/failure status",
        "Final test report is generated showing overall test health and remaining failures"
      ],
      "developerVisibleActions": [
        "Developer triggers test validation which runs Jest tests and captures results",
        "Developer receives structured test execution results with pass/fail counts per test file",
        "Developer can specify a single test file or run all tests in workspace",
        "Developer gets iterative fix attempts (up to 3 by default) for each failing test",
        "Developer receives a comprehensive test report with summary statistics",
        "Developer sees logged progress for test execution and fix attempts"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or a specific test file and returns aggregated results",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]> - array of test results with pass/fail counts"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to automatically fix a failing test using LLM with multiple retry attempts",
          "inputs": "testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts?: number",
          "outputs": "Promise<{success: boolean, attempts: number, finalError?: string}> - fix outcome"
        },
        {
          "name": "validateAndFix",
          "desc": "Orchestrates the complete test validation and auto-fix workflow for all failing tests",
          "inputs": "workspaceRoot: string, llmService: any, testFile?: string, maxAttempts?: number",
          "outputs": "Promise<TestReport> - comprehensive report of test execution and fix attempts"
        },
        {
          "name": "generateTestReport",
          "desc": "Creates a structured summary report of all test results and fix outcomes",
          "inputs": "results: TestExecutionResult[], fixes: Map<string, {success: boolean, attempts: number}>",
          "outputs": "TestReport - formatted report with statistics and per-file details"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "TestExecutionResult, TestReport, TestReportSummary (types)",
        "buildFixPrompt (prompts)",
        "SWLogger"
      ],
      "intent": "This file exists to automate the test validation and fixing workflow by running tests, detecting failures, and using LLM to intelligently repair broken tests. It solves the problem of manual test maintenance by providing automated analysis and fixes for failing tests, reducing developer time spent debugging test failures.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates and automatically fixes failing tests using LLM-powered analysis and code generation\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and results are displayed showing passed/failed counts\",\n    \"Failing tests are automatically analyzed and fixed without manual intervention\",\n    \"Test validation progress is logged showing attempt numbers and success/failure status\",\n    \"Final test report is generated showing overall test health and remaining failures\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer triggers test validation which runs Jest tests and captures results\",\n    \"Developer receives structured test execution results with pass/fail counts per test file\",\n    \"Developer can specify a single test file or run all tests in workspace\",\n    \"Developer gets iterative fix attempts (up to 3 by default) for each failing test\",\n    \"Developer receives a comprehensive test report with summary statistics\",\n    \"Developer sees logged progress for test execution and fix attempts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and returns aggregated results\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]> - array of test results with pass/fail counts\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with multiple retry attempts\",\n      \"inputs\": \"testFilePath: string, executionResult: TestExecutionResult, workspaceRoot: string, llmService: any, maxAttempts?: number\",\n      \"outputs\": \"Promise<{success: boolean, attempts: number, finalError?: string}> - fix outcome\"\n    },\n    {\n      \"name\": \"validateAndFix\",\n      \"desc\": \"Orchestrates the complete test validation and auto-fix workflow for all failing tests\",\n      \"inputs\": \"workspaceRoot: string, llmService: any, testFile?: string, maxAttempts?: number\",\n      \"outputs\": \"Promise<TestReport> - comprehensive report of test execution and fix attempts\"\n    },\n    {\n      \"name\": \"generateTestReport\",\n      \"desc\": \"Creates a structured summary report of all test results and fix outcomes\",\n      \"inputs\": \"results: TestExecutionResult[], fixes: Map<string, {success: boolean, attempts: number}>\",\n      \"outputs\": \"TestReport - formatted report with statistics and per-file details\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"TestExecutionResult, TestReport, TestReportSummary (types)\",\n    \"buildFixPrompt (prompts)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file exists to automate the test validation and fixing workflow by running tests, detecting failures, and using LLM to intelligently repair broken tests. It solves the problem of manual test maintenance by providing automated analysis and fixes for failing tests, reducing developer time spent debugging test failures.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes test suites (Jest, Pytest) and captures their results for display to users and developers",
      "userVisibleActions": [
        "Tests run when user triggers test execution",
        "Test results appear showing passed, failed, and error counts",
        "Test execution status displays (running, success, error)",
        "Individual test failures show with error messages and stack traces",
        "Test execution progress shows duration/timing information"
      ],
      "developerVisibleActions": [
        "Triggers Jest tests for specific files or entire test suite",
        "Triggers Pytest tests for specific files or entire test suite",
        "Parses test framework output to extract structured results",
        "Handles test execution errors and timeouts",
        "Returns standardized test results regardless of testing framework",
        "Provides detailed error information including stack traces"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Executes Jest tests and returns structured results",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> containing test outcomes"
        },
        {
          "name": "runPytest",
          "desc": "Executes Pytest tests and returns structured results",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Promise<TestExecutionResult[]> containing test outcomes"
        },
        {
          "name": "parseJestOutput",
          "desc": "Converts Jest JSON output into standardized test result format",
          "inputs": "stdout (string), stderr (string)",
          "outputs": "TestExecutionResult[] with parsed test data"
        },
        {
          "name": "parsePytestOutput",
          "desc": "Converts Pytest JSON output into standardized test result format",
          "inputs": "stdout (string), stderr (string)",
          "outputs": "TestExecutionResult[] with parsed test data"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "Provides a unified interface for executing different testing frameworks (Jest for JavaScript/TypeScript, Pytest for Python) and normalizing their outputs into a consistent format that can be displayed to users and processed by other services, handling execution failures gracefully and providing detailed error information.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Pytest) and captures their results for display to users and developers\",\n  \"userVisibleActions\": [\n    \"Tests run when user triggers test execution\",\n    \"Test results appear showing passed, failed, and error counts\",\n    \"Test execution status displays (running, success, error)\",\n    \"Individual test failures show with error messages and stack traces\",\n    \"Test execution progress shows duration/timing information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Triggers Jest tests for specific files or entire test suite\",\n    \"Triggers Pytest tests for specific files or entire test suite\",\n    \"Parses test framework output to extract structured results\",\n    \"Handles test execution errors and timeouts\",\n    \"Returns standardized test results regardless of testing framework\",\n    \"Provides detailed error information including stack traces\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests and returns structured results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Pytest tests and returns structured results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Promise<TestExecutionResult[]> containing test outcomes\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Converts Jest JSON output into standardized test result format\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test data\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Converts Pytest JSON output into standardized test result format\",\n      \"inputs\": \"stdout (string), stderr (string)\",\n      \"outputs\": \"TestExecutionResult[] with parsed test data\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for executing different testing frameworks (Jest for JavaScript/TypeScript, Pytest for Python) and normalizing their outputs into a consistent format that can be displayed to users and processed by other services, handling execution failures gracefully and providing detailed error information.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test planning and generation workflow, including test plans, function grouping, and generation state tracking.",
      "userVisibleActions": [
        "View test generation progress through phases (setup, planning, generation, validation, complete)",
        "See how many functions are being tested and their validation status",
        "Track test failures with error messages and retry attempts"
      ],
      "developerVisibleActions": [
        "Structure test plans with function groups organized by priority",
        "Track testable functions with metadata (complexity, dependencies, mocking requirements)",
        "Monitor test generation state across different phases",
        "Access function details including file location, line numbers, parameters, and return types",
        "Handle test failures with function name, error details, and attempt count"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a strongly-typed contract for the test planning and generation service, ensuring consistent data structures when creating test plans, tracking generation progress, identifying testable functions, and managing test failures across the automated testing workflow.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test planning and generation workflow, including test plans, function grouping, and generation state tracking.\",\n  \"userVisibleActions\": [\n    \"View test generation progress through phases (setup, planning, generation, validation, complete)\",\n    \"See how many functions are being tested and their validation status\",\n    \"Track test failures with error messages and retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Structure test plans with function groups organized by priority\",\n    \"Track testable functions with metadata (complexity, dependencies, mocking requirements)\",\n    \"Monitor test generation state across different phases\",\n    \"Access function details including file location, line numbers, parameters, and return types\",\n    \"Handle test failures with function name, error details, and attempt count\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for the test planning and generation service, ensuring consistent data structures when creating test plans, tracking generation progress, identifying testable functions, and managing test failures across the automated testing workflow.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type interfaces for test generation, validation, execution results, and reporting structures in the testing service.",
      "userVisibleActions": [
        "View test execution results showing passed/failed/error counts",
        "See test reports with summary statistics and pass rates",
        "Read recommendations for improving test quality",
        "Review error details including test names, error messages, and stack traces"
      ],
      "developerVisibleActions": [
        "Use TestGenerationResult to structure generated test files with imports, mocks, and test code",
        "Access TestValidationResult to check if tests pass, fail, or have errors with explanations",
        "Retrieve TestExecutionResult to get test run statistics including duration and error details",
        "Generate TestReport with overall summary, individual results, and recommendations",
        "Work with MockStatement to understand what code is being mocked and why",
        "Access setup and teardown code for test configuration"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "This file exists to provide a standardized type system for the entire testing workflow - from generating tests with mocks and setup code, through validating and executing them, to producing comprehensive reports. It ensures type safety and consistent data structures across test generation, validation, execution, and reporting phases.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type interfaces for test generation, validation, execution results, and reporting structures in the testing service.\",\n  \"userVisibleActions\": [\n    \"View test execution results showing passed/failed/error counts\",\n    \"See test reports with summary statistics and pass rates\",\n    \"Read recommendations for improving test quality\",\n    \"Review error details including test names, error messages, and stack traces\"\n  ],\n  \"developerVisibleActions\": [\n    \"Use TestGenerationResult to structure generated test files with imports, mocks, and test code\",\n    \"Access TestValidationResult to check if tests pass, fail, or have errors with explanations\",\n    \"Retrieve TestExecutionResult to get test run statistics including duration and error details\",\n    \"Generate TestReport with overall summary, individual results, and recommendations\",\n    \"Work with MockStatement to understand what code is being mocked and why\",\n    \"Access setup and teardown code for test configuration\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"This file exists to provide a standardized type system for the entire testing workflow - from generating tests with mocks and setup code, through validating and executing them, to producing comprehensive reports. It ensures type safety and consistent data structures across test generation, validation, execution, and reporting phases.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service",
      "userVisibleActions": [
        "User receives information about test setup plans including testing framework, dependencies, and configuration files",
        "User sees results of test setup execution including created files and installed dependencies",
        "User is notified of errors during test setup process",
        "User gets feedback about existing test environment (package.json, tsconfig, jest config, test directories)"
      ],
      "developerVisibleActions": [
        "Developer uses TestSetupPlan to structure test configuration recommendations",
        "Developer uses TestEnvironment to detect existing test infrastructure",
        "Developer uses SetupExecutionResult to communicate setup success/failure and changes made",
        "Developer defines dependencies with version and dev/prod distinction",
        "Developer specifies mock requirements with type and reasoning",
        "Developer creates configuration files with path and content"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides type safety and structure for the test setup service by defining interfaces that represent test configuration plans, environment analysis, setup execution results, and related components like dependencies, config files, and mock requirements",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service\",\n  \"userVisibleActions\": [\n    \"User receives information about test setup plans including testing framework, dependencies, and configuration files\",\n    \"User sees results of test setup execution including created files and installed dependencies\",\n    \"User is notified of errors during test setup process\",\n    \"User gets feedback about existing test environment (package.json, tsconfig, jest config, test directories)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer uses TestSetupPlan to structure test configuration recommendations\",\n    \"Developer uses TestEnvironment to detect existing test infrastructure\",\n    \"Developer uses SetupExecutionResult to communicate setup success/failure and changes made\",\n    \"Developer defines dependencies with version and dev/prod distinction\",\n    \"Developer specifies mock requirements with type and reasoning\",\n    \"Developer creates configuration files with path and content\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides type safety and structure for the test setup service by defining interfaces that represent test configuration plans, environment analysis, setup execution results, and related components like dependencies, config files, and mock requirements\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "Main extension entry point that initializes and coordinates all VS Code extension components, registers commands, and manages the extension lifecycle.",
      "userVisibleActions": [
        "Analyze code files to generate insights and behavior descriptions",
        "View code insights in a tree view sidebar",
        "Navigate through code structure and entry points",
        "Generate LLM-friendly summaries of code files",
        "See real-time diagnostics and warnings in the editor",
        "Export analysis results to files",
        "View context-aware code analysis in webview panels",
        "Get automatic cache updates when files change",
        "See status bar indicators for analysis progress",
        "Navigate to specific code elements from insights",
        "Analyze entire workspaces or individual files",
        "View product navigation structure"
      ],
      "developerVisibleActions": [
        "Extension activates when VS Code starts",
        "All components are initialized and wired together via bootstrapper",
        "Commands are registered for analyzing code, exporting results, and navigating insights",
        "File watcher monitors workspace changes and triggers re-analysis",
        "Cache stores analysis results for performance optimization",
        "Diagnostics are updated in real-time as code changes",
        "Tree view and webview panels are created and managed",
        "Status bar shows current analysis state",
        "Configuration changes trigger component updates",
        "Error handling captures and logs failures",
        "Extension deactivates and cleans up resources on shutdown"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Initializes the extension, sets up all components, registers commands, and starts file watching",
          "inputs": "vscode.ExtensionContext",
          "outputs": "void"
        },
        {
          "name": "deactivate",
          "desc": "Cleans up resources and stops all extension services when the extension is deactivated",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler",
        "./productNavigator"
      ],
      "intent": "This file serves as the central orchestration point for the VS Code extension, responsible for initializing all subsystems, wiring dependencies, registering user commands, and managing the complete extension lifecycle. It solves the problem of coordinating multiple independent components (analysis, insights, diagnostics, caching, UI) into a cohesive extension that provides code analysis and understanding capabilities to users.",
      "rawContent": "```json\n{\n  \"purpose\": \"Main extension entry point that initializes and coordinates all VS Code extension components, registers commands, and manages the extension lifecycle.\",\n  \"userVisibleActions\": [\n    \"Analyze code files to generate insights and behavior descriptions\",\n    \"View code insights in a tree view sidebar\",\n    \"Navigate through code structure and entry points\",\n    \"Generate LLM-friendly summaries of code files\",\n    \"See real-time diagnostics and warnings in the editor\",\n    \"Export analysis results to files\",\n    \"View context-aware code analysis in webview panels\",\n    \"Get automatic cache updates when files change\",\n    \"See status bar indicators for analysis progress\",\n    \"Navigate to specific code elements from insights\",\n    \"Analyze entire workspaces or individual files\",\n    \"View product navigation structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VS Code starts\",\n    \"All components are initialized and wired together via bootstrapper\",\n    \"Commands are registered for analyzing code, exporting results, and navigating insights\",\n    \"File watcher monitors workspace changes and triggers re-analysis\",\n    \"Cache stores analysis results for performance optimization\",\n    \"Diagnostics are updated in real-time as code changes\",\n    \"Tree view and webview panels are created and managed\",\n    \"Status bar shows current analysis state\",\n    \"Configuration changes trigger component updates\",\n    \"Error handling captures and logs failures\",\n    \"Extension deactivates and cleans up resources on shutdown\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes the extension, sets up all components, registers commands, and starts file watching\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources and stops all extension services when the extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\",\n    \"./productNavigator\"\n  ],\n  \"intent\": \"This file serves as the central orchestration point for the VS Code extension, responsible for initializing all subsystems, wiring dependencies, registering user commands, and managing the complete extension lifecycle. It solves the problem of coordinating multiple independent components (analysis, insights, diagnostics, caching, UI) into a cohesive extension that provides code analysis and understanding capabilities to users.\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and grep search functionality to enable iterative code analysis by LLMs within a workspace",
      "userVisibleActions": [
        "Users can request to read specific files by providing a file path",
        "Users can search for text patterns across multiple files using grep-like functionality",
        "Users receive file contents with line counts and existence status",
        "Users get search results showing matching lines with file locations and line numbers",
        "Users can see context lines before and after grep matches",
        "Users can limit search scope using file patterns (e.g., '*.ts', 'src/**/*.ts')",
        "Users can control maximum number of search results returned",
        "Users receive organized file listings grouped by folder"
      ],
      "developerVisibleActions": [
        "Developer creates FileRequest objects with file path and optional reason",
        "Developer creates GrepRequest objects with search pattern, optional file pattern, max results, and reason",
        "Developer receives FileResponse with file content, line count, and existence flag",
        "Developer receives GrepResponse with matches, total match count, and limited flag",
        "Developer gets structured grep matches with file path, line number, content, and optional context",
        "Developer can process file listings organized by directory structure",
        "Developer handles both successful file reads and missing file scenarios",
        "Developer works with workspace-relative paths through the FileAccessHelper instance"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Organizes and formats a list of files grouped by their containing folders",
          "inputs": "Array of file objects with path, optional lines, and optional language",
          "outputs": "String representation of files organized by folder structure"
        },
        {
          "name": "processRequest",
          "desc": "Processes either a file read request or grep search request and returns appropriate response",
          "inputs": "LLMRequest (FileRequest or GrepRequest)",
          "outputs": "FileResponse or GrepResponse depending on request type"
        },
        {
          "name": "readFile",
          "desc": "Reads a specific file from the workspace and returns its content with metadata",
          "inputs": "File path string",
          "outputs": "FileResponse with content, line count, and exists flag"
        },
        {
          "name": "grepSearch",
          "desc": "Searches for a text pattern across files with optional filtering and result limiting",
          "inputs": "GrepRequest with pattern, optional file pattern, max results, and reason",
          "outputs": "GrepResponse with matching lines, context, total count, and limited flag"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to enable LLMs to iteratively explore and analyze codebases by providing controlled file access and search capabilities, allowing LLMs to request specific files or search for patterns as needed during analysis rather than loading entire codebases upfront",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative code analysis by LLMs within a workspace\",\n  \"userVisibleActions\": [\n    \"Users can request to read specific files by providing a file path\",\n    \"Users can search for text patterns across multiple files using grep-like functionality\",\n    \"Users receive file contents with line counts and existence status\",\n    \"Users get search results showing matching lines with file locations and line numbers\",\n    \"Users can see context lines before and after grep matches\",\n    \"Users can limit search scope using file patterns (e.g., '*.ts', 'src/**/*.ts')\",\n    \"Users can control maximum number of search results returned\",\n    \"Users receive organized file listings grouped by folder\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates FileRequest objects with file path and optional reason\",\n    \"Developer creates GrepRequest objects with search pattern, optional file pattern, max results, and reason\",\n    \"Developer receives FileResponse with file content, line count, and existence flag\",\n    \"Developer receives GrepResponse with matches, total match count, and limited flag\",\n    \"Developer gets structured grep matches with file path, line number, content, and optional context\",\n    \"Developer can process file listings organized by directory structure\",\n    \"Developer handles both successful file reads and missing file scenarios\",\n    \"Developer works with workspace-relative paths through the FileAccessHelper instance\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Organizes and formats a list of files grouped by their containing folders\",\n      \"inputs\": \"Array of file objects with path, optional lines, and optional language\",\n      \"outputs\": \"String representation of files organized by folder structure\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Processes either a file read request or grep search request and returns appropriate response\",\n      \"inputs\": \"LLMRequest (FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a specific file from the workspace and returns its content with metadata\",\n      \"inputs\": \"File path string\",\n      \"outputs\": \"FileResponse with content, line count, and exists flag\"\n    },\n    {\n      \"name\": \"grepSearch\",\n      \"desc\": \"Searches for a text pattern across files with optional filtering and result limiting\",\n      \"inputs\": \"GrepRequest with pattern, optional file pattern, max results, and reason\",\n      \"outputs\": \"GrepResponse with matching lines, context, total count, and limited flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable LLMs to iteratively explore and analyze codebases by providing controlled file access and search capabilities, allowing LLMs to request specific files or search for patterns as needed during analysis rather than loading entire codebases upfront\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces and types for multi-level code documentation system (file  module  product  full aggregation)",
      "userVisibleActions": [
        "Users can view structured documentation showing what the product does from their perspective (GUI, CLI, API, CI/CD workflows)",
        "Users can see product capabilities organized by how they interact with the system",
        "Users can understand what problems the product solves and how it integrates into workflows"
      ],
      "developerVisibleActions": [
        "Developer defines file-level documentation structure including role, purpose, and user/developer visible actions",
        "Developer organizes files into module summaries with endpoints, commands, or workers",
        "Developer creates product-level documentation with overview, architecture diagrams, and workflow integration",
        "Developer structures documentation with titles, descriptions, and behavioral sections",
        "Developer aggregates all documentation levels into a complete reference document"
      ],
      "keyFunctions": [],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "Provides the type definitions and data structures for a hierarchical documentation system that captures what code does from user and developer perspectives across four levels: individual files, modules, product features, and complete product documentation. Enables documentation generation that focuses on behavior and outcomes rather than implementation details.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and types for multi-level code documentation system (file  module  product  full aggregation)\",\n  \"userVisibleActions\": [\n    \"Users can view structured documentation showing what the product does from their perspective (GUI, CLI, API, CI/CD workflows)\",\n    \"Users can see product capabilities organized by how they interact with the system\",\n    \"Users can understand what problems the product solves and how it integrates into workflows\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file-level documentation structure including role, purpose, and user/developer visible actions\",\n    \"Developer organizes files into module summaries with endpoints, commands, or workers\",\n    \"Developer creates product-level documentation with overview, architecture diagrams, and workflow integration\",\n    \"Developer structures documentation with titles, descriptions, and behavioral sections\",\n    \"Developer aggregates all documentation levels into a complete reference document\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Provides the type definitions and data structures for a hierarchical documentation system that captures what code does from user and developer perspectives across four levels: individual files, modules, product features, and complete product documentation. Enables documentation generation that focuses on behavior and outcomes rather than implementation details.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file saves in the workspace and automatically triggers code analysis when files are saved",
      "userVisibleActions": [
        "Automatically analyzes code when files are saved (if 'analyze on save' is enabled)",
        "Provides real-time feedback on code quality after saving",
        "Shows insights and diagnostics in the editor after file changes",
        "Batches multiple rapid saves together to avoid overwhelming the system",
        "Respects user's 'analyze on save' configuration setting"
      ],
      "developerVisibleActions": [
        "Starts and stops file watching based on configuration",
        "Debounces file save events to prevent excessive analysis",
        "Coordinates analysis workflow across analyzer, insight generator, diagnostics, and tree view",
        "Handles errors during file analysis gracefully",
        "Provides hooks for workspace-level analysis when files change",
        "Exposes status of whether watcher is active (isStarted)",
        "Allows testing by accepting FileWatcherService dependency injection"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins watching for file saves and enables automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops watching for file saves and disables automatic analysis",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save events by scheduling debounced analysis",
          "inputs": "document (TextDocument)",
          "outputs": "void"
        },
        {
          "name": "triggerAnalysis",
          "desc": "Executes the full analysis pipeline on a saved file",
          "inputs": "document (TextDocument)",
          "outputs": "Promise<void>"
        },
        {
          "name": "shouldAnalyzeDocument",
          "desc": "Determines if a document should be analyzed based on file type and configuration",
          "inputs": "document (TextDocument)",
          "outputs": "boolean"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources when the file watcher is no longer needed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "ConfigurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic, on-save code analysis functionality. It solves the problem of keeping code insights up-to-date without requiring manual user intervention. By watching file saves and intelligently debouncing analysis requests, it provides a responsive development experience that gives immediate feedback on code quality while avoiding performance issues from excessive analysis.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file saves in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Automatically analyzes code when files are saved (if 'analyze on save' is enabled)\",\n    \"Provides real-time feedback on code quality after saving\",\n    \"Shows insights and diagnostics in the editor after file changes\",\n    \"Batches multiple rapid saves together to avoid overwhelming the system\",\n    \"Respects user's 'analyze on save' configuration setting\"\n  ],\n  \"developerVisibleActions\": [\n    \"Starts and stops file watching based on configuration\",\n    \"Debounces file save events to prevent excessive analysis\",\n    \"Coordinates analysis workflow across analyzer, insight generator, diagnostics, and tree view\",\n    \"Handles errors during file analysis gracefully\",\n    \"Provides hooks for workspace-level analysis when files change\",\n    \"Exposes status of whether watcher is active (isStarted)\",\n    \"Allows testing by accepting FileWatcherService dependency injection\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file saves and enables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file saves and disables automatic analysis\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events by scheduling debounced analysis\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"triggerAnalysis\",\n      \"desc\": \"Executes the full analysis pipeline on a saved file\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"shouldAnalyzeDocument\",\n      \"desc\": \"Determines if a document should be analyzed based on file type and configuration\",\n      \"inputs\": \"document (TextDocument)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources when the file watcher is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, on-save code analysis functionality. It solves the problem of keeping code insights up-to-date without requiring manual user intervention. By watching file saves and intelligently debouncing analysis requests, it provides a responsive development experience that gives immediate feedback on code quality while avoiding performance issues from excessive analysis.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Optimizes file system operations by caching file contents to reduce redundant reads across multiple components",
      "userVisibleActions": [
        "Files load faster when accessed multiple times within a short period",
        "Extension responds more quickly when working with the same files repeatedly",
        "Automatic detection when files change on disk to ensure fresh content is always available"
      ],
      "developerVisibleActions": [
        "Cache automatically retrieves and stores file contents on first access",
        "Cache invalidates entries when files are modified, deleted, or become stale",
        "LRU eviction policy automatically removes old entries when cache reaches size limit",
        "File system watcher monitors for external file changes and updates cache accordingly",
        "Cache statistics track hits, misses, and evictions for performance monitoring"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath: string",
          "outputs": "Promise<string> - file content"
        },
        {
          "name": "invalidate",
          "desc": "Removes a specific file from the cache, forcing fresh read on next access",
          "inputs": "filePath: string",
          "outputs": "void"
        },
        {
          "name": "clear",
          "desc": "Removes all cached files and resets cache statistics",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getStats",
          "desc": "Returns cache performance statistics including hits, misses, evictions, and size",
          "inputs": "none",
          "outputs": "CacheStats object"
        },
        {
          "name": "dispose",
          "desc": "Cleans up resources including file system watcher when cache is no longer needed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "This file exists to improve extension performance by eliminating redundant file system reads. When multiple components need to access the same files repeatedly, the cache serves content from memory instead of disk, reducing I/O operations and improving responsiveness. It solves the problem of slow file access patterns common in analysis and refactoring operations where the same files are read multiple times in quick succession.",
      "rawContent": "```json\n{\n  \"purpose\": \"Optimizes file system operations by caching file contents to reduce redundant reads across multiple components\",\n  \"userVisibleActions\": [\n    \"Files load faster when accessed multiple times within a short period\",\n    \"Extension responds more quickly when working with the same files repeatedly\",\n    \"Automatic detection when files change on disk to ensure fresh content is always available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Cache automatically retrieves and stores file contents on first access\",\n    \"Cache invalidates entries when files are modified, deleted, or become stale\",\n    \"LRU eviction policy automatically removes old entries when cache reaches size limit\",\n    \"File system watcher monitors for external file changes and updates cache accordingly\",\n    \"Cache statistics track hits, misses, and evictions for performance monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> - file content\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file from the cache, forcing fresh read on next access\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached files and resets cache statistics\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance statistics including hits, misses, evictions, and size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up resources including file system watcher when cache is no longer needed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to improve extension performance by eliminating redundant file system reads. When multiple components need to access the same files repeatedly, the cache serves content from memory instead of disk, reducing I/O operations and improving responsiveness. It solves the problem of slow file access patterns common in analysis and refactoring operations where the same files are read multiple times in quick succession.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with error handling",
      "userVisibleActions": [
        "Files matching skip patterns (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea) are automatically excluded from processing",
        "Multiple files are processed simultaneously for faster results",
        "Errors during file processing are handled gracefully without crashing the application"
      ],
      "developerVisibleActions": [
        "Developer calls processFiles() with an array of file paths and a custom processing function",
        "Files are automatically filtered using configurable filter patterns before processing",
        "Each file's content is read and passed to the developer's processing function",
        "Results from all processed files are collected and returned as an array",
        "Custom file filters and readers can be injected to override default behavior",
        "Error context can be provided to track where processing failures occur"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines whether a file path should be processed based on filter patterns",
          "inputs": "filePath: string",
          "outputs": "boolean (true if file should be processed)"
        },
        {
          "name": "readFile",
          "desc": "Reads the content of a file as UTF-8 text",
          "inputs": "filePath: string",
          "outputs": "Promise<string> (file content)"
        },
        {
          "name": "processFiles",
          "desc": "Filters, reads, and processes multiple files in parallel using a custom processor function",
          "inputs": "files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext",
          "outputs": "Promise<T[]> (array of processed results)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "../../utils/errorHandler"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a centralized, configurable, and reusable file processing pipeline that handles filtering, reading, parallel processing, and error handling in one place",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a unified, reusable system for filtering, reading, and processing multiple files in parallel with error handling\",\n  \"userVisibleActions\": [\n    \"Files matching skip patterns (node_modules, .git, dist, build, .shadow, coverage, .vscode, .idea) are automatically excluded from processing\",\n    \"Multiple files are processed simultaneously for faster results\",\n    \"Errors during file processing are handled gracefully without crashing the application\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls processFiles() with an array of file paths and a custom processing function\",\n    \"Files are automatically filtered using configurable filter patterns before processing\",\n    \"Each file's content is read and passed to the developer's processing function\",\n    \"Results from all processed files are collected and returned as an array\",\n    \"Custom file filters and readers can be injected to override default behavior\",\n    \"Error context can be provided to track where processing failures occur\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines whether a file path should be processed based on filter patterns\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean (true if file should be processed)\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads the content of a file as UTF-8 text\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string> (file content)\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Filters, reads, and processes multiple files in parallel using a custom processor function\",\n      \"inputs\": \"files: string[], processor: (content, filePath) => Promise<T>, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]> (array of processed results)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"../../utils/errorHandler\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns throughout the codebase by providing a centralized, configurable, and reusable file processing pipeline that handles filtering, reading, parallel processing, and error handling in one place\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages persistence and storage of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory",
      "userVisibleActions": [
        "Product documentation is saved to timestamped directories in .shadow/docs",
        "Architecture insights are saved to timestamped directories in .shadow/insights",
        "Summary files are created combining all analysis results",
        "Incremental documentation updates are stored with timestamps",
        "Consolidated documentation files are generated from multiple analyses"
      ],
      "developerVisibleActions": [
        "Initialize product documentation run to create storage directories",
        "Initialize architecture insights run to create storage directories",
        "Save enhanced product documentation with formatted output",
        "Save architecture insights with formatted output",
        "Save summary files combining product docs and insights",
        "Store documentation updates incrementally with timestamps",
        "Retrieve latest documentation from storage",
        "Get consolidated documentation from all runs",
        "Finalize runs by creating summary files"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Creates a new timestamped directory for storing product documentation results",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Creates a new timestamped directory for storing architecture insights results",
          "inputs": "workspaceRoot: string",
          "outputs": "string (path to run directory)"
        },
        {
          "name": "saveProductDocs",
          "desc": "Saves enhanced product documentation to the current run directory",
          "inputs": "workspaceRoot: string, docs: EnhancedProductDocumentation",
          "outputs": "void"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Saves architecture insights to the current run directory",
          "inputs": "workspaceRoot: string, insights: LLMInsights",
          "outputs": "void"
        },
        {
          "name": "saveSummary",
          "desc": "Creates a summary file combining product docs and architecture insights",
          "inputs": "workspaceRoot: string, productDocs: EnhancedProductDocumentation, insights: LLMInsights",
          "outputs": "void"
        },
        {
          "name": "finalizeProductDocsRun",
          "desc": "Completes the product docs run by creating final summary files",
          "inputs": "workspaceRoot: string",
          "outputs": "void"
        },
        {
          "name": "finalizeArchitectureInsightsRun",
          "desc": "Completes the architecture insights run by creating final summary files",
          "inputs": "workspaceRoot: string",
          "outputs": "void"
        },
        {
          "name": "storeDocumentationUpdate",
          "desc": "Saves incremental documentation updates with timestamps",
          "inputs": "workspaceRoot: string, filePath: string, documentation: any",
          "outputs": "Promise<void>"
        },
        {
          "name": "getLatestDocumentation",
          "desc": "Retrieves the most recent documentation for a file",
          "inputs": "workspaceRoot: string, filePath: string",
          "outputs": "Promise<any | null>"
        },
        {
          "name": "getConsolidatedDocumentation",
          "desc": "Gets all documentation from all timestamped runs",
          "inputs": "workspaceRoot: string",
          "outputs": "Promise<Record<string, any>>"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "fileDocumentation (EnhancedProductDocumentation)",
        "llmService (LLMInsights)",
        "domain/formatters/documentationFormatter",
        "storage/incrementalStorage"
      ],
      "intent": "Separates persistence concerns from LLM integration by providing a dedicated repository for storing and retrieving all AI-generated analysis results, enabling organized storage with timestamps, incremental updates, and consolidated views of documentation across multiple analysis runs",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistence and storage of AI-generated analysis results including product documentation, architecture insights, and summaries to the workspace's .shadow directory\",\n  \"userVisibleActions\": [\n    \"Product documentation is saved to timestamped directories in .shadow/docs\",\n    \"Architecture insights are saved to timestamped directories in .shadow/insights\",\n    \"Summary files are created combining all analysis results\",\n    \"Incremental documentation updates are stored with timestamps\",\n    \"Consolidated documentation files are generated from multiple analyses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize product documentation run to create storage directories\",\n    \"Initialize architecture insights run to create storage directories\",\n    \"Save enhanced product documentation with formatted output\",\n    \"Save architecture insights with formatted output\",\n    \"Save summary files combining product docs and insights\",\n    \"Store documentation updates incrementally with timestamps\",\n    \"Retrieve latest documentation from storage\",\n    \"Get consolidated documentation from all runs\",\n    \"Finalize runs by creating summary files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture insights results\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (path to run directory)\"\n    },\n    {\n      \"name\": \"saveProductDocs\",\n      \"desc\": \"Saves enhanced product documentation to the current run directory\",\n      \"inputs\": \"workspaceRoot: string, docs: EnhancedProductDocumentation\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights to the current run directory\",\n      \"inputs\": \"workspaceRoot: string, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Creates a summary file combining product docs and architecture insights\",\n      \"inputs\": \"workspaceRoot: string, productDocs: EnhancedProductDocumentation, insights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeProductDocsRun\",\n      \"desc\": \"Completes the product docs run by creating final summary files\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"finalizeArchitectureInsightsRun\",\n      \"desc\": \"Completes the architecture insights run by creating final summary files\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"storeDocumentationUpdate\",\n      \"desc\": \"Saves incremental documentation updates with timestamps\",\n      \"inputs\": \"workspaceRoot: string, filePath: string, documentation: any\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getLatestDocumentation\",\n      \"desc\": \"Retrieves the most recent documentation for a file\",\n      \"inputs\": \"workspaceRoot: string, filePath: string\",\n      \"outputs\": \"Promise<any | null>\"\n    },\n    {\n      \"name\": \"getConsolidatedDocumentation\",\n      \"desc\": \"Gets all documentation from all timestamped runs\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Promise<Record<string, any>>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"fileDocumentation (EnhancedProductDocumentation)\",\n    \"llmService (LLMInsights)\",\n    \"domain/formatters/documentationFormatter\",\n    \"storage/incrementalStorage\"\n  ],\n  \"intent\": \"Separates persistence concerns from LLM integration by providing a dedicated repository for storing and retrieving all AI-generated analysis results, enabling organized storage with timestamps, incremental updates, and consolidated views of documentation across multiple analysis runs\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a standardized service for displaying progress notifications to users during long-running operations",
      "userVisibleActions": [
        "See progress notifications with titles and status messages during operations",
        "Cancel ongoing operations via cancel button in progress notification",
        "Track progress of operations with incremental updates",
        "View progress indicators in different locations (notification area, status bar, etc.)"
      ],
      "developerVisibleActions": [
        "Wrap async operations with standardized progress reporting",
        "Display titled progress notifications with customizable messages",
        "Configure progress location (notification, window, etc.)",
        "Enable or disable cancellation for operations",
        "Report progress updates with optional increment values",
        "Access cancellation token to handle user cancellation requests",
        "Use simple string title or full options object for flexibility"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying a progress notification to the user",
          "inputs": "options (title, cancellable flag, location), task function that receives a progress reporter",
          "outputs": "Result of the executed task"
        },
        {
          "name": "report",
          "desc": "Updates the progress notification with a new message and optional progress increment",
          "inputs": "message string, optional increment number",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "Eliminates boilerplate code for progress reporting by providing a consistent, reusable wrapper around VSCode's progress API, ensuring all long-running operations display uniform progress notifications to users",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications to users during long-running operations\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and status messages during operations\",\n    \"Cancel ongoing operations via cancel button in progress notification\",\n    \"Track progress of operations with incremental updates\",\n    \"View progress indicators in different locations (notification area, status bar, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async operations with standardized progress reporting\",\n    \"Display titled progress notifications with customizable messages\",\n    \"Configure progress location (notification, window, etc.)\",\n    \"Enable or disable cancellation for operations\",\n    \"Report progress updates with optional increment values\",\n    \"Access cancellation token to handle user cancellation requests\",\n    \"Use simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title, cancellable flag, location), task function that receives a progress reporter\",\n      \"outputs\": \"Result of the executed task\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress notification with a new message and optional progress increment\",\n      \"inputs\": \"message string, optional increment number\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Eliminates boilerplate code for progress reporting by providing a consistent, reusable wrapper around VSCode's progress API, ensuring all long-running operations display uniform progress notifications to users\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code to generate actionable insights about code quality, organization, and potential issues",
      "userVisibleActions": [
        "Receives warnings about large files exceeding 500 lines of code",
        "Gets notified about orphaned files with no imports or dependencies",
        "Sees alerts for missing entry points in the codebase",
        "Receives warnings about potential circular dependencies between files",
        "Gets notified about 'god objects' (overly complex files or classes)",
        "Sees suggestions for potential dead code that may not be used",
        "Receives recommendations about file organization and structure",
        "Gets warnings about overly complex functions",
        "Views insights categorized by severity (error, warning, info)",
        "Sees specific file locations and line numbers where issues occur",
        "Receives actionable suggestions for improving code quality",
        "Views code snippets highlighting problematic areas"
      ],
      "developerVisibleActions": [
        "Passes CodeAnalysis data to generate comprehensive insights for entire codebase",
        "Requests file-specific insights by providing a file path",
        "Receives structured Insight objects with id, title, description, severity, category, file location, line number, suggestion, and optional code snippet",
        "Gets insights filtered by severity levels (error, warning, info)",
        "Accesses categorized insights (Code Organization, Complexity, Dependencies, etc.)",
        "Integrates insight generation into code analysis workflows",
        "Uses insights to identify refactoring opportunities automatically",
        "Triggers different check methods for specific code quality concerns"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Generates all insights for an entire codebase analysis",
          "inputs": "analysis: CodeAnalysis object containing file and function information",
          "outputs": "Array of Insight objects describing code quality issues and recommendations"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Generates insights specific to a single file",
          "inputs": "analysis: CodeAnalysis object, filePath: string path to target file",
          "outputs": "Array of Insight objects relevant to the specified file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Identifies files exceeding recommended line count thresholds",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for oversized files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Detects files with no imports or dependencies",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for isolated files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Verifies presence of necessary entry point files",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Identifies potential circular dependency patterns",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for circular dependency risks"
        },
        {
          "name": "checkGodObjects",
          "desc": "Detects files or classes with excessive complexity or responsibility",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for overly complex components"
        },
        {
          "name": "checkDeadCode",
          "desc": "Identifies potential unused or unreachable code",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for potentially dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Evaluates file structure and organization patterns",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for organization improvements"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Analyzes function complexity metrics",
          "inputs": "analysis: CodeAnalysis object",
          "outputs": "Array of Insight objects for complex functions"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to transform raw code analysis data into actionable, prioritized insights that help developers identify code quality issues, architectural problems, and refactoring opportunities across their codebase",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code to generate actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"Receives warnings about large files exceeding 500 lines of code\",\n    \"Gets notified about orphaned files with no imports or dependencies\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Receives warnings about potential circular dependencies between files\",\n    \"Gets notified about 'god objects' (overly complex files or classes)\",\n    \"Sees suggestions for potential dead code that may not be used\",\n    \"Receives recommendations about file organization and structure\",\n    \"Gets warnings about overly complex functions\",\n    \"Views insights categorized by severity (error, warning, info)\",\n    \"Sees specific file locations and line numbers where issues occur\",\n    \"Receives actionable suggestions for improving code quality\",\n    \"Views code snippets highlighting problematic areas\"\n  ],\n  \"developerVisibleActions\": [\n    \"Passes CodeAnalysis data to generate comprehensive insights for entire codebase\",\n    \"Requests file-specific insights by providing a file path\",\n    \"Receives structured Insight objects with id, title, description, severity, category, file location, line number, suggestion, and optional code snippet\",\n    \"Gets insights filtered by severity levels (error, warning, info)\",\n    \"Accesses categorized insights (Code Organization, Complexity, Dependencies, etc.)\",\n    \"Integrates insight generation into code analysis workflows\",\n    \"Uses insights to identify refactoring opportunities automatically\",\n    \"Triggers different check methods for specific code quality concerns\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Generates all insights for an entire codebase analysis\",\n      \"inputs\": \"analysis: CodeAnalysis object containing file and function information\",\n      \"outputs\": \"Array of Insight objects describing code quality issues and recommendations\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Generates insights specific to a single file\",\n      \"inputs\": \"analysis: CodeAnalysis object, filePath: string path to target file\",\n      \"outputs\": \"Array of Insight objects relevant to the specified file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Identifies files exceeding recommended line count thresholds\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Detects files with no imports or dependencies\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for isolated files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies presence of necessary entry point files\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Identifies potential circular dependency patterns\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for circular dependency risks\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Detects files or classes with excessive complexity or responsibility\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for overly complex components\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Identifies potential unused or unreachable code\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for potentially dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Evaluates file structure and organization patterns\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for organization improvements\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Analyzes function complexity metrics\",\n      \"inputs\": \"analysis: CodeAnalysis object\",\n      \"outputs\": \"Array of Insight objects for complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, prioritized insights that help developers identify code quality issues, architectural problems, and refactoring opportunities across their codebase\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view interface for displaying and managing AI-generated code insights, documentation, test reports, and analysis results in the VS Code sidebar.",
      "userVisibleActions": [
        "View code insights organized in a tree structure with categories like Product Docs, Unit Tests, and Analysis",
        "Click 'Generate Product Docs' to create AI-generated documentation for the codebase",
        "Click 'Generate Insights' to get AI-powered code analysis and suggestions",
        "Click 'Generate Unit Tests' to create automated test cases",
        "View timestamps showing when each report was last generated",
        "Open generated reports (HTML files) in the browser or editor",
        "Copy report file paths to clipboard",
        "Reveal report files in the file explorer",
        "See loading indicators while reports are being generated",
        "View different report types: workspace overview, product docs, architecture, unit tests, and static analysis",
        "Refresh the insights tree to see updated information",
        "Expand and collapse insight categories to organize information"
      ],
      "developerVisibleActions": [
        "Tree provider updates automatically when insights are generated or status changes",
        "Insights are persisted across VS Code sessions using context state",
        "Report file paths and timestamps are tracked and restored on extension reload",
        "Status indicators show whether generation is idle, in progress, or complete",
        "Integration with LLM services to generate content asynchronously",
        "Tree items are created dynamically based on available insights and reports",
        "File system checks verify report existence before displaying items",
        "Context menu actions are available based on item type (copy path, reveal in explorer, open in browser)",
        "Icons and decorations indicate status (loading spinner, checkmarks, etc.)"
      ],
      "keyFunctions": [
        {
          "name": "getTreeItem",
          "desc": "Converts internal data into tree items for VS Code's tree view display",
          "inputs": "TreeItem element",
          "outputs": "vscode.TreeItem with label, icon, and command"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for tree hierarchy, showing insights categories and individual reports",
          "inputs": "Optional parent TreeItem",
          "outputs": "Array of TreeItem children or null"
        },
        {
          "name": "updateInsights",
          "desc": "Updates the displayed insights and refreshes the tree view",
          "inputs": "Array of Insight objects",
          "outputs": "void"
        },
        {
          "name": "setProductDocsStatus",
          "desc": "Updates the generation status for product documentation and refreshes display",
          "inputs": "Status string (idle/generating/complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setInsightsStatus",
          "desc": "Updates the generation status for insights and refreshes display",
          "inputs": "Status string (idle/generating/complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setUnitTestStatus",
          "desc": "Updates the generation status for unit tests and refreshes display",
          "inputs": "Status string (idle/generating/complete) and optional timestamp",
          "outputs": "void"
        },
        {
          "name": "setReportPath",
          "desc": "Stores the file path for a generated report and updates display",
          "inputs": "File path string and report type, optional timestamp",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a complete refresh of the tree view display",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "loadPersistedState",
          "desc": "Restores saved timestamps and report paths from previous sessions",
          "inputs": "None",
          "outputs": "Promise<void>"
        },
        {
          "name": "setLLMService",
          "desc": "Configures the LLM service used for generating insights",
          "inputs": "LLMService instance",
          "outputs": "void"
        },
        {
          "name": "setLLMInsights",
          "desc": "Updates the LLM-generated insights data and refreshes display",
          "inputs": "LLMInsights object",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator",
        "./llmFormatter",
        "./llmService"
      ],
      "intent": "This file exists to provide a visual interface in VS Code's sidebar where users can view, manage, and interact with AI-generated code documentation, insights, and analysis reports. It solves the problem of presenting complex analysis results in an organized, accessible tree structure with actions to generate, view, and manage different types of code intelligence reports.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface for displaying and managing AI-generated code insights, documentation, test reports, and analysis results in the VS Code sidebar.\",\n  \"userVisibleActions\": [\n    \"View code insights organized in a tree structure with categories like Product Docs, Unit Tests, and Analysis\",\n    \"Click 'Generate Product Docs' to create AI-generated documentation for the codebase\",\n    \"Click 'Generate Insights' to get AI-powered code analysis and suggestions\",\n    \"Click 'Generate Unit Tests' to create automated test cases\",\n    \"View timestamps showing when each report was last generated\",\n    \"Open generated reports (HTML files) in the browser or editor\",\n    \"Copy report file paths to clipboard\",\n    \"Reveal report files in the file explorer\",\n    \"See loading indicators while reports are being generated\",\n    \"View different report types: workspace overview, product docs, architecture, unit tests, and static analysis\",\n    \"Refresh the insights tree to see updated information\",\n    \"Expand and collapse insight categories to organize information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree provider updates automatically when insights are generated or status changes\",\n    \"Insights are persisted across VS Code sessions using context state\",\n    \"Report file paths and timestamps are tracked and restored on extension reload\",\n    \"Status indicators show whether generation is idle, in progress, or complete\",\n    \"Integration with LLM services to generate content asynchronously\",\n    \"Tree items are created dynamically based on available insights and reports\",\n    \"File system checks verify report existence before displaying items\",\n    \"Context menu actions are available based on item type (copy path, reveal in explorer, open in browser)\",\n    \"Icons and decorations indicate status (loading spinner, checkmarks, etc.)\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts internal data into tree items for VS Code's tree view display\",\n      \"inputs\": \"TreeItem element\",\n      \"outputs\": \"vscode.TreeItem with label, icon, and command\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for tree hierarchy, showing insights categories and individual reports\",\n      \"inputs\": \"Optional parent TreeItem\",\n      \"outputs\": \"Array of TreeItem children or null\"\n    },\n    {\n      \"name\": \"updateInsights\",\n      \"desc\": \"Updates the displayed insights and refreshes the tree view\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the generation status for product documentation and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the generation status for insights and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the generation status for unit tests and refreshes display\",\n      \"inputs\": \"Status string (idle/generating/complete) and optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Stores the file path for a generated report and updates display\",\n      \"inputs\": \"File path string and report type, optional timestamp\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a complete refresh of the tree view display\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores saved timestamps and report paths from previous sessions\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Configures the LLM service used for generating insights\",\n      \"inputs\": \"LLMService instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the LLM-generated insights data and refreshes display\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./llmService\"\n  ],\n  \"intent\": \"This file exists to provide a visual interface in VS Code's sidebar where users can view, manage, and interact with AI-generated code documentation, insights, and analysis reports. It solves the problem of presenting complex analysis results in an organized, accessible tree structure with actions to generate, view, and manage different types of code intelligence reports.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view in VSCode for browsing and navigating AI-generated architecture insights about the codebase",
      "userVisibleActions": [
        "View hierarchical insights tree showing architecture, decisions, principles, patterns, and risks",
        "Navigate to specific code files by clicking on file references in insights",
        "See file paths and line numbers associated with insights",
        "Refresh insights view to see updated analysis results",
        "Expand/collapse insight categories and subcategories",
        "View purpose documentation and architectural decisions in tree structure"
      ],
      "developerVisibleActions": [
        "Tree view automatically refreshes when .shadow/docs/insights.json file changes",
        "Tree view automatically updates when purpose.md file is modified",
        "Can manually refresh the insights view via command",
        "Set custom insights data programmatically via setInsights method",
        "File watchers monitor .shadow directory for changes",
        "Click on items to navigate to referenced source files"
      ],
      "keyFunctions": [
        {
          "name": "refresh",
          "desc": "Reloads insights from the .shadow/docs/insights.json file and updates the tree view",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts insight data into displayable tree items with icons and navigation",
          "inputs": "InsightItem",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given parent in the tree hierarchy",
          "inputs": "InsightItem or undefined",
          "outputs": "Promise<InsightItem[]>"
        },
        {
          "name": "setInsights",
          "desc": "Updates the insights data and refreshes the tree view",
          "inputs": "LLMInsights object",
          "outputs": "void"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Creates file system watchers to auto-refresh when insights or purpose files change",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "handleItemClick",
          "desc": "Opens source code file at specific line when user clicks an insight item with file reference",
          "inputs": "InsightItem",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs",
        "LLMInsights from ./llmService",
        "FileWatcherService from ./domain/services/fileWatcherService"
      ],
      "intent": "This file exists to provide developers with an organized, browsable view of AI-generated architecture insights within VSCode. It solves the problem of making complex architecture analysis accessible and navigable, allowing developers to understand project structure, design decisions, and potential risks through a familiar tree-view interface with direct navigation to relevant code locations.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view in VSCode for browsing and navigating AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View hierarchical insights tree showing architecture, decisions, principles, patterns, and risks\",\n    \"Navigate to specific code files by clicking on file references in insights\",\n    \"See file paths and line numbers associated with insights\",\n    \"Refresh insights view to see updated analysis results\",\n    \"Expand/collapse insight categories and subcategories\",\n    \"View purpose documentation and architectural decisions in tree structure\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically refreshes when .shadow/docs/insights.json file changes\",\n    \"Tree view automatically updates when purpose.md file is modified\",\n    \"Can manually refresh the insights view via command\",\n    \"Set custom insights data programmatically via setInsights method\",\n    \"File watchers monitor .shadow directory for changes\",\n    \"Click on items to navigate to referenced source files\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from the .shadow/docs/insights.json file and updates the tree view\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts insight data into displayable tree items with icons and navigation\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given parent in the tree hierarchy\",\n      \"inputs\": \"InsightItem or undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data and refreshes the tree view\",\n      \"inputs\": \"LLMInsights object\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers to auto-refresh when insights or purpose files change\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"handleItemClick\",\n      \"desc\": \"Opens source code file at specific line when user clicks an insight item with file reference\",\n      \"inputs\": \"InsightItem\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"LLMInsights from ./llmService\",\n    \"FileWatcherService from ./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide developers with an organized, browsable view of AI-generated architecture insights within VSCode. It solves the problem of making complex architecture analysis accessible and navigable, allowing developers to understand project structure, design decisions, and potential risks through a familiar tree-view interface with direct navigation to relevant code locations.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different presentation styles optimized for various AI assistants and human readers",
      "userVisibleActions": [
        "View architecture issues organized by severity (errors, warnings, info)",
        "See insights formatted for specific AI tools (Cursor, ChatGPT)",
        "Read compact summaries of code issues",
        "Review generic formatted reports of code problems",
        "Get actionable recommendations for fixing architecture issues",
        "See file locations and line numbers for each issue",
        "Understand impact and resolution suggestions for problems"
      ],
      "developerVisibleActions": [
        "Call formatInsights() to convert insight objects into formatted text reports",
        "Choose output format: 'cursor', 'chatgpt', 'compact', or 'generic'",
        "Receive markdown-formatted strings ready for display or AI consumption",
        "Get insights grouped by severity level automatically",
        "Obtain format-specific prompts and instructions for AI assistants",
        "Access structured reports with file paths, descriptions, and recommendations"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Converts insight objects into formatted text based on specified output format",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "Formatted string (markdown) tailored for the specified format"
        },
        {
          "name": "formatForCursor",
          "desc": "Creates Cursor AI-optimized report with severity grouping and action prompts",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string with sections for errors, warnings, info, and assistance requests"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Generates ChatGPT-friendly report with conversational tone and context",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string formatted for ChatGPT's interaction style"
        },
        {
          "name": "formatCompact",
          "desc": "Produces condensed summary showing only essential information",
          "inputs": "insights: Insight[]",
          "outputs": "Brief markdown string with counts and key issues"
        },
        {
          "name": "formatGeneric",
          "desc": "Creates standard format suitable for any AI assistant or human reader",
          "inputs": "insights: Insight[]",
          "outputs": "Generic markdown string with all insights listed sequentially"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats a single insight with full details for Cursor AI",
          "inputs": "insight: Insight",
          "outputs": "Formatted markdown string for one insight"
        },
        {
          "name": "formatInsightForChatGPT",
          "desc": "Formats a single insight optimized for ChatGPT interaction",
          "inputs": "insight: Insight",
          "outputs": "Formatted markdown string for one insight"
        },
        {
          "name": "formatInsightCompact",
          "desc": "Formats a single insight in condensed one-line format",
          "inputs": "insight: Insight",
          "outputs": "Brief string with essential insight information"
        },
        {
          "name": "formatInsightGeneric",
          "desc": "Formats a single insight in standard detailed format",
          "inputs": "insight: Insight",
          "outputs": "Generic formatted string for one insight"
        }
      ],
      "dependencies": [
        "./insightGenerator"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis data and AI-consumable formats, transforming technical insights into structured reports that different AI assistants (Cursor, ChatGPT) can understand and act upon, while also providing human-readable formats for developers to review code architecture issues",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different presentation styles optimized for various AI assistants and human readers\",\n  \"userVisibleActions\": [\n    \"View architecture issues organized by severity (errors, warnings, info)\",\n    \"See insights formatted for specific AI tools (Cursor, ChatGPT)\",\n    \"Read compact summaries of code issues\",\n    \"Review generic formatted reports of code problems\",\n    \"Get actionable recommendations for fixing architecture issues\",\n    \"See file locations and line numbers for each issue\",\n    \"Understand impact and resolution suggestions for problems\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call formatInsights() to convert insight objects into formatted text reports\",\n    \"Choose output format: 'cursor', 'chatgpt', 'compact', or 'generic'\",\n    \"Receive markdown-formatted strings ready for display or AI consumption\",\n    \"Get insights grouped by severity level automatically\",\n    \"Obtain format-specific prompts and instructions for AI assistants\",\n    \"Access structured reports with file paths, descriptions, and recommendations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Converts insight objects into formatted text based on specified output format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string (markdown) tailored for the specified format\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized report with severity grouping and action prompts\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with sections for errors, warnings, info, and assistance requests\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Generates ChatGPT-friendly report with conversational tone and context\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string formatted for ChatGPT's interaction style\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Produces condensed summary showing only essential information\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Brief markdown string with counts and key issues\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format suitable for any AI assistant or human reader\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Generic markdown string with all insights listed sequentially\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats a single insight with full details for Cursor AI\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats a single insight optimized for ChatGPT interaction\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted markdown string for one insight\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats a single insight in condensed one-line format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Brief string with essential insight information\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats a single insight in standard detailed format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Generic formatted string for one insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis data and AI-consumable formats, transforming technical insights into structured reports that different AI assistants (Cursor, ChatGPT) can understand and act upon, while also providing human-readable formats for developers to review code architecture issues\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Integrates LLM-powered analysis features with VS Code UI components and manages the lifecycle of code analysis, documentation generation, and insights display.",
      "userVisibleActions": [
        "View AI-generated code insights in a tree view sidebar",
        "Access product documentation with AI-enhanced descriptions",
        "Navigate codebase structure through AI-analyzed entry points",
        "View unit test analysis and coverage information",
        "See analysis results in dedicated viewer panels",
        "Refresh insights manually via command palette or UI buttons",
        "Configure LLM API keys through VS Code settings",
        "Export analysis results and documentation to files",
        "View loading indicators while AI analysis is in progress",
        "Receive notifications when analysis completes or encounters errors"
      ],
      "developerVisibleActions": [
        "Initialize LLM service that connects to AI providers (OpenAI, Anthropic, etc.)",
        "Trigger code analysis on workspace files to extract structure and behavior",
        "Generate product documentation from analyzed code automatically",
        "Load previously saved analysis results and insights from disk",
        "Register VS Code commands for analysis, documentation, and insights management",
        "Set up tree view providers for displaying insights, tests, and navigation",
        "Configure webview panels for rich HTML analysis visualization",
        "Handle configuration changes and API key updates reactively",
        "Manage state persistence across VS Code sessions",
        "Export analysis data in JSON format for external tools"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Sets up the LLM service and connects it to UI components with configuration change handlers",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "analyzeWorkspace",
          "desc": "Analyzes all code files in the workspace to extract structure, entry points, and behavior patterns",
          "inputs": "workspace folder path",
          "outputs": "CodeAnalysis object with insights"
        },
        {
          "name": "generateProductDocumentation",
          "desc": "Creates AI-enhanced documentation from code analysis results",
          "inputs": "CodeAnalysis object",
          "outputs": "EnhancedProductDocumentation object"
        },
        {
          "name": "loadSavedCodeAnalysis",
          "desc": "Retrieves previously saved analysis results from persistent storage",
          "inputs": "workspace identifier",
          "outputs": "CodeAnalysis object or null"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists analysis results to disk for later retrieval",
          "inputs": "CodeAnalysis object, workspace path",
          "outputs": "boolean success status"
        },
        {
          "name": "refreshInsights",
          "desc": "Re-runs AI analysis and updates all tree views and panels with latest insights",
          "inputs": "optional force refresh flag",
          "outputs": "Promise<void>"
        },
        {
          "name": "exportAnalysisResults",
          "desc": "Saves analysis data and documentation to user-specified file location",
          "inputs": "export format, file path",
          "outputs": "Promise<void>"
        },
        {
          "name": "registerCommands",
          "desc": "Registers all VS Code commands for triggering analysis, documentation, and insights features",
          "inputs": "VS Code extension context",
          "outputs": "Disposable array"
        },
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms code analysis results into LLM-compatible context format",
          "inputs": "CodeAnalysis object",
          "outputs": "AnalysisContext object"
        },
        {
          "name": "updateTreeProviders",
          "desc": "Refreshes all tree view providers with updated analysis data",
          "inputs": "analysis results",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "./llmService",
        "./insightsTreeView",
        "./fileDocumentation",
        "./analyzer",
        "./productNavigator",
        "./analysisViewer",
        "./insightsViewer",
        "./unitTestsNavigator",
        "./logger",
        "./state/llmStateManager",
        "./context/analysisContextBuilder",
        "./domain/formatters/documentationFormatter",
        "./infrastructure/persistence/analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis and user-facing AI insights by orchestrating LLM services, managing analysis lifecycle, coordinating multiple UI components (tree views, webviews, navigators), and providing a centralized integration layer that makes AI-powered code understanding accessible through VS Code's interface. It solves the problem of making complex AI analysis results consumable and actionable for developers working in their IDE.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered analysis features with VS Code UI components and manages the lifecycle of code analysis, documentation generation, and insights display.\",\n  \"userVisibleActions\": [\n    \"View AI-generated code insights in a tree view sidebar\",\n    \"Access product documentation with AI-enhanced descriptions\",\n    \"Navigate codebase structure through AI-analyzed entry points\",\n    \"View unit test analysis and coverage information\",\n    \"See analysis results in dedicated viewer panels\",\n    \"Refresh insights manually via command palette or UI buttons\",\n    \"Configure LLM API keys through VS Code settings\",\n    \"Export analysis results and documentation to files\",\n    \"View loading indicators while AI analysis is in progress\",\n    \"Receive notifications when analysis completes or encounters errors\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize LLM service that connects to AI providers (OpenAI, Anthropic, etc.)\",\n    \"Trigger code analysis on workspace files to extract structure and behavior\",\n    \"Generate product documentation from analyzed code automatically\",\n    \"Load previously saved analysis results and insights from disk\",\n    \"Register VS Code commands for analysis, documentation, and insights management\",\n    \"Set up tree view providers for displaying insights, tests, and navigation\",\n    \"Configure webview panels for rich HTML analysis visualization\",\n    \"Handle configuration changes and API key updates reactively\",\n    \"Manage state persistence across VS Code sessions\",\n    \"Export analysis data in JSON format for external tools\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service and connects it to UI components with configuration change handlers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeWorkspace\",\n      \"desc\": \"Analyzes all code files in the workspace to extract structure, entry points, and behavior patterns\",\n      \"inputs\": \"workspace folder path\",\n      \"outputs\": \"CodeAnalysis object with insights\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates AI-enhanced documentation from code analysis results\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"EnhancedProductDocumentation object\"\n    },\n    {\n      \"name\": \"loadSavedCodeAnalysis\",\n      \"desc\": \"Retrieves previously saved analysis results from persistent storage\",\n      \"inputs\": \"workspace identifier\",\n      \"outputs\": \"CodeAnalysis object or null\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists analysis results to disk for later retrieval\",\n      \"inputs\": \"CodeAnalysis object, workspace path\",\n      \"outputs\": \"boolean success status\"\n    },\n    {\n      \"name\": \"refreshInsights\",\n      \"desc\": \"Re-runs AI analysis and updates all tree views and panels with latest insights\",\n      \"inputs\": \"optional force refresh flag\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportAnalysisResults\",\n      \"desc\": \"Saves analysis data and documentation to user-specified file location\",\n      \"inputs\": \"export format, file path\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"registerCommands\",\n      \"desc\": \"Registers all VS Code commands for triggering analysis, documentation, and insights features\",\n      \"inputs\": \"VS Code extension context\",\n      \"outputs\": \"Disposable array\"\n    },\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms code analysis results into LLM-compatible context format\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"AnalysisContext object\"\n    },\n    {\n      \"name\": \"updateTreeProviders\",\n      \"desc\": \"Refreshes all tree view providers with updated analysis data\",\n      \"inputs\": \"analysis results\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"./llmService\",\n    \"./insightsTreeView\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./productNavigator\",\n    \"./analysisViewer\",\n    \"./insightsViewer\",\n    \"./unitTestsNavigator\",\n    \"./logger\",\n    \"./state/llmStateManager\",\n    \"./context/analysisContextBuilder\",\n    \"./domain/formatters/documentationFormatter\",\n    \"./infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and user-facing AI insights by orchestrating LLM services, managing analysis lifecycle, coordinating multiple UI components (tree views, webviews, navigators), and providing a centralized integration layer that makes AI-powered code understanding accessible through VS Code's interface. It solves the problem of making complex AI analysis results consumable and actionable for developers working in their IDE.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure and validate LLM responses for product analysis, code quality issues, behavior extraction, and documentation generation.",
      "userVisibleActions": [
        "Receives structured product purpose analysis explaining what the codebase does and why it's designed that way",
        "Gets organized lists of code quality issues with clear titles, descriptions, and severity levels",
        "Views extracted behavior information from code files in a consistent format",
        "Sees categorized file summaries organized by role (Core Logic, Configuration, etc.)",
        "Receives documentation generation plans with proposed file structures and content outlines"
      ],
      "developerVisibleActions": [
        "Uses schemas to guarantee valid, parseable LLM responses without manual parsing",
        "Ensures LLM outputs include required fields like productPurpose, architectureRationale, and userGoals",
        "Validates that code quality issues contain title, description, severity, and relevant files",
        "Enforces consistent structure for behavior extraction including purpose, actions, and intent",
        "Defines strict response formats for documentation planning with file paths and content sections"
      ],
      "keyFunctions": [
        {
          "name": "productPurposeAnalysisSchema",
          "desc": "Schema for analyzing product purpose and architecture decisions",
          "inputs": "None (schema definition)",
          "outputs": "Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
        },
        {
          "name": "codeQualityIssuesSchema",
          "desc": "Schema for identifying and documenting code quality issues",
          "inputs": "None (schema definition)",
          "outputs": "Object with issues array containing title, description, severity, relevantFiles, tags"
        },
        {
          "name": "behaviorExtractionSchema",
          "desc": "Schema for extracting user-facing and developer-facing behavior from code",
          "inputs": "None (schema definition)",
          "outputs": "Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent"
        },
        {
          "name": "fileCategorizationSchema",
          "desc": "Schema for categorizing files by role with summaries",
          "inputs": "None (schema definition)",
          "outputs": "Object with categorized file summaries by role (Core Logic, UI Components, Configuration, etc.)"
        },
        {
          "name": "documentationPlanSchema",
          "desc": "Schema for generating documentation plans with file structure and content",
          "inputs": "None (schema definition)",
          "outputs": "Object with overview, proposedFiles array, and nextSteps"
        }
      ],
      "dependencies": [],
      "intent": "Provides type-safe schema definitions that ensure Claude AI returns consistent, structured data for product analysis, code quality assessment, behavior extraction, and documentation generation, eliminating the need for fragile response parsing.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate LLM responses for product analysis, code quality issues, behavior extraction, and documentation generation.\",\n  \"userVisibleActions\": [\n    \"Receives structured product purpose analysis explaining what the codebase does and why it's designed that way\",\n    \"Gets organized lists of code quality issues with clear titles, descriptions, and severity levels\",\n    \"Views extracted behavior information from code files in a consistent format\",\n    \"Sees categorized file summaries organized by role (Core Logic, Configuration, etc.)\",\n    \"Receives documentation generation plans with proposed file structures and content outlines\"\n  ],\n  \"developerVisibleActions\": [\n    \"Uses schemas to guarantee valid, parseable LLM responses without manual parsing\",\n    \"Ensures LLM outputs include required fields like productPurpose, architectureRationale, and userGoals\",\n    \"Validates that code quality issues contain title, description, severity, and relevant files\",\n    \"Enforces consistent structure for behavior extraction including purpose, actions, and intent\",\n    \"Defines strict response formats for documentation planning with file paths and content sections\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema for analyzing product purpose and architecture decisions\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"codeQualityIssuesSchema\",\n      \"desc\": \"Schema for identifying and documenting code quality issues\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with issues array containing title, description, severity, relevantFiles, tags\"\n    },\n    {\n      \"name\": \"behaviorExtractionSchema\",\n      \"desc\": \"Schema for extracting user-facing and developer-facing behavior from code\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with purpose, userVisibleActions, developerVisibleActions, keyFunctions, dependencies, intent\"\n    },\n    {\n      \"name\": \"fileCategorizationSchema\",\n      \"desc\": \"Schema for categorizing files by role with summaries\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with categorized file summaries by role (Core Logic, UI Components, Configuration, etc.)\"\n    },\n    {\n      \"name\": \"documentationPlanSchema\",\n      \"desc\": \"Schema for generating documentation plans with file structure and content\",\n      \"inputs\": \"None (schema definition)\",\n      \"outputs\": \"Object with overview, proposedFiles array, and nextSteps\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Provides type-safe schema definitions that ensure Claude AI returns consistent, structured data for product analysis, code quality assessment, behavior extraction, and documentation generation, eliminating the need for fragile response parsing.\"\n}\n```"
    },
    {
      "file": "src/llmService.ts",
      "role": "Core Logic",
      "purpose": "Orchestrates AI-powered code analysis by calling OpenAI/Claude APIs to generate intelligent insights about codebases, including product purpose, architecture analysis, and refactoring suggestions.",
      "userVisibleActions": [
        "Generates comprehensive product documentation explaining what the codebase does and why",
        "Provides intelligent insights about code architecture and design patterns",
        "Analyzes product purpose and core value propositions from code structure",
        "Generates refactoring suggestions for improving code quality",
        "Creates unit test plans for functions and modules",
        "Detects entry points and orphaned files in the codebase",
        "Groups files by modules and analyzes module relationships"
      ],
      "developerVisibleActions": [
        "Calls LLM APIs (OpenAI/Claude) with structured prompts to analyze code",
        "Processes file summaries and module information into AI prompts",
        "Handles rate limiting and retries for API calls automatically",
        "Parses and validates LLM responses against defined schemas",
        "Provides incremental analysis for large codebases to avoid token limits",
        "Manages different LLM providers based on configuration settings",
        "Tracks analysis progress and budget constraints during execution",
        "Exposes methods for product purpose analysis, refactoring analysis, and documentation generation"
      ],
      "keyFunctions": [
        {
          "name": "analyzeProductPurpose",
          "desc": "Analyzes the entire codebase to determine what the product does and its architecture rationale",
          "inputs": "CodeAnalysis object containing file and function metadata",
          "outputs": "ProductPurposeAnalysis with product purpose, architecture rationale, and key insights"
        },
        {
          "name": "generateEnhancedProductDocumentation",
          "desc": "Creates comprehensive product documentation by analyzing file roles, modules, and relationships",
          "inputs": "Array of file paths and workspace root",
          "outputs": "EnhancedProductDocumentation with purpose, architecture, modules, and design patterns"
        },
        {
          "name": "generateLLMInsights",
          "desc": "Generates intelligent insights about code quality, patterns, and potential improvements",
          "inputs": "CodeAnalysis object and analysis context",
          "outputs": "Structured insights including quality metrics, patterns, and recommendations"
        },
        {
          "name": "generateRefactoringSuggestions",
          "desc": "Analyzes a function and provides AI-powered refactoring suggestions",
          "inputs": "Function metadata, file content, and surrounding context",
          "outputs": "Refactoring suggestions with rationale and proposed improvements"
        },
        {
          "name": "generateUnitTestPlan",
          "desc": "Creates a comprehensive unit test plan for a given function",
          "inputs": "Function analysis including code, dependencies, and context",
          "outputs": "Test plan with test cases, edge cases, and mocking strategies"
        },
        {
          "name": "callLLMWithRetry",
          "desc": "Makes API calls to LLM providers with automatic retry logic and rate limiting",
          "inputs": "Prompt text, schema for validation, and optional model preferences",
          "outputs": "Parsed and validated LLM response conforming to the specified schema"
        }
      ],
      "dependencies": [
        "vscode",
        "./fileDocumentation",
        "./analyzer",
        "./analysis/enhancedAnalyzer",
        "./llmSchemas",
        "./fileAccessHelper",
        "./logger",
        "./config/configurationManager",
        "./ai/providers/providerFactory",
        "./ai/llmResponseParser",
        "./ai/llmRateLimiter",
        "./ai/llmRetryHandler",
        "./domain/prompts/promptBuilder",
        "./domain/services/incrementalAnalysisService",
        "./domain/prompts/refactoringPromptBuilder",
        "./analysis/functionAnalyzer"
      ],
      "intent": "This file exists to bridge the gap between raw code analysis and human-understandable insights by leveraging LLM capabilities. It solves the problem of understanding large codebases by automatically generating documentation, detecting architectural patterns, and providing intelligent suggestions for improvements. It abstracts away the complexity of working with different AI providers and handles the challenges of token limits, rate limiting, and response parsing.",
      "rawContent": "```json\n{\n  \"purpose\": \"Orchestrates AI-powered code analysis by calling OpenAI/Claude APIs to generate intelligent insights about codebases, including product purpose, architecture analysis, and refactoring suggestions.\",\n  \"userVisibleActions\": [\n    \"Generates comprehensive product documentation explaining what the codebase does and why\",\n    \"Provides intelligent insights about code architecture and design patterns\",\n    \"Analyzes product purpose and core value propositions from code structure\",\n    \"Generates refactoring suggestions for improving code quality\",\n    \"Creates unit test plans for functions and modules\",\n    \"Detects entry points and orphaned files in the codebase\",\n    \"Groups files by modules and analyzes module relationships\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls LLM APIs (OpenAI/Claude) with structured prompts to analyze code\",\n    \"Processes file summaries and module information into AI prompts\",\n    \"Handles rate limiting and retries for API calls automatically\",\n    \"Parses and validates LLM responses against defined schemas\",\n    \"Provides incremental analysis for large codebases to avoid token limits\",\n    \"Manages different LLM providers based on configuration settings\",\n    \"Tracks analysis progress and budget constraints during execution\",\n    \"Exposes methods for product purpose analysis, refactoring analysis, and documentation generation\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Analyzes the entire codebase to determine what the product does and its architecture rationale\",\n      \"inputs\": \"CodeAnalysis object containing file and function metadata\",\n      \"outputs\": \"ProductPurposeAnalysis with product purpose, architecture rationale, and key insights\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates comprehensive product documentation by analyzing file roles, modules, and relationships\",\n      \"inputs\": \"Array of file paths and workspace root\",\n      \"outputs\": \"EnhancedProductDocumentation with purpose, architecture, modules, and design patterns\"\n    },\n    {\n      \"name\": \"generateLLMInsights\",\n      \"desc\": \"Generates intelligent insights about code quality, patterns, and potential improvements\",\n      \"inputs\": \"CodeAnalysis object and analysis context\",\n      \"outputs\": \"Structured insights including quality metrics, patterns, and recommendations\"\n    },\n    {\n      \"name\": \"generateRefactoringSuggestions\",\n      \"desc\": \"Analyzes a function and provides AI-powered refactoring suggestions\",\n      \"inputs\": \"Function metadata, file content, and surrounding context\",\n      \"outputs\": \"Refactoring suggestions with rationale and proposed improvements\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Creates a comprehensive unit test plan for a given function\",\n      \"inputs\": \"Function analysis including code, dependencies, and context\",\n      \"outputs\": \"Test plan with test cases, edge cases, and mocking strategies\"\n    },\n    {\n      \"name\": \"callLLMWithRetry\",\n      \"desc\": \"Makes API calls to LLM providers with automatic retry logic and rate limiting\",\n      \"inputs\": \"Prompt text, schema for validation, and optional model preferences\",\n      \"outputs\": \"Parsed and validated LLM response conforming to the specified schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw code analysis and human-understandable insights by leveraging LLM capabilities. It solves the problem of understanding large codebases by automatically generating documentation, detecting architectural patterns, and providing intelligent suggestions for improvements. It abstracts away the complexity of working with different AI providers and handles the challenges of token limits, rate limiting, and response parsing.\"\n}\n```"
    },
    {
      "file": "src/logger.ts",
      "role": "Core Logic",
      "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
      "userVisibleActions": [
        "Log files are automatically created in the .shadow/logs/ directory of the workspace",
        "All logged events are timestamped with ISO format timestamps",
        "Log messages are appended to shadow-watch.log file with date and time information"
      ],
      "developerVisibleActions": [
        "Developer calls SWLogger.log() to write timestamped messages to the log file",
        "Developer calls SWLogger.section() to create visual section separators in the log",
        "Logging automatically creates the .shadow/logs directory structure if it doesn't exist",
        "Logging fails silently if workspace is not available or file operations fail"
      ],
      "keyFunctions": [
        {
          "name": "log",
          "desc": "Writes a timestamped message to the shadow-watch.log file",
          "inputs": "message: string - the text to log",
          "outputs": "void - writes to file system, no return value"
        },
        {
          "name": "section",
          "desc": "Creates a visual section separator in the log with a title",
          "inputs": "title: string - the section heading",
          "outputs": "void - writes formatted section header to log"
        },
        {
          "name": "getLogPath",
          "desc": "Determines the full file path where logs should be written",
          "inputs": "none",
          "outputs": "string | null - path to log file or null if no workspace is open"
        },
        {
          "name": "ensureDir",
          "desc": "Creates a directory and parent directories if they don't exist",
          "inputs": "dir: string - directory path to create",
          "outputs": "void - creates directory structure"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "vscode"
      ],
      "intent": "Provides a centralized logging mechanism for the extension to track events and debugging information in a persistent file within the workspace, making it easier to diagnose issues and understand extension behavior over time",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are automatically created in the .shadow/logs/ directory of the workspace\",\n    \"All logged events are timestamped with ISO format timestamps\",\n    \"Log messages are appended to shadow-watch.log file with date and time information\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls SWLogger.log() to write timestamped messages to the log file\",\n    \"Developer calls SWLogger.section() to create visual section separators in the log\",\n    \"Logging automatically creates the .shadow/logs directory structure if it doesn't exist\",\n    \"Logging fails silently if workspace is not available or file operations fail\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - the text to log\",\n      \"outputs\": \"void - writes to file system, no return value\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Creates a visual section separator in the log with a title\",\n      \"inputs\": \"title: string - the section heading\",\n      \"outputs\": \"void - writes formatted section header to log\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the full file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - path to log file or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates a directory and parent directories if they don't exist\",\n      \"inputs\": \"dir: string - directory path to create\",\n      \"outputs\": \"void - creates directory structure\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"Provides a centralized logging mechanism for the extension to track events and debugging information in a persistent file within the workspace, making it easier to diagnose issues and understand extension behavior over time\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is a VS Code extension that provides AI-powered code intelligence and automated documentation for software development teams. The extension analyzes codebases to understand their architecture, purpose, and potential issues, then generates comprehensive insights and documentation automatically. Users interact with Shadow Watch primarily through VS Code's sidebar panels and command palette, where they can trigger analysis, view results in interactive tree views, and navigate directly to relevant code sections. The extension connects to AI services (OpenAI GPT or Anthropic Claude) to generate intelligent insights about code quality, architecture patterns, testability, and documentation.\\n\\nThe extension serves as an intelligent assistant that continuously monitors your codebase and provides actionable feedback. When you save files, Shadow Watch can automatically re-analyze them and update insights in real-time. It identifies code quality issues like large files, orphaned code, circular dependencies, and god objects, presenting these as inline diagnostics directly in your editor with specific line numbers and remediation suggestions. The extension also generates product-level documentation that explains what your application does, how components interact, and what workflows it supports.\\n\\nShadow Watch streamlines multiple development workflows including code review, documentation creation, test planning, and refactoring. Users can generate comprehensive test plans with AI-recommended test cases, receive step-by-step refactoring guidance for complex code, and export analysis results as formatted reports. The extension caches results for 24 hours to ensure fast subsequent loads, and all insights can be formatted for different AI assistants (Cursor, ChatGPT) or exported as standalone HTML reports.\",\"whatItDoes\":[\"Analyzes codebases to identify code quality issues, architectural patterns, and potential improvements\",\"Generates comprehensive product documentation explaining what your application does and how it works\",\"Creates AI-powered test plans identifying which functions need testing and recommending test strategies\",\"Provides inline diagnostics showing code issues directly in your editor with specific locations and fixes\",\"Automatically generates unit tests for your code using AI analysis of function behavior\",\"Validates and auto-fixes failing tests by analyzing failures and regenerating corrected test code\",\"Detects entry points including main functions, CLI tools, and test files across your codebase\",\"Navigates you directly to functions, endpoints, and code sections when you click items in tree views\",\"Monitors file changes and automatically re-analyzes code when you save files\",\"Exports analysis results and documentation as formatted reports for sharing with your team\",\"Provides architecture insights explaining component relationships and design patterns in your code\",\"Generates refactoring recommendations with before/after code examples and migration steps\",\"Formats insights for specific AI assistants to improve code generation and review workflows\"],\"userPerspective\":{\"gui\":[\"View code analysis results in an interactive tree structure showing files, functions, and dependencies\",\"See inline warnings and errors directly in your editor highlighting specific code issues\",\"Browse AI-generated insights about your codebase architecture in a dedicated sidebar panel\",\"Navigate product documentation organized by features, modules, and components\",\"Review test plans showing which functions need testing and why\",\"Monitor test generation progress with real-time status updates\",\"Click any code element to jump directly to its location in your editor\",\"Export analysis results and documentation as HTML reports\",\"Toggle analyze-on-save to automatically update insights when files change\",\"Switch between OpenAI and Claude AI providers through settings\"],\"cli\":[\"Trigger codebase analysis through VS Code command palette\",\"Generate product documentation on-demand via commands\",\"Create test plans for your codebase using commands\",\"Run automated test generation for specific files or entire projects\",\"Clear cached analysis results to force fresh analysis\",\"Copy insights to clipboard for sharing or documentation\",\"Switch LLM providers between OpenAI and Claude\"],\"api\":[\"Connect to OpenAI GPT models for AI-powered code analysis\",\"Integrate with Anthropic Claude for alternative AI analysis\",\"Submit code for analysis and receive structured insights\",\"Request file content or search patterns during iterative analysis\",\"Generate documentation in multiple formats optimized for different tools\"],\"cicd\":[\"Integrate automated test generation into CI pipelines\",\"Export analysis results for build-time quality checks\",\"Generate documentation as part of release processes\",\"Validate test coverage and quality metrics\"]},\"workflowIntegration\":[\"Code review workflow: Analyze code before review to identify issues and generate documentation for reviewers\",\"Documentation workflow: Automatically generate and maintain product documentation as code evolves\",\"Test-driven development: Generate test plans and test code to increase coverage systematically\",\"Refactoring workflow: Receive AI-guided refactoring recommendations with specific extraction plans\",\"Onboarding workflow: Help new developers understand codebase architecture through AI-generated insights\",\"Quality assurance workflow: Continuously monitor code quality with automatic analysis on save\",\"CI/CD integration: Generate tests and documentation as part of automated build pipelines\",\"Technical debt workflow: Identify and track code quality issues with prioritized remediation steps\"],\"problemsSolved\":[\"Eliminates manual documentation creation by automatically generating comprehensive product and architecture documentation\",\"Reduces time spent understanding unfamiliar codebases by providing AI-powered architecture insights and navigation\",\"Increases test coverage by automatically generating test plans and test code for functions\",\"Saves code review time by automatically identifying quality issues before human review\",\"Prevents technical debt accumulation by continuously monitoring for code smells and anti-patterns\",\"Reduces onboarding time for new developers by providing clear documentation and architecture explanations\",\"Eliminates guesswork in refactoring by providing AI-analyzed extraction plans and migration steps\",\"Automates test maintenance by detecting and auto-fixing failing tests\",\"Prevents API rate limit issues when using AI services through intelligent throttling and retry logic\",\"Reduces context switching by providing all insights within VS Code without external tools\"],\"architecture\":\"Shadow Watch follows a modular architecture organized around core capabilities: code analysis, AI integration, UI presentation, and persistence. The analysis engine parses code into abstract syntax trees to extract detailed metadata about functions, dependencies, complexity, and behavioral patterns. This structural analysis feeds into an AI integration layer that communicates with LLM providers (OpenAI or Claude) to generate intelligent insights about architecture, code quality, and documentation. The AI layer includes rate limiting, retry logic, and response parsing to ensure reliable operation even under challenging network conditions.\\n\\nThe UI layer consists of multiple tree view providers that present analysis results, insights, test plans, and documentation in VS Code's sidebar. A diagnostics provider surfaces code quality issues as inline editor warnings with specific line numbers and remediation suggestions. Navigation handlers enable users to jump directly from tree views to relevant code locations. All components communicate through a command registry and event system that coordinates user actions across the extension.\\n\\nPersistence and caching layers optimize performance by storing analysis results and AI-generated insights to disk, eliminating redundant processing. A file watcher monitors workspace changes and triggers automatic re-analysis when configured. Progress notifications keep users informed during long-running operations like test generation or comprehensive codebase analysis. The architecture supports iterative AI analysis where the system can request additional files or search results across multiple conversation rounds to build comprehensive understanding.\",\"titles\":[\"Code Analysis Engine\",\"AI Integration Layer\",\"Insights Viewer\",\"Product Navigator\",\"Unit Tests Navigator\",\"Analysis Viewer\",\"Reports Viewer\",\"Static Analysis Viewer\",\"Inline Diagnostics\",\"Rate Limiter\",\"Response Parser\",\"Retry Handler\",\"Test Generation Service\",\"Test Planning Service\",\"Test Setup Service\",\"Test Validation Service\",\"Test Execution Service\",\"Documentation Formatter\",\"Navigation Handler\",\"Prompt Builder\",\"File Watcher Service\",\"Incremental Analysis Service\",\"Configuration Manager\",\"Progress Service\",\"Cache Manager\",\"File Access Helper\",\"Architecture Insights\",\"Product Documentation\",\"Refactoring Recommendations\",\"Test Plans\",\"Code Quality Detection\",\"Entry Point Detection\",\"Dependency Analysis\",\"Function Analysis\",\"Module Analysis\",\"Enhanced Analyzer\",\"Function Analyzer\",\"LLM State Manager\",\"Incremental Storage\",\"Error Handler\",\"JSON Extractor\",\"Analysis Context Builder\",\"Analysis Result Repository\",\"File Cache\",\"File Processor\",\"Command Registry\",\"Extension Bootstrapper\",\"Refactoring Prompt Builder\",\"Test Prompts\",\"Test Configuration Service\",\"Analyze on Save\",\"Copy to Clipboard\",\"Clear Cache\",\"Switch LLM Provider\",\"Generate Test Plan\",\"Generate Tests\",\"Validate Tests\",\"Export Reports\"],\"descriptions\":[{\"title\":\"Code Analysis Engine\",\"description\":\"Parses source code to extract comprehensive metadata about files, functions, dependencies, imports, exports, and entry points. Builds a complete picture of codebase structure and relationships.\",\"category\":\"component\"},{\"title\":\"AI Integration Layer\",\"description\":\"Manages communication with LLM providers (OpenAI, Claude) including rate limiting, retry logic, and response parsing. Ensures reliable AI operations even under challenging conditions.\",\"category\":\"component\"},{\"title\":\"Insights Viewer\",\"description\":\"Interactive tree view displaying AI-generated architecture insights, code quality issues, and recommendations. Users can browse insights and navigate to relevant code sections.\",\"category\":\"feature\"},{\"title\":\"Product Navigator\",\"description\":\"Tree view showing product-level documentation organized by features, modules, components, and workflows. Enables quick navigation to understand what the application does.\",\"category\":\"feature\"},{\"title\":\"Unit Tests Navigator\",\"description\":\"Displays test plans, test generation progress, and test results. Shows which functions are tested, test coverage, and validation status.\",\"category\":\"feature\"},{\"title\":\"Analysis Viewer\",\"description\":\"Tree view presenting code analysis results including file statistics, function lists, imports, exports, and entry points. Provides structural overview of the codebase.\",\"category\":\"feature\"},{\"title\":\"Reports Viewer\",\"description\":\"Displays generated reports including documentation, test reports, and analysis summaries. Enables export to HTML for sharing with teams.\",\"category\":\"feature\"},{\"title\":\"Inline Diagnostics\",\"description\":\"Shows code quality issues as warnings, errors, or info messages directly in the editor at specific line numbers. Each diagnostic includes description and recommended fix.\",\"category\":\"feature\"},{\"title\":\"Rate Limiter\",\"description\":\"Tracks and throttles LLM API requests to prevent rate limit errors. Manages separate limits for different providers (OpenAI, Claude) and adjusts throttling automatically.\",\"category\":\"component\"},{\"title\":\"Response Parser\",\"description\":\"Transforms raw LLM text responses into structured data objects. Extracts JSON from markdown code blocks, validates against schemas, and handles parsing errors gracefully.\",\"category\":\"component\"},{\"title\":\"Retry Handler\",\"description\":\"Implements exponential backoff retry logic for failed LLM requests. Automatically retries on rate limits, timeouts, and transient errors without user intervention.\",\"category\":\"component\"},{\"title\":\"Test Generation Service\",\"description\":\"Generates unit test code incrementally using AI analysis of function behavior. Processes functions in small batches and provides progress updates during generation.\",\"category\":\"feature\"},{\"title\":\"Test Planning Service\",\"description\":\"Analyzes codebase to identify testable functions and creates prioritized test plans. Recommends testing strategies based on code complexity and importance.\",\"category\":\"feature\"},{\"title\":\"Test Setup Service\",\"description\":\"Automatically detects test framework (Jest, Mocha, Vitest, Pytest), configuration files, and test directories. Identifies missing dependencies and setup requirements.\",\"category\":\"feature\"},{\"title\":\"Test Validation Service\",\"description\":\"Validates generated tests by executing them and analyzing failures. Automatically regenerates failing tests with AI-powered fixes until tests pass.\",\"category\":\"feature\"},{\"title\":\"Test Execution Service\",\"description\":\"Runs test suites and captures detailed results including pass/fail counts, error messages, and stack traces. Supports multiple test frameworks.\",\"category\":\"feature\"},{\"title\":\"Documentation Formatter\",\"description\":\"Converts structured documentation data into polished Markdown format. Organizes content into sections including overview, architecture, usage, and insights.\",\"category\":\"component\"},{\"title\":\"Navigation Handler\",\"description\":\"Handles user clicks on tree view items to open files and navigate to specific code locations. Positions cursor at target line and highlights relevant code.\",\"category\":\"component\"},{\"title\":\"Prompt Builder\",\"description\":\"Constructs detailed prompts for LLM analysis tasks including architecture analysis, documentation generation, and test planning. Includes relevant code context and instructions.\",\"category\":\"component\"},{\"title\":\"File Watcher Service\",\"description\":\"Monitors workspace for file changes and triggers automatic re-analysis when files are saved. Enables real-time insights updates as code evolves.\",\"category\":\"feature\"},{\"title\":\"Incremental Analysis Service\",\"description\":\"Manages iterative LLM analysis sessions where the system can request additional files or search results across multiple conversation rounds.\",\"category\":\"component\"},{\"title\":\"Configuration Manager\",\"description\":\"Manages all extension settings including LLM provider selection, API keys, analyze-on-save toggle, severity thresholds, and output formats. Notifies components when settings change.\",\"category\":\"component\"},{\"title\":\"Analyze on Save\",\"description\":\"Automatically triggers code analysis and insight generation whenever you save a file. Keeps insights synchronized with your latest code changes.\",\"category\":\"feature\"},{\"title\":\"Copy to Clipboard\",\"description\":\"Copies analysis results, insights, or documentation to clipboard in formats optimized for specific AI assistants (Cursor, ChatGPT, Generic, Compact).\",\"category\":\"feature\"},{\"title\":\"Clear Cache\",\"description\":\"Removes cached analysis results to force fresh analysis. Useful when you want to regenerate all insights from scratch.\",\"category\":\"feature\"},{\"title\":\"Switch LLM Provider\",\"description\":\"Changes the AI provider between OpenAI and Claude. Allows you to use different models for analysis and compare results.\",\"category\":\"feature\"},{\"title\":\"Generate Test Plan\",\"description\":\"Analyzes your codebase to create a comprehensive test plan identifying which functions need tests and recommending testing strategies.\",\"category\":\"workflow\"},{\"title\":\"Generate Tests\",\"description\":\"Automatically writes unit test code for your functions using AI analysis. Generates tests incrementally with progress tracking.\",\"category\":\"workflow\"},{\"title\":\"Validate Tests\",\"description\":\"Executes generated tests and automatically fixes failures by regenerating test code until all tests pass.\",\"category\":\"workflow\"},{\"title\":\"Export Reports\",\"description\":\"Exports analysis results, documentation, and test reports as formatted HTML files for sharing with your team or including in documentation.\",\"category\":\"feature\"},{\"title\":\"Architecture Insights\",\"description\":\"AI-generated explanations of your codebase architecture including component relationships, design patterns, and architectural decisions.\",\"category\":\"feature\"},{\"title\":\"Product Documentation\",\"description\":\"Automatically generated documentation explaining what your application does, key features, user workflows, and problems solved.\",\"category\":\"feature\"},{\"title\":\"Refactoring Recommendations\",\"description\":\"AI-analyzed suggestions for improving code structure with specific extraction plans, before/after examples, and migration steps.\",\"category\":\"feature\"},{\"title\":\"Code Quality Detection\",\"description\":\"Automatically identifies issues like large files, orphaned code, circular dependencies, god objects, and other code smells.\",\"category\":\"feature\"},{\"title\":\"Entry Point Detection\",\"description\":\"Finds and categorizes entry points in your codebase including main functions, CLI tools, test files, and application initialization code.\",\"category\":\"feature\"},{\"title\":\"Dependency Analysis\",\"description\":\"Maps import and export relationships across your codebase to understand module dependencies and coupling.\",\"category\":\"feature\"},{\"title\":\"Function Analysis\",\"description\":\"Extracts detailed metadata about functions including signatures, parameters, return types, complexity, side effects, and behavior patterns.\",\"category\":\"feature\"},{\"title\":\"Module Analysis\",\"description\":\"Groups related files into logical modules and analyzes module-level architecture, capabilities, and responsibilities.\",\"category\":\"feature\"}],\"relevantFunctions\":[{\"name\":\"analyzeWorkspace\",\"description\":\"Triggers comprehensive codebase analysis including file parsing, dependency mapping, and quality detection\",\"module\":\"analyzer\"},{\"name\":\"generateProductDocumentation\",\"description\":\"Creates AI-powered product documentation explaining what the application does and how it works\",\"module\":\"llmIntegration\"},{\"name\":\"generateArchitectureInsights\",\"description\":\"Analyzes codebase structure to produce insights about architecture patterns, component relationships, and design decisions\",\"module\":\"llmService\"},{\"name\":\"generateTestPlan\",\"description\":\"Analyzes code to identify testable functions and creates prioritized test plans with recommended strategies\",\"module\":\"llmTestPlanningService\"},{\"name\":\"generateTests\",\"description\":\"Generates unit test code incrementally using AI analysis of function behavior and dependencies\",\"module\":\"llmTestGenerationService\"},{\"name\":\"validateTests\",\"description\":\"Executes tests and automatically regenerates failing tests with AI-powered fixes until they pass\",\"module\":\"llmTestValidationService\"},{\"name\":\"executeTests\",\"description\":\"Runs test suites (Jest, Pytest) and captures detailed execution results\",\"module\":\"testExecutionService\"},{\"name\":\"navigateToLocation\",\"description\":\"Opens files and positions cursor at specific line numbers when users click tree view items\",\"module\":\"navigationHandler\"},{\"name\":\"formatDocumentation\",\"description\":\"Converts structured documentation data into polished, human-readable Markdown format\",\"module\":\"documentationFormatter\"},{\"name\":\"parseResponse\",\"description\":\"Extracts and validates structured data from raw LLM text responses\",\"module\":\"llmResponseParser\"},{\"name\":\"throttleRequest\",\"description\":\"Manages rate limiting for LLM API requests to prevent service disruptions\",\"module\":\"llmRateLimiter\"},{\"name\":\"retryWithBackoff\",\"description\":\"Implements exponential backoff retry logic for failed LLM requests\",\"module\":\"llmRetryHandler\"},{\"name\":\"detectTestFramework\",\"description\":\"Automatically identifies test framework configuration and missing dependencies\",\"module\":\"testConfigurationService\"},{\"name\":\"buildPrompt\",\"description\":\"Constructs detailed prompts for LLM analysis tasks with relevant code context\",\"module\":\"promptBuilder\"},{\"name\":\"watchFiles\",\"description\":\"Monitors workspace for file changes and triggers automatic re-analysis\",\"module\":\"fileWatcherService\"},{\"name\":\"cacheResults\",\"description\":\"Stores analysis results to disk to improve performance on subsequent loads\",\"module\":\"cache\"},{\"name\":\"extractFunctionMetadata\",\"description\":\"Parses function AST to extract signatures, dependencies, branches, and behavior patterns\",\"module\":\"enhancedAnalyzer\"},{\"name\":\"detectCodeQualityIssues\",\"description\":\"Identifies large files, orphaned code, circular dependencies, and other quality issues\",\"module\":\"insightGenerator\"},{\"name\":\"findEntryPoints\",\"description\":\"Locates and categorizes entry points including main functions, CLI tools, and test files\",\"module\":\"analyzer\"}],\"relevantDataStructures\":[{\"name\":\"AnalysisResult\",\"description\":\"Complete codebase analysis including files, functions, dependencies, quality metrics, and entry points\",\"type\":\"interface\"},{\"name\":\"FileAnalysis\",\"description\":\"Detailed analysis of a single file including functions, imports, exports, and metadata\",\"type\":\"interface\"},{\"name\":\"FunctionInfo\",\"description\":\"Function metadata including signature, parameters, return type, complexity, and behavior\",\"type\":\"interface\"},{\"name\":\"ProductDocumentation\",\"description\":\"AI-generated product documentation including overview, features, architecture, and workflows\",\"type\":\"interface\"},{\"name\":\"ArchitectureInsight\",\"description\":\"AI-generated insight about code architecture, patterns, or design decisions\",\"type\":\"interface\"},{\"name\":\"TestPlan\",\"description\":\"Comprehensive test plan including function groups, priorities, and recommended strategies\",\"type\":\"interface\"},{\"name\":\"TestResult\",\"description\":\"Test execution results including pass/fail counts, errors, and validation status\",\"type\":\"interface\"},{\"name\":\"CodeQualityIssue\",\"description\":\"Detected code quality issue with severity, location, description, and recommended fix\",\"type\":\"interface\"},{\"name\":\"LLMRequest\",\"description\":\"Structured request to LLM provider including messages, model, temperature, and response format\",\"type\":\"interface\"},{\"name\":\"LLMResponse\",\"description\":\"Parsed response from LLM including generated content and token usage\",\"type\":\"interface\"},{\"name\":\"EntryPoint\",\"description\":\"Identified entry point with type (main, CLI, test), file location, and description\",\"type\":\"interface\"},{\"name\":\"DependencyGraph\",\"description\":\"Map of import/export relationships showing module dependencies\",\"type\":\"interface\"},{\"name\":\"FunctionAnalysisDetail\",\"description\":\"Deep function analysis including branches, state mutations, dependencies, and behavioral hints\",\"type\":\"interface\"},{\"name\":\"TestGenerationState\",\"description\":\"Current state of test generation workflow including progress, completed functions, and errors\",\"type\":\"interface\"},{\"name\":\"TestSetupConfig\",\"description\":\"Detected test environment configuration including framework, directories, and dependencies\",\"type\":\"interface\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Extension entry point that initializes all components and registers commands\",\"purpose\":\"Coordinates extension activation and lifecycle management\",\"role\":\"Main entry point\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Performs comprehensive codebase analysis including file parsing and dependency mapping\",\"purpose\":\"Extracts structural information and metadata from code\",\"role\":\"Core analysis engine\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"Manages AI-powered analysis features and documentation generation\",\"purpose\":\"Coordinates LLM-based insights and documentation workflows\",\"role\":\"AI integration coordinator\"},{\"path\":\"src/llmService.ts\",\"description\":\"Handles communication with LLM providers to generate insights\",\"purpose\":\"Sends prompts to AI services and processes responses\",\"role\":\"AI service interface\"},{\"path\":\"src/insightsTreeView.ts\",\"description\":\"Displays AI-generated insights in interactive tree view\",\"purpose\":\"Presents architecture insights and quality issues to users\",\"role\":\"Insights UI component\"},{\"path\":\"src/productNavigator.ts\",\"description\":\"Shows product documentation in navigable tree structure\",\"purpose\":\"Enables users to browse product features and architecture\",\"role\":\"Documentation UI component\"},{\"path\":\"src/unitTestsNavigator.ts\",\"description\":\"Displays test plans, generation progress, and test results\",\"purpose\":\"Provides visibility into testing workflow and status\",\"role\":\"Testing UI component\"},{\"path\":\"src/diagnosticsProvider.ts\",\"description\":\"Shows code quality issues as inline editor warnings\",\"purpose\":\"Surfaces problems directly in code at specific line numbers\",\"role\":\"Diagnostics provider\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Generates unit test code using AI analysis\",\"purpose\":\"Automates test creation for functions\",\"role\":\"Test generation service\"},{\"path\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"description\":\"Creates AI-powered test plans identifying functions to test\",\"purpose\":\"Provides testing strategy and priorities\",\"role\":\"Test planning service\"},{\"path\":\"src/domain/services/testing/llmTestValidationService.ts\",\"description\":\"Validates and auto-fixes failing tests\",\"purpose\":\"Ensures generated tests work correctly\",\"role\":\"Test validation service\"},{\"path\":\"src/ai/llmRateLimiter.ts\",\"description\":\"Prevents rate limit errors with AI providers\",\"purpose\":\"Manages API request throttling\",\"role\":\"Rate limiting component\"},{\"path\":\"src/ai/llmRetryHandler.ts\",\"description\":\"Handles retry logic for failed AI requests\",\"purpose\":\"Ensures reliable AI operations\",\"role\":\"Retry logic component\"},{\"path\":\"src/ai/llmResponseParser.ts\",\"description\":\"Parses structured data from AI text responses\",\"purpose\":\"Transforms AI output into usable data structures\",\"role\":\"Response parsing component\"},{\"path\":\"src/domain/formatters/documentationFormatter.ts\",\"description\":\"Formats documentation as polished Markdown\",\"purpose\":\"Makes AI-generated content human-readable\",\"role\":\"Documentation formatter\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Handles navigation from tree views to code locations\",\"purpose\":\"Opens files and positions cursor when users click items\",\"role\":\"Navigation handler\"},{\"path\":\"src/domain/prompts/promptBuilder.ts\",\"description\":\"Constructs prompts for all LLM analysis tasks\",\"purpose\":\"Provides context and instructions to AI services\",\"role\":\"Prompt engineering component\"},{\"path\":\"src/config/configurationManager.ts\",\"description\":\"Manages all extension settings and preferences\",\"purpose\":\"Provides centralized configuration access\",\"role\":\"Configuration manager\"},{\"path\":\"src/domain/services/fileWatcherService.ts\",\"description\":\"Monitors workspace for file changes\",\"purpose\":\"Triggers automatic re-analysis on save\",\"role\":\"File monitoring service\"}],\"exampleInput\":{\"description\":\"Example API request to generate architecture insights for a codebase, showing the structure of analysis data provided to the LLM\",\"json\":\"{\\\"analysisResult\\\":{\\\"files\\\":[{\\\"path\\\":\\\"src/server.ts\\\",\\\"functions\\\":[{\\\"name\\\":\\\"startServer\\\",\\\"signature\\\":\\\"startServer(port: number): Promise<void>\\\",\\\"complexity\\\":15,\\\"dependencies\\\":[\\\"express\\\",\\\"database\\\"]},{\\\"name\\\":\\\"handleRequest\\\",\\\"signature\\\":\\\"handleRequest(req: Request, res: Response): void\\\",\\\"complexity\\\":8,\\\"dependencies\\\":[\\\"validator\\\"]}],\\\"imports\\\":[\\\"express\\\",\\\"./database\\\",\\\"./validator\\\"],\\\"exports\\\":[\\\"startServer\\\"],\\\"loc\\\":250}],\\\"totalFiles\\\":45,\\\"totalLOC\\\":12500,\\\"entryPoints\\\":[{\\\"type\\\":\\\"main\\\",\\\"file\\\":\\\"src/server.ts\\\",\\\"function\\\":\\\"startServer\\\"}],\\\"modules\\\":[{\\\"name\\\":\\\"server\\\",\\\"files\\\":[\\\"src/server.ts\\\",\\\"src/routes.ts\\\"],\\\"capabilities\\\":[\\\"HTTP request handling\\\",\\\"API routing\\\"]}]},\\\"prompt\\\":\\\"Analyze this web server codebase and provide insights about its architecture, design patterns, and potential improvements.\\\"}\"},\"exampleOutput\":{\"description\":\"Example product documentation generated by the extension, showing the structured output format that users see\",\"json\":\"{\\\"overview\\\":\\\"This is a REST API server application that provides user authentication and data management services. It handles HTTP requests, manages database connections, and implements JWT-based authentication. Users interact with the API through HTTP endpoints to create accounts, login, and manage resources.\\\",\\\"whatItDoes\\\":[\\\"Provides RESTful API endpoints for user management\\\",\\\"Authenticates users with JWT tokens\\\",\\\"Stores and retrieves data from PostgreSQL database\\\",\\\"Validates incoming requests and sanitizes data\\\"],\\\"architecture\\\":\\\"The application follows a three-tier architecture with clear separation between HTTP handling, business logic, and data persistence. The server layer processes incoming requests and routes them to appropriate handlers. The service layer implements business logic and coordinates between different components. The data layer manages database connections and executes queries.\\\",\\\"titles\\\":[\\\"User Authentication\\\",\\\"Data Management\\\",\\\"Request Validation\\\",\\\"Database Connection Pool\\\"],\\\"descriptions\\\":[{\\\"title\\\":\\\"User Authentication\\\",\\\"description\\\":\\\"JWT-based authentication system that validates credentials and issues tokens for authenticated sessions\\\",\\\"category\\\":\\\"feature\\\"},{\\\"title\\\":\\\"Data Management\\\",\\\"description\\\":\\\"CRUD operations for resources with validation and authorization checks\\\",\\\"category\\\":\\\"feature\\\"}],\\\"relevantFunctions\\\":[{\\\"name\\\":\\\"startServer\\\",\\\"description\\\":\\\"Initializes HTTP server, connects to database, and begins listening for requests\\\",\\\"file\\\":\\\"src/server.ts\\\"},{\\\"name\\\":\\\"authenticateUser\\\",\\\"description\\\":\\\"Validates user credentials and generates JWT token\\\",\\\"file\\\":\\\"src/auth.ts\\\"}],\\\"insights\\\":{\\\"architecturePatterns\\\":[\\\"Three-tier architecture with clear separation of concerns\\\",\\\"Dependency injection for testability\\\"],\\\"qualityIssues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Large file detected\\\",\\\"file\\\":\\\"src/server.ts\\\",\\\"recommendation\\\":\\\"Consider splitting into smaller modules\\\"}]}}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-21T01:48:57.897Z",
    "generatedAtLocal": "11/20/2025, 5:48:57 PM",
    "runId": "product-docs-2025-11-21T01-33-03-691Z"
  }
}