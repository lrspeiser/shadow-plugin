{
  "file": "src/ai/providers/openAIProvider.ts",
  "role": "Core Logic",
  "purpose": "Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses",
  "userVisibleActions": [
    "User's prompts are sent to OpenAI's GPT models for AI-powered responses",
    "User receives AI-generated text responses based on their input",
    "User can get structured JSON responses when requesting specific data formats",
    "User experiences automatic API key validation before making requests"
  ],
  "developerVisibleActions": [
    "Developer configures OpenAI API key through configuration manager",
    "Developer sends chat completion requests with custom models, prompts, and messages",
    "Developer receives parsed JSON responses when using structured output format",
    "Developer gets error messages when API key is not configured or requests fail",
    "Developer can check if provider is properly configured before use",
    "Developer specifies system prompts, conversation history, and response format options"
  ],
  "keyFunctions": [
    {
      "name": "initialize",
      "desc": "Sets up the OpenAI client with API key from configuration",
      "inputs": "None (reads from config manager)",
      "outputs": "void (initializes client)"
    },
    {
      "name": "isConfigured",
      "desc": "Checks if the provider has a valid API key and is ready to use",
      "inputs": "None",
      "outputs": "boolean indicating configuration status"
    },
    {
      "name": "getName",
      "desc": "Returns the provider identifier",
      "inputs": "None",
      "outputs": "string 'openai'"
    },
    {
      "name": "sendRequest",
      "desc": "Sends a chat completion request to OpenAI with messages and optional system prompt",
      "inputs": "LLMRequestOptions (model, messages, systemPrompt, responseFormat)",
      "outputs": "Promise<LLMResponse> with content and finish reason"
    },
    {
      "name": "sendStructuredOutputRequest",
      "desc": "Sends a request expecting structured JSON output and parses the response",
      "inputs": "LLMRequestOptions with expected JSON format",
      "outputs": "Promise<StructuredOutputResponse> with parsed JSON data"
    }
  ],
  "dependencies": [
    "openai",
    "../../config/configurationManager",
    "../../utils/jsonExtractor",
    "./ILLMProvider"
  ],
  "intent": "This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI integration for making LLM requests with support for both standard and structured JSON responses\",\n  \"userVisibleActions\": [\n    \"User's prompts are sent to OpenAI's GPT models for AI-powered responses\",\n    \"User receives AI-generated text responses based on their input\",\n    \"User can get structured JSON responses when requesting specific data formats\",\n    \"User experiences automatic API key validation before making requests\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer configures OpenAI API key through configuration manager\",\n    \"Developer sends chat completion requests with custom models, prompts, and messages\",\n    \"Developer receives parsed JSON responses when using structured output format\",\n    \"Developer gets error messages when API key is not configured or requests fail\",\n    \"Developer can check if provider is properly configured before use\",\n    \"Developer specifies system prompts, conversation history, and response format options\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the OpenAI client with API key from configuration\",\n      \"inputs\": \"None (reads from config manager)\",\n      \"outputs\": \"void (initializes client)\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has a valid API key and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating configuration status\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"string 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI with messages and optional system prompt\",\n      \"inputs\": \"LLMRequestOptions (model, messages, systemPrompt, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content and finish reason\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends a request expecting structured JSON output and parses the response\",\n      \"inputs\": \"LLMRequestOptions with expected JSON format\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to encapsulate all OpenAI-specific API interactions, providing a consistent interface for the application to communicate with OpenAI's GPT models while handling configuration, error cases, and both standard text and structured JSON responses.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-21T01:34:18.391Z"
  }
}