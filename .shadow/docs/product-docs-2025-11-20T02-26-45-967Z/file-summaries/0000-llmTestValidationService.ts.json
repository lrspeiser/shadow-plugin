{
  "file": "src/domain/services/testing/llmTestValidationService.ts",
  "role": "Core Logic",
  "purpose": "Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution",
  "userVisibleActions": [
    "Tests are automatically run and validated",
    "Failing tests are detected and reported with detailed error messages",
    "Tests are automatically fixed through multiple retry attempts",
    "Test execution results show passed/failed counts and success rates",
    "Detailed test reports are generated showing which tests passed or failed"
  ],
  "developerVisibleActions": [
    "Trigger test validation for specific test files or entire workspace",
    "Configure maximum retry attempts for automatic test fixing",
    "Receive structured test execution results with pass/fail statistics",
    "Access detailed error messages and stack traces for failed tests",
    "Get feedback on which fix attempts succeeded or failed",
    "Review generated test reports with comprehensive test outcomes"
  ],
  "keyFunctions": [
    {
      "name": "runTests",
      "desc": "Executes all tests or a specific test file and captures results",
      "inputs": "workspaceRoot (string), optional testFile (string)",
      "outputs": "Array of TestExecutionResult objects with pass/fail statistics"
    },
    {
      "name": "fixFailingTest",
      "desc": "Attempts to automatically fix a failing test using LLM with retry logic",
      "inputs": "testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)",
      "outputs": "Object with success status, number of attempts, and final error if failed"
    },
    {
      "name": "buildFixPrompt",
      "desc": "Constructs an LLM prompt for fixing test failures based on error context",
      "inputs": "Test file content, execution results, error details",
      "outputs": "Formatted prompt string for LLM processing"
    }
  ],
  "dependencies": [
    "fs",
    "path",
    "TestExecutionService",
    "testResultTypes (TestExecutionResult, TestReport, TestReportSummary)",
    "testPrompts (buildFixPrompt)",
    "SWLogger"
  ],
  "intent": "This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.",
  "rawContent": "```json\n{\n  \"purpose\": \"Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and validated\",\n    \"Failing tests are detected and reported with detailed error messages\",\n    \"Tests are automatically fixed through multiple retry attempts\",\n    \"Test execution results show passed/failed counts and success rates\",\n    \"Detailed test reports are generated showing which tests passed or failed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test validation for specific test files or entire workspace\",\n    \"Configure maximum retry attempts for automatic test fixing\",\n    \"Receive structured test execution results with pass/fail statistics\",\n    \"Access detailed error messages and stack traces for failed tests\",\n    \"Get feedback on which fix attempts succeeded or failed\",\n    \"Review generated test reports with comprehensive test outcomes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and captures results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Array of TestExecutionResult objects with pass/fail statistics\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with retry logic\",\n      \"inputs\": \"testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)\",\n      \"outputs\": \"Object with success status, number of attempts, and final error if failed\"\n    },\n    {\n      \"name\": \"buildFixPrompt\",\n      \"desc\": \"Constructs an LLM prompt for fixing test failures based on error context\",\n      \"inputs\": \"Test file content, execution results, error details\",\n      \"outputs\": \"Formatted prompt string for LLM processing\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"testResultTypes (TestExecutionResult, TestReport, TestReportSummary)\",\n    \"testPrompts (buildFixPrompt)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T02:41:25.195Z"
  }
}