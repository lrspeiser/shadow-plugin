{
  "file": "src/ai/llmRateLimiter.ts",
  "role": "Core Logic",
  "purpose": "Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs",
  "userVisibleActions": [
    "Prevents application errors when too many AI requests are made in a short time",
    "Ensures smooth AI functionality by automatically managing request timing",
    "Avoids API quota exceeded errors during heavy AI usage"
  ],
  "developerVisibleActions": [
    "Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)",
    "Check if an AI request can proceed before making the API call",
    "Record each AI request to track usage against rate limits",
    "Get remaining request capacity for planning batched operations",
    "Automatically cleans up old request history outside the time window"
  ],
  "keyFunctions": [
    {
      "name": "canMakeRequest",
      "desc": "Checks if an AI request is allowed based on rate limits",
      "inputs": "provider ('openai' or 'claude')",
      "outputs": "boolean - true if request can proceed, false if limit reached"
    },
    {
      "name": "recordRequest",
      "desc": "Records that an AI request was made to track against limits",
      "inputs": "provider ('openai' or 'claude')",
      "outputs": "void - updates internal tracking"
    },
    {
      "name": "configure",
      "desc": "Sets custom rate limits for an AI provider",
      "inputs": "provider ('openai' or 'claude'), config (maxRequests and windowMs)",
      "outputs": "void - updates provider configuration"
    }
  ],
  "dependencies": [],
  "intent": "Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas",
  "rawContent": "```json\n{\n  \"purpose\": \"Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs\",\n  \"userVisibleActions\": [\n    \"Prevents application errors when too many AI requests are made in a short time\",\n    \"Ensures smooth AI functionality by automatically managing request timing\",\n    \"Avoids API quota exceeded errors during heavy AI usage\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)\",\n    \"Check if an AI request can proceed before making the API call\",\n    \"Record each AI request to track usage against rate limits\",\n    \"Get remaining request capacity for planning batched operations\",\n    \"Automatically cleans up old request history outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if an AI request is allowed based on rate limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"boolean - true if request can proceed, false if limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records that an AI request was made to track against limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"void - updates internal tracking\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limits for an AI provider\",\n      \"inputs\": \"provider ('openai' or 'claude'), config (maxRequests and windowMs)\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T02:35:26.723Z"
  }
}