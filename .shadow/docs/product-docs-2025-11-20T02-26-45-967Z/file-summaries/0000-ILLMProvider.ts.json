{
  "file": "src/ai/providers/ILLMProvider.ts",
  "role": "Core Logic",
  "purpose": "Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way",
  "userVisibleActions": [
    "User receives AI-generated text responses to their queries",
    "User receives structured JSON responses when requesting formatted data",
    "User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured"
  ],
  "developerVisibleActions": [
    "Developer implements this interface to add new AI provider support",
    "Developer calls sendRequest() to get text responses from any LLM provider",
    "Developer calls sendStructuredRequest() to get parsed JSON data from LLM",
    "Developer checks isConfigured() to verify provider is ready before making requests",
    "Developer configures conversation messages with role-based structure (system, user, assistant)",
    "Developer controls response parameters like temperature, max tokens, and response format"
  ],
  "keyFunctions": [
    {
      "name": "isConfigured",
      "desc": "Checks if the provider has valid credentials and is ready to use",
      "inputs": "None",
      "outputs": "Boolean indicating if provider is configured"
    },
    {
      "name": "sendRequest",
      "desc": "Sends a prompt to the LLM and returns text response",
      "inputs": "LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)",
      "outputs": "Promise<LLMResponse> with content, finish reason, model name, and raw response"
    },
    {
      "name": "sendStructuredRequest",
      "desc": "Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests",
      "inputs": "LLMRequestOptions and optional JSON schema",
      "outputs": "Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests"
    },
    {
      "name": "getName",
      "desc": "Returns the provider's display name",
      "inputs": "None",
      "outputs": "String provider name (e.g., 'OpenAI', 'Claude')"
    }
  ],
  "dependencies": [],
  "intent": "This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.",
  "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON responses when requesting formatted data\",\n    \"User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add new AI provider support\",\n    \"Developer calls sendRequest() to get text responses from any LLM provider\",\n    \"Developer calls sendStructuredRequest() to get parsed JSON data from LLM\",\n    \"Developer checks isConfigured() to verify provider is ready before making requests\",\n    \"Developer configures conversation messages with role-based structure (system, user, assistant)\",\n    \"Developer controls response parameters like temperature, max tokens, and response format\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has valid credentials and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns text response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, model name, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider's display name\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String provider name (e.g., 'OpenAI', 'Claude')\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T02:36:03.947Z"
  }
}