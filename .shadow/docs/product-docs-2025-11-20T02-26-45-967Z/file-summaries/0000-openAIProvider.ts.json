{
  "file": "src/ai/providers/openAIProvider.ts",
  "role": "Core Logic",
  "purpose": "Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses",
  "userVisibleActions": [
    "Sends user messages to OpenAI's GPT models and receives AI-generated responses",
    "Supports both regular text responses and structured JSON responses from the AI",
    "Handles streaming responses where AI text appears progressively",
    "Automatically validates and extracts JSON from AI responses when structured output is requested"
  ],
  "developerVisibleActions": [
    "Configures OpenAI API connection using API key from configuration manager",
    "Provides synchronous check if OpenAI is properly configured via isConfigured()",
    "Sends chat completion requests with customizable model, messages, and response format",
    "Returns structured responses with content, finish reason, and token usage statistics",
    "Streams chat completions with real-time content chunks via async iteration",
    "Extracts and validates JSON from AI responses for structured output requests",
    "Sets 5-minute timeout for all OpenAI API requests",
    "Throws errors when API key is not configured"
  ],
  "keyFunctions": [
    {
      "name": "initialize",
      "desc": "Sets up OpenAI client with API key from configuration",
      "inputs": "None",
      "outputs": "void"
    },
    {
      "name": "isConfigured",
      "desc": "Checks if OpenAI provider is ready to use",
      "inputs": "None",
      "outputs": "boolean indicating if API key is set"
    },
    {
      "name": "getName",
      "desc": "Returns provider identifier",
      "inputs": "None",
      "outputs": "String 'openai'"
    },
    {
      "name": "sendRequest",
      "desc": "Sends a chat completion request to OpenAI and returns the response",
      "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
      "outputs": "Promise<LLMResponse> with content, finishReason, and usage stats"
    },
    {
      "name": "streamRequest",
      "desc": "Streams a chat completion request with progressive content delivery",
      "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
      "outputs": "AsyncIterable<string> yielding content chunks as they arrive"
    },
    {
      "name": "sendStructuredOutputRequest",
      "desc": "Sends request expecting JSON response and validates the output",
      "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
      "outputs": "Promise<StructuredOutputResponse> with parsed JSON data or validation errors"
    }
  ],
  "dependencies": [
    "openai",
    "../../config/configurationManager",
    "../../utils/jsonExtractor",
    "./ILLMProvider"
  ],
  "intent": "This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally",
  "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Sends user messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Supports both regular text responses and structured JSON responses from the AI\",\n    \"Handles streaming responses where AI text appears progressively\",\n    \"Automatically validates and extracts JSON from AI responses when structured output is requested\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configures OpenAI API connection using API key from configuration manager\",\n    \"Provides synchronous check if OpenAI is properly configured via isConfigured()\",\n    \"Sends chat completion requests with customizable model, messages, and response format\",\n    \"Returns structured responses with content, finish reason, and token usage statistics\",\n    \"Streams chat completions with real-time content chunks via async iteration\",\n    \"Extracts and validates JSON from AI responses for structured output requests\",\n    \"Sets 5-minute timeout for all OpenAI API requests\",\n    \"Throws errors when API key is not configured\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI provider is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if API key is set\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<LLMResponse> with content, finishReason, and usage stats\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams a chat completion request with progressive content delivery\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"AsyncIterable<string> yielding content chunks as they arrive\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting JSON response and validates the output\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data or validation errors\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally\"\n}\n```",
  "_metadata": {
    "index": 0,
    "total": 0,
    "savedAt": "2025-11-20T02:36:31.215Z"
  }
}