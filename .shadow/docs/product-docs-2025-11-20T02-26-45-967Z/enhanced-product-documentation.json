{
  "overview": "Shadow Watch is a Visual Studio Code extension that provides AI-powered code intelligence and documentation generation for software development teams. It automatically analyzes codebases to understand their structure, purpose, and quality, then generates comprehensive documentation explaining what the code does and why it exists. Users can analyze individual files or entire projects, with results appearing as inline diagnostics, browsable tree views in the sidebar, and exportable markdown reports.\n\nThe extension integrates deeply with VS Code's interface, allowing developers to navigate seamlessly between analysis insights and source code locations. When users save files, Shadow Watch automatically re-analyzes the changes and updates its insights in real-time. The extension supports multiple AI providers (OpenAI GPT and Anthropic Claude) for generating documentation and architectural analysis, with configurable output formats optimized for different AI assistants and workflows.\n\nBeyond documentation, Shadow Watch helps development teams improve code quality by identifying architectural patterns, code smells, circular dependencies, orphaned files, and potential refactoring opportunities. It can generate unit test plans, create test code with proper mocks and assertions, validate tests by executing them, and automatically fix failing tests through iterative AI-powered corrections.",
  "whatItDoes": [
    "Analyzes codebases to generate product documentation explaining what applications do from a user perspective",
    "Creates module and file-level documentation describing code purpose, features, and capabilities",
    "Identifies architecture patterns, code quality issues, and potential improvement opportunities",
    "Generates unit test plans prioritized by function complexity and importance",
    "Creates unit test code with appropriate framework setup, mocks, and assertions",
    "Automatically validates and fixes failing tests through iterative AI corrections",
    "Displays inline diagnostics showing code issues as squiggly underlines in the editor",
    "Provides browsable tree views showing code structure, statistics, and analysis results",
    "Exports analysis results and documentation to markdown files for sharing",
    "Enables navigation from insights directly to relevant source code locations",
    "Monitors file changes and automatically updates analysis when files are saved",
    "Caches analysis results for fast repeated access without re-scanning",
    "Supports switching between OpenAI GPT and Anthropic Claude AI providers",
    "Formats documentation in multiple styles optimized for different AI assistants"
  ],
  "userPerspective": {
    "gui": [
      "Browse code analysis results in a hierarchical tree view in the VS Code sidebar",
      "View inline diagnostics with squiggly underlines showing code quality issues in the Problems panel",
      "Click on analysis insights to jump directly to the relevant source code location",
      "See real-time progress indicators in the status bar during long-running analysis operations",
      "Review generated documentation in formatted markdown within VS Code",
      "Access action buttons to generate tests, analyze files, or export results",
      "View unit test reports showing passed/failed counts, execution duration, and coverage metrics",
      "Navigate between different analysis views including insights, architecture, and test results"
    ],
    "cli": [
      "Execute extension commands through the VS Code command palette",
      "Trigger analysis on specific files or entire workspaces via keyboard shortcuts",
      "Switch between AI providers using command palette actions",
      "Copy generated insights and documentation to clipboard for external use"
    ],
    "api": [
      "Configure AI provider settings (API keys, model selection) through VS Code settings",
      "Set diagnostic severity levels to control which issues appear in the Problems panel",
      "Enable or disable automatic analysis on file save",
      "Choose output format for AI-generated content (Cursor, ChatGPT, Generic, Compact)",
      "Specify LLM models for different providers through configuration"
    ],
    "cicd": [
      "Export analysis results as markdown files for documentation repositories",
      "Generate test plans and test code that integrate with existing CI/CD test suites",
      "Produce architecture insights that can inform code review processes",
      "Create documentation artifacts suitable for version control and documentation systems"
    ]
  },
  "workflowIntegration": [
    "Code review workflow: Analyze pull requests to identify quality issues and generate documentation for new features",
    "Documentation generation workflow: Automatically create and update product, module, and file-level documentation as code evolves",
    "Test-driven development workflow: Generate test plans and initial test code from existing functions, then validate and fix tests iteratively",
    "Refactoring workflow: Identify large or complex functions that should be extracted, with detailed migration instructions",
    "Architecture assessment workflow: Understand codebase structure, identify patterns, and spot architectural issues like circular dependencies",
    "Onboarding workflow: Generate comprehensive documentation to help new team members understand what the codebase does",
    "Quality assurance workflow: Continuously monitor code quality through automatic analysis on file save, with inline feedback"
  ],
  "problemsSolved": [
    "Eliminates manual documentation writing by automatically generating comprehensive product and code documentation",
    "Reduces time spent understanding unfamiliar codebases by providing AI-generated summaries and architectural insights",
    "Prevents outdated documentation by automatically updating analysis when code changes",
    "Speeds up test creation by generating unit tests with proper setup, mocks, and assertions",
    "Reduces debugging time by automatically fixing failing tests through AI-powered corrections",
    "Improves code quality by identifying issues like circular dependencies, orphaned files, and code smells",
    "Accelerates code reviews by providing immediate insights into code structure and potential issues",
    "Simplifies onboarding by generating clear explanations of what code does from a user perspective",
    "Maintains consistent documentation quality across large codebases through standardized AI analysis",
    "Enables seamless navigation from analysis insights to source code, reducing context switching"
  ],
  "architecture": "Shadow Watch follows a layered architecture with clear separation between infrastructure, domain logic, and user interface components. The infrastructure layer manages AI provider integration (OpenAI and Claude), file system access with caching, and persistent storage of analysis results. The domain layer contains the core business logic for code analysis, test generation, and documentation creation, organized into services that orchestrate complex workflows like incremental AI analysis and test validation. The UI layer provides VS Code integration through tree view providers, diagnostic providers, webview panels, and command handlers.\n\nThe extension uses a request-response pattern for AI interactions, where analysis operations make structured requests to language models and parse responses into typed objects. A rate limiter prevents API quota exhaustion, while a retry handler manages transient failures with exponential backoff. Code analysis flows through an AST-based parser that extracts function metadata, dependencies, and behavioral patterns, feeding this structured data into prompt builders that generate context-rich queries for the AI.\n\nState management is centralized through managers that track analysis progress, configuration changes, and test generation status. File watching services monitor the workspace for changes and trigger automatic re-analysis. Results are cached both in memory and on disk to avoid redundant processing. The architecture supports extensibility through provider factories and standardized interfaces, allowing new AI providers or analysis capabilities to be added without modifying existing components.",
  "titles": [
    "Shadow Watch Extension",
    "Code Analysis Tree View",
    "Architecture Insights",
    "Product Documentation Generator",
    "Module Documentation",
    "File Documentation",
    "Unit Test Generator",
    "Test Plan Creator",
    "Test Validator",
    "Automatic Test Fixer",
    "Inline Diagnostics",
    "Navigation Handler",
    "Incremental Analysis",
    "File Watcher",
    "Progress Notifications",
    "AI Provider Integration",
    "OpenAI Provider",
    "Claude Provider",
    "Rate Limiter",
    "Retry Handler",
    "Response Parser",
    "Enhanced Analyzer",
    "Function Analyzer",
    "Insight Generator",
    "Refactoring Recommendations",
    "Configuration Manager",
    "Documentation Formatter",
    "Prompt Builder",
    "Test Execution Service",
    "Analysis Cache",
    "File Cache",
    "Analysis Result Repository",
    "LLM Integration",
    "Command Registry",
    "Extension Bootstrapper"
  ],
  "descriptions": [
    {
      "title": "Shadow Watch Extension",
      "description": "VS Code extension that provides AI-powered code intelligence, documentation generation, and automated testing capabilities for software development teams",
      "category": "feature"
    },
    {
      "title": "Code Analysis Tree View",
      "description": "Hierarchical sidebar view displaying code structure, statistics, and analysis results with clickable navigation to source locations",
      "category": "component"
    },
    {
      "title": "Architecture Insights",
      "description": "AI-generated analysis of codebase architecture patterns, dependencies, code quality issues, and improvement recommendations",
      "category": "feature"
    },
    {
      "title": "Product Documentation Generator",
      "description": "Automatically creates comprehensive documentation explaining what an application does from a user perspective, including features, workflows, and problems solved",
      "category": "feature"
    },
    {
      "title": "Module Documentation",
      "description": "Generates documentation for code modules describing their user-facing capabilities and how they contribute to the overall application",
      "category": "feature"
    },
    {
      "title": "File Documentation",
      "description": "Creates file-level documentation explaining the purpose, key functions, and role of individual source files",
      "category": "feature"
    },
    {
      "title": "Unit Test Generator",
      "description": "Automatically generates unit test code with proper framework setup, mocks, and assertions for functions in the codebase",
      "category": "feature"
    },
    {
      "title": "Test Plan Creator",
      "description": "Analyzes codebases to create prioritized test plans determining which functions should be tested and in what order based on complexity and importance",
      "category": "feature"
    },
    {
      "title": "Test Validator",
      "description": "Executes generated tests to verify they pass, capturing detailed results including pass/fail counts, execution duration, and error messages",
      "category": "feature"
    },
    {
      "title": "Automatic Test Fixer",
      "description": "Automatically repairs failing tests through iterative AI-powered corrections, analyzing failure messages and regenerating test code until tests pass",
      "category": "feature"
    },
    {
      "title": "Inline Diagnostics",
      "description": "Displays code quality issues and warnings as squiggly underlines in the editor with detailed messages in the Problems panel",
      "category": "feature"
    },
    {
      "title": "Navigation Handler",
      "description": "Manages seamless navigation from analysis results to source code locations, opening files and positioning the cursor at exact lines and columns",
      "category": "component"
    },
    {
      "title": "Incremental Analysis",
      "description": "Progressively gathers code context by making multiple AI requests, reading additional files and searching for patterns as needed to build comprehensive understanding",
      "category": "workflow"
    },
    {
      "title": "File Watcher",
      "description": "Monitors workspace for file changes (creation, modification, deletion) and automatically triggers re-analysis to keep insights current",
      "category": "component"
    },
    {
      "title": "Progress Notifications",
      "description": "Displays progress indicators with titles, messages, and cancellation support during long-running operations like analysis and test generation",
      "category": "component"
    },
    {
      "title": "AI Provider Integration",
      "description": "Unified interface for communicating with multiple AI language model providers (OpenAI GPT and Anthropic Claude) through a consistent API",
      "category": "integration"
    },
    {
      "title": "Rate Limiter",
      "description": "Prevents API quota exhaustion by tracking and controlling the frequency of requests to AI providers",
      "category": "component"
    },
    {
      "title": "Retry Handler",
      "description": "Automatically retries failed AI requests with exponential backoff when encountering transient errors like rate limits or network issues",
      "category": "component"
    },
    {
      "title": "Response Parser",
      "description": "Extracts structured data from AI text responses and converts them into typed objects for documentation, analysis, and test results",
      "category": "component"
    },
    {
      "title": "Enhanced Analyzer",
      "description": "Deep code analysis using Abstract Syntax Tree parsing to extract function metadata, dependencies, branches, and behavioral patterns from TypeScript and JavaScript files",
      "category": "module"
    },
    {
      "title": "Function Analyzer",
      "description": "Analyzes individual functions to extract signatures, parameters, return types, complexity metrics, and relationships for refactoring recommendations",
      "category": "module"
    },
    {
      "title": "Insight Generator",
      "description": "Generates actionable insights about code quality, organization, and potential issues by analyzing codebase structure and patterns",
      "category": "module"
    },
    {
      "title": "Refactoring Recommendations",
      "description": "Identifies functions that should be extracted to new files and provides detailed migration instructions with dependency analysis",
      "category": "feature"
    },
    {
      "title": "Configuration Manager",
      "description": "Manages all extension settings including AI provider selection, output format, automatic analysis, and diagnostic severity levels with real-time change notifications",
      "category": "component"
    },
    {
      "title": "Documentation Formatter",
      "description": "Converts raw analysis data into polished, human-readable Markdown documents with consistent structure and formatting",
      "category": "component"
    },
    {
      "title": "Prompt Builder",
      "description": "Constructs standardized prompts for all AI interactions including documentation generation, architecture analysis, test planning, and refactoring",
      "category": "component"
    },
    {
      "title": "Test Execution Service",
      "description": "Runs test suites using appropriate test frameworks (Jest, Mocha, Pytest) and captures structured results with pass/fail counts, durations, and error details",
      "category": "module"
    },
    {
      "title": "Analysis Cache",
      "description": "Stores analysis results in memory and on disk to avoid redundant processing and improve responsiveness during repeated access",
      "category": "component"
    },
    {
      "title": "File Cache",
      "description": "Caches file contents in memory with automatic invalidation on changes to eliminate redundant disk reads",
      "category": "component"
    },
    {
      "title": "Analysis Result Repository",
      "description": "Persists all analysis outputs including documentation and insights to the .shadow directory with unique identifiers and timestamps for historical tracking",
      "category": "component"
    }
  ],
  "relevantFunctions": [
    {
      "name": "activate",
      "description": "Main entry point that initializes the VS Code extension, registers commands, sets up UI components, and starts file monitoring",
      "file": "src/extension.ts",
      "module": "extension"
    },
    {
      "name": "analyzeCodebase",
      "description": "Analyzes an entire workspace to generate product documentation, module summaries, and file-level documentation",
      "file": "src/extension.ts",
      "module": "extension"
    },
    {
      "name": "analyzeFile",
      "description": "Analyzes a single file to generate documentation describing its purpose and key functions",
      "file": "src/extension.ts",
      "module": "extension"
    },
    {
      "name": "generateArchitectureInsights",
      "description": "Creates AI-generated insights about codebase architecture, patterns, dependencies, and quality issues",
      "file": "src/llmService.ts",
      "module": "llmService"
    },
    {
      "name": "generateTestPlan",
      "description": "Analyzes functions to create a prioritized test plan determining which functions should be tested and in what order",
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "module": "testing"
    },
    {
      "name": "generateTests",
      "description": "Generates unit test code for functions in batches with proper framework setup, mocks, and assertions",
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "module": "testing"
    },
    {
      "name": "validateAndFixTests",
      "description": "Executes tests and automatically fixes failures through iterative AI-powered corrections",
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "module": "testing"
    },
    {
      "name": "executeTests",
      "description": "Runs test suites using the appropriate framework and captures structured results",
      "file": "src/domain/services/testing/testExecutionService.ts",
      "module": "testing"
    },
    {
      "name": "analyzeFunction",
      "description": "Extracts detailed metadata about a function including signature, dependencies, complexity, and behavioral patterns",
      "file": "src/analysis/functionAnalyzer.ts",
      "module": "analysis"
    },
    {
      "name": "enhancedAnalyze",
      "description": "Performs deep AST-based analysis of TypeScript/JavaScript files to extract function metadata and relationships",
      "file": "src/analysis/enhancedAnalyzer.ts",
      "module": "analysis"
    },
    {
      "name": "navigateToCodeItem",
      "description": "Opens a file in the editor and positions the cursor at a specific line and column based on user selection",
      "file": "src/domain/handlers/navigationHandler.ts",
      "module": "handlers"
    },
    {
      "name": "buildProductDocumentationPrompt",
      "description": "Constructs an AI prompt for generating product documentation from codebase analysis",
      "file": "src/domain/prompts/promptBuilder.ts",
      "module": "prompts"
    },
    {
      "name": "buildRefactoringPrompt",
      "description": "Creates a detailed prompt for AI-based refactoring analysis with function extraction plans",
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "module": "prompts"
    },
    {
      "name": "performIncrementalAnalysis",
      "description": "Executes iterative AI analysis by processing file and grep requests across multiple rounds until completion",
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "module": "services"
    },
    {
      "name": "watchWorkspace",
      "description": "Monitors workspace files for changes and triggers automatic re-analysis when files are saved",
      "file": "src/domain/services/fileWatcherService.ts",
      "module": "services"
    },
    {
      "name": "detectTestSetup",
      "description": "Automatically identifies the project's test framework configuration and missing dependencies",
      "file": "src/domain/services/testConfigurationService.ts",
      "module": "services"
    },
    {
      "name": "rateLimitedRequest",
      "description": "Enforces rate limits on AI API requests to prevent quota exhaustion",
      "file": "src/ai/llmRateLimiter.ts",
      "module": "ai"
    },
    {
      "name": "retryWithBackoff",
      "description": "Automatically retries failed AI requests with exponential backoff for transient errors",
      "file": "src/ai/llmRetryHandler.ts",
      "module": "ai"
    },
    {
      "name": "parseFileSummary",
      "description": "Extracts structured file documentation from AI text responses",
      "file": "src/ai/llmResponseParser.ts",
      "module": "ai"
    },
    {
      "name": "formatProductDocumentation",
      "description": "Converts product documentation data into formatted Markdown for human readability",
      "file": "src/domain/formatters/documentationFormatter.ts",
      "module": "formatters"
    }
  ],
  "relevantDataStructures": [
    {
      "name": "ProductDocumentation",
      "description": "Structure representing comprehensive product documentation including overview, features, workflows, architecture, and examples",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "ModuleSummary",
      "description": "Structure describing a code module's user-facing capabilities and how it contributes to the application",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "FileSummary",
      "description": "Structure containing file-level documentation including purpose, key functions, and role",
      "type": "interface",
      "file": "src/fileDocumentation.ts"
    },
    {
      "name": "ArchitectureInsight",
      "description": "Structure containing AI-generated insights about codebase architecture, patterns, and quality issues",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "FunctionMetadata",
      "description": "Detailed metadata about a function including signature, dependencies, complexity, branches, and behavioral hints",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "TestPlan",
      "description": "Structure organizing functions to be tested with priorities, grouping, and metadata",
      "type": "interface",
      "file": "src/domain/services/testing/types/testPlanTypes.ts"
    },
    {
      "name": "TestGenerationResult",
      "description": "Results from test generation including generated code, validation status, and execution results",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestExecutionResult",
      "description": "Structured test execution results with pass/fail counts, duration, errors, and coverage information",
      "type": "interface",
      "file": "src/domain/services/testing/types/testResultTypes.ts"
    },
    {
      "name": "TestSetupConfig",
      "description": "Configuration for test environment including framework, dependencies, and execution settings",
      "type": "interface",
      "file": "src/domain/services/testing/types/testSetupTypes.ts"
    },
    {
      "name": "AnalysisRequest",
      "description": "Request for additional information during incremental analysis, either file content or grep search",
      "type": "interface",
      "file": "src/fileAccessHelper.ts"
    },
    {
      "name": "CodebaseStats",
      "description": "Statistics about a codebase including total files, lines of code, and entry points",
      "type": "interface",
      "file": "src/analyzer.ts"
    },
    {
      "name": "DiagnosticInfo",
      "description": "Information about a code quality issue for display in the Problems panel",
      "type": "interface",
      "file": "src/diagnosticsProvider.ts"
    },
    {
      "name": "LLMProviderConfig",
      "description": "Configuration for AI provider including model selection, temperature, and token limits",
      "type": "interface",
      "file": "src/ai/providers/ILLMProvider.ts"
    },
    {
      "name": "LLMMessage",
      "description": "Message structure for conversations with AI providers containing role and content",
      "type": "interface",
      "file": "src/ai/providers/ILLMProvider.ts"
    }
  ],
  "relevantCodeFiles": [
    {
      "path": "src/extension.ts",
      "description": "Main extension entry point that initializes all components and registers commands",
      "purpose": "Activates the extension and coordinates between UI components, analyzers, and AI services",
      "role": "Extension orchestrator and command handler"
    },
    {
      "path": "src/llmService.ts",
      "description": "Core service coordinating AI-powered code analysis and documentation generation",
      "purpose": "Manages interactions with AI providers to generate insights, summaries, and test plans",
      "role": "AI orchestration and analysis coordination"
    },
    {
      "path": "src/llmIntegration.ts",
      "description": "Integration layer connecting AI features with VS Code UI components",
      "purpose": "Manages state, commands, and UI updates for AI-powered features",
      "role": "UI and AI feature integration"
    },
    {
      "path": "src/analyzer.ts",
      "description": "Core data structures and interfaces for code analysis results",
      "purpose": "Defines the contract for analysis data throughout the application",
      "role": "Type definitions and data models"
    },
    {
      "path": "src/analysis/enhancedAnalyzer.ts",
      "description": "Deep code analysis using AST parsing to extract function metadata",
      "purpose": "Performs static analysis of TypeScript/JavaScript code to understand structure and behavior",
      "role": "Code parsing and metadata extraction"
    },
    {
      "path": "src/insightsTreeView.ts",
      "description": "Tree view component displaying analysis insights and documentation in the sidebar",
      "purpose": "Provides browsable interface for viewing and navigating analysis results",
      "role": "UI component for insights visualization"
    },
    {
      "path": "src/domain/services/testing/llmTestGenerationService.ts",
      "description": "Service generating unit test code using AI",
      "purpose": "Creates test code with proper setup, mocks, and assertions for functions",
      "role": "Test code generation"
    },
    {
      "path": "src/domain/services/testing/llmTestValidationService.ts",
      "description": "Service validating and automatically fixing failing tests",
      "purpose": "Executes tests and iteratively corrects failures using AI",
      "role": "Test validation and correction"
    },
    {
      "path": "src/domain/handlers/navigationHandler.ts",
      "description": "Handler managing navigation from insights to source code",
      "purpose": "Opens files and positions cursor at specific locations when users click analysis results",
      "role": "Navigation and editor control"
    },
    {
      "path": "src/domain/prompts/promptBuilder.ts",
      "description": "Centralized prompt construction for all AI interactions",
      "purpose": "Standardizes how requests are formatted for different AI tasks",
      "role": "Prompt engineering and standardization"
    },
    {
      "path": "src/ai/providers/providerFactory.ts",
      "description": "Factory creating AI provider instances based on configuration",
      "purpose": "Enables switching between OpenAI and Claude providers",
      "role": "Provider instantiation and management"
    },
    {
      "path": "src/config/configurationManager.ts",
      "description": "Manager for all extension configuration and settings",
      "purpose": "Provides access to user settings and notifies components of changes",
      "role": "Configuration management and change notification"
    },
    {
      "path": "src/infrastructure/persistence/analysisResultRepository.ts",
      "description": "Repository persisting analysis results to disk",
      "purpose": "Saves documentation and insights to .shadow directory with timestamps",
      "role": "Data persistence and retrieval"
    },
    {
      "path": "src/cache.ts",
      "description": "Caching layer for analysis results",
      "purpose": "Stores analysis in memory and on disk to avoid redundant processing",
      "role": "Performance optimization through caching"
    }
  ],
  "exampleInput": {
    "description": "Example configuration for analyzing a codebase and generating documentation",
    "json": "{\"workspace\":\"/Users/dev/my-project\",\"files\":[\"src/api/users.ts\",\"src/api/posts.ts\",\"src/models/user.ts\"],\"options\":{\"aiProvider\":\"openai\",\"model\":\"gpt-4\",\"generateTests\":true,\"analysisDepth\":\"detailed\",\"includeArchitecture\":true,\"outputFormat\":\"cursor\"}}"
  },
  "exampleOutput": {
    "description": "Example analysis result with product documentation and test generation results",
    "json": "{\"productDocumentation\":{\"name\":\"Blog API\",\"overview\":\"REST API for managing blog posts and user accounts with authentication and comment functionality\",\"features\":[\"User registration and authentication\",\"Create, read, update, delete blog posts\",\"Comment management on posts\",\"User profile management\"],\"architecture\":\"Three-tier architecture with Express.js API layer, business logic services, and PostgreSQL data layer\"},\"testResults\":{\"totalFunctions\":45,\"testsGenerated\":38,\"testsPassed\":35,\"testsFailed\":3,\"executionTime\":\"12.4s\",\"coverage\":\"87%\"},\"insights\":{\"patterns\":[\"RESTful API design\",\"Middleware authentication\",\"Repository pattern for data access\"],\"issues\":[\"Circular dependency between User and Post models\",\"Missing input validation in 3 endpoints\"],\"recommendations\":[\"Extract validation logic to separate module\",\"Add rate limiting to public endpoints\"]},\"timestamp\":\"2024-01-15T10:30:00Z\"}"
  },
  "modules": [
    {
      "module": ".",
      "moduleType": "other",
      "capabilities": [
        "Provides Jest testing framework configuration for TypeScript-based test execution",
        "Enables code coverage reporting for test suites",
        "Supports Visual Studio Code integration with mocking capabilities",
        "Configures test environment settings for consistent test execution across the project"
      ],
      "summary": "This module configures the Jest testing framework for the project, enabling developers to run and maintain automated tests written in TypeScript. It establishes the testing infrastructure that allows development teams to verify code functionality, track code coverage metrics, and ensure software quality through unit and integration tests.\n\nThe configuration supports seamless integration with Visual Studio Code, providing developers with in-editor testing capabilities and debugging support. The setup includes TypeScript transformation rules, coverage reporting thresholds, and mock handling for external dependencies, creating a comprehensive testing environment that helps maintain code reliability and catch regressions early in the development cycle.",
      "files": [
        {
          "file": "jest.config.js",
          "role": "Core Logic",
          "purpose": "Configures Jest testing framework for TypeScript test execution with coverage reporting and VS Code mocking support",
          "userVisibleActions": [
            "N/A - Configuration file with no direct user-facing actions"
          ],
          "developerVisibleActions": [
            "Runs TypeScript tests in Node.js environment when developer executes test commands",
            "Generates test coverage reports in text, lcov, and HTML formats in the 'coverage' directory",
            "Discovers and executes test files matching patterns like *.test.ts, *.spec.ts in __tests__ directories",
            "Provides code coverage metrics excluding test files, type definitions, and mock files",
            "Mocks VS Code API during test execution to enable testing without VS Code runtime",
            "Sets 10-second timeout for test execution to prevent hanging tests",
            "Transpiles TypeScript files to JavaScript using ts-jest with ES2020 target"
          ],
          "keyFunctions": [],
          "dependencies": [
            "ts-jest",
            "jest",
            "typescript"
          ],
          "intent": "This file exists to configure the Jest testing framework for a TypeScript-based VS Code extension project, enabling developers to write and run unit tests with proper TypeScript compilation, VS Code API mocking, and comprehensive code coverage reporting",
          "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript test execution with coverage reporting and VS Code mocking support\",\n  \"userVisibleActions\": [\n    \"N/A - Configuration file with no direct user-facing actions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Runs TypeScript tests in Node.js environment when developer executes test commands\",\n    \"Generates test coverage reports in text, lcov, and HTML formats in the 'coverage' directory\",\n    \"Discovers and executes test files matching patterns like *.test.ts, *.spec.ts in __tests__ directories\",\n    \"Provides code coverage metrics excluding test files, type definitions, and mock files\",\n    \"Mocks VS Code API during test execution to enable testing without VS Code runtime\",\n    \"Sets 10-second timeout for test execution to prevent hanging tests\",\n    \"Transpiles TypeScript files to JavaScript using ts-jest with ES2020 target\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript-based VS Code extension project, enabling developers to write and run unit tests with proper TypeScript compilation, VS Code API mocking, and comprehensive code coverage reporting\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai",
      "moduleType": "other",
      "capabilities": [
        "Reliable AI-powered code analysis with automatic error recovery",
        "Rate-limited API request management to prevent quota exhaustion",
        "Structured extraction of code insights from AI responses",
        "Automatic retry handling for transient API failures",
        "Seamless integration with OpenAI and Claude APIs"
      ],
      "summary": "The AI module provides robust infrastructure for interacting with large language model APIs (OpenAI and Claude) to analyze codebases. It ensures reliable AI-powered analysis by managing three critical aspects: rate limiting to prevent API quota errors, automatic retry logic for handling transient failures, and structured parsing of AI responses into typed objects.\n\nUsers benefit from seamless AI functionality that automatically handles common failure scenarios. When making AI requests to analyze code, the module prevents rate limit errors by tracking request frequency, automatically retries failed requests with exponential backoff for network issues or temporary API problems, and converts raw AI text responses into structured data about files, modules, and product documentation.\n\nThe module operates transparently in the background during code analysis workflows. When users trigger AI analysis operations, requests flow through the rate limiter to ensure they stay within API quotas, are automatically retried if they fail due to transient errors, and finally parsed into structured insights including file summaries (purpose and key functions), module summaries (user-facing capabilities), and product documentation (what the codebase does). This creates a resilient AI analysis pipeline that handles errors gracefully without requiring manual intervention.",
      "files": [
        {
          "file": "src/ai/llmRateLimiter.ts",
          "role": "Core Logic",
          "purpose": "Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs",
          "userVisibleActions": [
            "Prevents application errors when too many AI requests are made in a short time",
            "Ensures smooth AI functionality by automatically managing request timing",
            "Avoids API quota exceeded errors during heavy AI usage"
          ],
          "developerVisibleActions": [
            "Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)",
            "Check if an AI request can proceed before making the API call",
            "Record each AI request to track usage against rate limits",
            "Get remaining request capacity for planning batched operations",
            "Automatically cleans up old request history outside the time window"
          ],
          "keyFunctions": [
            {
              "name": "canMakeRequest",
              "desc": "Checks if an AI request is allowed based on rate limits",
              "inputs": "provider ('openai' or 'claude')",
              "outputs": "boolean - true if request can proceed, false if limit reached"
            },
            {
              "name": "recordRequest",
              "desc": "Records that an AI request was made to track against limits",
              "inputs": "provider ('openai' or 'claude')",
              "outputs": "void - updates internal tracking"
            },
            {
              "name": "configure",
              "desc": "Sets custom rate limits for an AI provider",
              "inputs": "provider ('openai' or 'claude'), config (maxRequests and windowMs)",
              "outputs": "void - updates provider configuration"
            }
          ],
          "dependencies": [],
          "intent": "Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas",
          "rawContent": "```json\n{\n  \"purpose\": \"Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs\",\n  \"userVisibleActions\": [\n    \"Prevents application errors when too many AI requests are made in a short time\",\n    \"Ensures smooth AI functionality by automatically managing request timing\",\n    \"Avoids API quota exceeded errors during heavy AI usage\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)\",\n    \"Check if an AI request can proceed before making the API call\",\n    \"Record each AI request to track usage against rate limits\",\n    \"Get remaining request capacity for planning batched operations\",\n    \"Automatically cleans up old request history outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if an AI request is allowed based on rate limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"boolean - true if request can proceed, false if limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records that an AI request was made to track against limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"void - updates internal tracking\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limits for an AI provider\",\n      \"inputs\": \"provider ('openai' or 'claude'), config (maxRequests and windowMs)\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas\"\n}\n```"
        },
        {
          "file": "src/ai/llmResponseParser.ts",
          "role": "Core Logic",
          "purpose": "Extracts structured data from LLM text responses and converts them into typed objects for file summaries, module summaries, and product documentation.",
          "userVisibleActions": [
            "Receives parsed insights about code files including their purpose and key functions",
            "Gets product-level documentation with clear explanations of what the codebase does",
            "Views structured information about user-facing actions and developer-facing actions extracted from AI responses"
          ],
          "developerVisibleActions": [
            "Parses LLM JSON or text responses into FileSummary objects with file metadata",
            "Converts LLM responses into ModuleSummary objects with module-level insights",
            "Transforms LLM output into EnhancedProductDocumentation with product purpose and architecture",
            "Extracts ProductPurposeAnalysis from LLM responses for high-level product understanding",
            "Falls back to text parsing when JSON parsing fails",
            "Handles malformed LLM responses gracefully with default values"
          ],
          "keyFunctions": [
            {
              "name": "parseFileSummary",
              "desc": "Converts LLM response text into a FileSummary object containing purpose, actions, and dependencies",
              "inputs": "content (string), filePath (string), role (string)",
              "outputs": "FileSummary object"
            },
            {
              "name": "extractSection",
              "desc": "Extracts a named section from text response",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Extracted text string"
            },
            {
              "name": "extractListSection",
              "desc": "Extracts a list/array section from text response",
              "inputs": "content (string), sectionName (string)",
              "outputs": "Array of strings"
            }
          ],
          "dependencies": [
            "../fileDocumentation",
            "../llmService"
          ],
          "intent": "This file exists to bridge the gap between raw LLM text responses and the typed data structures needed by the application. It solves the problem of handling unpredictable LLM output formats (JSON or text) and ensuring the application always receives valid structured data, even when the LLM response is malformed or incomplete.",
          "rawContent": "```json\n{\n  \"purpose\": \"Extracts structured data from LLM text responses and converts them into typed objects for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"Receives parsed insights about code files including their purpose and key functions\",\n    \"Gets product-level documentation with clear explanations of what the codebase does\",\n    \"Views structured information about user-facing actions and developer-facing actions extracted from AI responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Parses LLM JSON or text responses into FileSummary objects with file metadata\",\n    \"Converts LLM responses into ModuleSummary objects with module-level insights\",\n    \"Transforms LLM output into EnhancedProductDocumentation with product purpose and architecture\",\n    \"Extracts ProductPurposeAnalysis from LLM responses for high-level product understanding\",\n    \"Falls back to text parsing when JSON parsing fails\",\n    \"Handles malformed LLM responses gracefully with default values\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object containing purpose, actions, and dependencies\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a named section from text response\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted text string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array section from text response\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw LLM text responses and the typed data structures needed by the application. It solves the problem of handling unpredictable LLM output formats (JSON or text) and ensuring the application always receives valid structured data, even when the LLM response is malformed or incomplete.\"\n}\n```"
        },
        {
          "file": "src/ai/llmRetryHandler.ts",
          "role": "Core Logic",
          "purpose": "Provides automatic retry logic with exponential backoff for LLM API requests that fail due to transient errors like rate limits or network issues.",
          "userVisibleActions": [
            "Automatic retry of failed AI requests without manual intervention",
            "Seamless recovery from temporary API failures (rate limits, timeouts, network errors)",
            "Delayed retries that gradually increase wait time between attempts",
            "Eventual success or clear failure after exhausting retry attempts"
          ],
          "developerVisibleActions": [
            "Wrap LLM API calls with automatic retry handling using RetryHandler.executeWithRetry()",
            "Configure retry behavior (max attempts, delays, backoff multiplier)",
            "Specify which error types should trigger retries via retryableErrors option",
            "Receive retry attempt notifications through optional onRetry callback",
            "Get results with attempt count metadata via RetryResult interface",
            "Distinguish between retryable errors (rate limits, timeouts) and non-retryable errors (authentication, invalid requests)",
            "Customize initial delay, max delay, and exponential backoff multiplier"
          ],
          "keyFunctions": [
            {
              "name": "executeWithRetry",
              "desc": "Executes an async operation with automatic retry logic, exponential backoff, and error classification",
              "inputs": "operation (async function returning Promise<T>), options (RetryOptions with maxRetries, delays, retryableErrors, onRetry callback)",
              "outputs": "Promise<T> containing the operation result, or throws error if all retries exhausted"
            },
            {
              "name": "isRetryableError",
              "desc": "Determines if an error should trigger a retry based on error message/code matching",
              "inputs": "error object, array of retryable error patterns",
              "outputs": "boolean indicating if error is retryable"
            }
          ],
          "dependencies": [],
          "intent": "Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, network issues, temporary server errors) without requiring manual retry logic throughout the codebase. Prevents users from experiencing failures due to temporary API issues and reduces the need for developers to implement retry logic in every API call.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides automatic retry logic with exponential backoff for LLM API requests that fail due to transient errors like rate limits or network issues.\",\n  \"userVisibleActions\": [\n    \"Automatic retry of failed AI requests without manual intervention\",\n    \"Seamless recovery from temporary API failures (rate limits, timeouts, network errors)\",\n    \"Delayed retries that gradually increase wait time between attempts\",\n    \"Eventual success or clear failure after exhausting retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap LLM API calls with automatic retry handling using RetryHandler.executeWithRetry()\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries via retryableErrors option\",\n    \"Receive retry attempt notifications through optional onRetry callback\",\n    \"Get results with attempt count metadata via RetryResult interface\",\n    \"Distinguish between retryable errors (rate limits, timeouts) and non-retryable errors (authentication, invalid requests)\",\n    \"Customize initial delay, max delay, and exponential backoff multiplier\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic, exponential backoff, and error classification\",\n      \"inputs\": \"operation (async function returning Promise<T>), options (RetryOptions with maxRetries, delays, retryableErrors, onRetry callback)\",\n      \"outputs\": \"Promise<T> containing the operation result, or throws error if all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry based on error message/code matching\",\n      \"inputs\": \"error object, array of retryable error patterns\",\n      \"outputs\": \"boolean indicating if error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, network issues, temporary server errors) without requiring manual retry logic throughout the codebase. Prevents users from experiencing failures due to temporary API issues and reduces the need for developers to implement retry logic in every API call.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/ai/providers",
      "moduleType": "other",
      "capabilities": [
        "Switch between multiple AI providers (OpenAI GPT models and Anthropic Claude) for natural language processing",
        "Send prompts and receive AI-generated text responses in a provider-agnostic way",
        "Request and receive structured JSON responses from AI models for data extraction and code analysis",
        "Maintain conversation history across multiple exchanges with AI models",
        "Stream AI responses progressively for real-time user feedback",
        "Automatically validate and extract JSON from AI responses when structured output is needed",
        "Configure and manage AI provider credentials through a unified interface"
      ],
      "summary": "This module provides a unified abstraction layer for interacting with multiple AI language model providers. Users can communicate with either OpenAI's GPT models or Anthropic's Claude AI through a consistent interface, allowing them to switch between providers without changing how they interact with the AI. The module handles all provider-specific implementation details, authentication, and response formatting behind the scenes.\n\nUsers can send natural language prompts and receive AI-generated responses in two formats: regular text for conversational interactions, or structured JSON for data extraction and code analysis tasks. The module supports both streaming responses (where text appears progressively) and complete responses. It automatically handles message history to maintain context across multi-turn conversations and validates JSON responses to ensure data integrity.\n\nThe factory pattern implementation allows users to easily switch between AI providers based on their configuration settings, with the system automatically selecting and initializing the appropriate provider (OpenAI or Claude) based on available API keys. This flexibility enables users to choose the best AI model for their specific needs while maintaining a consistent experience regardless of which provider is active.",
      "files": [
        {
          "file": "src/ai/providers/ILLMProvider.ts",
          "role": "Core Logic",
          "purpose": "Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way",
          "userVisibleActions": [
            "User receives AI-generated text responses to their queries",
            "User receives structured JSON responses when requesting formatted data",
            "User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured"
          ],
          "developerVisibleActions": [
            "Developer implements this interface to add new AI provider support",
            "Developer calls sendRequest() to get text responses from any LLM provider",
            "Developer calls sendStructuredRequest() to get parsed JSON data from LLM",
            "Developer checks isConfigured() to verify provider is ready before making requests",
            "Developer configures conversation messages with role-based structure (system, user, assistant)",
            "Developer controls response parameters like temperature, max tokens, and response format"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if the provider has valid credentials and is ready to use",
              "inputs": "None",
              "outputs": "Boolean indicating if provider is configured"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt to the LLM and returns text response",
              "inputs": "LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)",
              "outputs": "Promise<LLMResponse> with content, finish reason, model name, and raw response"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests",
              "inputs": "LLMRequestOptions and optional JSON schema",
              "outputs": "Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests"
            },
            {
              "name": "getName",
              "desc": "Returns the provider's display name",
              "inputs": "None",
              "outputs": "String provider name (e.g., 'OpenAI', 'Claude')"
            }
          ],
          "dependencies": [],
          "intent": "This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON responses when requesting formatted data\",\n    \"User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add new AI provider support\",\n    \"Developer calls sendRequest() to get text responses from any LLM provider\",\n    \"Developer calls sendStructuredRequest() to get parsed JSON data from LLM\",\n    \"Developer checks isConfigured() to verify provider is ready before making requests\",\n    \"Developer configures conversation messages with role-based structure (system, user, assistant)\",\n    \"Developer controls response parameters like temperature, max tokens, and response format\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has valid credentials and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns text response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, model name, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider's display name\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String provider name (e.g., 'OpenAI', 'Claude')\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/anthropicProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides integration with Anthropic's Claude AI models for natural language processing and code analysis tasks",
          "userVisibleActions": [
            "Sends prompts to Claude AI and receives AI-generated responses",
            "Generates structured data (JSON) from Claude's responses for code analysis",
            "Processes conversations with Claude while maintaining message history",
            "Receives error messages when Claude API key is not configured"
          ],
          "developerVisibleActions": [
            "Initialize Claude API client with API key from configuration",
            "Send requests to Claude with custom models, system prompts, and message history",
            "Extract structured JSON data from Claude's text responses",
            "Check if Claude provider is properly configured before use",
            "Handle message format conversion between OpenAI-style and Claude-style formats",
            "Configure request timeouts and token limits for Claude API calls"
          ],
          "keyFunctions": [
            {
              "name": "isConfigured",
              "desc": "Checks if Claude API key is set up and ready to use",
              "inputs": "none",
              "outputs": "boolean indicating if provider is configured"
            },
            {
              "name": "getName",
              "desc": "Returns the provider identifier",
              "inputs": "none",
              "outputs": "string 'claude'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a prompt with conversation history to Claude and returns the response",
              "inputs": "LLMRequestOptions (messages, model, systemPrompt, maxTokens)",
              "outputs": "LLMResponse with text content and token usage"
            },
            {
              "name": "sendStructuredRequest",
              "desc": "Sends a request to Claude and extracts JSON data from the response",
              "inputs": "LLMRequestOptions with expected JSON structure",
              "outputs": "StructuredOutputResponse with parsed JSON data"
            },
            {
              "name": "initialize",
              "desc": "Sets up the Claude API client with credentials from configuration",
              "inputs": "none (reads from config manager)",
              "outputs": "void (initializes client)"
            }
          ],
          "dependencies": [
            "@anthropic-ai/sdk",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to abstract Claude AI integration so developers can interact with Anthropic's language models using a consistent interface. It solves the problem of converting between different AI provider formats and handling Claude-specific API requirements, making it easy to switch between AI providers without changing application code.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for natural language processing and code analysis tasks\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives AI-generated responses\",\n    \"Generates structured data (JSON) from Claude's responses for code analysis\",\n    \"Processes conversations with Claude while maintaining message history\",\n    \"Receives error messages when Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize Claude API client with API key from configuration\",\n    \"Send requests to Claude with custom models, system prompts, and message history\",\n    \"Extract structured JSON data from Claude's text responses\",\n    \"Check if Claude provider is properly configured before use\",\n    \"Handle message format conversion between OpenAI-style and Claude-style formats\",\n    \"Configure request timeouts and token limits for Claude API calls\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt with conversation history to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions (messages, model, systemPrompt, maxTokens)\",\n      \"outputs\": \"LLMResponse with text content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a request to Claude and extracts JSON data from the response\",\n      \"inputs\": \"LLMRequestOptions with expected JSON structure\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude API client with credentials from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"void (initializes client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract Claude AI integration so developers can interact with Anthropic's language models using a consistent interface. It solves the problem of converting between different AI provider formats and handling Claude-specific API requirements, making it easy to switch between AI providers without changing application code.\"\n}\n```"
        },
        {
          "file": "src/ai/providers/openAIProvider.ts",
          "role": "Core Logic",
          "purpose": "Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses",
          "userVisibleActions": [
            "Sends user messages to OpenAI's GPT models and receives AI-generated responses",
            "Supports both regular text responses and structured JSON responses from the AI",
            "Handles streaming responses where AI text appears progressively",
            "Automatically validates and extracts JSON from AI responses when structured output is requested"
          ],
          "developerVisibleActions": [
            "Configures OpenAI API connection using API key from configuration manager",
            "Provides synchronous check if OpenAI is properly configured via isConfigured()",
            "Sends chat completion requests with customizable model, messages, and response format",
            "Returns structured responses with content, finish reason, and token usage statistics",
            "Streams chat completions with real-time content chunks via async iteration",
            "Extracts and validates JSON from AI responses for structured output requests",
            "Sets 5-minute timeout for all OpenAI API requests",
            "Throws errors when API key is not configured"
          ],
          "keyFunctions": [
            {
              "name": "initialize",
              "desc": "Sets up OpenAI client with API key from configuration",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "isConfigured",
              "desc": "Checks if OpenAI provider is ready to use",
              "inputs": "None",
              "outputs": "boolean indicating if API key is set"
            },
            {
              "name": "getName",
              "desc": "Returns provider identifier",
              "inputs": "None",
              "outputs": "String 'openai'"
            },
            {
              "name": "sendRequest",
              "desc": "Sends a chat completion request to OpenAI and returns the response",
              "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
              "outputs": "Promise<LLMResponse> with content, finishReason, and usage stats"
            },
            {
              "name": "streamRequest",
              "desc": "Streams a chat completion request with progressive content delivery",
              "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
              "outputs": "AsyncIterable<string> yielding content chunks as they arrive"
            },
            {
              "name": "sendStructuredOutputRequest",
              "desc": "Sends request expecting JSON response and validates the output",
              "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
              "outputs": "Promise<StructuredOutputResponse> with parsed JSON data or validation errors"
            }
          ],
          "dependencies": [
            "openai",
            "../../config/configurationManager",
            "../../utils/jsonExtractor",
            "./ILLMProvider"
          ],
          "intent": "This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Sends user messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Supports both regular text responses and structured JSON responses from the AI\",\n    \"Handles streaming responses where AI text appears progressively\",\n    \"Automatically validates and extracts JSON from AI responses when structured output is requested\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configures OpenAI API connection using API key from configuration manager\",\n    \"Provides synchronous check if OpenAI is properly configured via isConfigured()\",\n    \"Sends chat completion requests with customizable model, messages, and response format\",\n    \"Returns structured responses with content, finish reason, and token usage statistics\",\n    \"Streams chat completions with real-time content chunks via async iteration\",\n    \"Extracts and validates JSON from AI responses for structured output requests\",\n    \"Sets 5-minute timeout for all OpenAI API requests\",\n    \"Throws errors when API key is not configured\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI provider is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if API key is set\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<LLMResponse> with content, finishReason, and usage stats\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams a chat completion request with progressive content delivery\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"AsyncIterable<string> yielding content chunks as they arrive\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting JSON response and validates the output\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data or validation errors\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally\"\n}\n```"
        },
        {
          "file": "src/ai/providers/providerFactory.ts",
          "role": "Core Logic",
          "purpose": "Factory that creates and manages AI provider instances (OpenAI or Claude) based on configuration settings",
          "userVisibleActions": [
            "Switches between different AI providers (OpenAI or Claude) for generating responses",
            "Ensures only configured AI providers are available for use",
            "Maintains consistent AI provider throughout the session unless configuration changes"
          ],
          "developerVisibleActions": [
            "Provides a centralized way to obtain AI provider instances without creating duplicates",
            "Returns the currently configured AI provider based on user settings",
            "Validates which AI providers have valid API keys and configuration",
            "Lists all AI providers that are properly configured and ready to use",
            "Maintains singleton instances of each provider to avoid redundant initialization"
          ],
          "keyFunctions": [
            {
              "name": "getProvider",
              "desc": "Returns the AI provider instance for a specific provider type (openai or claude)",
              "inputs": "provider: LLMProvider (either 'openai' or 'claude')",
              "outputs": "ILLMProvider instance"
            },
            {
              "name": "getCurrentProvider",
              "desc": "Returns the AI provider that is currently set in user configuration",
              "inputs": "none",
              "outputs": "ILLMProvider instance of the configured provider"
            },
            {
              "name": "isProviderConfigured",
              "desc": "Checks if a specific AI provider has valid configuration and API keys",
              "inputs": "provider: LLMProvider (either 'openai' or 'claude')",
              "outputs": "boolean indicating if provider is ready to use"
            },
            {
              "name": "getConfiguredProviders",
              "desc": "Returns a list of all AI providers that are properly configured",
              "inputs": "none",
              "outputs": "Array of LLMProvider types that are configured"
            }
          ],
          "dependencies": [
            "./ILLMProvider",
            "./openAIProvider",
            "./anthropicProvider",
            "../../config/configurationManager"
          ],
          "intent": "Provides a centralized factory pattern for creating and managing AI provider instances, ensuring proper initialization, configuration validation, and singleton behavior to avoid duplicate provider instances while supporting multiple AI backends.",
          "rawContent": "```json\n{\n  \"purpose\": \"Factory that creates and manages AI provider instances (OpenAI or Claude) based on configuration settings\",\n  \"userVisibleActions\": [\n    \"Switches between different AI providers (OpenAI or Claude) for generating responses\",\n    \"Ensures only configured AI providers are available for use\",\n    \"Maintains consistent AI provider throughout the session unless configuration changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a centralized way to obtain AI provider instances without creating duplicates\",\n    \"Returns the currently configured AI provider based on user settings\",\n    \"Validates which AI providers have valid API keys and configuration\",\n    \"Lists all AI providers that are properly configured and ready to use\",\n    \"Maintains singleton instances of each provider to avoid redundant initialization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the AI provider instance for a specific provider type (openai or claude)\",\n      \"inputs\": \"provider: LLMProvider (either 'openai' or 'claude')\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently set in user configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance of the configured provider\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific AI provider has valid configuration and API keys\",\n      \"inputs\": \"provider: LLMProvider (either 'openai' or 'claude')\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all AI providers that are properly configured\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of LLMProvider types that are configured\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Provides a centralized factory pattern for creating and managing AI provider instances, ensuring proper initialization, configuration validation, and singleton behavior to avoid duplicate provider instances while supporting multiple AI backends.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/analysis",
      "moduleType": "other",
      "capabilities": [
        "Deep code analysis through Abstract Syntax Tree (AST) parsing of TypeScript and JavaScript files",
        "Function-level metadata extraction including signatures, parameters, return types, and complexity metrics",
        "Automatic dependency and relationship mapping between functions",
        "Behavioral pattern detection (queries, mutations, validations, side effects)",
        "Branch coverage analysis showing different execution paths",
        "State mutation and side effect identification",
        "Large file refactoring recommendations based on complexity and size thresholds",
        "Function interdependency visualization"
      ],
      "summary": "The analysis module provides comprehensive code intelligence for TypeScript and JavaScript codebases. It performs deep static analysis by parsing source files into Abstract Syntax Trees (ASTs) and extracting detailed metadata about functions, their relationships, and behavioral patterns. Users gain insights into code complexity, dependencies, and structure to make informed refactoring decisions.\n\nThe module enables developers to understand their codebase at both the macro and micro levels. At the file level, it identifies large or complex files that may benefit from refactoring. At the function level, it provides granular details including complexity metrics, dependency chains, branch coverage, and behavioral hints such as whether a function performs queries, mutations, or validations. This helps teams maintain code quality and identify technical debt.\n\nTypical workflows include analyzing existing codebases to find refactoring opportunities, understanding function relationships before making changes, identifying potential side effects, and tracking code complexity metrics. The module serves as the foundation for automated refactoring suggestions by providing the structured data needed to understand how code components interact and where improvements can be made.",
      "files": [
        {
          "file": "src/analysis/enhancedAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Provides deep code analysis capabilities by parsing TypeScript/JavaScript files using AST to extract function metadata, dependencies, branches, and behavioral patterns.",
          "userVisibleActions": [
            "Receives detailed analysis of code functions including complexity metrics",
            "Gets insights about code dependencies and how functions relate to each other",
            "Views behavioral hints about what functions do (queries, mutations, validations)",
            "Sees branch coverage information showing different code paths",
            "Understands state mutations and side effects in functions"
          ],
          "developerVisibleActions": [
            "Calls analyzeFileMetadata() to extract comprehensive metadata from a code file",
            "Receives FunctionMetadata objects containing branches, dependencies, and behavioral hints",
            "Gets AST-based analysis for TypeScript/JavaScript files with deep introspection",
            "Falls back to regex-based analysis for non-TypeScript languages",
            "Obtains branch information showing conditional paths and complexity",
            "Retrieves dependency information showing function calls and imports",
            "Accesses state mutation tracking for variables and properties",
            "Uses test mapping to understand test coverage relationships"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFileMetadata",
              "desc": "Analyzes a code file and extracts enhanced metadata for all functions in it",
              "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
              "outputs": "Map<string, FunctionMetadata> containing detailed analysis for each function"
            },
            {
              "name": "analyzeTypeScriptFunction",
              "desc": "Performs AST-based analysis of TypeScript/JavaScript functions to extract detailed metadata",
              "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
              "outputs": "FunctionMetadata with branches, dependencies, mutations, and behavioral hints"
            },
            {
              "name": "analyzeFunctionWithRegex",
              "desc": "Provides fallback regex-based analysis for non-TypeScript languages",
              "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
              "outputs": "FunctionMetadata with basic pattern-matched analysis"
            },
            {
              "name": "extractFunctionContent",
              "desc": "Extracts the source code content of a function between specified line numbers",
              "inputs": "content (string), startLine (number), endLine (number)",
              "outputs": "String containing the function's source code"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer"
          ],
          "intent": "This file exists to provide advanced code analysis beyond basic pattern matching by leveraging TypeScript's compiler API to deeply understand code structure, identify branches, track dependencies, detect behavioral patterns, and extract comprehensive metadata that enables intelligent code understanding and test generation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities by parsing TypeScript/JavaScript files using AST to extract function metadata, dependencies, branches, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including complexity metrics\",\n    \"Gets insights about code dependencies and how functions relate to each other\",\n    \"Views behavioral hints about what functions do (queries, mutations, validations)\",\n    \"Sees branch coverage information showing different code paths\",\n    \"Understands state mutations and side effects in functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFileMetadata() to extract comprehensive metadata from a code file\",\n    \"Receives FunctionMetadata objects containing branches, dependencies, and behavioral hints\",\n    \"Gets AST-based analysis for TypeScript/JavaScript files with deep introspection\",\n    \"Falls back to regex-based analysis for non-TypeScript languages\",\n    \"Obtains branch information showing conditional paths and complexity\",\n    \"Retrieves dependency information showing function calls and imports\",\n    \"Accesses state mutation tracking for variables and properties\",\n    \"Uses test mapping to understand test coverage relationships\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a code file and extracts enhanced metadata for all functions in it\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing detailed analysis for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis of TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata with branches, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for non-TypeScript languages\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata with basic pattern-matched analysis\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function between specified line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced code analysis beyond basic pattern matching by leveraging TypeScript's compiler API to deeply understand code structure, identify branches, track dependencies, detect behavioral patterns, and extract comprehensive metadata that enables intelligent code understanding and test generation.\"\n}\n```"
        },
        {
          "file": "src/analysis/functionAnalyzer.ts",
          "role": "Core Logic",
          "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and relationships for refactoring recommendations",
          "userVisibleActions": [
            "Identifies functions in large files that may need refactoring",
            "Provides detailed function analysis reports showing what each function does",
            "Shows which functions depend on each other",
            "Highlights functions that exceed complexity or size thresholds"
          ],
          "developerVisibleActions": [
            "Analyzes all functions in files exceeding a configurable line threshold (default 500 lines)",
            "Extracts function signatures including parameters and return types",
            "Maps function dependencies showing which functions call which",
            "Maps function dependents showing where each function is used",
            "Identifies function responsibilities and behavior patterns",
            "Returns structured FunctionAnalysis objects containing all extracted metadata",
            "Handles analysis failures gracefully with warnings",
            "Resolves file paths across different project structures"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Analyzes all functions in files that exceed the size threshold and returns detailed analysis for each",
              "inputs": "CodeAnalysis object, optional largeFileThreshold (default 500)",
              "outputs": "Array of FunctionAnalysis objects containing function metadata"
            },
            {
              "name": "analyzeFunction",
              "desc": "Performs detailed analysis of a single function extracting its signature, dependencies, and relationships",
              "inputs": "File path, FunctionInfo object, CodeAnalysis context",
              "outputs": "FunctionAnalysis object or null if analysis fails"
            },
            {
              "name": "resolveFilePath",
              "desc": "Resolves relative file paths to absolute paths in the project structure",
              "inputs": "Relative file path, CodeAnalysis context",
              "outputs": "Absolute file path string"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "typescript",
            "../analyzer",
            "../domain/prompts/refactoringPromptBuilder"
          ],
          "intent": "This file exists to provide deep analysis of functions in large code files, extracting comprehensive metadata needed to generate intelligent refactoring recommendations. It solves the problem of understanding complex function relationships and dependencies when suggesting how to break down large files into smaller, more maintainable modules.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and relationships for refactoring recommendations\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Provides detailed function analysis reports showing what each function does\",\n    \"Shows which functions depend on each other\",\n    \"Highlights functions that exceed complexity or size thresholds\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes all functions in files exceeding a configurable line threshold (default 500 lines)\",\n    \"Extracts function signatures including parameters and return types\",\n    \"Maps function dependencies showing which functions call which\",\n    \"Maps function dependents showing where each function is used\",\n    \"Identifies function responsibilities and behavior patterns\",\n    \"Returns structured FunctionAnalysis objects containing all extracted metadata\",\n    \"Handles analysis failures gracefully with warnings\",\n    \"Resolves file paths across different project structures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files that exceed the size threshold and returns detailed analysis for each\",\n      \"inputs\": \"CodeAnalysis object, optional largeFileThreshold (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing function metadata\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis of a single function extracting its signature, dependencies, and relationships\",\n      \"inputs\": \"File path, FunctionInfo object, CodeAnalysis context\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths in the project structure\",\n      \"inputs\": \"Relative file path, CodeAnalysis context\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions in large code files, extracting comprehensive metadata needed to generate intelligent refactoring recommendations. It solves the problem of understanding complex function relationships and dependencies when suggesting how to break down large files into smaller, more maintainable modules.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src",
      "moduleType": "other",
      "capabilities": [
        "Automated code analysis and architecture insight generation using AI (LLM)",
        "Visual tree-view browsing of code structure, statistics, and analysis results",
        "Inline diagnostics showing code quality issues and warnings in the Problems panel",
        "AI-powered documentation generation for products, modules, and files",
        "Unit test analysis and AI-assisted test generation",
        "Real-time file monitoring with automatic analysis on save",
        "Intelligent code search and file content inspection",
        "Caching system for faster repeated analysis",
        "Multiple LLM provider support (OpenAI, Claude) with configurable models",
        "Export and sharing of generated insights and documentation"
      ],
      "summary": "This module is a VSCode extension that provides comprehensive AI-powered code analysis and documentation capabilities. It analyzes your codebase to identify architecture patterns, code quality issues, dependencies, entry points, and organizational problems. The extension surfaces these insights through multiple interfaces: inline diagnostics with squiggly underlines, a browsable tree view in the sidebar showing code structure and statistics, and an insights panel displaying AI-generated recommendations.\n\nThe module supports end-to-end workflows from initial analysis through documentation generation. Users can analyze individual files or entire workspaces, with results automatically updating when files are saved. The AI integration generates structured documentation explaining what code does and why it exists, identifies potential issues like circular dependencies and orphaned files, and can even generate unit test plans. All analysis results are cached for performance and can be exported to markdown files.\n\nThe extension integrates deeply with VSCode's UI, providing clickable navigation from insights to source code locations, status bar indicators showing analysis progress, and multiple output formats optimized for different AI assistants. Users can configure LLM providers and API settings, control when analysis runs, and choose between different formatting styles for generated content.",
      "files": [
        {
          "file": "src/analysisViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view panel in VSCode that displays code analysis results in an organized, browsable hierarchy.",
          "userVisibleActions": [
            "View a tree-structured panel showing code analysis results organized by categories",
            "Browse statistics about analyzed code (file counts, function counts, line counts)",
            "Explore files and directories in the analyzed codebase",
            "See detailed information about individual files (lines, functions, imports, exports)",
            "View function details (name, parameters, return type, line numbers)",
            "Browse entry points (main functions, exports, classes) discovered in the code",
            "Click on items to navigate to specific locations in source files",
            "See contextual descriptions for each tree item",
            "View 'No analysis available' message when no analysis has been run",
            "Refresh the view to see updated analysis results"
          ],
          "developerVisibleActions": [
            "Tree view automatically updates when setAnalysis() is called with new analysis data",
            "Tree items are organized hierarchically: root categories  files/functions  details",
            "Each tree item shows icons, labels, tooltips, and descriptions",
            "Items can be collapsed or expanded to show nested information",
            "Clicking items triggers commands to reveal file locations in editor",
            "View integrates with VSCode's tree data provider API",
            "Analysis data is passed in as CodeAnalysis objects containing files, functions, and entry points"
          ],
          "keyFunctions": [
            {
              "name": "setAnalysis",
              "desc": "Updates the tree view with new analysis results",
              "inputs": "analysis: CodeAnalysis | null",
              "outputs": "void"
            },
            {
              "name": "refresh",
              "desc": "Triggers a refresh of the entire tree view",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the VSCode tree item for display",
              "inputs": "element: AnalysisItem",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "getChildren",
              "desc": "Returns child items for a given tree node or root items if none specified",
              "inputs": "element?: AnalysisItem",
              "outputs": "Thenable<AnalysisItem[]>"
            },
            {
              "name": "getRootItems",
              "desc": "Returns top-level categories in the tree (Statistics, Files, Functions, Entry Points)",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getStatisticsItems",
              "desc": "Returns statistical summary items about the analyzed code",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFilesItems",
              "desc": "Returns file and directory items organized by directory structure",
              "inputs": "none",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getFileDetails",
              "desc": "Returns detailed information items for a specific file",
              "inputs": "element: AnalysisItem",
              "outputs": "AnalysisItem[]"
            },
            {
              "name": "getDirectoryFiles",
              "desc": "Returns files contained within a directory item",
              "inputs": "element: AnalysisItem",
              "outputs": "AnalysisItem[]"
            }
          ],
          "dependencies": [
            "vscode",
            "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
            "path"
          ],
          "intent": "This file exists to provide developers with a visual, interactive way to browse and understand code analysis results within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree view interface, allowing developers to quickly explore code structure, statistics, and relationships without examining raw data structures.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view panel in VSCode that displays code analysis results in an organized, browsable hierarchy.\",\n  \"userVisibleActions\": [\n    \"View a tree-structured panel showing code analysis results organized by categories\",\n    \"Browse statistics about analyzed code (file counts, function counts, line counts)\",\n    \"Explore files and directories in the analyzed codebase\",\n    \"See detailed information about individual files (lines, functions, imports, exports)\",\n    \"View function details (name, parameters, return type, line numbers)\",\n    \"Browse entry points (main functions, exports, classes) discovered in the code\",\n    \"Click on items to navigate to specific locations in source files\",\n    \"See contextual descriptions for each tree item\",\n    \"View 'No analysis available' message when no analysis has been run\",\n    \"Refresh the view to see updated analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically updates when setAnalysis() is called with new analysis data\",\n    \"Tree items are organized hierarchically: root categories  files/functions  details\",\n    \"Each tree item shows icons, labels, tooltips, and descriptions\",\n    \"Items can be collapsed or expanded to show nested information\",\n    \"Clicking items triggers commands to reveal file locations in editor\",\n    \"View integrates with VSCode's tree data provider API\",\n    \"Analysis data is passed in as CodeAnalysis objects containing files, functions, and entry points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the entire tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VSCode tree item for display\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if none specified\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Returns top-level categories in the tree (Statistics, Files, Functions, Entry Points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Returns statistical summary items about the analyzed code\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Returns file and directory items organized by directory structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information items for a specific file\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getDirectoryFiles\",\n      \"desc\": \"Returns files contained within a directory item\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide developers with a visual, interactive way to browse and understand code analysis results within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree view interface, allowing developers to quickly explore code structure, statistics, and relationships without examining raw data structures.\"\n}\n```"
        },
        {
          "file": "src/analyzer.ts",
          "role": "Core Logic",
          "purpose": "Defines core data structures and interfaces for code analysis results, including file metrics, function metadata, dependencies, and test mappings.",
          "userVisibleActions": [
            "View total project statistics (files, lines, functions)",
            "See large files identified in the codebase",
            "Browse function information with parameters and return types",
            "Examine import relationships between files",
            "Identify orphaned files not imported anywhere",
            "Discover entry points in the application",
            "View duplicate code groups",
            "See function risk levels (high/medium/low)",
            "Review function documentation and visibility",
            "Explore test coverage mapping for functions"
          ],
          "developerVisibleActions": [
            "Import CodeAnalysis interface to structure analysis results",
            "Use FunctionMetadata to store detailed function information including parameters, return types, and docstrings",
            "Track branch complexity with BranchInfo (if/else/switch/loop/exception handling)",
            "Map dependencies by type (database, HTTP, filesystem, cache, etc.)",
            "Monitor state mutations (assign/modify/delete/read operations)",
            "Link source files to their test files using TestMapping",
            "Identify uncovered functions without tests",
            "Detect duplicate code sections with similarity scores",
            "Cache analysis results using AnalysisCache",
            "Track function relationships through imports and dependencies"
          ],
          "keyFunctions": [
            {
              "name": "CodeAnalysis",
              "desc": "Main interface that aggregates all analysis results for a codebase",
              "inputs": "Analysis data from file system traversal",
              "outputs": "Structured metrics including files, functions, imports, orphans, entry points, and optional enhanced metadata"
            },
            {
              "name": "FunctionMetadata",
              "desc": "Comprehensive metadata for individual functions including control flow and dependencies",
              "inputs": "Parsed function information from source code",
              "outputs": "Structured function details with parameters, branches, dependencies, mutations, and risk assessment"
            },
            {
              "name": "TestMapping",
              "desc": "Maps source code to test files and identifies untested functions",
              "inputs": "Source files and test files from analysis",
              "outputs": "Bidirectional mapping between source files/functions and their tests, plus uncovered functions list"
            },
            {
              "name": "DependencyInfo",
              "desc": "Categorizes and tracks external and internal dependencies",
              "inputs": "Import statements and function calls",
              "outputs": "Classified dependencies by type (db/http/filesystem/etc.) with internal/external flag"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./cache"
          ],
          "intent": "This file exists to establish a comprehensive, type-safe contract for code analysis results. It solves the problem of consistently structuring complex codebase analysis data including metrics, metadata, relationships, and test coverage so that other components can reliably process and display analysis insights to users.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines core data structures and interfaces for code analysis results, including file metrics, function metadata, dependencies, and test mappings.\",\n  \"userVisibleActions\": [\n    \"View total project statistics (files, lines, functions)\",\n    \"See large files identified in the codebase\",\n    \"Browse function information with parameters and return types\",\n    \"Examine import relationships between files\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points in the application\",\n    \"View duplicate code groups\",\n    \"See function risk levels (high/medium/low)\",\n    \"Review function documentation and visibility\",\n    \"Explore test coverage mapping for functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import CodeAnalysis interface to structure analysis results\",\n    \"Use FunctionMetadata to store detailed function information including parameters, return types, and docstrings\",\n    \"Track branch complexity with BranchInfo (if/else/switch/loop/exception handling)\",\n    \"Map dependencies by type (database, HTTP, filesystem, cache, etc.)\",\n    \"Monitor state mutations (assign/modify/delete/read operations)\",\n    \"Link source files to their test files using TestMapping\",\n    \"Identify uncovered functions without tests\",\n    \"Detect duplicate code sections with similarity scores\",\n    \"Cache analysis results using AnalysisCache\",\n    \"Track function relationships through imports and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface that aggregates all analysis results for a codebase\",\n      \"inputs\": \"Analysis data from file system traversal\",\n      \"outputs\": \"Structured metrics including files, functions, imports, orphans, entry points, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Comprehensive metadata for individual functions including control flow and dependencies\",\n      \"inputs\": \"Parsed function information from source code\",\n      \"outputs\": \"Structured function details with parameters, branches, dependencies, mutations, and risk assessment\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test files and identifies untested functions\",\n      \"inputs\": \"Source files and test files from analysis\",\n      \"outputs\": \"Bidirectional mapping between source files/functions and their tests, plus uncovered functions list\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Categorizes and tracks external and internal dependencies\",\n      \"inputs\": \"Import statements and function calls\",\n      \"outputs\": \"Classified dependencies by type (db/http/filesystem/etc.) with internal/external flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file exists to establish a comprehensive, type-safe contract for code analysis results. It solves the problem of consistently structuring complex codebase analysis data including metrics, metadata, relationships, and test coverage so that other components can reliably process and display analysis insights to users.\"\n}\n```"
        },
        {
          "file": "src/cache.ts",
          "role": "Core Logic",
          "purpose": "Manages persistent caching of code analysis results to improve performance by avoiding redundant analysis.",
          "userVisibleActions": [
            "Analysis results load faster when reopening a workspace (within 24 hours)",
            "Previously analyzed code doesn't need to be re-analyzed immediately",
            "Cache data is automatically cleaned up when old"
          ],
          "developerVisibleActions": [
            "Stores code analysis results in a hidden .shadowwatch-cache directory",
            "Automatically retrieves cached analysis when available and valid",
            "Cache expires after 24 hours requiring fresh analysis",
            "Cache can be manually cleared to force new analysis",
            "Failed cache operations are logged but don't break functionality"
          ],
          "keyFunctions": [
            {
              "name": "constructor",
              "desc": "Initializes cache storage location",
              "inputs": "storagePath: string",
              "outputs": "AnalysisCache instance"
            },
            {
              "name": "get",
              "desc": "Retrieves cached analysis results for a workspace if valid",
              "inputs": "workspaceRoot: string",
              "outputs": "Promise<CodeAnalysis | null>"
            },
            {
              "name": "set",
              "desc": "Saves analysis results to cache with timestamp",
              "inputs": "workspaceRoot: string, data: CodeAnalysis",
              "outputs": "Promise<void>"
            },
            {
              "name": "clear",
              "desc": "Removes all cached analysis data",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "getCacheKey",
              "desc": "Generates a safe filename identifier from workspace path",
              "inputs": "workspaceRoot: string",
              "outputs": "string (base64 encoded safe filename)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "Improves extension performance by caching expensive code analysis results, preventing redundant analysis of the same codebase within a 24-hour window. This makes subsequent workspace loads faster and reduces computational overhead.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent caching of code analysis results to improve performance by avoiding redundant analysis.\",\n  \"userVisibleActions\": [\n    \"Analysis results load faster when reopening a workspace (within 24 hours)\",\n    \"Previously analyzed code doesn't need to be re-analyzed immediately\",\n    \"Cache data is automatically cleaned up when old\"\n  ],\n  \"developerVisibleActions\": [\n    \"Stores code analysis results in a hidden .shadowwatch-cache directory\",\n    \"Automatically retrieves cached analysis when available and valid\",\n    \"Cache expires after 24 hours requiring fresh analysis\",\n    \"Cache can be manually cleared to force new analysis\",\n    \"Failed cache operations are logged but don't break functionality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache storage location\",\n      \"inputs\": \"storagePath: string\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results for a workspace if valid\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier from workspace path\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (base64 encoded safe filename)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis results, preventing redundant analysis of the same codebase within a 24-hour window. This makes subsequent workspace loads faster and reduces computational overhead.\"\n}\n```"
        },
        {
          "file": "src/diagnosticsProvider.ts",
          "role": "Core Logic",
          "purpose": "Displays code insights as inline diagnostics (squiggly underlines) in the VS Code editor's Problems panel",
          "userVisibleActions": [
            "Shows warnings or errors under specific lines of code with squiggly underlines",
            "Displays insights in the Problems panel at the bottom of VS Code",
            "Highlights problematic code locations across multiple files",
            "Shows insight descriptions when hovering over underlined code",
            "Groups diagnostics by file in the Problems panel"
          ],
          "developerVisibleActions": [
            "Converts generated insights into VS Code diagnostic entries",
            "Updates the Problems panel whenever new insights are generated",
            "Maps insight severity levels to VS Code diagnostic severity (Error, Warning, Information, Hint)",
            "Clears all diagnostics when insights are refreshed",
            "Associates each diagnostic with its source file and line number",
            "Tags diagnostics with 'Shadow Watch' as the source"
          ],
          "keyFunctions": [
            {
              "name": "updateDiagnostics",
              "desc": "Updates all diagnostics across all files based on provided insights",
              "inputs": "Array of Insight objects",
              "outputs": "void (updates UI)"
            },
            {
              "name": "updateDiagnosticsForFile",
              "desc": "Updates diagnostics for a single specific file",
              "inputs": "File URI and array of Insight objects",
              "outputs": "void (updates UI)"
            },
            {
              "name": "clear",
              "desc": "Removes all diagnostics from the Problems panel",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "createDiagnostic",
              "desc": "Converts an insight into a VS Code diagnostic entry with range, severity, and metadata",
              "inputs": "Single Insight object",
              "outputs": "vscode.Diagnostic object"
            },
            {
              "name": "getSeverity",
              "desc": "Maps insight severity to VS Code diagnostic severity level",
              "inputs": "Insight severity string",
              "outputs": "vscode.DiagnosticSeverity enum"
            }
          ],
          "dependencies": [
            "vscode",
            "./insightGenerator"
          ],
          "intent": "Bridges the gap between Shadow Watch's code analysis insights and VS Code's native diagnostics system, making insights visible to users as familiar editor warnings and errors in the Problems panel",
          "rawContent": "```json\n{\n  \"purpose\": \"Displays code insights as inline diagnostics (squiggly underlines) in the VS Code editor's Problems panel\",\n  \"userVisibleActions\": [\n    \"Shows warnings or errors under specific lines of code with squiggly underlines\",\n    \"Displays insights in the Problems panel at the bottom of VS Code\",\n    \"Highlights problematic code locations across multiple files\",\n    \"Shows insight descriptions when hovering over underlined code\",\n    \"Groups diagnostics by file in the Problems panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Converts generated insights into VS Code diagnostic entries\",\n    \"Updates the Problems panel whenever new insights are generated\",\n    \"Maps insight severity levels to VS Code diagnostic severity (Error, Warning, Information, Hint)\",\n    \"Clears all diagnostics when insights are refreshed\",\n    \"Associates each diagnostic with its source file and line number\",\n    \"Tags diagnostics with 'Shadow Watch' as the source\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across all files based on provided insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void (updates UI)\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a single specific file\",\n      \"inputs\": \"File URI and array of Insight objects\",\n      \"outputs\": \"void (updates UI)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic entry with range, severity, and metadata\",\n      \"inputs\": \"Single Insight object\",\n      \"outputs\": \"vscode.Diagnostic object\"\n    },\n    {\n      \"name\": \"getSeverity\",\n      \"desc\": \"Maps insight severity to VS Code diagnostic severity level\",\n      \"inputs\": \"Insight severity string\",\n      \"outputs\": \"vscode.DiagnosticSeverity enum\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Bridges the gap between Shadow Watch's code analysis insights and VS Code's native diagnostics system, making insights visible to users as familiar editor warnings and errors in the Problems panel\"\n}\n```"
        },
        {
          "file": "src/extension.ts",
          "role": "Core Logic",
          "purpose": "Main entry point that activates the VSCode extension, initializes all components, and registers commands for code analysis and insight generation.",
          "userVisibleActions": [
            "Analyze current file to see code insights and structure",
            "Generate LLM-friendly documentation from code",
            "View analysis results in a tree view sidebar",
            "Navigate to code locations by clicking tree items",
            "See diagnostics and warnings for analyzed code",
            "Refresh analysis results manually",
            "Copy generated documentation to clipboard",
            "Open documentation in a webview panel",
            "Clear analysis cache",
            "Export insights to file",
            "Configure analysis settings",
            "View status bar indicator showing analysis state"
          ],
          "developerVisibleActions": [
            "Extension activates when VSCode starts or workspace opens",
            "File watcher monitors code changes and triggers re-analysis",
            "Analysis results are cached to improve performance",
            "Components are bootstrapped using dependency injection pattern",
            "Commands are registered through a command registry",
            "Tree view updates automatically when analysis completes",
            "Diagnostics panel shows code quality issues",
            "Configuration changes trigger re-initialization",
            "Error handling captures and reports failures",
            "Navigation handler manages code location jumping"
          ],
          "keyFunctions": [
            {
              "name": "activate",
              "desc": "Initializes and activates the extension, setting up all components and command handlers",
              "inputs": "context: vscode.ExtensionContext",
              "outputs": "void"
            },
            {
              "name": "deactivate",
              "desc": "Cleans up resources and disposes of components when extension is deactivated",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "./analyzer",
            "./insightGenerator",
            "./llmFormatter",
            "./fileWatcher",
            "./insightsTreeView",
            "./diagnosticsProvider",
            "./cache",
            "./llmIntegration",
            "./config/configurationManager",
            "./utils/errorHandler",
            "./ui/webview/webviewTemplateEngine",
            "./domain/bootstrap/extensionBootstrapper",
            "./domain/bootstrap/commandRegistry",
            "./domain/handlers/navigationHandler"
          ],
          "intent": "This file serves as the extension's main controller, orchestrating all features by initializing components, registering commands, and managing the lifecycle of the code analysis and insight generation functionality. It bridges user actions with the underlying analysis engine and presents results through multiple UI elements (tree view, webview, diagnostics, status bar).",
          "rawContent": "```json\n{\n  \"purpose\": \"Main entry point that activates the VSCode extension, initializes all components, and registers commands for code analysis and insight generation.\",\n  \"userVisibleActions\": [\n    \"Analyze current file to see code insights and structure\",\n    \"Generate LLM-friendly documentation from code\",\n    \"View analysis results in a tree view sidebar\",\n    \"Navigate to code locations by clicking tree items\",\n    \"See diagnostics and warnings for analyzed code\",\n    \"Refresh analysis results manually\",\n    \"Copy generated documentation to clipboard\",\n    \"Open documentation in a webview panel\",\n    \"Clear analysis cache\",\n    \"Export insights to file\",\n    \"Configure analysis settings\",\n    \"View status bar indicator showing analysis state\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or workspace opens\",\n    \"File watcher monitors code changes and triggers re-analysis\",\n    \"Analysis results are cached to improve performance\",\n    \"Components are bootstrapped using dependency injection pattern\",\n    \"Commands are registered through a command registry\",\n    \"Tree view updates automatically when analysis completes\",\n    \"Diagnostics panel shows code quality issues\",\n    \"Configuration changes trigger re-initialization\",\n    \"Error handling captures and reports failures\",\n    \"Navigation handler manages code location jumping\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes and activates the extension, setting up all components and command handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources and disposes of components when extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file serves as the extension's main controller, orchestrating all features by initializing components, registering commands, and managing the lifecycle of the code analysis and insight generation functionality. It bridges user actions with the underlying analysis engine and presents results through multiple UI elements (tree view, webview, diagnostics, status bar).\"\n}\n```"
        },
        {
          "file": "src/fileAccessHelper.ts",
          "role": "Core Logic",
          "purpose": "Provides file reading and grep search functionality to enable iterative LLM code analysis with structured request/response handling",
          "userVisibleActions": [
            "User requests to view file contents through LLM analysis",
            "User searches for code patterns across multiple files using grep",
            "User sees organized file listings grouped by folder",
            "User receives search results with line numbers and context",
            "User gets notified when search results are limited due to too many matches"
          ],
          "developerVisibleActions": [
            "Developer creates FileRequest or GrepRequest objects to access code",
            "Developer receives structured FileResponse with content and metadata",
            "Developer receives GrepResponse with matching lines and context",
            "Developer specifies file patterns to limit grep search scope",
            "Developer controls maximum number of search results returned",
            "Developer gets file listings organized by folder hierarchy",
            "Developer provides reasons for file/grep requests for transparency"
          ],
          "keyFunctions": [
            {
              "name": "getFileListing",
              "desc": "Returns organized file listing grouped by folders with sorting",
              "inputs": "Array of file objects with path, lines, and language",
              "outputs": "Formatted string showing files organized by directory"
            },
            {
              "name": "readFile",
              "desc": "Reads a file from the workspace and returns its contents",
              "inputs": "File path relative to workspace root",
              "outputs": "FileResponse with content, line count, and existence flag"
            },
            {
              "name": "grep",
              "desc": "Searches for pattern across files matching optional glob pattern",
              "inputs": "Search pattern, optional file pattern glob, max results limit",
              "outputs": "GrepResponse with matches including line numbers and context"
            },
            {
              "name": "processRequest",
              "desc": "Handles both file and grep requests based on request type",
              "inputs": "LLMRequest (either FileRequest or GrepRequest)",
              "outputs": "FileResponse or GrepResponse depending on request type"
            },
            {
              "name": "formatResponse",
              "desc": "Converts response objects to human-readable formatted text",
              "inputs": "FileResponse or GrepResponse object",
              "outputs": "Formatted string for display to user or LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path"
          ],
          "intent": "This file exists to enable iterative LLM code analysis by providing a structured way to request and retrieve file contents or search for patterns across the codebase. It solves the problem of LLMs needing to explore and understand code incrementally without loading entire files upfront, supporting intelligent code navigation through grep searches and targeted file reading.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative LLM code analysis with structured request/response handling\",\n  \"userVisibleActions\": [\n    \"User requests to view file contents through LLM analysis\",\n    \"User searches for code patterns across multiple files using grep\",\n    \"User sees organized file listings grouped by folder\",\n    \"User receives search results with line numbers and context\",\n    \"User gets notified when search results are limited due to too many matches\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates FileRequest or GrepRequest objects to access code\",\n    \"Developer receives structured FileResponse with content and metadata\",\n    \"Developer receives GrepResponse with matching lines and context\",\n    \"Developer specifies file patterns to limit grep search scope\",\n    \"Developer controls maximum number of search results returned\",\n    \"Developer gets file listings organized by folder hierarchy\",\n    \"Developer provides reasons for file/grep requests for transparency\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Returns organized file listing grouped by folders with sorting\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files organized by directory\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its contents\",\n      \"inputs\": \"File path relative to workspace root\",\n      \"outputs\": \"FileResponse with content, line count, and existence flag\"\n    },\n    {\n      \"name\": \"grep\",\n      \"desc\": \"Searches for pattern across files matching optional glob pattern\",\n      \"inputs\": \"Search pattern, optional file pattern glob, max results limit\",\n      \"outputs\": \"GrepResponse with matches including line numbers and context\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Handles both file and grep requests based on request type\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"formatResponse\",\n      \"desc\": \"Converts response objects to human-readable formatted text\",\n      \"inputs\": \"FileResponse or GrepResponse object\",\n      \"outputs\": \"Formatted string for display to user or LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable iterative LLM code analysis by providing a structured way to request and retrieve file contents or search for patterns across the codebase. It solves the problem of LLMs needing to explore and understand code incrementally without loading entire files upfront, supporting intelligent code navigation through grep searches and targeted file reading.\"\n}\n```"
        },
        {
          "file": "src/fileDocumentation.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.",
          "userVisibleActions": [
            "User receives structured documentation showing what each file does and why it exists",
            "User sees organized documentation by modules (API routes, CLI commands, workers, GUI views)",
            "User views product-level documentation with overviews, workflows, and problems solved",
            "User accesses categorized features, components, and capabilities descriptions",
            "User reads endpoint documentation with paths, methods, and descriptions",
            "User reviews command documentation with usage and descriptions",
            "User explores worker job flows and descriptions"
          ],
          "developerVisibleActions": [
            "Developer defines file summaries with role, purpose, and key functions",
            "Developer creates module summaries grouping related files by type",
            "Developer documents user-visible and developer-visible actions for each file",
            "Developer specifies file dependencies and intent",
            "Developer generates product documentation with architecture diagrams",
            "Developer structures documentation with titles, descriptions, and categories",
            "Developer organizes capabilities by user perspective (GUI, CLI, API, CI/CD)",
            "Developer includes raw LLM responses for documentation generation",
            "Developer maps endpoints, commands, and workers to their descriptions"
          ],
          "keyFunctions": [],
          "dependencies": [
            "fs",
            "path",
            "./analyzer"
          ],
          "intent": "This file exists to provide a standardized schema for organizing and structuring code documentation across multiple levels (file, module, product), enabling consistent documentation generation and making codebases easier to understand for both users and developers.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"User receives structured documentation showing what each file does and why it exists\",\n    \"User sees organized documentation by modules (API routes, CLI commands, workers, GUI views)\",\n    \"User views product-level documentation with overviews, workflows, and problems solved\",\n    \"User accesses categorized features, components, and capabilities descriptions\",\n    \"User reads endpoint documentation with paths, methods, and descriptions\",\n    \"User reviews command documentation with usage and descriptions\",\n    \"User explores worker job flows and descriptions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file summaries with role, purpose, and key functions\",\n    \"Developer creates module summaries grouping related files by type\",\n    \"Developer documents user-visible and developer-visible actions for each file\",\n    \"Developer specifies file dependencies and intent\",\n    \"Developer generates product documentation with architecture diagrams\",\n    \"Developer structures documentation with titles, descriptions, and categories\",\n    \"Developer organizes capabilities by user perspective (GUI, CLI, API, CI/CD)\",\n    \"Developer includes raw LLM responses for documentation generation\",\n    \"Developer maps endpoints, commands, and workers to their descriptions\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for organizing and structuring code documentation across multiple levels (file, module, product), enabling consistent documentation generation and making codebases easier to understand for both users and developers.\"\n}\n```"
        },
        {
          "file": "src/fileWatcher.ts",
          "role": "Core Logic",
          "purpose": "Monitors file changes in the workspace and automatically triggers code analysis when files are saved",
          "userVisibleActions": [
            "Code analysis runs automatically when saving a file (if 'analyze on save' is enabled)",
            "Diagnostics and insights update in the UI after file saves",
            "Analysis waits until typing stops (debounced) to avoid interrupting workflow",
            "User can see when analysis is in progress or completed"
          ],
          "developerVisibleActions": [
            "File watcher starts when extension activates if 'analyzeOnSave' configuration is enabled",
            "Watches for document save events in VS Code",
            "Triggers code analysis pipeline on file saves",
            "Updates diagnostics provider with new analysis results",
            "Refreshes insights tree view after analysis completes",
            "Prevents concurrent analysis runs to avoid performance issues",
            "Implements debouncing to batch rapid file saves",
            "Cleans up resources when stopped or disposed"
          ],
          "keyFunctions": [
            {
              "name": "start",
              "desc": "Begins watching for file save events and enables automatic analysis",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "stop",
              "desc": "Stops watching for file saves and cancels pending analysis",
              "inputs": "None",
              "outputs": "void"
            },
            {
              "name": "onFileSaved",
              "desc": "Handles file save events and schedules analysis with debouncing",
              "inputs": "document: vscode.TextDocument",
              "outputs": "void"
            },
            {
              "name": "analyzeFile",
              "desc": "Executes the full analysis pipeline for a saved file and updates UI",
              "inputs": "document: vscode.TextDocument",
              "outputs": "Promise<void>"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file watcher resources and stops monitoring",
              "inputs": "None",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "CodeAnalyzer",
            "InsightGenerator",
            "DiagnosticsProvider",
            "InsightsTreeProvider",
            "ConfigurationManager",
            "ErrorHandler",
            "FileWatcherService"
          ],
          "intent": "This file exists to provide automatic, real-time code analysis by watching for file changes in the workspace. It solves the problem of keeping code insights and diagnostics up-to-date without requiring manual user intervention, while intelligently managing when and how often analysis runs to balance responsiveness with performance.",
          "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Code analysis runs automatically when saving a file (if 'analyze on save' is enabled)\",\n    \"Diagnostics and insights update in the UI after file saves\",\n    \"Analysis waits until typing stops (debounced) to avoid interrupting workflow\",\n    \"User can see when analysis is in progress or completed\"\n  ],\n  \"developerVisibleActions\": [\n    \"File watcher starts when extension activates if 'analyzeOnSave' configuration is enabled\",\n    \"Watches for document save events in VS Code\",\n    \"Triggers code analysis pipeline on file saves\",\n    \"Updates diagnostics provider with new analysis results\",\n    \"Refreshes insights tree view after analysis completes\",\n    \"Prevents concurrent analysis runs to avoid performance issues\",\n    \"Implements debouncing to batch rapid file saves\",\n    \"Cleans up resources when stopped or disposed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events and enables automatic analysis\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file saves and cancels pending analysis\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and schedules analysis with debouncing\",\n      \"inputs\": \"document: vscode.TextDocument\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Executes the full analysis pipeline for a saved file and updates UI\",\n      \"inputs\": \"document: vscode.TextDocument\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watcher resources and stops monitoring\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by watching for file changes in the workspace. It solves the problem of keeping code insights and diagnostics up-to-date without requiring manual user intervention, while intelligently managing when and how often analysis runs to balance responsiveness with performance.\"\n}\n```"
        },
        {
          "file": "src/insightGenerator.ts",
          "role": "Core Logic",
          "purpose": "Analyzes code and generates actionable insights about code quality, organization, and potential issues",
          "userVisibleActions": [
            "Receives warnings about large files exceeding 500 lines of code",
            "Gets notified about orphaned files that aren't imported anywhere",
            "Sees alerts for missing entry points in the codebase",
            "Receives warnings about circular dependencies between files",
            "Gets notified about 'god objects' (files with too many functions)",
            "Sees suggestions about potential dead code",
            "Receives insights about file organization issues",
            "Gets warnings about complex functions that may need refactoring"
          ],
          "developerVisibleActions": [
            "Call generateInsights() with code analysis to get all insights for the entire codebase",
            "Call generateInsightsForFile() to get insights for a specific file",
            "Receive structured Insight objects with severity levels (error, warning, info)",
            "Each insight includes title, description, category, file location, line number, and actionable suggestions",
            "Insights are categorized by type (Code Organization, Maintainability, Performance, etc.)",
            "Get code snippets included in insights when relevant"
          ],
          "keyFunctions": [
            {
              "name": "generateInsights",
              "desc": "Analyzes entire codebase and returns all detected issues and recommendations",
              "inputs": "CodeAnalysis object containing files, functions, and dependencies",
              "outputs": "Array of Insight objects with problems and suggestions"
            },
            {
              "name": "generateInsightsForFile",
              "desc": "Analyzes a specific file and returns insights relevant to that file only",
              "inputs": "CodeAnalysis object and file path string",
              "outputs": "Array of Insight objects filtered for the specified file"
            },
            {
              "name": "checkLargeFiles",
              "desc": "Detects files that exceed recommended line count thresholds",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about oversized files"
            },
            {
              "name": "checkOrphanedFiles",
              "desc": "Identifies files that aren't imported or used anywhere in the codebase",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about unused files"
            },
            {
              "name": "checkEntryPoints",
              "desc": "Verifies that the codebase has proper entry points defined",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about missing entry points"
            },
            {
              "name": "checkCircularDependencies",
              "desc": "Detects potential circular dependency patterns between files",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about circular dependencies"
            },
            {
              "name": "checkGodObjects",
              "desc": "Identifies files with excessive functions that violate single responsibility principle",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about files with too many responsibilities"
            },
            {
              "name": "checkDeadCode",
              "desc": "Detects potentially unused or unreachable code",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about dead code"
            },
            {
              "name": "checkFileOrganization",
              "desc": "Analyzes project structure and suggests organizational improvements",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about file organization issues"
            },
            {
              "name": "checkFunctionComplexity",
              "desc": "Identifies functions that are too complex and may need simplification",
              "inputs": "CodeAnalysis object",
              "outputs": "Array of insights about overly complex functions"
            }
          ],
          "dependencies": [
            "./analyzer"
          ],
          "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, maintainability problems, and architectural concerns. It solves the problem of making sense of complex code metrics by categorizing issues, assigning severity levels, and providing specific suggestions for improvement.",
          "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code and generates actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"Receives warnings about large files exceeding 500 lines of code\",\n    \"Gets notified about orphaned files that aren't imported anywhere\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Receives warnings about circular dependencies between files\",\n    \"Gets notified about 'god objects' (files with too many functions)\",\n    \"Sees suggestions about potential dead code\",\n    \"Receives insights about file organization issues\",\n    \"Gets warnings about complex functions that may need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateInsights() with code analysis to get all insights for the entire codebase\",\n    \"Call generateInsightsForFile() to get insights for a specific file\",\n    \"Receive structured Insight objects with severity levels (error, warning, info)\",\n    \"Each insight includes title, description, category, file location, line number, and actionable suggestions\",\n    \"Insights are categorized by type (Code Organization, Maintainability, Performance, etc.)\",\n    \"Get code snippets included in insights when relevant\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all detected issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing files, functions, and dependencies\",\n      \"outputs\": \"Array of Insight objects with problems and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights relevant to that file only\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects filtered for the specified file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Detects files that exceed recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Identifies files that aren't imported or used anywhere in the codebase\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about unused files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies that the codebase has proper entry points defined\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with excessive functions that violate single responsibility principle\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about files with too many responsibilities\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Detects potentially unused or unreachable code\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Analyzes project structure and suggests organizational improvements\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about file organization issues\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Identifies functions that are too complex and may need simplification\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about overly complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, maintainability problems, and architectural concerns. It solves the problem of making sense of complex code metrics by categorizing issues, assigning severity levels, and providing specific suggestions for improvement.\"\n}\n```"
        },
        {
          "file": "src/insightsTreeView.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view interface in VS Code's sidebar that displays code analysis insights, documentation status, and generated reports with timestamps and action buttons.",
          "userVisibleActions": [
            "View code analysis insights organized in a tree structure in the sidebar",
            "See status indicators (idle/generating/complete) for product documentation, insights, and unit tests",
            "Click on insight items to navigate to specific code locations",
            "Refresh the insights tree view to update the display",
            "Open generated reports (workspace, product, architecture, unit test) from the tree",
            "Copy insight descriptions to clipboard",
            "Generate product documentation, insights, unit tests, and analysis reports via tree item buttons",
            "Regenerate existing insights and documentation",
            "See timestamps showing when reports and documentation were last generated",
            "View dependency tree and architecture insights",
            "Access static analysis results through the tree view"
          ],
          "developerVisibleActions": [
            "Tree provider manages state for multiple report types (workspace, product, architecture, unit test)",
            "Persists timestamps and file paths across VS Code sessions using workspace state",
            "Tracks generation status for documentation, insights, unit tests, and analysis",
            "Handles LLM service integration for generating AI-powered insights",
            "Provides tree data structure with expandable/collapsible sections",
            "Manages navigation from tree items to code locations via file paths and line numbers",
            "Exposes refresh mechanism to update tree view when analysis completes",
            "Supports copying insight text to clipboard programmatically",
            "Validates existence of generated report files before displaying them",
            "Integrates with static analysis viewer component"
          ],
          "keyFunctions": [
            {
              "name": "refresh",
              "desc": "Triggers the tree view to reload and display updated insights and statuses",
              "inputs": "none",
              "outputs": "void (fires onDidChangeTreeData event)"
            },
            {
              "name": "setInsights",
              "desc": "Updates the insights data displayed in the tree view",
              "inputs": "insights: Insight[] - array of insight objects",
              "outputs": "void"
            },
            {
              "name": "getTreeItem",
              "desc": "Returns the VS Code tree item representation for a given tree node",
              "inputs": "element: TreeItem - tree node element",
              "outputs": "vscode.TreeItem or Thenable<vscode.TreeItem>"
            },
            {
              "name": "getChildren",
              "desc": "Returns child nodes for a given tree item or root nodes if no element provided",
              "inputs": "element?: TreeItem - optional parent tree item",
              "outputs": "TreeItem[] - array of child tree items"
            },
            {
              "name": "setProductDocsStatus",
              "desc": "Updates the product documentation generation status",
              "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setInsightsStatus",
              "desc": "Updates the insights generation status",
              "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setUnitTestStatus",
              "desc": "Updates the unit test generation status",
              "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setAnalysisStatus",
              "desc": "Updates the analysis completion status",
              "inputs": "status: 'idle' | 'complete', timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setReportPath",
              "desc": "Sets the file path for a generated report",
              "inputs": "path: string, timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setWorkspaceReportPath",
              "desc": "Sets the file path for the workspace report",
              "inputs": "path: string, timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setProductReportPath",
              "desc": "Sets the file path for the product report",
              "inputs": "path: string, timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setArchitectureReportPath",
              "desc": "Sets the file path for the architecture report",
              "inputs": "path: string, timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setUnitTestReportPath",
              "desc": "Sets the file path for the unit test report",
              "inputs": "path: string, timestamp?: number",
              "outputs": "void"
            },
            {
              "name": "setLLMService",
              "desc": "Configures the LLM service for generating AI-powered insights",
              "inputs": "llmService: LLMService",
              "outputs": "void"
            },
            {
              "name": "setLLMInsights",
              "desc": "Updates the LLM-generated insights data",
              "inputs": "llmInsights: LLMInsights",
              "outputs": "void"
            },
            {
              "name": "setStaticAnalysisViewer",
              "desc": "Sets the static analysis viewer component for integration",
              "inputs": "viewer: any - static analysis viewer instance",
              "outputs": "void"
            },
            {
              "name": "loadPersistedState",
              "desc": "Restores previously saved timestamps and report paths from workspace storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "formatTimestamp",
              "desc": "Converts a timestamp number into a human-readable date/time string",
              "inputs": "timestamp: number",
              "outputs": "string - formatted date/time"
            }
          ],
          "dependencies": [
            "vscode",
            "insightGenerator",
            "llmFormatter",
            "llmService"
          ],
          "intent": "This file exists to provide a user-friendly sidebar interface in VS Code that visualizes code analysis results, tracks generation status of various documentation and test reports, and offers quick access to generated artifacts. It solves the problem of presenting complex analysis data in an organized, navigable tree structure with actionable buttons and status indicators, making it easy for developers to understand their codebase and access generated documentation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface in VS Code's sidebar that displays code analysis insights, documentation status, and generated reports with timestamps and action buttons.\",\n  \"userVisibleActions\": [\n    \"View code analysis insights organized in a tree structure in the sidebar\",\n    \"See status indicators (idle/generating/complete) for product documentation, insights, and unit tests\",\n    \"Click on insight items to navigate to specific code locations\",\n    \"Refresh the insights tree view to update the display\",\n    \"Open generated reports (workspace, product, architecture, unit test) from the tree\",\n    \"Copy insight descriptions to clipboard\",\n    \"Generate product documentation, insights, unit tests, and analysis reports via tree item buttons\",\n    \"Regenerate existing insights and documentation\",\n    \"See timestamps showing when reports and documentation were last generated\",\n    \"View dependency tree and architecture insights\",\n    \"Access static analysis results through the tree view\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree provider manages state for multiple report types (workspace, product, architecture, unit test)\",\n    \"Persists timestamps and file paths across VS Code sessions using workspace state\",\n    \"Tracks generation status for documentation, insights, unit tests, and analysis\",\n    \"Handles LLM service integration for generating AI-powered insights\",\n    \"Provides tree data structure with expandable/collapsible sections\",\n    \"Manages navigation from tree items to code locations via file paths and line numbers\",\n    \"Exposes refresh mechanism to update tree view when analysis completes\",\n    \"Supports copying insight text to clipboard programmatically\",\n    \"Validates existence of generated report files before displaying them\",\n    \"Integrates with static analysis viewer component\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers the tree view to reload and display updated insights and statuses\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (fires onDidChangeTreeData event)\"\n    },\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data displayed in the tree view\",\n      \"inputs\": \"insights: Insight[] - array of insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VS Code tree item representation for a given tree node\",\n      \"inputs\": \"element: TreeItem - tree node element\",\n      \"outputs\": \"vscode.TreeItem or Thenable<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child nodes for a given tree item or root nodes if no element provided\",\n      \"inputs\": \"element?: TreeItem - optional parent tree item\",\n      \"outputs\": \"TreeItem[] - array of child tree items\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the product documentation generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the insights generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the unit test generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the analysis completion status\",\n      \"inputs\": \"status: 'idle' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setWorkspaceReportPath\",\n      \"desc\": \"Sets the file path for the workspace report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductReportPath\",\n      \"desc\": \"Sets the file path for the product report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setArchitectureReportPath\",\n      \"desc\": \"Sets the file path for the architecture report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestReportPath\",\n      \"desc\": \"Sets the file path for the unit test report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Configures the LLM service for generating AI-powered insights\",\n      \"inputs\": \"llmService: LLMService\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the LLM-generated insights data\",\n      \"inputs\": \"llmInsights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setStaticAnalysisViewer\",\n      \"desc\": \"Sets the static analysis viewer component for integration\",\n      \"inputs\": \"viewer: any - static analysis viewer instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores previously saved timestamps and report paths from workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatTimestamp\",\n      \"desc\": \"Converts a timestamp number into a human-readable date/time string\",\n      \"inputs\": \"timestamp: number\",\n      \"outputs\": \"string - formatted date/time\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"insightGenerator\",\n    \"llmFormatter\",\n    \"llmService\"\n  ],\n  \"intent\": \"This file exists to provide a user-friendly sidebar interface in VS Code that visualizes code analysis results, tracks generation status of various documentation and test reports, and offers quick access to generated artifacts. It solves the problem of presenting complex analysis data in an organized, navigable tree structure with actionable buttons and status indicators, making it easy for developers to understand their codebase and access generated documentation.\"\n}\n```"
        },
        {
          "file": "src/insightsViewer.ts",
          "role": "GUI View",
          "purpose": "Provides a tree view panel in VS Code that displays and allows browsing of AI-generated architecture insights about the codebase",
          "userVisibleActions": [
            "View architecture insights organized in a tree structure in the sidebar",
            "Browse different insight categories (Intent, Key Components, Data Flow, Entry Points, Architecture, Diagrams, Requirements, Recommendations)",
            "Click on insights to open related files or documentation",
            "See insights automatically update when analysis files change",
            "Open files directly from insight items that reference them",
            "View markdown documentation when clicking on insights",
            "See file paths and line numbers linked to specific insights",
            "Refresh insights view manually when needed"
          ],
          "developerVisibleActions": [
            "Tree view automatically watches .shadow/docs/architecture-insights.json for changes",
            "Tree view automatically watches .shadow/docs/PROJECT_PURPOSE.md for changes",
            "Insights data is loaded from architecture-insights.json file when available",
            "File system watchers trigger automatic refresh when insights files are modified",
            "Tree items are created with icons, descriptions, and navigation commands",
            "Clicking insight items triggers openFile command with file path and line number",
            "Purpose document changes trigger tree view refresh",
            "Provides TreeDataProvider interface for VS Code tree view integration"
          ],
          "keyFunctions": [
            {
              "name": "refresh",
              "desc": "Reloads insights from the file system and updates the tree view",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "loadInsights",
              "desc": "Reads architecture-insights.json file and parses it into insights object",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getChildren",
              "desc": "Returns tree items for a given parent node to populate the tree structure",
              "inputs": "element: InsightItem | undefined",
              "outputs": "Promise<InsightItem[]>"
            },
            {
              "name": "getTreeItem",
              "desc": "Converts an InsightItem into a VS Code TreeItem with visual properties",
              "inputs": "element: InsightItem",
              "outputs": "vscode.TreeItem"
            },
            {
              "name": "setupFileWatcher",
              "desc": "Creates file system watchers for insights and purpose files to auto-refresh view",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getInsightIcon",
              "desc": "Returns appropriate icon for different insight types and categories",
              "inputs": "type: string",
              "outputs": "vscode.ThemeIcon"
            },
            {
              "name": "dispose",
              "desc": "Cleans up file watchers and resources when view is destroyed",
              "inputs": "none",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs",
            "./llmService",
            "./domain/services/fileWatcherService"
          ],
          "intent": "This file exists to provide users with a visual, navigable tree interface in VS Code that displays AI-generated architecture insights about their codebase, making it easy to understand project structure, intent, and key components by browsing organized categories and clicking through to relevant files and documentation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view panel in VS Code that displays and allows browsing of AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View architecture insights organized in a tree structure in the sidebar\",\n    \"Browse different insight categories (Intent, Key Components, Data Flow, Entry Points, Architecture, Diagrams, Requirements, Recommendations)\",\n    \"Click on insights to open related files or documentation\",\n    \"See insights automatically update when analysis files change\",\n    \"Open files directly from insight items that reference them\",\n    \"View markdown documentation when clicking on insights\",\n    \"See file paths and line numbers linked to specific insights\",\n    \"Refresh insights view manually when needed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically watches .shadow/docs/architecture-insights.json for changes\",\n    \"Tree view automatically watches .shadow/docs/PROJECT_PURPOSE.md for changes\",\n    \"Insights data is loaded from architecture-insights.json file when available\",\n    \"File system watchers trigger automatic refresh when insights files are modified\",\n    \"Tree items are created with icons, descriptions, and navigation commands\",\n    \"Clicking insight items triggers openFile command with file path and line number\",\n    \"Purpose document changes trigger tree view refresh\",\n    \"Provides TreeDataProvider interface for VS Code tree view integration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from the file system and updates the tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadInsights\",\n      \"desc\": \"Reads architecture-insights.json file and parses it into insights object\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns tree items for a given parent node to populate the tree structure\",\n      \"inputs\": \"element: InsightItem | undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem with visual properties\",\n      \"inputs\": \"element: InsightItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers for insights and purpose files to auto-refresh view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getInsightIcon\",\n      \"desc\": \"Returns appropriate icon for different insight types and categories\",\n      \"inputs\": \"type: string\",\n      \"outputs\": \"vscode.ThemeIcon\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and resources when view is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"./llmService\",\n    \"./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide users with a visual, navigable tree interface in VS Code that displays AI-generated architecture insights about their codebase, making it easy to understand project structure, intent, and key components by browsing organized categories and clicking through to relevant files and documentation.\"\n}\n```"
        },
        {
          "file": "src/llmFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats code architecture insights into different output styles optimized for various AI assistants and display formats",
          "userVisibleActions": [
            "User receives formatted architecture issues grouped by severity (errors, warnings, info)",
            "User sees insights organized with emoji indicators ( for errors,  for warnings,  for info)",
            "User gets actionable prompts asking AI to prioritize issues and suggest fixes",
            "User can choose between different format styles: Cursor, ChatGPT, Compact, or Generic",
            "User sees file locations, specific issues, and improvement suggestions for each problem",
            "User receives a summary of total issues found in the codebase"
          ],
          "developerVisibleActions": [
            "Developer calls formatInsights() with an array of insights and a format type",
            "System transforms raw insight data into human-readable markdown text",
            "Different AI assistants receive optimized formatting (Cursor gets conversational prompts, ChatGPT gets structured sections, Compact gets minimal output)",
            "Insights are automatically grouped and sorted by severity level",
            "Each insight includes file path, rule violated, issue description, and improvement guidance",
            "Output includes actionable next steps tailored to the target AI assistant"
          ],
          "keyFunctions": [
            {
              "name": "formatInsights",
              "desc": "Formats a list of insights into the specified output format",
              "inputs": "insights: Insight[], format: string (default 'cursor')",
              "outputs": "Formatted string in markdown"
            },
            {
              "name": "formatForCursor",
              "desc": "Creates Cursor AI-optimized format with conversational prompts and grouped severity sections",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string with critical issues, warnings, info, and actionable requests"
            },
            {
              "name": "formatForChatGPT",
              "desc": "Creates ChatGPT-optimized format with structured analysis sections",
              "inputs": "insights: Insight[]",
              "outputs": "Markdown string with severity breakdown and detailed issue listings"
            },
            {
              "name": "formatCompact",
              "desc": "Creates minimal format with just issue counts and brief descriptions",
              "inputs": "insights: Insight[]",
              "outputs": "Compact markdown string with essential information only"
            },
            {
              "name": "formatGeneric",
              "desc": "Creates standard format suitable for any AI assistant or display",
              "inputs": "insights: Insight[]",
              "outputs": "Plain markdown string with severity sections and issue details"
            },
            {
              "name": "formatInsightForCursor",
              "desc": "Formats individual insight with file path, rule, and improvement guidance",
              "inputs": "insight: Insight",
              "outputs": "Formatted string for single insight"
            },
            {
              "name": "formatInsightForChatGPT",
              "desc": "Formats individual insight with numbered structure for ChatGPT",
              "inputs": "insight: Insight",
              "outputs": "Formatted string for single insight"
            },
            {
              "name": "formatInsightCompact",
              "desc": "Formats individual insight in minimal one-line format",
              "inputs": "insight: Insight",
              "outputs": "Compact string for single insight"
            },
            {
              "name": "formatInsightGeneric",
              "desc": "Formats individual insight in standard format",
              "inputs": "insight: Insight",
              "outputs": "Standard formatted string for single insight"
            }
          ],
          "dependencies": [
            "./insightGenerator"
          ],
          "intent": "Solves the problem of presenting technical code architecture issues in a way that's optimized for different AI assistants to understand and act upon, making it easier for users to get relevant help from their AI coding assistant of choice",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output styles optimized for various AI assistants and display formats\",\n  \"userVisibleActions\": [\n    \"User receives formatted architecture issues grouped by severity (errors, warnings, info)\",\n    \"User sees insights organized with emoji indicators ( for errors,  for warnings,  for info)\",\n    \"User gets actionable prompts asking AI to prioritize issues and suggest fixes\",\n    \"User can choose between different format styles: Cursor, ChatGPT, Compact, or Generic\",\n    \"User sees file locations, specific issues, and improvement suggestions for each problem\",\n    \"User receives a summary of total issues found in the codebase\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls formatInsights() with an array of insights and a format type\",\n    \"System transforms raw insight data into human-readable markdown text\",\n    \"Different AI assistants receive optimized formatting (Cursor gets conversational prompts, ChatGPT gets structured sections, Compact gets minimal output)\",\n    \"Insights are automatically grouped and sorted by severity level\",\n    \"Each insight includes file path, rule violated, issue description, and improvement guidance\",\n    \"Output includes actionable next steps tailored to the target AI assistant\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Formats a list of insights into the specified output format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string in markdown\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized format with conversational prompts and grouped severity sections\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with critical issues, warnings, info, and actionable requests\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT-optimized format with structured analysis sections\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with severity breakdown and detailed issue listings\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates minimal format with just issue counts and brief descriptions\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with essential information only\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format suitable for any AI assistant or display\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Plain markdown string with severity sections and issue details\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file path, rule, and improvement guidance\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats individual insight with numbered structure for ChatGPT\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats individual insight in minimal one-line format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Compact string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats individual insight in standard format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Standard formatted string for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Solves the problem of presenting technical code architecture issues in a way that's optimized for different AI assistants to understand and act upon, making it easier for users to get relevant help from their AI coding assistant of choice\"\n}\n```"
        },
        {
          "file": "src/llmIntegration.ts",
          "role": "Core Logic",
          "purpose": "Integrates LLM-powered code analysis features with VS Code UI components, managing initialization, commands, and state for insights, documentation, and test generation.",
          "userVisibleActions": [
            "Generate AI-powered code insights for the entire workspace",
            "Analyze specific code files or selected code snippets",
            "View generated insights in a tree view panel",
            "Generate product documentation from codebase analysis",
            "View formatted documentation in the output panel and webview",
            "Export documentation to markdown files",
            "Navigate through code structure and entry points",
            "View unit test analysis and coverage",
            "Generate unit tests using AI",
            "Clear cached insights and analysis results",
            "Configure LLM API settings (provider, API key, model)",
            "See analysis progress through status messages and progress bars"
          ],
          "developerVisibleActions": [
            "Register VS Code commands for triggering LLM analysis workflows",
            "Initialize LLM service with configuration from workspace settings",
            "Save and load analysis results to/from workspace storage",
            "Trigger tree view refreshes when data changes",
            "Handle errors and display user-friendly error messages",
            "Manage state across different analysis views and panels",
            "Coordinate between multiple UI providers (insights, documentation, tests)",
            "Execute analysis workflows with proper context and scope",
            "Format and present analysis results in multiple output formats",
            "Handle file system operations for saving/loading cached data"
          ],
          "keyFunctions": [
            {
              "name": "initializeLLMService",
              "desc": "Sets up the LLM service, output channels, and loads saved analysis data on extension startup",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "analyzeFull",
              "desc": "Performs comprehensive codebase analysis and generates insights for the entire workspace",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeFile",
              "desc": "Analyzes a specific file or currently active editor and generates insights",
              "inputs": "optional URI",
              "outputs": "Promise<void>"
            },
            {
              "name": "analyzeSelection",
              "desc": "Analyzes only the selected code in the active editor",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "generateProductDocumentation",
              "desc": "Creates formatted product documentation from code analysis results",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "exportDocumentation",
              "desc": "Saves generated documentation to markdown files in the workspace",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "clearInsights",
              "desc": "Removes all cached insights and analysis results from storage",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "generateUnitTests",
              "desc": "Uses AI to generate unit tests for selected code or active file",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "showInsights",
              "desc": "Displays the insights tree view panel in the VS Code sidebar",
              "inputs": "none",
              "outputs": "Promise<void>"
            },
            {
              "name": "configureAPISettings",
              "desc": "Opens configuration interface for setting LLM provider and API credentials",
              "inputs": "none",
              "outputs": "Promise<void>"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "child_process",
            "util",
            "llmService",
            "insightsTreeView",
            "fileDocumentation",
            "analyzer",
            "productNavigator",
            "analysisViewer",
            "insightsViewer",
            "unitTestsNavigator",
            "logger",
            "state/llmStateManager",
            "context/analysisContextBuilder",
            "domain/formatters/documentationFormatter",
            "infrastructure/persistence/analysisResultRepository"
          ],
          "intent": "This file exists to bridge the gap between LLM-powered code analysis capabilities and VS Code's user interface, providing a complete integration layer that allows users to leverage AI for understanding codebases, generating documentation, and creating tests through familiar VS Code commands and UI components.",
          "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered code analysis features with VS Code UI components, managing initialization, commands, and state for insights, documentation, and test generation.\",\n  \"userVisibleActions\": [\n    \"Generate AI-powered code insights for the entire workspace\",\n    \"Analyze specific code files or selected code snippets\",\n    \"View generated insights in a tree view panel\",\n    \"Generate product documentation from codebase analysis\",\n    \"View formatted documentation in the output panel and webview\",\n    \"Export documentation to markdown files\",\n    \"Navigate through code structure and entry points\",\n    \"View unit test analysis and coverage\",\n    \"Generate unit tests using AI\",\n    \"Clear cached insights and analysis results\",\n    \"Configure LLM API settings (provider, API key, model)\",\n    \"See analysis progress through status messages and progress bars\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register VS Code commands for triggering LLM analysis workflows\",\n    \"Initialize LLM service with configuration from workspace settings\",\n    \"Save and load analysis results to/from workspace storage\",\n    \"Trigger tree view refreshes when data changes\",\n    \"Handle errors and display user-friendly error messages\",\n    \"Manage state across different analysis views and panels\",\n    \"Coordinate between multiple UI providers (insights, documentation, tests)\",\n    \"Execute analysis workflows with proper context and scope\",\n    \"Format and present analysis results in multiple output formats\",\n    \"Handle file system operations for saving/loading cached data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service, output channels, and loads saved analysis data on extension startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFull\",\n      \"desc\": \"Performs comprehensive codebase analysis and generates insights for the entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Analyzes a specific file or currently active editor and generates insights\",\n      \"inputs\": \"optional URI\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeSelection\",\n      \"desc\": \"Analyzes only the selected code in the active editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates formatted product documentation from code analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportDocumentation\",\n      \"desc\": \"Saves generated documentation to markdown files in the workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearInsights\",\n      \"desc\": \"Removes all cached insights and analysis results from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateUnitTests\",\n      \"desc\": \"Uses AI to generate unit tests for selected code or active file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showInsights\",\n      \"desc\": \"Displays the insights tree view panel in the VS Code sidebar\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"configureAPISettings\",\n      \"desc\": \"Opens configuration interface for setting LLM provider and API credentials\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"state/llmStateManager\",\n    \"context/analysisContextBuilder\",\n    \"domain/formatters/documentationFormatter\",\n    \"infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM-powered code analysis capabilities and VS Code's user interface, providing a complete integration layer that allows users to leverage AI for understanding codebases, generating documentation, and creating tests through familiar VS Code commands and UI components.\"\n}\n```"
        },
        {
          "file": "src/llmSchemas.ts",
          "role": "Core Logic",
          "purpose": "Defines JSON schemas that structure and validate AI (Claude) responses for code analysis, ensuring parseable outputs without manual parsing.",
          "userVisibleActions": [
            "Receives structured analysis of product purpose and architecture rationale",
            "Gets organized lists of design decisions and user goals",
            "Sees formatted issue reports with titles, descriptions, and affected files",
            "Receives behavior descriptions with user-facing and developer-facing actions",
            "Gets dependency analysis with module relationships and purposes",
            "Sees intent explanations for why files exist and what problems they solve"
          ],
          "developerVisibleActions": [
            "Provides schema templates that guarantee valid JSON responses from Claude AI",
            "Enforces required fields in AI responses to prevent missing data",
            "Structures AI output into predictable formats for programmatic consumption",
            "Validates that AI responses include specific information categories",
            "Defines metadata fields for tracking analysis completeness and confidence",
            "Ensures AI responses distinguish between user-facing and developer-facing behavior",
            "Generates structured issue reports with severity levels and fix proposals"
          ],
          "keyFunctions": [
            {
              "name": "productPurposeAnalysisSchema",
              "desc": "Schema that structures AI analysis of product purpose and architecture decisions",
              "inputs": "Used by AI to format analysis results",
              "outputs": "Structured object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
            },
            {
              "name": "issueItemSchema",
              "desc": "Schema that formats individual code issues with titles, descriptions, and affected files",
              "inputs": "Used by AI to format issue detection results",
              "outputs": "Structured object with title, description, relevantFiles, relevantFunctions fields"
            },
            {
              "name": "behaviorItemSchema",
              "desc": "Schema that separates user-facing actions from developer-facing implementation details",
              "inputs": "Used by AI to categorize code behavior",
              "outputs": "Structured object with userVisibleActions and developerVisibleActions arrays"
            },
            {
              "name": "dependencyItemSchema",
              "desc": "Schema that documents module dependencies with their purposes and relationships",
              "inputs": "Used by AI to format dependency analysis",
              "outputs": "Structured object with module name, purpose, and usedBy/uses relationships"
            },
            {
              "name": "fileAnalysisSchema",
              "desc": "Comprehensive schema that combines purpose, behavior, dependencies, and intent analysis for a file",
              "inputs": "Used by AI to format complete file analysis",
              "outputs": "Structured object with purpose, behaviors, dependencies, intent, and metadata fields"
            }
          ],
          "dependencies": [],
          "intent": "Eliminates ambiguity in AI responses by defining strict JSON schemas that guarantee parseable, structured output for code analysis tasks, enabling reliable automated processing of AI-generated insights without manual parsing or error handling.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate AI (Claude) responses for code analysis, ensuring parseable outputs without manual parsing.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and architecture rationale\",\n    \"Gets organized lists of design decisions and user goals\",\n    \"Sees formatted issue reports with titles, descriptions, and affected files\",\n    \"Receives behavior descriptions with user-facing and developer-facing actions\",\n    \"Gets dependency analysis with module relationships and purposes\",\n    \"Sees intent explanations for why files exist and what problems they solve\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides schema templates that guarantee valid JSON responses from Claude AI\",\n    \"Enforces required fields in AI responses to prevent missing data\",\n    \"Structures AI output into predictable formats for programmatic consumption\",\n    \"Validates that AI responses include specific information categories\",\n    \"Defines metadata fields for tracking analysis completeness and confidence\",\n    \"Ensures AI responses distinguish between user-facing and developer-facing behavior\",\n    \"Generates structured issue reports with severity levels and fix proposals\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema that structures AI analysis of product purpose and architecture decisions\",\n      \"inputs\": \"Used by AI to format analysis results\",\n      \"outputs\": \"Structured object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema that formats individual code issues with titles, descriptions, and affected files\",\n      \"inputs\": \"Used by AI to format issue detection results\",\n      \"outputs\": \"Structured object with title, description, relevantFiles, relevantFunctions fields\"\n    },\n    {\n      \"name\": \"behaviorItemSchema\",\n      \"desc\": \"Schema that separates user-facing actions from developer-facing implementation details\",\n      \"inputs\": \"Used by AI to categorize code behavior\",\n      \"outputs\": \"Structured object with userVisibleActions and developerVisibleActions arrays\"\n    },\n    {\n      \"name\": \"dependencyItemSchema\",\n      \"desc\": \"Schema that documents module dependencies with their purposes and relationships\",\n      \"inputs\": \"Used by AI to format dependency analysis\",\n      \"outputs\": \"Structured object with module name, purpose, and usedBy/uses relationships\"\n    },\n    {\n      \"name\": \"fileAnalysisSchema\",\n      \"desc\": \"Comprehensive schema that combines purpose, behavior, dependencies, and intent analysis for a file\",\n      \"inputs\": \"Used by AI to format complete file analysis\",\n      \"outputs\": \"Structured object with purpose, behaviors, dependencies, intent, and metadata fields\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Eliminates ambiguity in AI responses by defining strict JSON schemas that guarantee parseable, structured output for code analysis tasks, enabling reliable automated processing of AI-generated insights without manual parsing or error handling.\"\n}\n```"
        },
        {
          "file": "src/llmService.ts",
          "role": "Core Logic",
          "purpose": "Provides AI-powered code analysis and documentation generation by coordinating LLM providers (OpenAI/Claude) to generate insights, summaries, and test plans for codebases.",
          "userVisibleActions": [
            "Generate intelligent product purpose analysis from codebase",
            "Create comprehensive documentation with architecture insights",
            "Generate unit test plans for code files",
            "Receive AI-powered refactoring suggestions for functions",
            "Get incremental analysis updates as code changes",
            "View module-level summaries and insights",
            "See file role classifications (entry point, core logic, etc.)",
            "Receive budget-aware analysis notifications"
          ],
          "developerVisibleActions": [
            "Call analyzeChatRequest() to get AI insights for chat interactions",
            "Use analyzeCodebase() to generate full codebase analysis with LLM insights",
            "Invoke analyzeProductPurpose() to extract high-level product goals",
            "Generate documentation via generateEnhancedProductDocumentation()",
            "Request test plans with generateUnitTestPlan()",
            "Get refactoring suggestions through analyzeForRefactoring()",
            "Configure LLM provider (OpenAI, Claude, Gemini) through settings",
            "Monitor token budget consumption across analysis operations",
            "Handle rate limiting and retry logic automatically",
            "Access parsed JSON responses from LLM outputs",
            "Receive structured analysis results with metadata"
          ],
          "keyFunctions": [
            {
              "name": "analyzeChatRequest",
              "desc": "Processes user chat requests and generates AI-powered responses about the codebase",
              "inputs": "userMessage (string), codebaseContext (analysis data), chatHistory (conversation array)",
              "outputs": "AI-generated response string addressing the user's question"
            },
            {
              "name": "analyzeCodebase",
              "desc": "Performs comprehensive codebase analysis using LLM to extract insights, patterns, and documentation",
              "inputs": "CodeAnalysis object with file structure and metadata",
              "outputs": "LLMInsights object with architectural patterns, tech stack, risks, and recommendations"
            },
            {
              "name": "analyzeProductPurpose",
              "desc": "Determines the high-level purpose and goals of the product from code analysis",
              "inputs": "CodeAnalysis with file summaries and structure",
              "outputs": "ProductPurposeAnalysis with purpose, rationale, and key capabilities"
            },
            {
              "name": "generateEnhancedProductDocumentation",
              "desc": "Creates detailed product documentation including purpose, architecture, and module descriptions",
              "inputs": "CodeAnalysis and optional ProductPurposeAnalysis",
              "outputs": "EnhancedProductDocumentation with comprehensive project documentation"
            },
            {
              "name": "generateUnitTestPlan",
              "desc": "Generates test plans with specific test cases for a code file",
              "inputs": "file path, file content, file role, module context",
              "outputs": "UnitTestPlan with test scenarios, coverage areas, and suggested test cases"
            },
            {
              "name": "analyzeForRefactoring",
              "desc": "Analyzes functions and provides refactoring suggestions to improve code quality",
              "inputs": "file path, file content, function metadata",
              "outputs": "RefactoringAnalysis with suggestions for improvements, complexity reduction, and best practices"
            },
            {
              "name": "callLLM",
              "desc": "Core method that handles all LLM API calls with rate limiting, retries, and response parsing",
              "inputs": "prompt, schema definition, token budget, provider selection",
              "outputs": "Parsed JSON response matching the requested schema"
            }
          ],
          "dependencies": [
            "vscode",
            "./fileDocumentation",
            "./analyzer",
            "./analysis/enhancedAnalyzer",
            "./llmSchemas",
            "./fileAccessHelper",
            "./logger",
            "./config/configurationManager",
            "./ai/providers/providerFactory",
            "./ai/llmResponseParser",
            "./ai/llmRateLimiter",
            "./ai/llmRetryHandler",
            "./domain/prompts/promptBuilder",
            "./domain/services/incrementalAnalysisService",
            "./domain/prompts/refactoringPromptBuilder",
            "./analysis/functionAnalyzer"
          ],
          "intent": "This file exists to bridge the gap between code analysis and AI-powered insights by managing all interactions with Large Language Models (OpenAI, Claude, Gemini). It solves the problem of extracting meaningful, human-readable insights from raw code structure by orchestrating LLM calls with proper rate limiting, retry logic, token budget management, and structured response parsing. It enables developers to get intelligent documentation, refactoring suggestions, test plans, and architectural insights without manually analyzing large codebases.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis and documentation generation by coordinating LLM providers (OpenAI/Claude) to generate insights, summaries, and test plans for codebases.\",\n  \"userVisibleActions\": [\n    \"Generate intelligent product purpose analysis from codebase\",\n    \"Create comprehensive documentation with architecture insights\",\n    \"Generate unit test plans for code files\",\n    \"Receive AI-powered refactoring suggestions for functions\",\n    \"Get incremental analysis updates as code changes\",\n    \"View module-level summaries and insights\",\n    \"See file role classifications (entry point, core logic, etc.)\",\n    \"Receive budget-aware analysis notifications\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzeChatRequest() to get AI insights for chat interactions\",\n    \"Use analyzeCodebase() to generate full codebase analysis with LLM insights\",\n    \"Invoke analyzeProductPurpose() to extract high-level product goals\",\n    \"Generate documentation via generateEnhancedProductDocumentation()\",\n    \"Request test plans with generateUnitTestPlan()\",\n    \"Get refactoring suggestions through analyzeForRefactoring()\",\n    \"Configure LLM provider (OpenAI, Claude, Gemini) through settings\",\n    \"Monitor token budget consumption across analysis operations\",\n    \"Handle rate limiting and retry logic automatically\",\n    \"Access parsed JSON responses from LLM outputs\",\n    \"Receive structured analysis results with metadata\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeChatRequest\",\n      \"desc\": \"Processes user chat requests and generates AI-powered responses about the codebase\",\n      \"inputs\": \"userMessage (string), codebaseContext (analysis data), chatHistory (conversation array)\",\n      \"outputs\": \"AI-generated response string addressing the user's question\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Performs comprehensive codebase analysis using LLM to extract insights, patterns, and documentation\",\n      \"inputs\": \"CodeAnalysis object with file structure and metadata\",\n      \"outputs\": \"LLMInsights object with architectural patterns, tech stack, risks, and recommendations\"\n    },\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Determines the high-level purpose and goals of the product from code analysis\",\n      \"inputs\": \"CodeAnalysis with file summaries and structure\",\n      \"outputs\": \"ProductPurposeAnalysis with purpose, rationale, and key capabilities\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates detailed product documentation including purpose, architecture, and module descriptions\",\n      \"inputs\": \"CodeAnalysis and optional ProductPurposeAnalysis\",\n      \"outputs\": \"EnhancedProductDocumentation with comprehensive project documentation\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Generates test plans with specific test cases for a code file\",\n      \"inputs\": \"file path, file content, file role, module context\",\n      \"outputs\": \"UnitTestPlan with test scenarios, coverage areas, and suggested test cases\"\n    },\n    {\n      \"name\": \"analyzeForRefactoring\",\n      \"desc\": \"Analyzes functions and provides refactoring suggestions to improve code quality\",\n      \"inputs\": \"file path, file content, function metadata\",\n      \"outputs\": \"RefactoringAnalysis with suggestions for improvements, complexity reduction, and best practices\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Core method that handles all LLM API calls with rate limiting, retries, and response parsing\",\n      \"inputs\": \"prompt, schema definition, token budget, provider selection\",\n      \"outputs\": \"Parsed JSON response matching the requested schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis and AI-powered insights by managing all interactions with Large Language Models (OpenAI, Claude, Gemini). It solves the problem of extracting meaningful, human-readable insights from raw code structure by orchestrating LLM calls with proper rate limiting, retry logic, token budget management, and structured response parsing. It enables developers to get intelligent documentation, refactoring suggestions, test plans, and architectural insights without manually analyzing large codebases.\"\n}\n```"
        },
        {
          "file": "src/logger.ts",
          "role": "Core Logic",
          "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
          "userVisibleActions": [
            "Log files are created in the workspace's .shadow/logs directory",
            "A shadow-watch.log file accumulates timestamped entries of extension activity",
            "Logs persist across sessions for debugging and auditing purposes"
          ],
          "developerVisibleActions": [
            "Developers can call SWLogger.log() to write timestamped messages to the log file",
            "Developers can call SWLogger.section() to add formatted section headers to organize log entries",
            "Logging fails silently if the workspace is not available or file operations fail",
            "Log entries include ISO timestamp format for precise timing information"
          ],
          "keyFunctions": [
            {
              "name": "log",
              "desc": "Writes a timestamped message to the shadow-watch.log file",
              "inputs": "message: string - the text to log",
              "outputs": "void - no return value, writes to file system"
            },
            {
              "name": "section",
              "desc": "Adds a formatted section header to the log for organizing related entries",
              "inputs": "title: string - the section title",
              "outputs": "void - writes formatted header to log"
            },
            {
              "name": "getLogPath",
              "desc": "Determines the full file path where logs should be written",
              "inputs": "none",
              "outputs": "string | null - the log file path or null if no workspace is open"
            },
            {
              "name": "ensureDir",
              "desc": "Creates the directory structure if it doesn't exist",
              "inputs": "dir: string - directory path to create",
              "outputs": "void - creates directory recursively"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "vscode"
          ],
          "intent": "This file exists to provide centralized, file-based logging for the extension, allowing developers to track extension behavior and debug issues by writing persistent logs to the workspace. It solves the problem of needing visibility into extension operations without relying on console output or VS Code's output panel alone.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are created in the workspace's .shadow/logs directory\",\n    \"A shadow-watch.log file accumulates timestamped entries of extension activity\",\n    \"Logs persist across sessions for debugging and auditing purposes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can call SWLogger.log() to write timestamped messages to the log file\",\n    \"Developers can call SWLogger.section() to add formatted section headers to organize log entries\",\n    \"Logging fails silently if the workspace is not available or file operations fail\",\n    \"Log entries include ISO timestamp format for precise timing information\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - the text to log\",\n      \"outputs\": \"void - no return value, writes to file system\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Adds a formatted section header to the log for organizing related entries\",\n      \"inputs\": \"title: string - the section title\",\n      \"outputs\": \"void - writes formatted header to log\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the full file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - the log file path or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates the directory structure if it doesn't exist\",\n      \"inputs\": \"dir: string - directory path to create\",\n      \"outputs\": \"void - creates directory recursively\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide centralized, file-based logging for the extension, allowing developers to track extension behavior and debug issues by writing persistent logs to the workspace. It solves the problem of needing visibility into extension operations without relying on console output or VS Code's output panel alone.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "shadow-watch.analyzeFile",
          "description": "Analyze the current file to generate code insights, structure analysis, and quality metrics"
        },
        {
          "command": "shadow-watch.generateDocumentation",
          "description": "Generate comprehensive LLM-powered documentation for the entire codebase"
        },
        {
          "command": "shadow-watch.refreshAnalysis",
          "description": "Manually refresh the analysis results and update all views"
        },
        {
          "command": "shadow-watch.clearCache",
          "description": "Clear all cached analysis data to force fresh analysis"
        },
        {
          "command": "shadow-watch.exportInsights",
          "description": "Export generated insights and analysis results to a file"
        },
        {
          "command": "shadow-watch.generateProductDoc",
          "description": "Generate AI-powered product-level documentation explaining purpose and architecture"
        },
        {
          "command": "shadow-watch.generateInsights",
          "description": "Generate AI-powered insights about code quality, organization, and potential issues"
        },
        {
          "command": "shadow-watch.generateUnitTests",
          "description": "Analyze test coverage and generate AI-powered unit test plans"
        },
        {
          "command": "shadow-watch.openReport",
          "description": "Open a generated report (workspace, product, architecture, or unit test analysis)"
        },
        {
          "command": "shadow-watch.configureSettings",
          "description": "Configure extension settings including LLM provider, API keys, and analysis options"
        }
      ],
      "workers": []
    },
    {
      "module": "src/config",
      "moduleType": "other",
      "capabilities": [
        "Centralized management of all Shadow Watch extension settings",
        "Real-time configuration change notifications to extension components",
        "User control over extension activation and automatic analysis behavior",
        "Customizable display options for code hints and diagnostics",
        "Flexible LLM provider selection and output format configuration",
        "Configurable diagnostic severity filtering"
      ],
      "summary": "The config module serves as the central configuration hub for the Shadow Watch extension, managing all user preferences and settings. It provides a unified interface for accessing and updating extension configuration, including core features like extension activation, automatic file analysis, inline hint display, and diagnostic severity levels.\n\nThis module enables users to customize their Shadow Watch experience through VS Code's settings UI. Users can choose between different LLM providers (OpenAI or Claude), select their preferred output format for AI interactions (Cursor, ChatGPT, Generic, or Compact), and control when and how the extension provides feedback. The module implements a reactive architecture that automatically notifies all relevant extension components when settings change, ensuring the extension behavior always reflects current user preferences.\n\nThe configuration manager handles the complete lifecycle of settings management, from reading initial values to propagating updates throughout the extension. This ensures consistent behavior across all Shadow Watch features and provides users with immediate feedback when they adjust settings, making the extension highly responsive and adaptable to individual workflow requirements.",
      "files": [
        {
          "file": "src/config/configurationManager.ts",
          "role": "Core Logic",
          "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes occur",
          "userVisibleActions": [
            "User enables/disables Shadow Watch extension",
            "User toggles automatic analysis when saving files",
            "User toggles inline hints display in code editor",
            "User configures which LLM provider to use (OpenAI or Claude)",
            "User selects output format for LLM interactions (Cursor, ChatGPT, Generic, or Compact)",
            "User sets minimum severity level for showing diagnostics (Error, Warning, or Info)",
            "User changes any Shadow Watch setting in VS Code settings UI"
          ],
          "developerVisibleActions": [
            "Developer components can access all Shadow Watch configuration settings through type-safe getters",
            "Developer components can register callbacks to be notified when configuration changes",
            "Developer components can validate configuration settings before using them",
            "Developer can query whether the extension is enabled",
            "Developer can check if analysis should run on file save",
            "Developer can determine which LLM provider and format to use",
            "Developer can check severity threshold for filtering diagnostics"
          ],
          "keyFunctions": [
            {
              "name": "onConfigurationChange",
              "desc": "Registers a callback function to be invoked whenever Shadow Watch settings change",
              "inputs": "callback function with no parameters",
              "outputs": "void"
            },
            {
              "name": "removeConfigurationChangeListener",
              "desc": "Unregisters a previously registered configuration change callback",
              "inputs": "callback function to remove",
              "outputs": "void"
            },
            {
              "name": "enabled",
              "desc": "Returns whether the Shadow Watch extension is currently enabled",
              "inputs": "none (getter property)",
              "outputs": "boolean"
            },
            {
              "name": "analyzeOnSave",
              "desc": "Returns whether automatic analysis should run when files are saved",
              "inputs": "none (getter property)",
              "outputs": "boolean"
            },
            {
              "name": "showInlineHints",
              "desc": "Returns whether inline hints should be displayed in the code editor",
              "inputs": "none (getter property)",
              "outputs": "boolean"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety and consistency across the extension. It solves the problem of scattered configuration access and provides a reactive system where components can automatically respond to setting changes without manual polling.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes occur\",\n  \"userVisibleActions\": [\n    \"User enables/disables Shadow Watch extension\",\n    \"User toggles automatic analysis when saving files\",\n    \"User toggles inline hints display in code editor\",\n    \"User configures which LLM provider to use (OpenAI or Claude)\",\n    \"User selects output format for LLM interactions (Cursor, ChatGPT, Generic, or Compact)\",\n    \"User sets minimum severity level for showing diagnostics (Error, Warning, or Info)\",\n    \"User changes any Shadow Watch setting in VS Code settings UI\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer components can access all Shadow Watch configuration settings through type-safe getters\",\n    \"Developer components can register callbacks to be notified when configuration changes\",\n    \"Developer components can validate configuration settings before using them\",\n    \"Developer can query whether the extension is enabled\",\n    \"Developer can check if analysis should run on file save\",\n    \"Developer can determine which LLM provider and format to use\",\n    \"Developer can check severity threshold for filtering diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be invoked whenever Shadow Watch settings change\",\n      \"inputs\": \"callback function with no parameters\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback function to remove\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Returns whether inline hints should be displayed in the code editor\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety and consistency across the extension. It solves the problem of scattered configuration access and provides a reactive system where components can automatically respond to setting changes without manual polling.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/context",
      "moduleType": "other",
      "capabilities": [
        "Automatically persists code analysis results to disk for future reference",
        "Converts code analysis data into LLM-optimized format for AI consumption",
        "Maintains analysis context across VS Code sessions",
        "Stores structured documentation in a standardized location (.shadow/docs/)",
        "Enables analysis data reuse without re-scanning codebases"
      ],
      "summary": "The context module provides automated persistence and formatting of code analysis results. When code is analyzed, this module automatically captures the results and saves them to .shadow/docs/code-analysis.json in a format optimized for Large Language Model consumption. This ensures that analysis insights are preserved across VS Code sessions and can be referenced by AI features without requiring repeated analysis.\n\nThe module acts as a bridge between raw code analysis output and AI-ready context. It transforms analysis data into a structured format that LLMs can efficiently process, making code understanding and documentation generation more effective. Users benefit from faster AI responses since previously analyzed code doesn't need to be re-scanned.\n\nAll analysis data is automatically managed in the background - users don't need to manually save or load analysis results. The module ensures that documentation and code insights remain available even after closing and reopening projects, creating a seamless experience for AI-assisted development workflows.",
      "files": [
        {
          "file": "src/context/analysisContextBuilder.ts",
          "role": "Core Logic",
          "purpose": "Converts code analysis data into a format suitable for LLM consumption and saves it to disk for future reference.",
          "userVisibleActions": [
            "Code analysis results are automatically saved to .shadow/docs/code-analysis.json for future use",
            "Analysis data is persisted across VS Code sessions"
          ],
          "developerVisibleActions": [
            "Transforms CodeAnalysis objects into AnalysisContext format that can be sent to LLM services",
            "Creates .shadow/docs directory structure if it doesn't exist",
            "Saves analysis with metadata including generation timestamp",
            "Enables analysis data to be reused without re-scanning the codebase"
          ],
          "keyFunctions": [
            {
              "name": "convertCodeAnalysisToContext",
              "desc": "Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption",
              "inputs": "analysis: CodeAnalysis (contains files, imports, entry points, metrics)",
              "outputs": "AnalysisContext (formatted data with files, imports, entry points, orphaned files, and totals)"
            },
            {
              "name": "saveCodeAnalysis",
              "desc": "Persists code analysis data to .shadow/docs/code-analysis.json with timestamp metadata",
              "inputs": "analysis: CodeAnalysis (code analysis data to save)",
              "outputs": "void (writes to file system)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../analyzer (CodeAnalysis, EntryPoint types)",
            "../llmService (AnalysisContext type)"
          ],
          "intent": "This file exists to bridge the gap between the code analyzer and LLM service by converting analysis data into LLM-friendly format and caching it on disk. This allows analysis results to be reused without re-scanning the entire codebase, improving performance and enabling offline access to previously generated analysis data.",
          "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis data into a format suitable for LLM consumption and saves it to disk for future reference.\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to .shadow/docs/code-analysis.json for future use\",\n    \"Analysis data is persisted across VS Code sessions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transforms CodeAnalysis objects into AnalysisContext format that can be sent to LLM services\",\n    \"Creates .shadow/docs directory structure if it doesn't exist\",\n    \"Saves analysis with metadata including generation timestamp\",\n    \"Enables analysis data to be reused without re-scanning the codebase\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"analysis: CodeAnalysis (contains files, imports, entry points, metrics)\",\n      \"outputs\": \"AnalysisContext (formatted data with files, imports, entry points, orphaned files, and totals)\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis data to .shadow/docs/code-analysis.json with timestamp metadata\",\n      \"inputs\": \"analysis: CodeAnalysis (code analysis data to save)\",\n      \"outputs\": \"void (writes to file system)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer (CodeAnalysis, EntryPoint types)\",\n    \"../llmService (AnalysisContext type)\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between the code analyzer and LLM service by converting analysis data into LLM-friendly format and caching it on disk. This allows analysis results to be reused without re-scanning the entire codebase, improving performance and enabling offline access to previously generated analysis data.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/bootstrap",
      "moduleType": "other",
      "capabilities": [
        "Initialize and configure all extension components during VS Code activation",
        "Register and manage all user-facing commands for workspace and file analysis",
        "Set up automatic file watching and re-analysis triggers",
        "Configure UI elements including status bar, tree views, and diagnostics panels",
        "Establish command mappings between user actions and their corresponding handlers",
        "Bootstrap analyzers, providers, and reporting systems for code intelligence"
      ],
      "summary": "This bootstrap module serves as the initialization layer for the VS Code extension, responsible for setting up all user-facing features and workflows when the extension activates. It coordinates the registration of commands, configuration of UI components, and establishment of automatic analysis triggers that enable users to interact with the extension's code intelligence capabilities.\n\nThe module handles two primary responsibilities: command registration and extension bootstrapping. Command registration maps user actions (such as analyzing files, copying insights, switching LLM providers, and navigating code) to their execution handlers, making these features accessible through the VS Code command palette, context menus, and keyboard shortcuts. Extension bootstrapping initializes all supporting infrastructure including tree view providers for insights and analysis results, file system watchers for automatic re-analysis, diagnostics providers for displaying warnings and errors, status bar indicators, and custom webview renderers for reports.\n\nUsers interact with this module indirectly through the features it enables. Upon activation, the extension becomes fully functional with visible UI elements (status bar, tree views in the sidebar), active command mappings (accessible via command palette), and automatic workflows (file change detection triggering re-analysis). This module ensures that all components work together cohesively, providing a seamless experience for code analysis, insight generation, unit test reporting, and navigation throughout the codebase.",
      "files": [
        {
          "file": "src/domain/bootstrap/commandRegistry.ts",
          "role": "Core Logic",
          "purpose": "Registers all VS Code commands for the extension, mapping user actions to their corresponding handlers",
          "userVisibleActions": [
            "Analyze entire workspace for insights",
            "Analyze current open file",
            "Copy all insights to clipboard",
            "Copy file-specific insights to clipboard",
            "Copy individual insight to clipboard",
            "Clear analysis cache",
            "Clear all extension data",
            "Open extension settings",
            "View latest analysis report",
            "View latest unit test report",
            "Switch between LLM providers (OpenAI, Anthropic, etc.)",
            "Copy menu structure to clipboard",
            "View current LLM provider status",
            "Navigate to product items in codebase",
            "Navigate to analysis items",
            "Show detailed information for product items",
            "Show detailed information for insights",
            "Show detailed information for unit test items"
          ],
          "developerVisibleActions": [
            "Provides centralized command registration separating concerns from main extension file",
            "Maps command IDs to handler functions for all extension commands",
            "Integrates with LLM services, code analyzer, insight generator, and UI providers",
            "Manages command lifecycle within VS Code extension context",
            "Handles navigation between different views (product navigator, analysis viewer, insights tree)",
            "Coordinates between cache management, diagnostics, and configuration systems"
          ],
          "keyFunctions": [
            {
              "name": "register",
              "desc": "Registers all VS Code commands with their corresponding handlers",
              "inputs": "VS Code extension context and extension components (analyzers, providers, caches)",
              "outputs": "void - commands are registered as side effect"
            }
          ],
          "dependencies": [
            "vscode",
            "llmIntegration",
            "CodeAnalyzer",
            "InsightGenerator",
            "LLMFormatter",
            "InsightsTreeProvider",
            "DiagnosticsProvider",
            "AnalysisCache",
            "AnalysisViewerProvider",
            "ProductNavItem",
            "configurationManager",
            "ExtensionComponents"
          ],
          "intent": "Separates command registration logic from the main extension file to improve code organization, maintainability, and testability by providing a single place to define all user-triggered commands and their handlers",
          "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension, mapping user actions to their corresponding handlers\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for insights\",\n    \"Analyze current open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy file-specific insights to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear analysis cache\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to product items in codebase\",\n    \"Navigate to analysis items\",\n    \"Show detailed information for product items\",\n    \"Show detailed information for insights\",\n    \"Show detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized command registration separating concerns from main extension file\",\n    \"Maps command IDs to handler functions for all extension commands\",\n    \"Integrates with LLM services, code analyzer, insight generator, and UI providers\",\n    \"Manages command lifecycle within VS Code extension context\",\n    \"Handles navigation between different views (product navigator, analysis viewer, insights tree)\",\n    \"Coordinates between cache management, diagnostics, and configuration systems\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their corresponding handlers\",\n      \"inputs\": \"VS Code extension context and extension components (analyzers, providers, caches)\",\n      \"outputs\": \"void - commands are registered as side effect\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"Separates command registration logic from the main extension file to improve code organization, maintainability, and testability by providing a single place to define all user-triggered commands and their handlers\"\n}\n```"
        },
        {
          "file": "src/domain/bootstrap/extensionBootstrapper.ts",
          "role": "Core Logic",
          "purpose": "Initializes and configures all extension components during VS Code extension activation, setting up analyzers, watchers, providers, and UI elements.",
          "userVisibleActions": [
            "Status bar item appears showing extension state",
            "Tree views become available in sidebar (Insights, Analysis, Static Analysis, Unit Tests, Product Navigator, Reports)",
            "Diagnostics (warnings/errors) appear in Problems panel",
            "File change notifications trigger automatic re-analysis",
            "Reports viewer displays analysis reports",
            "Custom webviews render for different analysis types"
          ],
          "developerVisibleActions": [
            "Extension activates and all components initialize on workspace open",
            "File watcher monitors code changes and triggers analysis",
            "Cache system stores analysis results for performance",
            "Configuration manager loads user settings",
            "Error handler captures and logs failures during initialization",
            "State manager tracks LLM integration status",
            "Multiple tree providers populate different sidebar views",
            "Diagnostics provider integrates with VS Code's Problems panel"
          ],
          "keyFunctions": [
            {
              "name": "ExtensionComponents interface",
              "desc": "Defines all components that need to be initialized for the extension to function",
              "inputs": "N/A (interface definition)",
              "outputs": "Type definition including analyzer, generators, watchers, providers, cache, UI elements"
            },
            {
              "name": "bootstrap (implied)",
              "desc": "Orchestrates initialization of all extension components in correct order",
              "inputs": "vscode.ExtensionContext",
              "outputs": "ExtensionComponents object with all initialized services"
            }
          ],
          "dependencies": [
            "vscode",
            "../../analyzer (CodeAnalyzer)",
            "../../insightGenerator (InsightGenerator)",
            "../../llmFormatter (LLMFormatter)",
            "../../fileWatcher (FileWatcher)",
            "../../insightsTreeView (InsightsTreeProvider)",
            "../../diagnosticsProvider (DiagnosticsProvider)",
            "../../cache (AnalysisCache)",
            "../../llmIntegration",
            "../../productNavigator (ProductNavigatorProvider)",
            "../../analysisViewer (AnalysisViewerProvider, AnalysisItem)",
            "../../insightsViewer (InsightsViewerProvider, InsightItem)",
            "../../staticAnalysisViewer (StaticAnalysisViewerProvider, StaticAnalysisItem)",
            "../../unitTestsNavigator (UnitTestsNavigatorProvider, UnitTestItem)",
            "../../config/configurationManager",
            "../../utils/errorHandler (ErrorHandler)",
            "../../domain/services/fileWatcherService (FileWatcherService)",
            "../../ui/reportsViewer (ReportsViewer)",
            "../../reportsTreeProvider (ReportsTreeProvider, ReportTreeItem)",
            "../../state/llmStateManager"
          ],
          "intent": "This file exists to centralize and organize the complex initialization sequence required to start the VS Code extension. It solves the problem of managing multiple interdependent components (analyzers, UI providers, watchers, caches) that must be initialized in a specific order, making the activation logic maintainable and testable by separating it from the main extension entry point.",
          "rawContent": "```json\n{\n  \"purpose\": \"Initializes and configures all extension components during VS Code extension activation, setting up analyzers, watchers, providers, and UI elements.\",\n  \"userVisibleActions\": [\n    \"Status bar item appears showing extension state\",\n    \"Tree views become available in sidebar (Insights, Analysis, Static Analysis, Unit Tests, Product Navigator, Reports)\",\n    \"Diagnostics (warnings/errors) appear in Problems panel\",\n    \"File change notifications trigger automatic re-analysis\",\n    \"Reports viewer displays analysis reports\",\n    \"Custom webviews render for different analysis types\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates and all components initialize on workspace open\",\n    \"File watcher monitors code changes and triggers analysis\",\n    \"Cache system stores analysis results for performance\",\n    \"Configuration manager loads user settings\",\n    \"Error handler captures and logs failures during initialization\",\n    \"State manager tracks LLM integration status\",\n    \"Multiple tree providers populate different sidebar views\",\n    \"Diagnostics provider integrates with VS Code's Problems panel\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"ExtensionComponents interface\",\n      \"desc\": \"Defines all components that need to be initialized for the extension to function\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Type definition including analyzer, generators, watchers, providers, cache, UI elements\"\n    },\n    {\n      \"name\": \"bootstrap (implied)\",\n      \"desc\": \"Orchestrates initialization of all extension components in correct order\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object with all initialized services\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer (CodeAnalyzer)\",\n    \"../../insightGenerator (InsightGenerator)\",\n    \"../../llmFormatter (LLMFormatter)\",\n    \"../../fileWatcher (FileWatcher)\",\n    \"../../insightsTreeView (InsightsTreeProvider)\",\n    \"../../diagnosticsProvider (DiagnosticsProvider)\",\n    \"../../cache (AnalysisCache)\",\n    \"../../llmIntegration\",\n    \"../../productNavigator (ProductNavigatorProvider)\",\n    \"../../analysisViewer (AnalysisViewerProvider, AnalysisItem)\",\n    \"../../insightsViewer (InsightsViewerProvider, InsightItem)\",\n    \"../../staticAnalysisViewer (StaticAnalysisViewerProvider, StaticAnalysisItem)\",\n    \"../../unitTestsNavigator (UnitTestsNavigatorProvider, UnitTestItem)\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler (ErrorHandler)\",\n    \"../../domain/services/fileWatcherService (FileWatcherService)\",\n    \"../../ui/reportsViewer (ReportsViewer)\",\n    \"../../reportsTreeProvider (ReportsTreeProvider, ReportTreeItem)\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and organize the complex initialization sequence required to start the VS Code extension. It solves the problem of managing multiple interdependent components (analyzers, UI providers, watchers, caches) that must be initialized in a specific order, making the activation logic maintainable and testable by separating it from the main extension entry point.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [
        {
          "command": "analyze-workspace",
          "description": "Analyze entire workspace for code insights and patterns"
        },
        {
          "command": "analyze-file",
          "description": "Analyze the currently open file for insights"
        },
        {
          "command": "copy-all-insights",
          "description": "Copy all generated insights to clipboard"
        },
        {
          "command": "copy-file-insights",
          "description": "Copy insights specific to current file to clipboard"
        },
        {
          "command": "copy-insight",
          "description": "Copy individual insight item to clipboard"
        },
        {
          "command": "clear-cache",
          "description": "Clear analysis cache to force re-analysis"
        },
        {
          "command": "clear-all-data",
          "description": "Clear all extension data including cache and stored results"
        },
        {
          "command": "open-settings",
          "description": "Open extension settings configuration"
        },
        {
          "command": "view-analysis-report",
          "description": "View latest analysis report in custom viewer"
        },
        {
          "command": "view-unit-test-report",
          "description": "View latest unit test report with coverage details"
        },
        {
          "command": "switch-llm-provider",
          "description": "Switch between LLM providers (OpenAI, Anthropic, etc.)"
        },
        {
          "command": "copy-menu-structure",
          "description": "Copy extension menu structure to clipboard"
        },
        {
          "command": "view-provider-status",
          "description": "View current LLM provider status and configuration"
        },
        {
          "command": "navigate-to-product-item",
          "description": "Navigate to product items in codebase"
        },
        {
          "command": "navigate-to-analysis-item",
          "description": "Navigate to specific analysis items"
        },
        {
          "command": "show-product-item-details",
          "description": "Show detailed information for product items"
        },
        {
          "command": "show-insight-details",
          "description": "Show detailed information for insights"
        },
        {
          "command": "show-unit-test-details",
          "description": "Show detailed information for unit test items"
        }
      ],
      "workers": []
    },
    {
      "module": "src/domain/formatters",
      "moduleType": "other",
      "capabilities": [
        "Generates comprehensive product documentation in human-readable Markdown format",
        "Formats product metadata including name, type, description, and timestamps",
        "Organizes documentation by interface type (GUI, CLI, API) with detailed sections",
        "Presents key features and capabilities in structured bullet-point lists",
        "Formats technical architecture details including patterns, dependencies, and file structure",
        "Displays AI-generated insights with architectural recommendations and best practices",
        "Shows quality assessment metrics and scores in an easy-to-read format",
        "Highlights improvement suggestions and actionable items for development teams"
      ],
      "summary": "The formatters module provides documentation generation capabilities that transform raw product data and AI insights into polished, human-readable Markdown documents. Users can generate comprehensive documentation that includes product overviews, feature descriptions, technical architecture details, and quality assessments, all formatted with consistent structure and clear sections.\n\nThis module enables users to create professional documentation that organizes information by interface type (GUI, CLI, API), presenting key features, main capabilities, and technical implementation details in an accessible format. The generated documents include timestamps, structured headings, and bullet-pointed lists that make it easy for developers and stakeholders to understand product capabilities and architecture.\n\nThe module also formats AI-generated insights, incorporating architectural pattern analysis, dependency assessments, and quality metrics into the documentation. Users can view improvement suggestions, technical recommendations, and action items in a clear, organized manner that facilitates decision-making and development planning. All documentation is formatted with proper Markdown syntax for seamless integration into documentation systems, wikis, or version control repositories.",
      "files": [
        {
          "file": "src/domain/formatters/documentationFormatter.ts",
          "role": "Core Logic",
          "purpose": "Formats product documentation and LLM insights into structured Markdown documents for human readability",
          "userVisibleActions": [
            "Generates comprehensive product documentation in Markdown format with timestamps",
            "Creates formatted sections for product overview, features, and user perspectives",
            "Displays documentation organized by interface type (GUI, CLI, API)",
            "Shows key features and main capabilities in bullet-point format",
            "Presents technical details including architecture, dependencies, and file structure",
            "Formats AI-generated insights with architectural patterns and recommendations",
            "Displays quality assessment scores and metrics",
            "Shows identified improvement suggestions and action items"
          ],
          "developerVisibleActions": [
            "Converts EnhancedProductDocumentation objects into readable Markdown documents",
            "Converts LLMInsights objects into structured Markdown reports",
            "Applies consistent formatting and section ordering to documentation",
            "Generates timestamps in both local and UTC formats",
            "Creates hierarchical document structure with headers and subheaders",
            "Formats lists and bullet points for features, dependencies, and insights",
            "Handles optional sections gracefully (only includes sections with content)",
            "Provides standardized documentation output format for the application"
          ],
          "keyFunctions": [
            {
              "name": "formatEnhancedDocsAsMarkdown",
              "desc": "Converts enhanced product documentation object into a comprehensive Markdown document",
              "inputs": "EnhancedProductDocumentation object containing overview, features, perspectives, architecture, etc.",
              "outputs": "Formatted Markdown string with sections for overview, features, user perspectives, technical details, and file structure"
            },
            {
              "name": "formatInsightsAsMarkdown",
              "desc": "Converts LLM-generated insights into a structured Markdown report",
              "inputs": "LLMInsights object containing architectural patterns, quality assessment, and recommendations",
              "outputs": "Formatted Markdown string with sections for key insights, architecture, quality scores, and improvement suggestions"
            }
          ],
          "dependencies": [
            "../../fileDocumentation (EnhancedProductDocumentation type)",
            "../../llmService (LLMInsights type)"
          ],
          "intent": "Separates documentation formatting logic from business logic to create consistent, human-readable Markdown output from structured data objects. Solves the problem of presenting complex product documentation and AI insights in a standardized, readable format that users can easily consume and understand.",
          "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and LLM insights into structured Markdown documents for human readability\",\n  \"userVisibleActions\": [\n    \"Generates comprehensive product documentation in Markdown format with timestamps\",\n    \"Creates formatted sections for product overview, features, and user perspectives\",\n    \"Displays documentation organized by interface type (GUI, CLI, API)\",\n    \"Shows key features and main capabilities in bullet-point format\",\n    \"Presents technical details including architecture, dependencies, and file structure\",\n    \"Formats AI-generated insights with architectural patterns and recommendations\",\n    \"Displays quality assessment scores and metrics\",\n    \"Shows identified improvement suggestions and action items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Converts EnhancedProductDocumentation objects into readable Markdown documents\",\n    \"Converts LLMInsights objects into structured Markdown reports\",\n    \"Applies consistent formatting and section ordering to documentation\",\n    \"Generates timestamps in both local and UTC formats\",\n    \"Creates hierarchical document structure with headers and subheaders\",\n    \"Formats lists and bullet points for features, dependencies, and insights\",\n    \"Handles optional sections gracefully (only includes sections with content)\",\n    \"Provides standardized documentation output format for the application\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into a comprehensive Markdown document\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, perspectives, architecture, etc.\",\n      \"outputs\": \"Formatted Markdown string with sections for overview, features, user perspectives, technical details, and file structure\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into a structured Markdown report\",\n      \"inputs\": \"LLMInsights object containing architectural patterns, quality assessment, and recommendations\",\n      \"outputs\": \"Formatted Markdown string with sections for key insights, architecture, quality scores, and improvement suggestions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates documentation formatting logic from business logic to create consistent, human-readable Markdown output from structured data objects. Solves the problem of presenting complex product documentation and AI insights in a standardized, readable format that users can easily consume and understand.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/handlers",
      "moduleType": "other",
      "capabilities": [
        "Navigate to any code location (files, functions, endpoints) directly from analysis results",
        "Jump to precise line and column positions within source code files",
        "Open and display file contents in the VS Code editor",
        "View detailed information about code elements when selected",
        "Handle navigation errors gracefully with user-friendly error messages"
      ],
      "summary": "The navigation handler module enables seamless code navigation within VS Code by managing all editor interactions triggered by user selections. When users interact with code analysis results, this module handles the heavy lifting of opening files, positioning the cursor, and displaying the relevant code context.\n\nUsers can click on any code item from analysis viewswhether it's a file reference, function definition, API endpoint, or other code elementand the handler will automatically open the correct file in the editor and position the cursor at the exact location. This creates a smooth workflow where users can explore code relationships, trace dependencies, and investigate analysis findings without manually searching for files or locations.\n\nThe module provides robust error handling, displaying clear messages when files cannot be found or locations are invalid. This ensures users always receive feedback about navigation actions, whether successful or unsuccessful, maintaining a reliable and predictable editing experience.",
      "files": [
        {
          "file": "src/domain/handlers/navigationHandler.ts",
          "role": "Core Logic",
          "purpose": "Handles navigation to files, functions, endpoints, and other code locations within the VS Code editor, displaying details about code items when clicked.",
          "userVisibleActions": [
            "Click on a file item to open that file in the editor",
            "Click on a function to jump to its definition in the source code",
            "Click on an endpoint to navigate to its implementation",
            "Click on an analysis item to view its details in the editor",
            "View error messages when navigation fails to find a file or location",
            "See the cursor positioned at the exact line and column of the selected code element"
          ],
          "developerVisibleActions": [
            "Navigates to product items (files, functions, endpoints) from navigation trees",
            "Opens files at specific line and column positions",
            "Handles navigation from analysis viewer items",
            "Resolves relative file paths against workspace root",
            "Converts absolute paths to proper file URIs",
            "Shows error messages when files cannot be opened",
            "Manages text document opening and editor display",
            "Handles navigation to entry points from code analysis"
          ],
          "keyFunctions": [
            {
              "name": "navigateToProductItem",
              "desc": "Opens files and navigates to specific code locations (functions, endpoints) from product navigation items",
              "inputs": "ProductNavItem containing file path, function name, and location data",
              "outputs": "Promise<void> - opens document in editor or shows error"
            },
            {
              "name": "navigateToAnalysisItem",
              "desc": "Navigates to code locations from analysis results, positioning cursor at specific lines",
              "inputs": "AnalysisItem with file path and line/column information",
              "outputs": "Promise<void> - opens document and sets cursor position"
            },
            {
              "name": "navigateToEntryPoint",
              "desc": "Jumps to entry point definitions in the codebase from analysis data",
              "inputs": "EntryPoint object with file location and position details",
              "outputs": "Promise<void> - navigates to entry point location"
            },
            {
              "name": "showItemDetails",
              "desc": "Displays detailed information about a selected code item",
              "inputs": "Product item or analysis item with metadata",
              "outputs": "void - shows details in appropriate VS Code panel"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "ProductNavItem from productNavigator",
            "AnalysisItem from analysisViewer",
            "EntryPoint from analyzer"
          ],
          "intent": "This file exists to centralize all navigation logic for the extension, separating the concern of 'going to code locations' from other extension functionality. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual source code files, handling path resolution, error cases, and editor positioning in one place.",
          "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations within the VS Code editor, displaying details about code items when clicked.\",\n  \"userVisibleActions\": [\n    \"Click on a file item to open that file in the editor\",\n    \"Click on a function to jump to its definition in the source code\",\n    \"Click on an endpoint to navigate to its implementation\",\n    \"Click on an analysis item to view its details in the editor\",\n    \"View error messages when navigation fails to find a file or location\",\n    \"See the cursor positioned at the exact line and column of the selected code element\"\n  ],\n  \"developerVisibleActions\": [\n    \"Navigates to product items (files, functions, endpoints) from navigation trees\",\n    \"Opens files at specific line and column positions\",\n    \"Handles navigation from analysis viewer items\",\n    \"Resolves relative file paths against workspace root\",\n    \"Converts absolute paths to proper file URIs\",\n    \"Shows error messages when files cannot be opened\",\n    \"Manages text document opening and editor display\",\n    \"Handles navigation to entry points from code analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Opens files and navigates to specific code locations (functions, endpoints) from product navigation items\",\n      \"inputs\": \"ProductNavItem containing file path, function name, and location data\",\n      \"outputs\": \"Promise<void> - opens document in editor or shows error\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to code locations from analysis results, positioning cursor at specific lines\",\n      \"inputs\": \"AnalysisItem with file path and line/column information\",\n      \"outputs\": \"Promise<void> - opens document and sets cursor position\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Jumps to entry point definitions in the codebase from analysis data\",\n      \"inputs\": \"EntryPoint object with file location and position details\",\n      \"outputs\": \"Promise<void> - navigates to entry point location\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a selected code item\",\n      \"inputs\": \"Product item or analysis item with metadata\",\n      \"outputs\": \"void - shows details in appropriate VS Code panel\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic for the extension, separating the concern of 'going to code locations' from other extension functionality. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual source code files, handling path resolution, error cases, and editor positioning in one place.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/prompts",
      "moduleType": "other",
      "capabilities": [
        "Standardizes LLM prompt generation for all code analysis and documentation tasks",
        "Generates structured prompts for architecture analysis with configurable depth and detail levels",
        "Creates prompts for comprehensive test plan generation aligned with project conventions",
        "Produces prompts for code refactoring recommendations with function-level extraction plans",
        "Builds prompts for module and file-level documentation summaries with consistent formatting",
        "Generates prompts for test configuration setup and framework selection",
        "Provides detailed migration instructions and dependency analysis for refactoring workflows"
      ],
      "summary": "The prompts module serves as the centralized prompt engineering layer for all LLM-powered features in the application. It ensures that every interaction with language modelswhether for documentation generation, architecture analysis, test planning, or code refactoringfollows consistent formatting conventions and produces structured, predictable outputs. This standardization enables reliable parsing of LLM responses and maintains quality across all AI-generated content.\n\nUsers benefit from this module through enhanced documentation workflows that generate consistent, well-organized technical documentation at file, module, and product levels. When analyzing codebases, the module produces architecture insights with customizable depth, helping teams understand system structure and dependencies. For testing, it generates prioritized test plans based on code analysis and provides framework-specific recommendations including mock requirements for external dependencies.\n\nThe refactoring capabilities stand out by providing actionable, step-by-step guidance for improving code structure. Users receive detailed extraction plans showing exactly which functions should move to new files, complete with dependency analysis revealing caller-callee relationships. Each refactoring recommendation includes before-and-after code examples and comprehensive migration instructions, making it straightforward to implement suggested improvements while maintaining code functionality.",
      "files": [
        {
          "file": "src/domain/prompts/promptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Centralizes and standardizes the construction of LLM prompts for all code analysis, documentation, and testing tasks across the application.",
          "userVisibleActions": [
            "Documentation generation with consistent structure and formatting",
            "Architecture analysis results with standardized depth and detail",
            "Test plan generation following project conventions",
            "Module and file summaries with consistent organization",
            "Product-level documentation that combines all analysis results"
          ],
          "developerVisibleActions": [
            "Call buildArchitecturePrompt() to generate prompts for analyzing code architecture patterns",
            "Call buildProductDocsPrompt() to create prompts for generating product documentation",
            "Call buildProductPurposePrompt() to analyze and extract product purpose from documentation",
            "Call buildFileAnalysisPrompt() to generate file-level analysis prompts with role context",
            "Call buildModuleRollupPrompt() to create module-level summary prompts from file summaries",
            "Call buildProductLevelPrompt() to generate comprehensive product documentation prompts",
            "Call buildPerFileTestPlanPrompt() to create test planning prompts for individual files",
            "Call buildTestCodeGenerationPrompt() to generate actual test code from test plans",
            "All prompts are returned as formatted strings ready for LLM consumption",
            "Prompts include context, code analysis, and metadata to guide LLM responses",
            "Token budgets and formatting instructions are embedded in generated prompts"
          ],
          "keyFunctions": [
            {
              "name": "buildArchitecturePrompt",
              "desc": "Creates a prompt for LLM to analyze code architecture including patterns, structure, and design decisions",
              "inputs": "AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper",
              "outputs": "Formatted string prompt for architecture analysis"
            },
            {
              "name": "buildProductDocsPrompt",
              "desc": "Generates a prompt for extracting product documentation from existing files and context",
              "inputs": "AnalysisContext",
              "outputs": "Formatted string prompt for documentation extraction"
            },
            {
              "name": "buildProductPurposePrompt",
              "desc": "Creates a prompt to analyze and determine the core purpose and goals of the product",
              "inputs": "EnhancedProductDocumentation, AnalysisContext",
              "outputs": "Formatted string prompt for purpose analysis"
            },
            {
              "name": "buildFileAnalysisPrompt",
              "desc": "Generates a prompt for analyzing individual code files including their role and behavior",
              "inputs": "FileInfo, file content string, role string",
              "outputs": "Formatted string prompt for file-level analysis"
            },
            {
              "name": "buildModuleRollupPrompt",
              "desc": "Creates a prompt for summarizing multiple file summaries into a cohesive module summary",
              "inputs": "Module path, module type, array of FileSummary objects",
              "outputs": "Formatted string prompt for module rollup"
            },
            {
              "name": "buildProductLevelPrompt",
              "desc": "Generates a comprehensive prompt for creating product-wide documentation from all analyses",
              "inputs": "FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper",
              "outputs": "Formatted string prompt for product documentation"
            },
            {
              "name": "buildPerFileTestPlanPrompt",
              "desc": "Creates a prompt for generating test plans for individual files based on their functions",
              "inputs": "File path, content, FunctionMetadata array, existing tests, language, test framework, optional project summary",
              "outputs": "Formatted string prompt for test planning"
            },
            {
              "name": "buildTestCodeGenerationPrompt",
              "desc": "Generates a prompt for creating actual test code from test plan specifications",
              "inputs": "Test plan item, source code, function code, language, test framework",
              "outputs": "Formatted string prompt for test code generation"
            }
          ],
          "dependencies": [
            "../../llmService",
            "../../analyzer",
            "../../fileDocumentation",
            "../../fileAccessHelper"
          ],
          "intent": "This file exists to eliminate duplication and ensure consistency across all LLM prompt construction. By centralizing prompt building, it ensures that all AI-driven analysis, documentation, and testing tasks receive properly formatted, context-rich prompts with consistent structure, token budgets, and instructions, making LLM responses more reliable and maintainable.",
          "rawContent": "```json\n{\n  \"purpose\": \"Centralizes and standardizes the construction of LLM prompts for all code analysis, documentation, and testing tasks across the application.\",\n  \"userVisibleActions\": [\n    \"Documentation generation with consistent structure and formatting\",\n    \"Architecture analysis results with standardized depth and detail\",\n    \"Test plan generation following project conventions\",\n    \"Module and file summaries with consistent organization\",\n    \"Product-level documentation that combines all analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildArchitecturePrompt() to generate prompts for analyzing code architecture patterns\",\n    \"Call buildProductDocsPrompt() to create prompts for generating product documentation\",\n    \"Call buildProductPurposePrompt() to analyze and extract product purpose from documentation\",\n    \"Call buildFileAnalysisPrompt() to generate file-level analysis prompts with role context\",\n    \"Call buildModuleRollupPrompt() to create module-level summary prompts from file summaries\",\n    \"Call buildProductLevelPrompt() to generate comprehensive product documentation prompts\",\n    \"Call buildPerFileTestPlanPrompt() to create test planning prompts for individual files\",\n    \"Call buildTestCodeGenerationPrompt() to generate actual test code from test plans\",\n    \"All prompts are returned as formatted strings ready for LLM consumption\",\n    \"Prompts include context, code analysis, and metadata to guide LLM responses\",\n    \"Token budgets and formatting instructions are embedded in generated prompts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Creates a prompt for LLM to analyze code architecture including patterns, structure, and design decisions\",\n      \"inputs\": \"AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for architecture analysis\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Generates a prompt for extracting product documentation from existing files and context\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Formatted string prompt for documentation extraction\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates a prompt to analyze and determine the core purpose and goals of the product\",\n      \"inputs\": \"EnhancedProductDocumentation, AnalysisContext\",\n      \"outputs\": \"Formatted string prompt for purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Generates a prompt for analyzing individual code files including their role and behavior\",\n      \"inputs\": \"FileInfo, file content string, role string\",\n      \"outputs\": \"Formatted string prompt for file-level analysis\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Creates a prompt for summarizing multiple file summaries into a cohesive module summary\",\n      \"inputs\": \"Module path, module type, array of FileSummary objects\",\n      \"outputs\": \"Formatted string prompt for module rollup\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Generates a comprehensive prompt for creating product-wide documentation from all analyses\",\n      \"inputs\": \"FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates a prompt for generating test plans for individual files based on their functions\",\n      \"inputs\": \"File path, content, FunctionMetadata array, existing tests, language, test framework, optional project summary\",\n      \"outputs\": \"Formatted string prompt for test planning\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates a prompt for creating actual test code from test plan specifications\",\n      \"inputs\": \"Test plan item, source code, function code, language, test framework\",\n      \"outputs\": \"Formatted string prompt for test code generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and ensure consistency across all LLM prompt construction. By centralizing prompt building, it ensures that all AI-driven analysis, documentation, and testing tasks receive properly formatted, context-rich prompts with consistent structure, token budgets, and instructions, making LLM responses more reliable and maintainable.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/refactoringPromptBuilder.ts",
          "role": "Core Logic",
          "purpose": "Generates detailed, structured prompts for LLM-based code refactoring analysis with function-level extraction plans and migration steps.",
          "userVisibleActions": [
            "Receives comprehensive refactoring recommendations for improving code structure",
            "Gets detailed extraction plans showing which functions should move to new files",
            "Sees step-by-step migration instructions for implementing refactoring changes",
            "Views before-and-after code examples for proposed refactorings",
            "Obtains function dependency analysis showing which functions call or are called by others"
          ],
          "developerVisibleActions": [
            "Builds prompts that request detailed refactoring analysis from LLM services",
            "Incorporates code analysis results, product documentation, and architecture insights into prompts",
            "Generates prompts with function-level metadata including signatures, parameters, and line ranges",
            "Creates extraction plans identifying source files, target files, and functions to move",
            "Includes migration steps and code examples in the refactoring instructions",
            "Constructs prompts that analyze function responsibilities and dependencies"
          ],
          "keyFunctions": [
            {
              "name": "buildDetailedRefactoringPrompt",
              "desc": "Creates a comprehensive prompt for LLM to generate detailed refactoring recommendations",
              "inputs": "context (analysis context), codeAnalysis (code structure), productDocs (optional product documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)",
              "outputs": "Formatted prompt string for LLM consumption"
            },
            {
              "name": "buildFunctionAnalysisSection",
              "desc": "Constructs the section of the prompt containing function-level analysis details",
              "inputs": "functionAnalyses (array of function metadata)",
              "outputs": "Formatted string section with function details"
            },
            {
              "name": "buildExtractionRequirementsSection",
              "desc": "Generates prompt section specifying what extraction plans should include",
              "inputs": "None",
              "outputs": "Formatted string with extraction requirements"
            },
            {
              "name": "buildBasePrompt",
              "desc": "Creates the foundational prompt structure with context and analysis data",
              "inputs": "context, codeAnalysis, productDocs, architectureInsights",
              "outputs": "Base prompt string"
            }
          ],
          "dependencies": [
            "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
            "../../llmService (AnalysisContext, LLMInsights)",
            "../../fileDocumentation (EnhancedProductDocumentation)"
          ],
          "intent": "This file exists to systematically construct detailed, prescriptive prompts that guide LLMs in generating actionable refactoring recommendations. It solves the problem of getting high-quality, structured refactoring analysis by ensuring prompts include all necessary context: function metadata, dependencies, architectural insights, and explicit requirements for extraction plans and migration steps.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates detailed, structured prompts for LLM-based code refactoring analysis with function-level extraction plans and migration steps.\",\n  \"userVisibleActions\": [\n    \"Receives comprehensive refactoring recommendations for improving code structure\",\n    \"Gets detailed extraction plans showing which functions should move to new files\",\n    \"Sees step-by-step migration instructions for implementing refactoring changes\",\n    \"Views before-and-after code examples for proposed refactorings\",\n    \"Obtains function dependency analysis showing which functions call or are called by others\"\n  ],\n  \"developerVisibleActions\": [\n    \"Builds prompts that request detailed refactoring analysis from LLM services\",\n    \"Incorporates code analysis results, product documentation, and architecture insights into prompts\",\n    \"Generates prompts with function-level metadata including signatures, parameters, and line ranges\",\n    \"Creates extraction plans identifying source files, target files, and functions to move\",\n    \"Includes migration steps and code examples in the refactoring instructions\",\n    \"Constructs prompts that analyze function responsibilities and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for LLM to generate detailed refactoring recommendations\",\n      \"inputs\": \"context (analysis context), codeAnalysis (code structure), productDocs (optional product documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)\",\n      \"outputs\": \"Formatted prompt string for LLM consumption\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Constructs the section of the prompt containing function-level analysis details\",\n      \"inputs\": \"functionAnalyses (array of function metadata)\",\n      \"outputs\": \"Formatted string section with function details\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates prompt section specifying what extraction plans should include\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Formatted string with extraction requirements\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundational prompt structure with context and analysis data\",\n      \"inputs\": \"context, codeAnalysis, productDocs, architectureInsights\",\n      \"outputs\": \"Base prompt string\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to systematically construct detailed, prescriptive prompts that guide LLMs in generating actionable refactoring recommendations. It solves the problem of getting high-quality, structured refactoring analysis by ensuring prompts include all necessary context: function metadata, dependencies, architectural insights, and explicit requirements for extraction plans and migration steps.\"\n}\n```"
        },
        {
          "file": "src/domain/prompts/testPrompts.ts",
          "role": "Core Logic",
          "purpose": "Provides LLM prompt builders for generating test configuration and test plans from codebase analysis",
          "userVisibleActions": [
            "Generates test setup recommendations when initializing test configuration",
            "Creates prioritized test plans based on code analysis",
            "Provides structured JSON responses for test framework selection",
            "Suggests mock requirements for external dependencies like VSCode API"
          ],
          "developerVisibleActions": [
            "Call buildSetupPrompt() with workspace root and file list to get test configuration recommendations",
            "Call buildPlanningPrompt() with analysis context and functions to generate test strategies",
            "Receive JSON-formatted responses specifying testing frameworks, dependencies, and configurations",
            "Get recommendations for test directory structure and required mock setups",
            "Obtain prioritized lists of functions to test based on complexity and code statistics"
          ],
          "keyFunctions": [
            {
              "name": "buildSetupPrompt",
              "desc": "Generates an LLM prompt that analyzes codebase and recommends test setup configuration",
              "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
              "outputs": "string (formatted prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements)"
            },
            {
              "name": "buildPlanningPrompt",
              "desc": "Creates an LLM prompt for generating prioritized test plans from analyzed functions",
              "inputs": "context: AnalysisContext, functions: any[], productDocs?: any, architectureInsights?: any",
              "outputs": "string (formatted prompt with function list and codebase statistics for test strategy generation)"
            }
          ],
          "dependencies": [
            "../../analyzer (AnalysisContext)",
            "../services/testing/types/testPlanTypes (TestableFunction)"
          ],
          "intent": "This file exists to bridge code analysis with LLM-powered test generation by constructing structured prompts that guide the LLM to produce actionable test configurations and strategies. It solves the problem of automating test setup decisions by providing the LLM with relevant codebase context in a format that produces consistent, parseable JSON responses.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides LLM prompt builders for generating test configuration and test plans from codebase analysis\",\n  \"userVisibleActions\": [\n    \"Generates test setup recommendations when initializing test configuration\",\n    \"Creates prioritized test plans based on code analysis\",\n    \"Provides structured JSON responses for test framework selection\",\n    \"Suggests mock requirements for external dependencies like VSCode API\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace root and file list to get test configuration recommendations\",\n    \"Call buildPlanningPrompt() with analysis context and functions to generate test strategies\",\n    \"Receive JSON-formatted responses specifying testing frameworks, dependencies, and configurations\",\n    \"Get recommendations for test directory structure and required mock setups\",\n    \"Obtain prioritized lists of functions to test based on complexity and code statistics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Generates an LLM prompt that analyzes codebase and recommends test setup configuration\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"string (formatted prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements)\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates an LLM prompt for generating prioritized test plans from analyzed functions\",\n      \"inputs\": \"context: AnalysisContext, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"string (formatted prompt with function list and codebase statistics for test strategy generation)\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (AnalysisContext)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction)\"\n  ],\n  \"intent\": \"This file exists to bridge code analysis with LLM-powered test generation by constructing structured prompts that guide the LLM to produce actionable test configurations and strategies. It solves the problem of automating test setup decisions by providing the LLM with relevant codebase context in a format that produces consistent, parseable JSON responses.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services",
      "moduleType": "other",
      "capabilities": [
        "Automatically monitors workspace file system changes in real-time",
        "Progressively analyzes code using AI with iterative context gathering",
        "Automatically detects test framework configuration and setup requirements",
        "Filters and manages which files trigger automated responses",
        "Performs intelligent code searches when AI needs specific information",
        "Validates test environment configuration without manual user intervention"
      ],
      "summary": "This module provides intelligent automation services that enhance the development workflow through file monitoring, AI-powered analysis, and test environment management. Users benefit from automatic detection of file changes (creation, modification, deletion) that trigger relevant UI updates across the extension, while file watching can be configured to ignore specific patterns or directories. The module orchestrates multi-step AI analysis workflows that progressively gather code context by reading additional files and searching for patterns when needed, with built-in safeguards to prevent infinite analysis loops.\n\nThe services work together to minimize manual configuration and provide a seamless experience. When users save documents or modify their workspace, the file watcher automatically propagates these changes to relevant components. During code analysis, the incremental analysis service intelligently determines what additional information is needed and fetches it iteratively, showing progress throughout long-running operations. The test configuration service automatically identifies the project's test framework, detects missing dependencies, and flags configuration issues, ensuring that generated tests work correctly without requiring users to manually configure test setups or specify framework details.",
      "files": [
        {
          "file": "src/domain/services/fileWatcherService.ts",
          "role": "Core Logic",
          "purpose": "Provides a centralized service for monitoring file system changes across the extension, consolidating all file watching functionality to eliminate duplication.",
          "userVisibleActions": [
            "Automatically detects when files are created in the workspace",
            "Automatically detects when files are modified in the workspace",
            "Automatically detects when files are deleted from the workspace",
            "Automatically responds when user saves a document in the editor",
            "Filters out specific files or patterns from being watched (e.g., ignoring certain directories)",
            "Triggers updates in various UI components when relevant files change"
          ],
          "developerVisibleActions": [
            "Register file watchers for specific file patterns (e.g., '**/*.md', '**/*.json')",
            "Receive notifications when files matching patterns are created, changed, or deleted",
            "Subscribe to document save events across all open documents",
            "Configure which file system events to monitor (create, change, delete)",
            "Set up ignore patterns to exclude certain files from being watched",
            "Clean up watchers when components are disposed",
            "Handle file change events asynchronously with custom logic",
            "Use a single service instance to avoid duplicate file watchers"
          ],
          "keyFunctions": [
            {
              "name": "watch",
              "desc": "Registers a file watcher for a specific pattern and returns a disposable to stop watching",
              "inputs": "id (string), pattern (glob or RelativePattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)",
              "outputs": "vscode.Disposable to stop the watcher"
            },
            {
              "name": "onDocumentSave",
              "desc": "Registers a handler to be called whenever any document is saved in the editor",
              "inputs": "handler (callback function accepting TextDocument)",
              "outputs": "vscode.Disposable to unregister the handler"
            },
            {
              "name": "dispose",
              "desc": "Cleans up all active file watchers and document save handlers",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "getPatternKey",
              "desc": "Generates a unique key for a file pattern to avoid duplicate watchers",
              "inputs": "pattern (string or RelativePattern)",
              "outputs": "string key"
            },
            {
              "name": "shouldIgnore",
              "desc": "Determines if a file path should be ignored based on configured patterns",
              "inputs": "filePath (string), ignorePatterns (array of glob patterns)",
              "outputs": "boolean indicating whether to ignore the file"
            },
            {
              "name": "handleFileSystemEvent",
              "desc": "Processes file system events and dispatches them to registered handlers",
              "inputs": "uri (file URI), type (created/changed/deleted), patternKey (string)",
              "outputs": "void (triggers async handlers)"
            }
          ],
          "dependencies": [
            "vscode",
            "path",
            "fs"
          ],
          "intent": "This file exists to eliminate code duplication across multiple extension components that need to watch for file changes. Previously, fileWatcher.ts, productNavigator.ts, and insightsViewer.ts each had their own file watching logic. By consolidating into a single service, the extension can efficiently manage file system monitoring, avoid redundant watchers, ensure consistent behavior, and make it easier to maintain file watching functionality across the entire codebase.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes across the extension, consolidating all file watching functionality to eliminate duplication.\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created in the workspace\",\n    \"Automatically detects when files are modified in the workspace\",\n    \"Automatically detects when files are deleted from the workspace\",\n    \"Automatically responds when user saves a document in the editor\",\n    \"Filters out specific files or patterns from being watched (e.g., ignoring certain directories)\",\n    \"Triggers updates in various UI components when relevant files change\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers for specific file patterns (e.g., '**/*.md', '**/*.json')\",\n    \"Receive notifications when files matching patterns are created, changed, or deleted\",\n    \"Subscribe to document save events across all open documents\",\n    \"Configure which file system events to monitor (create, change, delete)\",\n    \"Set up ignore patterns to exclude certain files from being watched\",\n    \"Clean up watchers when components are disposed\",\n    \"Handle file change events asynchronously with custom logic\",\n    \"Use a single service instance to avoid duplicate file watchers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file watcher for a specific pattern and returns a disposable to stop watching\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)\",\n      \"outputs\": \"vscode.Disposable to stop the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever any document is saved in the editor\",\n      \"inputs\": \"handler (callback function accepting TextDocument)\",\n      \"outputs\": \"vscode.Disposable to unregister the handler\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all active file watchers and document save handlers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to avoid duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file path should be ignored based on configured patterns\",\n      \"inputs\": \"filePath (string), ignorePatterns (array of glob patterns)\",\n      \"outputs\": \"boolean indicating whether to ignore the file\"\n    },\n    {\n      \"name\": \"handleFileSystemEvent\",\n      \"desc\": \"Processes file system events and dispatches them to registered handlers\",\n      \"inputs\": \"uri (file URI), type (created/changed/deleted), patternKey (string)\",\n      \"outputs\": \"void (triggers async handlers)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate code duplication across multiple extension components that need to watch for file changes. Previously, fileWatcher.ts, productNavigator.ts, and insightsViewer.ts each had their own file watching logic. By consolidating into a single service, the extension can efficiently manage file system monitoring, avoid redundant watchers, ensure consistent behavior, and make it easier to maintain file watching functionality across the entire codebase.\"\n}\n```"
        },
        {
          "file": "src/domain/services/incrementalAnalysisService.ts",
          "role": "Core Logic",
          "purpose": "Manages iterative LLM analysis by processing file and grep requests across multiple analysis iterations until completion or limit is reached",
          "userVisibleActions": [
            "Performs multi-step code analysis that progressively gathers more information",
            "Reads additional files when the AI needs more context",
            "Searches code using grep when the AI needs to find specific patterns",
            "Limits analysis to prevent infinite loops (max iterations)",
            "Shows progress through iteration callbacks during long-running analysis"
          ],
          "developerVisibleActions": [
            "Provides async iterator pattern for testable incremental analysis",
            "Executes file read requests from LLM responses",
            "Executes grep search requests from LLM responses",
            "Limits requests to 5 per iteration to prevent overload",
            "Maintains conversation history across iterations",
            "Returns structured results with iteration count and request history",
            "Notifies through callbacks when iterations start and complete",
            "Determines when to continue or stop iterations"
          ],
          "keyFunctions": [
            {
              "name": "processRequests",
              "desc": "Processes LLM file and grep requests to gather additional information",
              "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation history)",
              "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
            },
            {
              "name": "readFiles",
              "desc": "Reads requested files through FileAccessHelper",
              "inputs": "file paths from LLM requests",
              "outputs": "formatted file content as additional info"
            },
            {
              "name": "performGrep",
              "desc": "Executes grep searches through FileAccessHelper",
              "inputs": "grep requests with patterns and paths",
              "outputs": "formatted search results as additional info"
            },
            {
              "name": "async iterator pattern",
              "desc": "Converts while loops to async iterator for iteration control",
              "inputs": "iteration callbacks and max iterations",
              "outputs": "IterationResult with result, iteration count, requests, and continuation flag"
            }
          ],
          "dependencies": [
            "FileAccessHelper",
            "LLMRequest types"
          ],
          "intent": "Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a testable, reusable service that handles the common pattern of LLM requesting additional files and performing searches during multi-step code analysis",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file and grep requests across multiple analysis iterations until completion or limit is reached\",\n  \"userVisibleActions\": [\n    \"Performs multi-step code analysis that progressively gathers more information\",\n    \"Reads additional files when the AI needs more context\",\n    \"Searches code using grep when the AI needs to find specific patterns\",\n    \"Limits analysis to prevent infinite loops (max iterations)\",\n    \"Shows progress through iteration callbacks during long-running analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides async iterator pattern for testable incremental analysis\",\n    \"Executes file read requests from LLM responses\",\n    \"Executes grep search requests from LLM responses\",\n    \"Limits requests to 5 per iteration to prevent overload\",\n    \"Maintains conversation history across iterations\",\n    \"Returns structured results with iteration count and request history\",\n    \"Notifies through callbacks when iterations start and complete\",\n    \"Determines when to continue or stop iterations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM file and grep requests to gather additional information\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"readFiles\",\n      \"desc\": \"Reads requested files through FileAccessHelper\",\n      \"inputs\": \"file paths from LLM requests\",\n      \"outputs\": \"formatted file content as additional info\"\n    },\n    {\n      \"name\": \"performGrep\",\n      \"desc\": \"Executes grep searches through FileAccessHelper\",\n      \"inputs\": \"grep requests with patterns and paths\",\n      \"outputs\": \"formatted search results as additional info\"\n    },\n    {\n      \"name\": \"async iterator pattern\",\n      \"desc\": \"Converts while loops to async iterator for iteration control\",\n      \"inputs\": \"iteration callbacks and max iterations\",\n      \"outputs\": \"IterationResult with result, iteration count, requests, and continuation flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest types\"\n  ],\n  \"intent\": \"Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a testable, reusable service that handles the common pattern of LLM requesting additional files and performing searches during multi-step code analysis\"\n}\n```"
        },
        {
          "file": "src/domain/services/testConfigurationService.ts",
          "role": "Core Logic",
          "purpose": "Automatically detects test framework configuration and identifies setup requirements to ensure generated tests work without manual user configuration",
          "userVisibleActions": [
            "Test framework is automatically detected from project files",
            "Missing test dependencies are identified and reported",
            "Configuration issues are detected and flagged",
            "Setup requirements are automatically determined",
            "Test configuration status is provided"
          ],
          "developerVisibleActions": [
            "Service scans workspace root for package.json and test configuration files",
            "Detects which test framework is in use (Jest, Mocha, Vitest, Pytest)",
            "Checks if test dependencies are installed",
            "Identifies missing dependencies that need to be installed",
            "Determines if TypeScript test support is configured",
            "Provides list of setup actions needed to make tests work",
            "Returns comprehensive test configuration status"
          ],
          "keyFunctions": [
            {
              "name": "detectTestConfiguration",
              "desc": "Analyzes workspace to detect test framework and configuration status",
              "inputs": "workspaceRoot: string (path to workspace)",
              "outputs": "TestConfigStatus (framework type, configuration state, missing dependencies, setup actions)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "SWLogger"
          ],
          "intent": "Eliminates the need for users to manually configure test environments by automatically detecting what test framework is being used, what's already configured, and what needs to be set up to make generated tests run successfully",
          "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration and identifies setup requirements to ensure generated tests work without manual user configuration\",\n  \"userVisibleActions\": [\n    \"Test framework is automatically detected from project files\",\n    \"Missing test dependencies are identified and reported\",\n    \"Configuration issues are detected and flagged\",\n    \"Setup requirements are automatically determined\",\n    \"Test configuration status is provided\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service scans workspace root for package.json and test configuration files\",\n    \"Detects which test framework is in use (Jest, Mocha, Vitest, Pytest)\",\n    \"Checks if test dependencies are installed\",\n    \"Identifies missing dependencies that need to be installed\",\n    \"Determines if TypeScript test support is configured\",\n    \"Provides list of setup actions needed to make tests work\",\n    \"Returns comprehensive test configuration status\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to workspace)\",\n      \"outputs\": \"TestConfigStatus (framework type, configuration state, missing dependencies, setup actions)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates the need for users to manually configure test environments by automatically detecting what test framework is being used, what's already configured, and what needs to be set up to make generated tests run successfully\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing",
      "moduleType": "tests",
      "capabilities": [
        "Automatically generate unit tests for code functions using AI-powered analysis",
        "Create prioritized test plans by analyzing codebases to determine testing strategy",
        "Detect and configure test environments across multiple languages and frameworks",
        "Execute test suites and capture structured results with detailed reporting",
        "Automatically validate and fix failing tests through iterative AI-powered corrections",
        "Track test generation progress with real-time updates on function coverage",
        "Support multiple test frameworks including Jest, Mocha, Pytest, and JUnit"
      ],
      "summary": "This module provides comprehensive AI-powered test generation and management capabilities for software projects. It leverages LLM technology to intelligently analyze codebases, create test plans, generate unit tests, and automatically fix failing tests. The module handles the complete testing workflow from environment detection and setup through test execution and validation.\n\nUsers can automatically generate tests for their code functions in batches, with the system tracking progress and providing feedback on each function being tested. The module intelligently prioritizes which functions should be tested based on complexity and importance, then generates appropriate test cases using AI analysis. When tests fail, the system automatically attempts to fix them through multiple retry attempts, significantly reducing manual debugging effort.\n\nThe module supports a wide range of programming languages and testing frameworks, automatically detecting the project environment and configuring the appropriate test runners and dependencies. Test execution results are captured in structured formats showing passed/failed counts, execution duration, error messages, stack traces, and coverage information. This comprehensive approach streamlines the entire testing process from setup through validation.",
      "files": [
        {
          "file": "src/domain/services/testing/llmTestGenerationService.ts",
          "role": "Core Logic",
          "purpose": "Generates unit tests for code functions in small batches using an LLM service, with progress tracking and execution validation.",
          "userVisibleActions": [
            "Progress updates showing current function being tested (e.g., 'Processing function 3 of 10: calculateTotal')",
            "Test generation results for each function with pass/fail status",
            "Error messages when test generation or execution fails",
            "Notifications about which functions have been successfully tested"
          ],
          "developerVisibleActions": [
            "Trigger test generation for a batch of functions by providing function metadata and workspace path",
            "Receive progress callbacks during batch processing showing which function is currently being processed",
            "Get structured test generation results including generated test code and execution status",
            "Access test state that tracks which functions have been processed and which remain",
            "View generated test code that can be saved to test files",
            "See whether generated tests pass or fail when executed",
            "Extract function source code from workspace files for test context"
          ],
          "keyFunctions": [
            {
              "name": "generateTestBatch",
              "desc": "Generates tests for multiple functions in a batch, calling LLM for each function and tracking progress",
              "inputs": "functions (array of TestableFunction), workspaceRoot (string), llmService (LLM service instance), onProgress (optional callback)",
              "outputs": "Map of function names to TestGenerationResult objects"
            },
            {
              "name": "extractFunctionSource",
              "desc": "Reads and extracts the source code of a specific function from the workspace files",
              "inputs": "func (TestableFunction), workspaceRoot (string)",
              "outputs": "Source code string for the function"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./types/testPlanTypes",
            "./types/testResultTypes",
            "../../prompts/testPrompts",
            "./testExecutionService",
            "../../../logger"
          ],
          "intent": "Enables incremental, batch-based test generation using LLMs to avoid overwhelming the system with too many simultaneous test generation requests. Provides progress tracking so developers can monitor which functions are being tested and get immediate feedback on test generation success or failure.",
          "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions in small batches using an LLM service, with progress tracking and execution validation.\",\n  \"userVisibleActions\": [\n    \"Progress updates showing current function being tested (e.g., 'Processing function 3 of 10: calculateTotal')\",\n    \"Test generation results for each function with pass/fail status\",\n    \"Error messages when test generation or execution fails\",\n    \"Notifications about which functions have been successfully tested\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test generation for a batch of functions by providing function metadata and workspace path\",\n    \"Receive progress callbacks during batch processing showing which function is currently being processed\",\n    \"Get structured test generation results including generated test code and execution status\",\n    \"Access test state that tracks which functions have been processed and which remain\",\n    \"View generated test code that can be saved to test files\",\n    \"See whether generated tests pass or fail when executed\",\n    \"Extract function source code from workspace files for test context\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, calling LLM for each function and tracking progress\",\n      \"inputs\": \"functions (array of TestableFunction), workspaceRoot (string), llmService (LLM service instance), onProgress (optional callback)\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Reads and extracts the source code of a specific function from the workspace files\",\n      \"inputs\": \"func (TestableFunction), workspaceRoot (string)\",\n      \"outputs\": \"Source code string for the function\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./types/testPlanTypes\",\n    \"./types/testResultTypes\",\n    \"../../prompts/testPrompts\",\n    \"./testExecutionService\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"Enables incremental, batch-based test generation using LLMs to avoid overwhelming the system with too many simultaneous test generation requests. Provides progress tracking so developers can monitor which functions are being tested and get immediate feedback on test generation success or failure.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestPlanningService.ts",
          "role": "Core Logic",
          "purpose": "Creates prioritized test plans by analyzing code functions using LLM to determine which functions should be tested and in what order.",
          "userVisibleActions": [
            "Receives a test plan showing which functions in their codebase need testing",
            "Sees functions categorized by priority and complexity",
            "Gets count of testable vs non-testable functions",
            "Views function groups organized for testing strategy"
          ],
          "developerVisibleActions": [
            "Calls analyzeFunctions() to extract function metadata from code analysis results",
            "Invokes createTestPlan() to generate LLM-based test strategy with context, functions, and optional documentation",
            "Uses saveTestPlanToDisk() to persist the generated test plan to a file",
            "Receives structured TestPlan object containing function groups and testability assessment",
            "Sees logging output showing number of functions analyzed and how many are testable"
          ],
          "keyFunctions": [
            {
              "name": "analyzeFunctions",
              "desc": "Extracts and normalizes function information from code analysis results",
              "inputs": "codeAnalysis object containing functions array",
              "outputs": "Array of function metadata including name, file, line numbers, complexity, parameters, and return type"
            },
            {
              "name": "createTestPlan",
              "desc": "Generates a prioritized test plan by sending function data to LLM service",
              "inputs": "AnalysisContext, functions array, llmService, optional productDocs and architectureInsights",
              "outputs": "TestPlan object with function groups and testability metrics"
            },
            {
              "name": "saveTestPlanToDisk",
              "desc": "Persists the generated test plan to a JSON file in the analysis results directory",
              "inputs": "context (containing resultDir path) and testPlan object",
              "outputs": "void (writes file to disk)"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "./types/testPlanTypes",
            "../../prompts/testPrompts",
            "../../../analyzer",
            "../../../logger"
          ],
          "intent": "This service exists to automate test planning by leveraging LLM intelligence to analyze code functions and determine optimal testing strategies. It solves the problem of manually identifying which functions need testing and prioritizing test effort based on function complexity, parameters, and codebase context.",
          "rawContent": "```json\n{\n  \"purpose\": \"Creates prioritized test plans by analyzing code functions using LLM to determine which functions should be tested and in what order.\",\n  \"userVisibleActions\": [\n    \"Receives a test plan showing which functions in their codebase need testing\",\n    \"Sees functions categorized by priority and complexity\",\n    \"Gets count of testable vs non-testable functions\",\n    \"Views function groups organized for testing strategy\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis results\",\n    \"Invokes createTestPlan() to generate LLM-based test strategy with context, functions, and optional documentation\",\n    \"Uses saveTestPlanToDisk() to persist the generated test plan to a file\",\n    \"Receives structured TestPlan object containing function groups and testability assessment\",\n    \"Sees logging output showing number of functions analyzed and how many are testable\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function information from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing functions array\",\n      \"outputs\": \"Array of function metadata including name, file, line numbers, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan by sending function data to LLM service\",\n      \"inputs\": \"AnalysisContext, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups and testability metrics\"\n    },\n    {\n      \"name\": \"saveTestPlanToDisk\",\n      \"desc\": \"Persists the generated test plan to a JSON file in the analysis results directory\",\n      \"inputs\": \"context (containing resultDir path) and testPlan object\",\n      \"outputs\": \"void (writes file to disk)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./types/testPlanTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../analyzer\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This service exists to automate test planning by leveraging LLM intelligence to analyze code functions and determine optimal testing strategies. It solves the problem of manually identifying which functions need testing and prioritizing test effort based on function complexity, parameters, and codebase context.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestSetupService.ts",
          "role": "Core Logic",
          "purpose": "Detects the test environment and generates LLM-powered test setup configurations for different programming languages and frameworks.",
          "userVisibleActions": [
            "Automatically detects the project's testing framework and language",
            "Generates test configuration files based on the detected environment",
            "Creates test directory structure if missing",
            "Installs required testing dependencies",
            "Sets up appropriate test runners (Jest, pytest, JUnit, etc.)"
          ],
          "developerVisibleActions": [
            "Call detectTestEnvironment() to analyze project structure and identify language/framework",
            "Use LLM prompts to generate context-aware test setup plans",
            "Execute setup plans to install dependencies and create configuration files",
            "Receive structured TestEnvironment data showing what was detected",
            "Get TestSetupPlan with specific actions needed to configure testing",
            "Obtain SetupExecutionResult indicating success/failure of setup operations"
          ],
          "keyFunctions": [
            {
              "name": "detectTestEnvironment",
              "desc": "Analyzes workspace to detect primary language, testing framework, and existing test setup",
              "inputs": "workspaceRoot: string (path to project root)",
              "outputs": "TestEnvironment object containing language, framework, and configuration status"
            },
            {
              "name": "getAllFiles",
              "desc": "Recursively scans directory to find all files for language detection",
              "inputs": "directory path",
              "outputs": "Array of file paths"
            },
            {
              "name": "buildSetupPrompt",
              "desc": "Constructs LLM prompt for generating test setup configuration",
              "inputs": "TestEnvironment data",
              "outputs": "Formatted prompt string for LLM"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "child_process",
            "./types/testSetupTypes",
            "../../prompts/testPrompts",
            "../../../logger"
          ],
          "intent": "This file exists to eliminate manual test setup by automatically detecting a project's programming environment and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, install dependencies, and create test structures for different languages and environments by using LLM intelligence to understand the project context and generate optimal setup plans.",
          "rawContent": "```json\n{\n  \"purpose\": \"Detects the test environment and generates LLM-powered test setup configurations for different programming languages and frameworks.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the project's testing framework and language\",\n    \"Generates test configuration files based on the detected environment\",\n    \"Creates test directory structure if missing\",\n    \"Installs required testing dependencies\",\n    \"Sets up appropriate test runners (Jest, pytest, JUnit, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call detectTestEnvironment() to analyze project structure and identify language/framework\",\n    \"Use LLM prompts to generate context-aware test setup plans\",\n    \"Execute setup plans to install dependencies and create configuration files\",\n    \"Receive structured TestEnvironment data showing what was detected\",\n    \"Get TestSetupPlan with specific actions needed to configure testing\",\n    \"Obtain SetupExecutionResult indicating success/failure of setup operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to detect primary language, testing framework, and existing test setup\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object containing language, framework, and configuration status\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans directory to find all files for language detection\",\n      \"inputs\": \"directory path\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Constructs LLM prompt for generating test setup configuration\",\n      \"inputs\": \"TestEnvironment data\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This file exists to eliminate manual test setup by automatically detecting a project's programming environment and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, install dependencies, and create test structures for different languages and environments by using LLM intelligence to understand the project context and generate optimal setup plans.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/llmTestValidationService.ts",
          "role": "Core Logic",
          "purpose": "Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution",
          "userVisibleActions": [
            "Tests are automatically run and validated",
            "Failing tests are detected and reported with detailed error messages",
            "Tests are automatically fixed through multiple retry attempts",
            "Test execution results show passed/failed counts and success rates",
            "Detailed test reports are generated showing which tests passed or failed"
          ],
          "developerVisibleActions": [
            "Trigger test validation for specific test files or entire workspace",
            "Configure maximum retry attempts for automatic test fixing",
            "Receive structured test execution results with pass/fail statistics",
            "Access detailed error messages and stack traces for failed tests",
            "Get feedback on which fix attempts succeeded or failed",
            "Review generated test reports with comprehensive test outcomes"
          ],
          "keyFunctions": [
            {
              "name": "runTests",
              "desc": "Executes all tests or a specific test file and captures results",
              "inputs": "workspaceRoot (string), optional testFile (string)",
              "outputs": "Array of TestExecutionResult objects with pass/fail statistics"
            },
            {
              "name": "fixFailingTest",
              "desc": "Attempts to automatically fix a failing test using LLM with retry logic",
              "inputs": "testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)",
              "outputs": "Object with success status, number of attempts, and final error if failed"
            },
            {
              "name": "buildFixPrompt",
              "desc": "Constructs an LLM prompt for fixing test failures based on error context",
              "inputs": "Test file content, execution results, error details",
              "outputs": "Formatted prompt string for LLM processing"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "TestExecutionService",
            "testResultTypes (TestExecutionResult, TestReport, TestReportSummary)",
            "testPrompts (buildFixPrompt)",
            "SWLogger"
          ],
          "intent": "This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.",
          "rawContent": "```json\n{\n  \"purpose\": \"Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and validated\",\n    \"Failing tests are detected and reported with detailed error messages\",\n    \"Tests are automatically fixed through multiple retry attempts\",\n    \"Test execution results show passed/failed counts and success rates\",\n    \"Detailed test reports are generated showing which tests passed or failed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test validation for specific test files or entire workspace\",\n    \"Configure maximum retry attempts for automatic test fixing\",\n    \"Receive structured test execution results with pass/fail statistics\",\n    \"Access detailed error messages and stack traces for failed tests\",\n    \"Get feedback on which fix attempts succeeded or failed\",\n    \"Review generated test reports with comprehensive test outcomes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and captures results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Array of TestExecutionResult objects with pass/fail statistics\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with retry logic\",\n      \"inputs\": \"testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)\",\n      \"outputs\": \"Object with success status, number of attempts, and final error if failed\"\n    },\n    {\n      \"name\": \"buildFixPrompt\",\n      \"desc\": \"Constructs an LLM prompt for fixing test failures based on error context\",\n      \"inputs\": \"Test file content, execution results, error details\",\n      \"outputs\": \"Formatted prompt string for LLM processing\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"testResultTypes (TestExecutionResult, TestReport, TestReportSummary)\",\n    \"testPrompts (buildFixPrompt)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/testExecutionService.ts",
          "role": "Core Logic",
          "purpose": "Executes test suites (Jest, Mocha, Pytest) and captures their results in a structured format",
          "userVisibleActions": [
            "Run all tests in the workspace",
            "Run tests for a specific file",
            "View test execution results (passed, failed, error counts)",
            "See test execution duration",
            "View detailed error messages and stack traces for failed tests",
            "Get test coverage information when available"
          ],
          "developerVisibleActions": [
            "Call runJest() to execute Jest tests with optional file parameter",
            "Call runMocha() to execute Mocha tests with optional file parameter",
            "Call runPytest() to execute Python pytest with optional file parameter",
            "Receive TestExecutionResult array with status, counts, and error details",
            "Handle test execution errors and timeouts",
            "Parse JSON output from test runners automatically",
            "Access test coverage data from execution results"
          ],
          "keyFunctions": [
            {
              "name": "runJest",
              "desc": "Executes Jest tests for a specific file or entire workspace",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runMocha",
              "desc": "Executes Mocha tests for a specific file or entire workspace",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "runPytest",
              "desc": "Executes Python pytest for a specific file or entire workspace",
              "inputs": "workspaceRoot: string, testFile?: string",
              "outputs": "Promise<TestExecutionResult[]>"
            },
            {
              "name": "parseJestOutput",
              "desc": "Parses JSON output from Jest test execution into structured results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parseMochaOutput",
              "desc": "Parses JSON output from Mocha test execution into structured results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            },
            {
              "name": "parsePytestOutput",
              "desc": "Parses JSON output from pytest execution into structured results",
              "inputs": "stdout: string, stderr: string",
              "outputs": "TestExecutionResult[]"
            }
          ],
          "dependencies": [
            "child_process",
            "path",
            "./types/testResultTypes"
          ],
          "intent": "Provides a unified interface for executing different test frameworks (Jest, Mocha, Pytest) and converting their outputs into a consistent result format, enabling the extension to support multiple testing technologies with test execution, result tracking, and error reporting capabilities.",
          "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest) and captures their results in a structured format\",\n  \"userVisibleActions\": [\n    \"Run all tests in the workspace\",\n    \"Run tests for a specific file\",\n    \"View test execution results (passed, failed, error counts)\",\n    \"See test execution duration\",\n    \"View detailed error messages and stack traces for failed tests\",\n    \"Get test coverage information when available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runJest() to execute Jest tests with optional file parameter\",\n    \"Call runMocha() to execute Mocha tests with optional file parameter\",\n    \"Call runPytest() to execute Python pytest with optional file parameter\",\n    \"Receive TestExecutionResult array with status, counts, and error details\",\n    \"Handle test execution errors and timeouts\",\n    \"Parse JSON output from test runners automatically\",\n    \"Access test coverage data from execution results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha tests for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Python pytest for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses JSON output from Jest test execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses JSON output from Mocha test execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses JSON output from pytest execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for executing different test frameworks (Jest, Mocha, Pytest) and converting their outputs into a consistent result format, enabling the extension to support multiple testing technologies with test execution, result tracking, and error reporting capabilities.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/domain/services/testing/types",
      "moduleType": "tests",
      "capabilities": [
        "Define type structures for automated test generation workflow tracking",
        "Track test generation progress through multiple phases (setup, planning, generation, validation, completion)",
        "Monitor test coverage across codebases with function-level granularity",
        "Organize test generation by function groups with priority management",
        "View detailed test execution results including pass/fail counts and durations",
        "Access comprehensive test reports with summaries and improvement recommendations",
        "Configure test environment setup with framework and dependency specifications",
        "Track test validation status with detailed error reporting"
      ],
      "summary": "This module provides the type definitions that enable comprehensive test generation and execution tracking across an entire codebase. Users can monitor the complete testing lifecycle from initial setup through test generation, validation, and execution, with detailed visibility into which functions are testable, which have been tested, and which encountered issues. The types support organizing tests by function groups with priorities, tracking complexity and dependencies, and viewing granular results.\n\nThe module structures three main workflow areas: test planning (tracking progress and function analysis), test results (generation, validation, and execution outcomes), and test setup (environment configuration and initialization). Users receive clear feedback at each stage, including phase indicators, success/failure metrics, pass rates, execution durations, and actionable recommendations. Error details include test names, messages, and stack traces to facilitate debugging.\n\nThrough these type definitions, users can configure testing frameworks, establish test directories, install dependencies, generate test files with appropriate imports and mocks, validate test correctness, execute tests, and review comprehensive reports. The system provides both high-level summaries (total functions analyzed, overall pass rates) and detailed function-level information (complexity scores, dependencies, individual test results) to support effective test management and quality assurance workflows.",
      "files": [
        {
          "file": "src/domain/services/testing/types/testPlanTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type structures for organizing and tracking automated test generation across codebases",
          "userVisibleActions": [
            "View test generation progress with phase indicators (setup, planning, generation, validation, complete)",
            "See total count of functions analyzed and how many are testable",
            "Track which functions have been tested and which failed",
            "Monitor test generation organized by function groups with priorities",
            "View detailed function information including complexity and dependencies"
          ],
          "developerVisibleActions": [
            "Define test plans with strategy selection and function grouping",
            "Structure testable functions with metadata (file location, line numbers, complexity, dependencies)",
            "Track test generation state across multiple phases with batch processing",
            "Group functions by priority for systematic test generation",
            "Record test failures with error messages and retry attempts",
            "Mark functions that require mocking based on dependencies",
            "Include function parameters and return types for accurate test generation"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a standardized type system for the test planning service to organize code analysis results, track test generation progress through multiple phases, and structure metadata needed for automated test creation across large codebases with proper prioritization and failure handling",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type structures for organizing and tracking automated test generation across codebases\",\n  \"userVisibleActions\": [\n    \"View test generation progress with phase indicators (setup, planning, generation, validation, complete)\",\n    \"See total count of functions analyzed and how many are testable\",\n    \"Track which functions have been tested and which failed\",\n    \"Monitor test generation organized by function groups with priorities\",\n    \"View detailed function information including complexity and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define test plans with strategy selection and function grouping\",\n    \"Structure testable functions with metadata (file location, line numbers, complexity, dependencies)\",\n    \"Track test generation state across multiple phases with batch processing\",\n    \"Group functions by priority for systematic test generation\",\n    \"Record test failures with error messages and retry attempts\",\n    \"Mark functions that require mocking based on dependencies\",\n    \"Include function parameters and return types for accurate test generation\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for the test planning service to organize code analysis results, track test generation progress through multiple phases, and structure metadata needed for automated test creation across large codebases with proper prioritization and failure handling\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testResultTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript type definitions for test generation, validation, execution results, and reporting",
          "userVisibleActions": [
            "View test generation results showing which test files were created with their imports and mocks",
            "See test validation status indicating whether tests passed, failed, or encountered errors",
            "Review test execution results showing how many tests passed, failed, or had errors with duration",
            "Read test reports with summaries, pass rates, and recommendations for improvement",
            "Examine error details including test names, error messages, and stack traces when tests fail"
          ],
          "developerVisibleActions": [
            "Define structure for test generation output including file paths, imports, mocks, and test code",
            "Specify test validation results with status, fixed code, and remaining issues",
            "Structure test execution results with pass/fail counts and timing information",
            "Create test reports with summaries and recommendations",
            "Define mock statement format with explanations for generated test mocks",
            "Capture setup and teardown code for test initialization and cleanup"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a strongly-typed contract for test generation and validation workflows, ensuring consistent data structures across test creation, execution, and reporting phases. Enables type-safe handling of test results, error details, and test report generation throughout the testing service.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test generation, validation, execution results, and reporting\",\n  \"userVisibleActions\": [\n    \"View test generation results showing which test files were created with their imports and mocks\",\n    \"See test validation status indicating whether tests passed, failed, or encountered errors\",\n    \"Review test execution results showing how many tests passed, failed, or had errors with duration\",\n    \"Read test reports with summaries, pass rates, and recommendations for improvement\",\n    \"Examine error details including test names, error messages, and stack traces when tests fail\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test generation output including file paths, imports, mocks, and test code\",\n    \"Specify test validation results with status, fixed code, and remaining issues\",\n    \"Structure test execution results with pass/fail counts and timing information\",\n    \"Create test reports with summaries and recommendations\",\n    \"Define mock statement format with explanations for generated test mocks\",\n    \"Capture setup and teardown code for test initialization and cleanup\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for test generation and validation workflows, ensuring consistent data structures across test creation, execution, and reporting phases. Enables type-safe handling of test results, error details, and test report generation throughout the testing service.\"\n}\n```"
        },
        {
          "file": "src/domain/services/testing/types/testSetupTypes.ts",
          "role": "Core Logic",
          "purpose": "Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service.",
          "userVisibleActions": [
            "Test setup plans are created with specific testing frameworks and dependencies",
            "Configuration files are generated for the test environment",
            "Test directories are established in the project",
            "Dependencies are installed for testing frameworks",
            "Success or error messages are displayed after test setup execution"
          ],
          "developerVisibleActions": [
            "Provides type-safe structures for planning test setup with language, framework, and dependency information",
            "Enables detection of existing test environment features (package.json, tsconfig, jest config, test directories)",
            "Structures mock requirements with types and reasons for test isolation",
            "Returns execution results with lists of created files, installed dependencies, and any errors",
            "Supports identifying missing dependencies and existing test frameworks in the project"
          ],
          "keyFunctions": [],
          "dependencies": [],
          "intent": "Provides a type-safe contract for test setup operations, ensuring consistent data structures across the testing service for planning, environment detection, and execution reporting. This enables developers to reliably configure test environments with proper typing and validation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service.\",\n  \"userVisibleActions\": [\n    \"Test setup plans are created with specific testing frameworks and dependencies\",\n    \"Configuration files are generated for the test environment\",\n    \"Test directories are established in the project\",\n    \"Dependencies are installed for testing frameworks\",\n    \"Success or error messages are displayed after test setup execution\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides type-safe structures for planning test setup with language, framework, and dependency information\",\n    \"Enables detection of existing test environment features (package.json, tsconfig, jest config, test directories)\",\n    \"Structures mock requirements with types and reasons for test isolation\",\n    \"Returns execution results with lists of created files, installed dependencies, and any errors\",\n    \"Supports identifying missing dependencies and existing test frameworks in the project\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a type-safe contract for test setup operations, ensuring consistent data structures across the testing service for planning, environment detection, and execution reporting. This enables developers to reliably configure test environments with proper typing and validation.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/fileSystem",
      "moduleType": "other",
      "capabilities": [
        "Provides fast, cached access to file contents with automatic cache invalidation",
        "Filters files intelligently to skip non-source directories (node_modules, .git, dist, build, etc.)",
        "Processes multiple files in parallel for improved performance",
        "Standardizes file reading and processing with consistent error handling across the codebase"
      ],
      "summary": "The fileSystem module provides optimized file access and processing capabilities for the codebase analysis system. It acts as an intelligent layer between the application and the file system, ensuring fast and efficient file operations.\n\nThe module automatically caches file contents in memory, eliminating redundant disk reads when the same files are accessed multiple times. The cache stays synchronized with disk changes, automatically updating when files are modified. This dramatically improves responsiveness during analysis operations that require repeated file access.\n\nFor file processing workflows, the module automatically filters out non-source directories and processes multiple files in parallel. This ensures that operations like scanning repositories or analyzing codebases focus only on relevant source files while maintaining high performance through concurrent processing. All file operations use standardized error handling to provide consistent and reliable behavior throughout the application.",
      "files": [
        {
          "file": "src/infrastructure/fileSystem/fileCache.ts",
          "role": "Core Logic",
          "purpose": "Caches file contents in memory to avoid redundant disk reads and improve performance when accessing the same files multiple times",
          "userVisibleActions": [
            "Faster file access when the same file is read multiple times",
            "Automatic updates when files change on disk",
            "Reduced disk activity and improved responsiveness"
          ],
          "developerVisibleActions": [
            "Request file content through the cache instead of direct file system access",
            "Files are automatically re-read when they change on disk",
            "Cache evicts least recently used files when memory limit is reached",
            "File changes are detected through file system watching",
            "Cache statistics track hits, misses, and evictions for monitoring"
          ],
          "keyFunctions": [
            {
              "name": "getFile",
              "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
              "inputs": "filePath (string) - path to the file to read",
              "outputs": "Promise<string> - the file content as text"
            },
            {
              "name": "setupWatcher",
              "desc": "Sets up file system monitoring to automatically invalidate cached files when they change",
              "inputs": "none",
              "outputs": "void - creates file watcher in background"
            },
            {
              "name": "isStale",
              "desc": "Checks if a cached file has exceeded its time-to-live and needs refreshing",
              "inputs": "cached file entry with timestamp",
              "outputs": "boolean - true if cache entry is expired"
            },
            {
              "name": "evictIfNeeded",
              "desc": "Removes least recently used files from cache when total size exceeds the configured limit",
              "inputs": "none",
              "outputs": "void - modifies cache by removing old entries"
            },
            {
              "name": "invalidate",
              "desc": "Removes a specific file or all files from the cache",
              "inputs": "optional filePath (string) - specific file to remove, or all if omitted",
              "outputs": "void - removes entries from cache"
            },
            {
              "name": "getStats",
              "desc": "Returns cache performance metrics including hits, misses, and current size",
              "inputs": "none",
              "outputs": "CacheStats object with performance counters"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path"
          ],
          "intent": "Eliminates redundant file system reads by caching file contents in memory, improving performance when multiple components need to access the same files repeatedly. Ensures cache stays synchronized with file system changes through automatic invalidation.",
          "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to avoid redundant disk reads and improve performance when accessing the same files multiple times\",\n  \"userVisibleActions\": [\n    \"Faster file access when the same file is read multiple times\",\n    \"Automatic updates when files change on disk\",\n    \"Reduced disk activity and improved responsiveness\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request file content through the cache instead of direct file system access\",\n    \"Files are automatically re-read when they change on disk\",\n    \"Cache evicts least recently used files when memory limit is reached\",\n    \"File changes are detected through file system watching\",\n    \"Cache statistics track hits, misses, and evictions for monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath (string) - path to the file to read\",\n      \"outputs\": \"Promise<string> - the file content as text\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Sets up file system monitoring to automatically invalidate cached files when they change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - creates file watcher in background\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Checks if a cached file has exceeded its time-to-live and needs refreshing\",\n      \"inputs\": \"cached file entry with timestamp\",\n      \"outputs\": \"boolean - true if cache entry is expired\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used files from cache when total size exceeds the configured limit\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - modifies cache by removing old entries\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file or all files from the cache\",\n      \"inputs\": \"optional filePath (string) - specific file to remove, or all if omitted\",\n      \"outputs\": \"void - removes entries from cache\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, and current size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object with performance counters\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"Eliminates redundant file system reads by caching file contents in memory, improving performance when multiple components need to access the same files repeatedly. Ensures cache stays synchronized with file system changes through automatic invalidation.\"\n}\n```"
        },
        {
          "file": "src/infrastructure/fileSystem/fileProcessor.ts",
          "role": "Core Logic",
          "purpose": "Consolidates and standardizes file processing logic across the codebase by providing reusable filtering, reading, and parallel processing capabilities.",
          "userVisibleActions": [
            "Files are automatically filtered to skip non-source directories (node_modules, .git, dist, build, etc.)",
            "Multiple files are processed in parallel for faster performance",
            "Files are read and processed with consistent error handling"
          ],
          "developerVisibleActions": [
            "Developer provides file paths and a processing function to handle file content",
            "Developer can customize file filtering by implementing IFileFilter interface",
            "Developer can customize file reading by implementing IFileReader interface",
            "Developer receives array of processed results from all files",
            "Developer can pass error context for better error tracking"
          ],
          "keyFunctions": [
            {
              "name": "shouldProcess",
              "desc": "Determines if a file should be processed based on filtering rules",
              "inputs": "filePath: string",
              "outputs": "boolean"
            },
            {
              "name": "readFile",
              "desc": "Reads file content from disk",
              "inputs": "filePath: string",
              "outputs": "Promise<string>"
            },
            {
              "name": "processFiles",
              "desc": "Processes multiple files in parallel with filtering and error handling",
              "inputs": "files: string[], processor: function, context?: ErrorContext",
              "outputs": "Promise<T[]>"
            }
          ],
          "dependencies": [
            "fs",
            "path",
            "ErrorHandler",
            "ErrorContext"
          ],
          "intent": "This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and processing by providing a single, reusable, and extensible file processing pipeline with built-in parallel processing and error handling.",
          "rawContent": "```json\n{\n  \"purpose\": \"Consolidates and standardizes file processing logic across the codebase by providing reusable filtering, reading, and parallel processing capabilities.\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip non-source directories (node_modules, .git, dist, build, etc.)\",\n    \"Multiple files are processed in parallel for faster performance\",\n    \"Files are read and processed with consistent error handling\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides file paths and a processing function to handle file content\",\n    \"Developer can customize file filtering by implementing IFileFilter interface\",\n    \"Developer can customize file reading by implementing IFileReader interface\",\n    \"Developer receives array of processed results from all files\",\n    \"Developer can pass error context for better error tracking\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on filtering rules\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads file content from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string>\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel with filtering and error handling\",\n      \"inputs\": \"files: string[], processor: function, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"ErrorHandler\",\n    \"ErrorContext\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and processing by providing a single, reusable, and extensible file processing pipeline with built-in parallel processing and error handling.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure/persistence",
      "moduleType": "other",
      "capabilities": [
        "Persist code analysis results to the local filesystem in a structured format",
        "Store product documentation generated from code analysis in timestamped directories",
        "Save architecture insights and patterns discovered during analysis",
        "Organize analysis outputs by run with unique identifiers for traceability",
        "Maintain file-level documentation with metadata for tracking analysis history",
        "Create summary files and overview documentation for each analysis session"
      ],
      "summary": "The persistence module provides the storage layer for all code analysis outputs, managing how documentation and insights are saved to the .shadow directory. It ensures that each analysis run is preserved with a unique identifier and timestamp, creating an organized historical record of all documentation generation activities.\n\nUsers benefit from automatic organization of their analysis results, with product documentation saved to .shadow/docs and architecture insights to .shadow/architecture. Each analysis session creates a complete snapshot including individual file documentation, summary overviews, and metadata, making it easy to track changes over time and reference previous analysis runs. The module handles all file system operations transparently, allowing users to focus on analyzing their code while documentation is reliably stored in a well-structured format.",
      "files": [
        {
          "file": "src/infrastructure/persistence/analysisResultRepository.ts",
          "role": "Core Logic",
          "purpose": "Manages storage and retrieval of code analysis results including product documentation, architecture insights, and summaries to the .shadow directory.",
          "userVisibleActions": [
            "Generated documentation files are saved to timestamped directories in .shadow/docs",
            "Architecture insights are saved to timestamped directories in .shadow/architecture",
            "Individual file documentation is stored with metadata for tracking",
            "Analysis results are organized by run with unique identifiers",
            "Summary files and overview documentation are created for each analysis run"
          ],
          "developerVisibleActions": [
            "Initialize documentation runs with timestamped directories",
            "Save enhanced product documentation for individual files",
            "Store architecture insights and summaries",
            "Retrieve current run directories for accessing results",
            "Create structured output with metadata tracking",
            "Generate formatted documentation in markdown",
            "Manage incremental storage for documentation updates"
          ],
          "keyFunctions": [
            {
              "name": "initializeProductDocsRun",
              "desc": "Creates a new timestamped directory for storing product documentation results",
              "inputs": "workspaceRoot (string)",
              "outputs": "runDir path (string)"
            },
            {
              "name": "initializeArchitectureInsightsRun",
              "desc": "Creates a new timestamped directory for storing architecture analysis results",
              "inputs": "workspaceRoot (string)",
              "outputs": "runDir path (string)"
            },
            {
              "name": "saveProductDocumentation",
              "desc": "Saves enhanced product documentation for a file to the current run directory",
              "inputs": "filePath (string), documentation (EnhancedProductDocumentation), workspaceRoot (string)",
              "outputs": "saved file path (string)"
            },
            {
              "name": "saveArchitectureInsights",
              "desc": "Saves architecture insights and analysis summaries to the current run directory",
              "inputs": "insights (LLMInsights), workspaceRoot (string), summary (optional string)",
              "outputs": "saved file paths object"
            },
            {
              "name": "getCurrentProductDocsRunDir",
              "desc": "Returns the directory path of the current product documentation run",
              "inputs": "none",
              "outputs": "runDir path (string) or null"
            },
            {
              "name": "getCurrentArchitectureInsightsRunDir",
              "desc": "Returns the directory path of the current architecture insights run",
              "inputs": "none",
              "outputs": "runDir path (string) or null"
            },
            {
              "name": "resetProductDocsRun",
              "desc": "Clears the current product documentation run context",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "resetArchitectureInsightsRun",
              "desc": "Clears the current architecture insights run context",
              "inputs": "none",
              "outputs": "void"
            },
            {
              "name": "saveSummary",
              "desc": "Saves a summary file to the specified run directory",
              "inputs": "runDir (string), summary (string)",
              "outputs": "saved file path (string)"
            }
          ],
          "dependencies": [
            "vscode",
            "fs",
            "path",
            "../../fileDocumentation",
            "../../llmService",
            "../../domain/formatters/documentationFormatter",
            "../../storage/incrementalStorage"
          ],
          "intent": "This file exists to separate persistence concerns from the LLM integration logic, providing a dedicated layer for storing and organizing analysis results in a structured, timestamped manner so that documentation and insights can be tracked across multiple analysis runs.",
          "rawContent": "```json\n{\n  \"purpose\": \"Manages storage and retrieval of code analysis results including product documentation, architecture insights, and summaries to the .shadow directory.\",\n  \"userVisibleActions\": [\n    \"Generated documentation files are saved to timestamped directories in .shadow/docs\",\n    \"Architecture insights are saved to timestamped directories in .shadow/architecture\",\n    \"Individual file documentation is stored with metadata for tracking\",\n    \"Analysis results are organized by run with unique identifiers\",\n    \"Summary files and overview documentation are created for each analysis run\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize documentation runs with timestamped directories\",\n    \"Save enhanced product documentation for individual files\",\n    \"Store architecture insights and summaries\",\n    \"Retrieve current run directories for accessing results\",\n    \"Create structured output with metadata tracking\",\n    \"Generate formatted documentation in markdown\",\n    \"Manage incremental storage for documentation updates\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"runDir path (string)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture analysis results\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"runDir path (string)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves enhanced product documentation for a file to the current run directory\",\n      \"inputs\": \"filePath (string), documentation (EnhancedProductDocumentation), workspaceRoot (string)\",\n      \"outputs\": \"saved file path (string)\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights and analysis summaries to the current run directory\",\n      \"inputs\": \"insights (LLMInsights), workspaceRoot (string), summary (optional string)\",\n      \"outputs\": \"saved file paths object\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Returns the directory path of the current product documentation run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path (string) or null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Returns the directory path of the current architecture insights run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path (string) or null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product documentation run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Saves a summary file to the specified run directory\",\n      \"inputs\": \"runDir (string), summary (string)\",\n      \"outputs\": \"saved file path (string)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../../fileDocumentation\",\n    \"../../llmService\",\n    \"../../domain/formatters/documentationFormatter\",\n    \"../../storage/incrementalStorage\"\n  ],\n  \"intent\": \"This file exists to separate persistence concerns from the LLM integration logic, providing a dedicated layer for storing and organizing analysis results in a structured, timestamped manner so that documentation and insights can be tracked across multiple analysis runs.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    },
    {
      "module": "src/infrastructure",
      "moduleType": "other",
      "capabilities": [
        "Display progress notifications for long-running operations with customizable titles and messages",
        "Show incremental progress updates as operations proceed through their tasks",
        "Allow users to cancel operations in progress when cancellation is supported",
        "Present progress indicators in various UI locations (notification area, window status, etc.)",
        "Provide standardized progress reporting across all application features"
      ],
      "summary": "This infrastructure module provides a centralized progress notification system that keeps users informed during long-running operations throughout the application. It standardizes how progress is displayed, ensuring a consistent experience whether users are processing files, running analyses, or executing other time-intensive tasks.\n\nUsers see progress notifications that include descriptive titles and messages explaining what's happening. As operations proceed, the progress indicator updates incrementally to show completion status. For operations that support cancellation, users can click a cancel button to stop the process early. The service flexibly displays progress in different UI locations depending on the context, such as the notification area for background tasks or the window status bar for focused operations.\n\nThis module serves as the foundation for all progress reporting in the application, ensuring that users always have visibility into what the application is doing and how long operations might take. It eliminates uncertainty during long tasks and gives users control over cancellable operations.",
      "files": [
        {
          "file": "src/infrastructure/progressService.ts",
          "role": "Core Logic",
          "purpose": "Provides a standardized service for displaying progress notifications with messages and cancellation support throughout the application.",
          "userVisibleActions": [
            "See progress notifications with titles and messages during long-running operations",
            "View incremental progress updates as operations proceed",
            "Cancel operations in progress using a cancel button (when cancellable)",
            "See progress indicators in different locations (notification area, window, etc.)"
          ],
          "developerVisibleActions": [
            "Wrap async tasks with progress reporting using a simple API",
            "Report progress messages and optional increment values during task execution",
            "Access cancellation tokens to respond to user cancellation requests",
            "Configure progress notification title, cancellability, and display location",
            "Use either a simple string title or full options object for flexibility"
          ],
          "keyFunctions": [
            {
              "name": "withProgress",
              "desc": "Executes an async task while displaying a progress notification to the user",
              "inputs": "options (title string or ProgressOptions object), task function that receives a ProgressReporter",
              "outputs": "Promise resolving to the task result"
            },
            {
              "name": "report",
              "desc": "Updates the progress notification with a new message and optional increment",
              "inputs": "message (string), increment (optional number)",
              "outputs": "void"
            }
          ],
          "dependencies": [
            "vscode"
          ],
          "intent": "Reduces boilerplate code and ensures consistent progress reporting UX across the entire codebase by wrapping VSCode's native progress API with a simpler, standardized interface.",
          "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications with messages and cancellation support throughout the application.\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during long-running operations\",\n    \"View incremental progress updates as operations proceed\",\n    \"Cancel operations in progress using a cancel button (when cancellable)\",\n    \"See progress indicators in different locations (notification area, window, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async tasks with progress reporting using a simple API\",\n    \"Report progress messages and optional increment values during task execution\",\n    \"Access cancellation tokens to respond to user cancellation requests\",\n    \"Configure progress notification title, cancellability, and display location\",\n    \"Use either a simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title string or ProgressOptions object), task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise resolving to the task result\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment\",\n      \"inputs\": \"message (string), increment (optional number)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Reduces boilerplate code and ensures consistent progress reporting UX across the entire codebase by wrapping VSCode's native progress API with a simpler, standardized interface.\"\n}\n```"
        }
      ],
      "endpoints": [],
      "commands": [],
      "workers": []
    }
  ],
  "fileSummaries": [
    {
      "file": "jest.config.js",
      "role": "Core Logic",
      "purpose": "Configures Jest testing framework for TypeScript test execution with coverage reporting and VS Code mocking support",
      "userVisibleActions": [
        "N/A - Configuration file with no direct user-facing actions"
      ],
      "developerVisibleActions": [
        "Runs TypeScript tests in Node.js environment when developer executes test commands",
        "Generates test coverage reports in text, lcov, and HTML formats in the 'coverage' directory",
        "Discovers and executes test files matching patterns like *.test.ts, *.spec.ts in __tests__ directories",
        "Provides code coverage metrics excluding test files, type definitions, and mock files",
        "Mocks VS Code API during test execution to enable testing without VS Code runtime",
        "Sets 10-second timeout for test execution to prevent hanging tests",
        "Transpiles TypeScript files to JavaScript using ts-jest with ES2020 target"
      ],
      "keyFunctions": [],
      "dependencies": [
        "ts-jest",
        "jest",
        "typescript"
      ],
      "intent": "This file exists to configure the Jest testing framework for a TypeScript-based VS Code extension project, enabling developers to write and run unit tests with proper TypeScript compilation, VS Code API mocking, and comprehensive code coverage reporting",
      "rawContent": "```json\n{\n  \"purpose\": \"Configures Jest testing framework for TypeScript test execution with coverage reporting and VS Code mocking support\",\n  \"userVisibleActions\": [\n    \"N/A - Configuration file with no direct user-facing actions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Runs TypeScript tests in Node.js environment when developer executes test commands\",\n    \"Generates test coverage reports in text, lcov, and HTML formats in the 'coverage' directory\",\n    \"Discovers and executes test files matching patterns like *.test.ts, *.spec.ts in __tests__ directories\",\n    \"Provides code coverage metrics excluding test files, type definitions, and mock files\",\n    \"Mocks VS Code API during test execution to enable testing without VS Code runtime\",\n    \"Sets 10-second timeout for test execution to prevent hanging tests\",\n    \"Transpiles TypeScript files to JavaScript using ts-jest with ES2020 target\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"ts-jest\",\n    \"jest\",\n    \"typescript\"\n  ],\n  \"intent\": \"This file exists to configure the Jest testing framework for a TypeScript-based VS Code extension project, enabling developers to write and run unit tests with proper TypeScript compilation, VS Code API mocking, and comprehensive code coverage reporting\"\n}\n```"
    },
    {
      "file": "src/ai/llmRateLimiter.ts",
      "role": "Core Logic",
      "purpose": "Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs",
      "userVisibleActions": [
        "Prevents application errors when too many AI requests are made in a short time",
        "Ensures smooth AI functionality by automatically managing request timing",
        "Avoids API quota exceeded errors during heavy AI usage"
      ],
      "developerVisibleActions": [
        "Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)",
        "Check if an AI request can proceed before making the API call",
        "Record each AI request to track usage against rate limits",
        "Get remaining request capacity for planning batched operations",
        "Automatically cleans up old request history outside the time window"
      ],
      "keyFunctions": [
        {
          "name": "canMakeRequest",
          "desc": "Checks if an AI request is allowed based on rate limits",
          "inputs": "provider ('openai' or 'claude')",
          "outputs": "boolean - true if request can proceed, false if limit reached"
        },
        {
          "name": "recordRequest",
          "desc": "Records that an AI request was made to track against limits",
          "inputs": "provider ('openai' or 'claude')",
          "outputs": "void - updates internal tracking"
        },
        {
          "name": "configure",
          "desc": "Sets custom rate limits for an AI provider",
          "inputs": "provider ('openai' or 'claude'), config (maxRequests and windowMs)",
          "outputs": "void - updates provider configuration"
        }
      ],
      "dependencies": [],
      "intent": "Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas",
      "rawContent": "```json\n{\n  \"purpose\": \"Prevents AI API rate limit errors by tracking and controlling the frequency of requests to OpenAI and Claude APIs\",\n  \"userVisibleActions\": [\n    \"Prevents application errors when too many AI requests are made in a short time\",\n    \"Ensures smooth AI functionality by automatically managing request timing\",\n    \"Avoids API quota exceeded errors during heavy AI usage\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configure custom rate limits for OpenAI (default: 60 requests/minute) and Claude (default: 50 requests/minute)\",\n    \"Check if an AI request can proceed before making the API call\",\n    \"Record each AI request to track usage against rate limits\",\n    \"Get remaining request capacity for planning batched operations\",\n    \"Automatically cleans up old request history outside the time window\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"canMakeRequest\",\n      \"desc\": \"Checks if an AI request is allowed based on rate limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"boolean - true if request can proceed, false if limit reached\"\n    },\n    {\n      \"name\": \"recordRequest\",\n      \"desc\": \"Records that an AI request was made to track against limits\",\n      \"inputs\": \"provider ('openai' or 'claude')\",\n      \"outputs\": \"void - updates internal tracking\"\n    },\n    {\n      \"name\": \"configure\",\n      \"desc\": \"Sets custom rate limits for an AI provider\",\n      \"inputs\": \"provider ('openai' or 'claude'), config (maxRequests and windowMs)\",\n      \"outputs\": \"void - updates provider configuration\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Protects the application from hitting API rate limits that would cause failures, by implementing a sliding window algorithm that tracks request timestamps per AI provider and enforces configurable request quotas\"\n}\n```"
    },
    {
      "file": "src/ai/llmResponseParser.ts",
      "role": "Core Logic",
      "purpose": "Extracts structured data from LLM text responses and converts them into typed objects for file summaries, module summaries, and product documentation.",
      "userVisibleActions": [
        "Receives parsed insights about code files including their purpose and key functions",
        "Gets product-level documentation with clear explanations of what the codebase does",
        "Views structured information about user-facing actions and developer-facing actions extracted from AI responses"
      ],
      "developerVisibleActions": [
        "Parses LLM JSON or text responses into FileSummary objects with file metadata",
        "Converts LLM responses into ModuleSummary objects with module-level insights",
        "Transforms LLM output into EnhancedProductDocumentation with product purpose and architecture",
        "Extracts ProductPurposeAnalysis from LLM responses for high-level product understanding",
        "Falls back to text parsing when JSON parsing fails",
        "Handles malformed LLM responses gracefully with default values"
      ],
      "keyFunctions": [
        {
          "name": "parseFileSummary",
          "desc": "Converts LLM response text into a FileSummary object containing purpose, actions, and dependencies",
          "inputs": "content (string), filePath (string), role (string)",
          "outputs": "FileSummary object"
        },
        {
          "name": "extractSection",
          "desc": "Extracts a named section from text response",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Extracted text string"
        },
        {
          "name": "extractListSection",
          "desc": "Extracts a list/array section from text response",
          "inputs": "content (string), sectionName (string)",
          "outputs": "Array of strings"
        }
      ],
      "dependencies": [
        "../fileDocumentation",
        "../llmService"
      ],
      "intent": "This file exists to bridge the gap between raw LLM text responses and the typed data structures needed by the application. It solves the problem of handling unpredictable LLM output formats (JSON or text) and ensuring the application always receives valid structured data, even when the LLM response is malformed or incomplete.",
      "rawContent": "```json\n{\n  \"purpose\": \"Extracts structured data from LLM text responses and converts them into typed objects for file summaries, module summaries, and product documentation.\",\n  \"userVisibleActions\": [\n    \"Receives parsed insights about code files including their purpose and key functions\",\n    \"Gets product-level documentation with clear explanations of what the codebase does\",\n    \"Views structured information about user-facing actions and developer-facing actions extracted from AI responses\"\n  ],\n  \"developerVisibleActions\": [\n    \"Parses LLM JSON or text responses into FileSummary objects with file metadata\",\n    \"Converts LLM responses into ModuleSummary objects with module-level insights\",\n    \"Transforms LLM output into EnhancedProductDocumentation with product purpose and architecture\",\n    \"Extracts ProductPurposeAnalysis from LLM responses for high-level product understanding\",\n    \"Falls back to text parsing when JSON parsing fails\",\n    \"Handles malformed LLM responses gracefully with default values\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"parseFileSummary\",\n      \"desc\": \"Converts LLM response text into a FileSummary object containing purpose, actions, and dependencies\",\n      \"inputs\": \"content (string), filePath (string), role (string)\",\n      \"outputs\": \"FileSummary object\"\n    },\n    {\n      \"name\": \"extractSection\",\n      \"desc\": \"Extracts a named section from text response\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Extracted text string\"\n    },\n    {\n      \"name\": \"extractListSection\",\n      \"desc\": \"Extracts a list/array section from text response\",\n      \"inputs\": \"content (string), sectionName (string)\",\n      \"outputs\": \"Array of strings\"\n    }\n  ],\n  \"dependencies\": [\n    \"../fileDocumentation\",\n    \"../llmService\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between raw LLM text responses and the typed data structures needed by the application. It solves the problem of handling unpredictable LLM output formats (JSON or text) and ensuring the application always receives valid structured data, even when the LLM response is malformed or incomplete.\"\n}\n```"
    },
    {
      "file": "src/ai/llmRetryHandler.ts",
      "role": "Core Logic",
      "purpose": "Provides automatic retry logic with exponential backoff for LLM API requests that fail due to transient errors like rate limits or network issues.",
      "userVisibleActions": [
        "Automatic retry of failed AI requests without manual intervention",
        "Seamless recovery from temporary API failures (rate limits, timeouts, network errors)",
        "Delayed retries that gradually increase wait time between attempts",
        "Eventual success or clear failure after exhausting retry attempts"
      ],
      "developerVisibleActions": [
        "Wrap LLM API calls with automatic retry handling using RetryHandler.executeWithRetry()",
        "Configure retry behavior (max attempts, delays, backoff multiplier)",
        "Specify which error types should trigger retries via retryableErrors option",
        "Receive retry attempt notifications through optional onRetry callback",
        "Get results with attempt count metadata via RetryResult interface",
        "Distinguish between retryable errors (rate limits, timeouts) and non-retryable errors (authentication, invalid requests)",
        "Customize initial delay, max delay, and exponential backoff multiplier"
      ],
      "keyFunctions": [
        {
          "name": "executeWithRetry",
          "desc": "Executes an async operation with automatic retry logic, exponential backoff, and error classification",
          "inputs": "operation (async function returning Promise<T>), options (RetryOptions with maxRetries, delays, retryableErrors, onRetry callback)",
          "outputs": "Promise<T> containing the operation result, or throws error if all retries exhausted"
        },
        {
          "name": "isRetryableError",
          "desc": "Determines if an error should trigger a retry based on error message/code matching",
          "inputs": "error object, array of retryable error patterns",
          "outputs": "boolean indicating if error is retryable"
        }
      ],
      "dependencies": [],
      "intent": "Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, network issues, temporary server errors) without requiring manual retry logic throughout the codebase. Prevents users from experiencing failures due to temporary API issues and reduces the need for developers to implement retry logic in every API call.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides automatic retry logic with exponential backoff for LLM API requests that fail due to transient errors like rate limits or network issues.\",\n  \"userVisibleActions\": [\n    \"Automatic retry of failed AI requests without manual intervention\",\n    \"Seamless recovery from temporary API failures (rate limits, timeouts, network errors)\",\n    \"Delayed retries that gradually increase wait time between attempts\",\n    \"Eventual success or clear failure after exhausting retry attempts\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap LLM API calls with automatic retry handling using RetryHandler.executeWithRetry()\",\n    \"Configure retry behavior (max attempts, delays, backoff multiplier)\",\n    \"Specify which error types should trigger retries via retryableErrors option\",\n    \"Receive retry attempt notifications through optional onRetry callback\",\n    \"Get results with attempt count metadata via RetryResult interface\",\n    \"Distinguish between retryable errors (rate limits, timeouts) and non-retryable errors (authentication, invalid requests)\",\n    \"Customize initial delay, max delay, and exponential backoff multiplier\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"executeWithRetry\",\n      \"desc\": \"Executes an async operation with automatic retry logic, exponential backoff, and error classification\",\n      \"inputs\": \"operation (async function returning Promise<T>), options (RetryOptions with maxRetries, delays, retryableErrors, onRetry callback)\",\n      \"outputs\": \"Promise<T> containing the operation result, or throws error if all retries exhausted\"\n    },\n    {\n      \"name\": \"isRetryableError\",\n      \"desc\": \"Determines if an error should trigger a retry based on error message/code matching\",\n      \"inputs\": \"error object, array of retryable error patterns\",\n      \"outputs\": \"boolean indicating if error is retryable\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Improves reliability and user experience when interacting with LLM APIs by automatically handling transient failures (rate limits, network issues, temporary server errors) without requiring manual retry logic throughout the codebase. Prevents users from experiencing failures due to temporary API issues and reduces the need for developers to implement retry logic in every API call.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/ILLMProvider.ts",
      "role": "Core Logic",
      "purpose": "Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way",
      "userVisibleActions": [
        "User receives AI-generated text responses to their queries",
        "User receives structured JSON responses when requesting formatted data",
        "User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured"
      ],
      "developerVisibleActions": [
        "Developer implements this interface to add new AI provider support",
        "Developer calls sendRequest() to get text responses from any LLM provider",
        "Developer calls sendStructuredRequest() to get parsed JSON data from LLM",
        "Developer checks isConfigured() to verify provider is ready before making requests",
        "Developer configures conversation messages with role-based structure (system, user, assistant)",
        "Developer controls response parameters like temperature, max tokens, and response format"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if the provider has valid credentials and is ready to use",
          "inputs": "None",
          "outputs": "Boolean indicating if provider is configured"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt to the LLM and returns text response",
          "inputs": "LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)",
          "outputs": "Promise<LLMResponse> with content, finish reason, model name, and raw response"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests",
          "inputs": "LLMRequestOptions and optional JSON schema",
          "outputs": "Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests"
        },
        {
          "name": "getName",
          "desc": "Returns the provider's display name",
          "inputs": "None",
          "outputs": "String provider name (e.g., 'OpenAI', 'Claude')"
        }
      ],
      "dependencies": [],
      "intent": "This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines the contract for AI language model providers (OpenAI, Claude, etc.) to enable communication with different LLM services in a unified way\",\n  \"userVisibleActions\": [\n    \"User receives AI-generated text responses to their queries\",\n    \"User receives structured JSON responses when requesting formatted data\",\n    \"User experiences consistent AI behavior regardless of which provider (OpenAI, Claude, etc.) is configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer implements this interface to add new AI provider support\",\n    \"Developer calls sendRequest() to get text responses from any LLM provider\",\n    \"Developer calls sendStructuredRequest() to get parsed JSON data from LLM\",\n    \"Developer checks isConfigured() to verify provider is ready before making requests\",\n    \"Developer configures conversation messages with role-based structure (system, user, assistant)\",\n    \"Developer controls response parameters like temperature, max tokens, and response format\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if the provider has valid credentials and is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns text response\",\n      \"inputs\": \"LLMRequestOptions (model, messages, temperature, maxTokens, responseFormat)\",\n      \"outputs\": \"Promise<LLMResponse> with content, finish reason, model name, and raw response\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a prompt to the LLM and returns parsed JSON data with optional follow-up requests\",\n      \"inputs\": \"LLMRequestOptions and optional JSON schema\",\n      \"outputs\": \"Promise<StructuredOutputResponse<T>> with typed data and optional file/grep requests\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider's display name\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String provider name (e.g., 'OpenAI', 'Claude')\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"This interface exists to abstract away differences between AI providers (OpenAI, Claude, custom models), allowing the application to switch providers without changing calling code. It solves the problem of vendor lock-in and enables consistent AI interactions regardless of the underlying service.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/anthropicProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides integration with Anthropic's Claude AI models for natural language processing and code analysis tasks",
      "userVisibleActions": [
        "Sends prompts to Claude AI and receives AI-generated responses",
        "Generates structured data (JSON) from Claude's responses for code analysis",
        "Processes conversations with Claude while maintaining message history",
        "Receives error messages when Claude API key is not configured"
      ],
      "developerVisibleActions": [
        "Initialize Claude API client with API key from configuration",
        "Send requests to Claude with custom models, system prompts, and message history",
        "Extract structured JSON data from Claude's text responses",
        "Check if Claude provider is properly configured before use",
        "Handle message format conversion between OpenAI-style and Claude-style formats",
        "Configure request timeouts and token limits for Claude API calls"
      ],
      "keyFunctions": [
        {
          "name": "isConfigured",
          "desc": "Checks if Claude API key is set up and ready to use",
          "inputs": "none",
          "outputs": "boolean indicating if provider is configured"
        },
        {
          "name": "getName",
          "desc": "Returns the provider identifier",
          "inputs": "none",
          "outputs": "string 'claude'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a prompt with conversation history to Claude and returns the response",
          "inputs": "LLMRequestOptions (messages, model, systemPrompt, maxTokens)",
          "outputs": "LLMResponse with text content and token usage"
        },
        {
          "name": "sendStructuredRequest",
          "desc": "Sends a request to Claude and extracts JSON data from the response",
          "inputs": "LLMRequestOptions with expected JSON structure",
          "outputs": "StructuredOutputResponse with parsed JSON data"
        },
        {
          "name": "initialize",
          "desc": "Sets up the Claude API client with credentials from configuration",
          "inputs": "none (reads from config manager)",
          "outputs": "void (initializes client)"
        }
      ],
      "dependencies": [
        "@anthropic-ai/sdk",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to abstract Claude AI integration so developers can interact with Anthropic's language models using a consistent interface. It solves the problem of converting between different AI provider formats and handling Claude-specific API requirements, making it easy to switch between AI providers without changing application code.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides integration with Anthropic's Claude AI models for natural language processing and code analysis tasks\",\n  \"userVisibleActions\": [\n    \"Sends prompts to Claude AI and receives AI-generated responses\",\n    \"Generates structured data (JSON) from Claude's responses for code analysis\",\n    \"Processes conversations with Claude while maintaining message history\",\n    \"Receives error messages when Claude API key is not configured\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize Claude API client with API key from configuration\",\n    \"Send requests to Claude with custom models, system prompts, and message history\",\n    \"Extract structured JSON data from Claude's text responses\",\n    \"Check if Claude provider is properly configured before use\",\n    \"Handle message format conversion between OpenAI-style and Claude-style formats\",\n    \"Configure request timeouts and token limits for Claude API calls\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if Claude API key is set up and ready to use\",\n      \"inputs\": \"none\",\n      \"outputs\": \"boolean indicating if provider is configured\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns the provider identifier\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string 'claude'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a prompt with conversation history to Claude and returns the response\",\n      \"inputs\": \"LLMRequestOptions (messages, model, systemPrompt, maxTokens)\",\n      \"outputs\": \"LLMResponse with text content and token usage\"\n    },\n    {\n      \"name\": \"sendStructuredRequest\",\n      \"desc\": \"Sends a request to Claude and extracts JSON data from the response\",\n      \"inputs\": \"LLMRequestOptions with expected JSON structure\",\n      \"outputs\": \"StructuredOutputResponse with parsed JSON data\"\n    },\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up the Claude API client with credentials from configuration\",\n      \"inputs\": \"none (reads from config manager)\",\n      \"outputs\": \"void (initializes client)\"\n    }\n  ],\n  \"dependencies\": [\n    \"@anthropic-ai/sdk\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract Claude AI integration so developers can interact with Anthropic's language models using a consistent interface. It solves the problem of converting between different AI provider formats and handling Claude-specific API requirements, making it easy to switch between AI providers without changing application code.\"\n}\n```"
    },
    {
      "file": "src/ai/providers/openAIProvider.ts",
      "role": "Core Logic",
      "purpose": "Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses",
      "userVisibleActions": [
        "Sends user messages to OpenAI's GPT models and receives AI-generated responses",
        "Supports both regular text responses and structured JSON responses from the AI",
        "Handles streaming responses where AI text appears progressively",
        "Automatically validates and extracts JSON from AI responses when structured output is requested"
      ],
      "developerVisibleActions": [
        "Configures OpenAI API connection using API key from configuration manager",
        "Provides synchronous check if OpenAI is properly configured via isConfigured()",
        "Sends chat completion requests with customizable model, messages, and response format",
        "Returns structured responses with content, finish reason, and token usage statistics",
        "Streams chat completions with real-time content chunks via async iteration",
        "Extracts and validates JSON from AI responses for structured output requests",
        "Sets 5-minute timeout for all OpenAI API requests",
        "Throws errors when API key is not configured"
      ],
      "keyFunctions": [
        {
          "name": "initialize",
          "desc": "Sets up OpenAI client with API key from configuration",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "isConfigured",
          "desc": "Checks if OpenAI provider is ready to use",
          "inputs": "None",
          "outputs": "boolean indicating if API key is set"
        },
        {
          "name": "getName",
          "desc": "Returns provider identifier",
          "inputs": "None",
          "outputs": "String 'openai'"
        },
        {
          "name": "sendRequest",
          "desc": "Sends a chat completion request to OpenAI and returns the response",
          "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
          "outputs": "Promise<LLMResponse> with content, finishReason, and usage stats"
        },
        {
          "name": "streamRequest",
          "desc": "Streams a chat completion request with progressive content delivery",
          "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
          "outputs": "AsyncIterable<string> yielding content chunks as they arrive"
        },
        {
          "name": "sendStructuredOutputRequest",
          "desc": "Sends request expecting JSON response and validates the output",
          "inputs": "LLMRequestOptions with model, messages, systemPrompt, responseFormat",
          "outputs": "Promise<StructuredOutputResponse> with parsed JSON data or validation errors"
        }
      ],
      "dependencies": [
        "openai",
        "../../config/configurationManager",
        "../../utils/jsonExtractor",
        "./ILLMProvider"
      ],
      "intent": "This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides OpenAI API integration for sending chat completion requests and receiving AI-generated responses\",\n  \"userVisibleActions\": [\n    \"Sends user messages to OpenAI's GPT models and receives AI-generated responses\",\n    \"Supports both regular text responses and structured JSON responses from the AI\",\n    \"Handles streaming responses where AI text appears progressively\",\n    \"Automatically validates and extracts JSON from AI responses when structured output is requested\"\n  ],\n  \"developerVisibleActions\": [\n    \"Configures OpenAI API connection using API key from configuration manager\",\n    \"Provides synchronous check if OpenAI is properly configured via isConfigured()\",\n    \"Sends chat completion requests with customizable model, messages, and response format\",\n    \"Returns structured responses with content, finish reason, and token usage statistics\",\n    \"Streams chat completions with real-time content chunks via async iteration\",\n    \"Extracts and validates JSON from AI responses for structured output requests\",\n    \"Sets 5-minute timeout for all OpenAI API requests\",\n    \"Throws errors when API key is not configured\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initialize\",\n      \"desc\": \"Sets up OpenAI client with API key from configuration\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"isConfigured\",\n      \"desc\": \"Checks if OpenAI provider is ready to use\",\n      \"inputs\": \"None\",\n      \"outputs\": \"boolean indicating if API key is set\"\n    },\n    {\n      \"name\": \"getName\",\n      \"desc\": \"Returns provider identifier\",\n      \"inputs\": \"None\",\n      \"outputs\": \"String 'openai'\"\n    },\n    {\n      \"name\": \"sendRequest\",\n      \"desc\": \"Sends a chat completion request to OpenAI and returns the response\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<LLMResponse> with content, finishReason, and usage stats\"\n    },\n    {\n      \"name\": \"streamRequest\",\n      \"desc\": \"Streams a chat completion request with progressive content delivery\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"AsyncIterable<string> yielding content chunks as they arrive\"\n    },\n    {\n      \"name\": \"sendStructuredOutputRequest\",\n      \"desc\": \"Sends request expecting JSON response and validates the output\",\n      \"inputs\": \"LLMRequestOptions with model, messages, systemPrompt, responseFormat\",\n      \"outputs\": \"Promise<StructuredOutputResponse> with parsed JSON data or validation errors\"\n    }\n  ],\n  \"dependencies\": [\n    \"openai\",\n    \"../../config/configurationManager\",\n    \"../../utils/jsonExtractor\",\n    \"./ILLMProvider\"\n  ],\n  \"intent\": \"This file exists to abstract OpenAI's API into a standardized provider interface, allowing the application to send AI requests, receive responses (both streaming and non-streaming), and handle structured JSON outputs while managing API configuration and error handling centrally\"\n}\n```"
    },
    {
      "file": "src/ai/providers/providerFactory.ts",
      "role": "Core Logic",
      "purpose": "Factory that creates and manages AI provider instances (OpenAI or Claude) based on configuration settings",
      "userVisibleActions": [
        "Switches between different AI providers (OpenAI or Claude) for generating responses",
        "Ensures only configured AI providers are available for use",
        "Maintains consistent AI provider throughout the session unless configuration changes"
      ],
      "developerVisibleActions": [
        "Provides a centralized way to obtain AI provider instances without creating duplicates",
        "Returns the currently configured AI provider based on user settings",
        "Validates which AI providers have valid API keys and configuration",
        "Lists all AI providers that are properly configured and ready to use",
        "Maintains singleton instances of each provider to avoid redundant initialization"
      ],
      "keyFunctions": [
        {
          "name": "getProvider",
          "desc": "Returns the AI provider instance for a specific provider type (openai or claude)",
          "inputs": "provider: LLMProvider (either 'openai' or 'claude')",
          "outputs": "ILLMProvider instance"
        },
        {
          "name": "getCurrentProvider",
          "desc": "Returns the AI provider that is currently set in user configuration",
          "inputs": "none",
          "outputs": "ILLMProvider instance of the configured provider"
        },
        {
          "name": "isProviderConfigured",
          "desc": "Checks if a specific AI provider has valid configuration and API keys",
          "inputs": "provider: LLMProvider (either 'openai' or 'claude')",
          "outputs": "boolean indicating if provider is ready to use"
        },
        {
          "name": "getConfiguredProviders",
          "desc": "Returns a list of all AI providers that are properly configured",
          "inputs": "none",
          "outputs": "Array of LLMProvider types that are configured"
        }
      ],
      "dependencies": [
        "./ILLMProvider",
        "./openAIProvider",
        "./anthropicProvider",
        "../../config/configurationManager"
      ],
      "intent": "Provides a centralized factory pattern for creating and managing AI provider instances, ensuring proper initialization, configuration validation, and singleton behavior to avoid duplicate provider instances while supporting multiple AI backends.",
      "rawContent": "```json\n{\n  \"purpose\": \"Factory that creates and manages AI provider instances (OpenAI or Claude) based on configuration settings\",\n  \"userVisibleActions\": [\n    \"Switches between different AI providers (OpenAI or Claude) for generating responses\",\n    \"Ensures only configured AI providers are available for use\",\n    \"Maintains consistent AI provider throughout the session unless configuration changes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides a centralized way to obtain AI provider instances without creating duplicates\",\n    \"Returns the currently configured AI provider based on user settings\",\n    \"Validates which AI providers have valid API keys and configuration\",\n    \"Lists all AI providers that are properly configured and ready to use\",\n    \"Maintains singleton instances of each provider to avoid redundant initialization\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getProvider\",\n      \"desc\": \"Returns the AI provider instance for a specific provider type (openai or claude)\",\n      \"inputs\": \"provider: LLMProvider (either 'openai' or 'claude')\",\n      \"outputs\": \"ILLMProvider instance\"\n    },\n    {\n      \"name\": \"getCurrentProvider\",\n      \"desc\": \"Returns the AI provider that is currently set in user configuration\",\n      \"inputs\": \"none\",\n      \"outputs\": \"ILLMProvider instance of the configured provider\"\n    },\n    {\n      \"name\": \"isProviderConfigured\",\n      \"desc\": \"Checks if a specific AI provider has valid configuration and API keys\",\n      \"inputs\": \"provider: LLMProvider (either 'openai' or 'claude')\",\n      \"outputs\": \"boolean indicating if provider is ready to use\"\n    },\n    {\n      \"name\": \"getConfiguredProviders\",\n      \"desc\": \"Returns a list of all AI providers that are properly configured\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Array of LLMProvider types that are configured\"\n    }\n  ],\n  \"dependencies\": [\n    \"./ILLMProvider\",\n    \"./openAIProvider\",\n    \"./anthropicProvider\",\n    \"../../config/configurationManager\"\n  ],\n  \"intent\": \"Provides a centralized factory pattern for creating and managing AI provider instances, ensuring proper initialization, configuration validation, and singleton behavior to avoid duplicate provider instances while supporting multiple AI backends.\"\n}\n```"
    },
    {
      "file": "src/analysis/enhancedAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Provides deep code analysis capabilities by parsing TypeScript/JavaScript files using AST to extract function metadata, dependencies, branches, and behavioral patterns.",
      "userVisibleActions": [
        "Receives detailed analysis of code functions including complexity metrics",
        "Gets insights about code dependencies and how functions relate to each other",
        "Views behavioral hints about what functions do (queries, mutations, validations)",
        "Sees branch coverage information showing different code paths",
        "Understands state mutations and side effects in functions"
      ],
      "developerVisibleActions": [
        "Calls analyzeFileMetadata() to extract comprehensive metadata from a code file",
        "Receives FunctionMetadata objects containing branches, dependencies, and behavioral hints",
        "Gets AST-based analysis for TypeScript/JavaScript files with deep introspection",
        "Falls back to regex-based analysis for non-TypeScript languages",
        "Obtains branch information showing conditional paths and complexity",
        "Retrieves dependency information showing function calls and imports",
        "Accesses state mutation tracking for variables and properties",
        "Uses test mapping to understand test coverage relationships"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFileMetadata",
          "desc": "Analyzes a code file and extracts enhanced metadata for all functions in it",
          "inputs": "filePath (string), content (string), language (string), functions (FunctionInfo[])",
          "outputs": "Map<string, FunctionMetadata> containing detailed analysis for each function"
        },
        {
          "name": "analyzeTypeScriptFunction",
          "desc": "Performs AST-based analysis of TypeScript/JavaScript functions to extract detailed metadata",
          "inputs": "filePath (string), content (string), func (FunctionInfo), functionContent (string)",
          "outputs": "FunctionMetadata with branches, dependencies, mutations, and behavioral hints"
        },
        {
          "name": "analyzeFunctionWithRegex",
          "desc": "Provides fallback regex-based analysis for non-TypeScript languages",
          "inputs": "filePath (string), func (FunctionInfo), functionContent (string), language (string)",
          "outputs": "FunctionMetadata with basic pattern-matched analysis"
        },
        {
          "name": "extractFunctionContent",
          "desc": "Extracts the source code content of a function between specified line numbers",
          "inputs": "content (string), startLine (number), endLine (number)",
          "outputs": "String containing the function's source code"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer"
      ],
      "intent": "This file exists to provide advanced code analysis beyond basic pattern matching by leveraging TypeScript's compiler API to deeply understand code structure, identify branches, track dependencies, detect behavioral patterns, and extract comprehensive metadata that enables intelligent code understanding and test generation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides deep code analysis capabilities by parsing TypeScript/JavaScript files using AST to extract function metadata, dependencies, branches, and behavioral patterns.\",\n  \"userVisibleActions\": [\n    \"Receives detailed analysis of code functions including complexity metrics\",\n    \"Gets insights about code dependencies and how functions relate to each other\",\n    \"Views behavioral hints about what functions do (queries, mutations, validations)\",\n    \"Sees branch coverage information showing different code paths\",\n    \"Understands state mutations and side effects in functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFileMetadata() to extract comprehensive metadata from a code file\",\n    \"Receives FunctionMetadata objects containing branches, dependencies, and behavioral hints\",\n    \"Gets AST-based analysis for TypeScript/JavaScript files with deep introspection\",\n    \"Falls back to regex-based analysis for non-TypeScript languages\",\n    \"Obtains branch information showing conditional paths and complexity\",\n    \"Retrieves dependency information showing function calls and imports\",\n    \"Accesses state mutation tracking for variables and properties\",\n    \"Uses test mapping to understand test coverage relationships\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFileMetadata\",\n      \"desc\": \"Analyzes a code file and extracts enhanced metadata for all functions in it\",\n      \"inputs\": \"filePath (string), content (string), language (string), functions (FunctionInfo[])\",\n      \"outputs\": \"Map<string, FunctionMetadata> containing detailed analysis for each function\"\n    },\n    {\n      \"name\": \"analyzeTypeScriptFunction\",\n      \"desc\": \"Performs AST-based analysis of TypeScript/JavaScript functions to extract detailed metadata\",\n      \"inputs\": \"filePath (string), content (string), func (FunctionInfo), functionContent (string)\",\n      \"outputs\": \"FunctionMetadata with branches, dependencies, mutations, and behavioral hints\"\n    },\n    {\n      \"name\": \"analyzeFunctionWithRegex\",\n      \"desc\": \"Provides fallback regex-based analysis for non-TypeScript languages\",\n      \"inputs\": \"filePath (string), func (FunctionInfo), functionContent (string), language (string)\",\n      \"outputs\": \"FunctionMetadata with basic pattern-matched analysis\"\n    },\n    {\n      \"name\": \"extractFunctionContent\",\n      \"desc\": \"Extracts the source code content of a function between specified line numbers\",\n      \"inputs\": \"content (string), startLine (number), endLine (number)\",\n      \"outputs\": \"String containing the function's source code\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\"\n  ],\n  \"intent\": \"This file exists to provide advanced code analysis beyond basic pattern matching by leveraging TypeScript's compiler API to deeply understand code structure, identify branches, track dependencies, detect behavioral patterns, and extract comprehensive metadata that enables intelligent code understanding and test generation.\"\n}\n```"
    },
    {
      "file": "src/analysis/functionAnalyzer.ts",
      "role": "Core Logic",
      "purpose": "Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and relationships for refactoring recommendations",
      "userVisibleActions": [
        "Identifies functions in large files that may need refactoring",
        "Provides detailed function analysis reports showing what each function does",
        "Shows which functions depend on each other",
        "Highlights functions that exceed complexity or size thresholds"
      ],
      "developerVisibleActions": [
        "Analyzes all functions in files exceeding a configurable line threshold (default 500 lines)",
        "Extracts function signatures including parameters and return types",
        "Maps function dependencies showing which functions call which",
        "Maps function dependents showing where each function is used",
        "Identifies function responsibilities and behavior patterns",
        "Returns structured FunctionAnalysis objects containing all extracted metadata",
        "Handles analysis failures gracefully with warnings",
        "Resolves file paths across different project structures"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Analyzes all functions in files that exceed the size threshold and returns detailed analysis for each",
          "inputs": "CodeAnalysis object, optional largeFileThreshold (default 500)",
          "outputs": "Array of FunctionAnalysis objects containing function metadata"
        },
        {
          "name": "analyzeFunction",
          "desc": "Performs detailed analysis of a single function extracting its signature, dependencies, and relationships",
          "inputs": "File path, FunctionInfo object, CodeAnalysis context",
          "outputs": "FunctionAnalysis object or null if analysis fails"
        },
        {
          "name": "resolveFilePath",
          "desc": "Resolves relative file paths to absolute paths in the project structure",
          "inputs": "Relative file path, CodeAnalysis context",
          "outputs": "Absolute file path string"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "typescript",
        "../analyzer",
        "../domain/prompts/refactoringPromptBuilder"
      ],
      "intent": "This file exists to provide deep analysis of functions in large code files, extracting comprehensive metadata needed to generate intelligent refactoring recommendations. It solves the problem of understanding complex function relationships and dependencies when suggesting how to break down large files into smaller, more maintainable modules.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes functions in large code files to extract detailed metadata including signatures, dependencies, and relationships for refactoring recommendations\",\n  \"userVisibleActions\": [\n    \"Identifies functions in large files that may need refactoring\",\n    \"Provides detailed function analysis reports showing what each function does\",\n    \"Shows which functions depend on each other\",\n    \"Highlights functions that exceed complexity or size thresholds\"\n  ],\n  \"developerVisibleActions\": [\n    \"Analyzes all functions in files exceeding a configurable line threshold (default 500 lines)\",\n    \"Extracts function signatures including parameters and return types\",\n    \"Maps function dependencies showing which functions call which\",\n    \"Maps function dependents showing where each function is used\",\n    \"Identifies function responsibilities and behavior patterns\",\n    \"Returns structured FunctionAnalysis objects containing all extracted metadata\",\n    \"Handles analysis failures gracefully with warnings\",\n    \"Resolves file paths across different project structures\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Analyzes all functions in files that exceed the size threshold and returns detailed analysis for each\",\n      \"inputs\": \"CodeAnalysis object, optional largeFileThreshold (default 500)\",\n      \"outputs\": \"Array of FunctionAnalysis objects containing function metadata\"\n    },\n    {\n      \"name\": \"analyzeFunction\",\n      \"desc\": \"Performs detailed analysis of a single function extracting its signature, dependencies, and relationships\",\n      \"inputs\": \"File path, FunctionInfo object, CodeAnalysis context\",\n      \"outputs\": \"FunctionAnalysis object or null if analysis fails\"\n    },\n    {\n      \"name\": \"resolveFilePath\",\n      \"desc\": \"Resolves relative file paths to absolute paths in the project structure\",\n      \"inputs\": \"Relative file path, CodeAnalysis context\",\n      \"outputs\": \"Absolute file path string\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"typescript\",\n    \"../analyzer\",\n    \"../domain/prompts/refactoringPromptBuilder\"\n  ],\n  \"intent\": \"This file exists to provide deep analysis of functions in large code files, extracting comprehensive metadata needed to generate intelligent refactoring recommendations. It solves the problem of understanding complex function relationships and dependencies when suggesting how to break down large files into smaller, more maintainable modules.\"\n}\n```"
    },
    {
      "file": "src/analysisViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view panel in VSCode that displays code analysis results in an organized, browsable hierarchy.",
      "userVisibleActions": [
        "View a tree-structured panel showing code analysis results organized by categories",
        "Browse statistics about analyzed code (file counts, function counts, line counts)",
        "Explore files and directories in the analyzed codebase",
        "See detailed information about individual files (lines, functions, imports, exports)",
        "View function details (name, parameters, return type, line numbers)",
        "Browse entry points (main functions, exports, classes) discovered in the code",
        "Click on items to navigate to specific locations in source files",
        "See contextual descriptions for each tree item",
        "View 'No analysis available' message when no analysis has been run",
        "Refresh the view to see updated analysis results"
      ],
      "developerVisibleActions": [
        "Tree view automatically updates when setAnalysis() is called with new analysis data",
        "Tree items are organized hierarchically: root categories  files/functions  details",
        "Each tree item shows icons, labels, tooltips, and descriptions",
        "Items can be collapsed or expanded to show nested information",
        "Clicking items triggers commands to reveal file locations in editor",
        "View integrates with VSCode's tree data provider API",
        "Analysis data is passed in as CodeAnalysis objects containing files, functions, and entry points"
      ],
      "keyFunctions": [
        {
          "name": "setAnalysis",
          "desc": "Updates the tree view with new analysis results",
          "inputs": "analysis: CodeAnalysis | null",
          "outputs": "void"
        },
        {
          "name": "refresh",
          "desc": "Triggers a refresh of the entire tree view",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the VSCode tree item for display",
          "inputs": "element: AnalysisItem",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "getChildren",
          "desc": "Returns child items for a given tree node or root items if none specified",
          "inputs": "element?: AnalysisItem",
          "outputs": "Thenable<AnalysisItem[]>"
        },
        {
          "name": "getRootItems",
          "desc": "Returns top-level categories in the tree (Statistics, Files, Functions, Entry Points)",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getStatisticsItems",
          "desc": "Returns statistical summary items about the analyzed code",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFilesItems",
          "desc": "Returns file and directory items organized by directory structure",
          "inputs": "none",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getFileDetails",
          "desc": "Returns detailed information items for a specific file",
          "inputs": "element: AnalysisItem",
          "outputs": "AnalysisItem[]"
        },
        {
          "name": "getDirectoryFiles",
          "desc": "Returns files contained within a directory item",
          "inputs": "element: AnalysisItem",
          "outputs": "AnalysisItem[]"
        }
      ],
      "dependencies": [
        "vscode",
        "analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)",
        "path"
      ],
      "intent": "This file exists to provide developers with a visual, interactive way to browse and understand code analysis results within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree view interface, allowing developers to quickly explore code structure, statistics, and relationships without examining raw data structures.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view panel in VSCode that displays code analysis results in an organized, browsable hierarchy.\",\n  \"userVisibleActions\": [\n    \"View a tree-structured panel showing code analysis results organized by categories\",\n    \"Browse statistics about analyzed code (file counts, function counts, line counts)\",\n    \"Explore files and directories in the analyzed codebase\",\n    \"See detailed information about individual files (lines, functions, imports, exports)\",\n    \"View function details (name, parameters, return type, line numbers)\",\n    \"Browse entry points (main functions, exports, classes) discovered in the code\",\n    \"Click on items to navigate to specific locations in source files\",\n    \"See contextual descriptions for each tree item\",\n    \"View 'No analysis available' message when no analysis has been run\",\n    \"Refresh the view to see updated analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically updates when setAnalysis() is called with new analysis data\",\n    \"Tree items are organized hierarchically: root categories  files/functions  details\",\n    \"Each tree item shows icons, labels, tooltips, and descriptions\",\n    \"Items can be collapsed or expanded to show nested information\",\n    \"Clicking items triggers commands to reveal file locations in editor\",\n    \"View integrates with VSCode's tree data provider API\",\n    \"Analysis data is passed in as CodeAnalysis objects containing files, functions, and entry points\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"setAnalysis\",\n      \"desc\": \"Updates the tree view with new analysis results\",\n      \"inputs\": \"analysis: CodeAnalysis | null\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers a refresh of the entire tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VSCode tree item for display\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child items for a given tree node or root items if none specified\",\n      \"inputs\": \"element?: AnalysisItem\",\n      \"outputs\": \"Thenable<AnalysisItem[]>\"\n    },\n    {\n      \"name\": \"getRootItems\",\n      \"desc\": \"Returns top-level categories in the tree (Statistics, Files, Functions, Entry Points)\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getStatisticsItems\",\n      \"desc\": \"Returns statistical summary items about the analyzed code\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFilesItems\",\n      \"desc\": \"Returns file and directory items organized by directory structure\",\n      \"inputs\": \"none\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getFileDetails\",\n      \"desc\": \"Returns detailed information items for a specific file\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    },\n    {\n      \"name\": \"getDirectoryFiles\",\n      \"desc\": \"Returns files contained within a directory item\",\n      \"inputs\": \"element: AnalysisItem\",\n      \"outputs\": \"AnalysisItem[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"analyzer (CodeAnalysis, FileInfo, FunctionInfo, EntryPoint types)\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to provide developers with a visual, interactive way to browse and understand code analysis results within VSCode. It solves the problem of making complex analysis data accessible and navigable through a familiar tree view interface, allowing developers to quickly explore code structure, statistics, and relationships without examining raw data structures.\"\n}\n```"
    },
    {
      "file": "src/analyzer.ts",
      "role": "Core Logic",
      "purpose": "Defines core data structures and interfaces for code analysis results, including file metrics, function metadata, dependencies, and test mappings.",
      "userVisibleActions": [
        "View total project statistics (files, lines, functions)",
        "See large files identified in the codebase",
        "Browse function information with parameters and return types",
        "Examine import relationships between files",
        "Identify orphaned files not imported anywhere",
        "Discover entry points in the application",
        "View duplicate code groups",
        "See function risk levels (high/medium/low)",
        "Review function documentation and visibility",
        "Explore test coverage mapping for functions"
      ],
      "developerVisibleActions": [
        "Import CodeAnalysis interface to structure analysis results",
        "Use FunctionMetadata to store detailed function information including parameters, return types, and docstrings",
        "Track branch complexity with BranchInfo (if/else/switch/loop/exception handling)",
        "Map dependencies by type (database, HTTP, filesystem, cache, etc.)",
        "Monitor state mutations (assign/modify/delete/read operations)",
        "Link source files to their test files using TestMapping",
        "Identify uncovered functions without tests",
        "Detect duplicate code sections with similarity scores",
        "Cache analysis results using AnalysisCache",
        "Track function relationships through imports and dependencies"
      ],
      "keyFunctions": [
        {
          "name": "CodeAnalysis",
          "desc": "Main interface that aggregates all analysis results for a codebase",
          "inputs": "Analysis data from file system traversal",
          "outputs": "Structured metrics including files, functions, imports, orphans, entry points, and optional enhanced metadata"
        },
        {
          "name": "FunctionMetadata",
          "desc": "Comprehensive metadata for individual functions including control flow and dependencies",
          "inputs": "Parsed function information from source code",
          "outputs": "Structured function details with parameters, branches, dependencies, mutations, and risk assessment"
        },
        {
          "name": "TestMapping",
          "desc": "Maps source code to test files and identifies untested functions",
          "inputs": "Source files and test files from analysis",
          "outputs": "Bidirectional mapping between source files/functions and their tests, plus uncovered functions list"
        },
        {
          "name": "DependencyInfo",
          "desc": "Categorizes and tracks external and internal dependencies",
          "inputs": "Import statements and function calls",
          "outputs": "Classified dependencies by type (db/http/filesystem/etc.) with internal/external flag"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./cache"
      ],
      "intent": "This file exists to establish a comprehensive, type-safe contract for code analysis results. It solves the problem of consistently structuring complex codebase analysis data including metrics, metadata, relationships, and test coverage so that other components can reliably process and display analysis insights to users.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines core data structures and interfaces for code analysis results, including file metrics, function metadata, dependencies, and test mappings.\",\n  \"userVisibleActions\": [\n    \"View total project statistics (files, lines, functions)\",\n    \"See large files identified in the codebase\",\n    \"Browse function information with parameters and return types\",\n    \"Examine import relationships between files\",\n    \"Identify orphaned files not imported anywhere\",\n    \"Discover entry points in the application\",\n    \"View duplicate code groups\",\n    \"See function risk levels (high/medium/low)\",\n    \"Review function documentation and visibility\",\n    \"Explore test coverage mapping for functions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Import CodeAnalysis interface to structure analysis results\",\n    \"Use FunctionMetadata to store detailed function information including parameters, return types, and docstrings\",\n    \"Track branch complexity with BranchInfo (if/else/switch/loop/exception handling)\",\n    \"Map dependencies by type (database, HTTP, filesystem, cache, etc.)\",\n    \"Monitor state mutations (assign/modify/delete/read operations)\",\n    \"Link source files to their test files using TestMapping\",\n    \"Identify uncovered functions without tests\",\n    \"Detect duplicate code sections with similarity scores\",\n    \"Cache analysis results using AnalysisCache\",\n    \"Track function relationships through imports and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"CodeAnalysis\",\n      \"desc\": \"Main interface that aggregates all analysis results for a codebase\",\n      \"inputs\": \"Analysis data from file system traversal\",\n      \"outputs\": \"Structured metrics including files, functions, imports, orphans, entry points, and optional enhanced metadata\"\n    },\n    {\n      \"name\": \"FunctionMetadata\",\n      \"desc\": \"Comprehensive metadata for individual functions including control flow and dependencies\",\n      \"inputs\": \"Parsed function information from source code\",\n      \"outputs\": \"Structured function details with parameters, branches, dependencies, mutations, and risk assessment\"\n    },\n    {\n      \"name\": \"TestMapping\",\n      \"desc\": \"Maps source code to test files and identifies untested functions\",\n      \"inputs\": \"Source files and test files from analysis\",\n      \"outputs\": \"Bidirectional mapping between source files/functions and their tests, plus uncovered functions list\"\n    },\n    {\n      \"name\": \"DependencyInfo\",\n      \"desc\": \"Categorizes and tracks external and internal dependencies\",\n      \"inputs\": \"Import statements and function calls\",\n      \"outputs\": \"Classified dependencies by type (db/http/filesystem/etc.) with internal/external flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./cache\"\n  ],\n  \"intent\": \"This file exists to establish a comprehensive, type-safe contract for code analysis results. It solves the problem of consistently structuring complex codebase analysis data including metrics, metadata, relationships, and test coverage so that other components can reliably process and display analysis insights to users.\"\n}\n```"
    },
    {
      "file": "src/cache.ts",
      "role": "Core Logic",
      "purpose": "Manages persistent caching of code analysis results to improve performance by avoiding redundant analysis.",
      "userVisibleActions": [
        "Analysis results load faster when reopening a workspace (within 24 hours)",
        "Previously analyzed code doesn't need to be re-analyzed immediately",
        "Cache data is automatically cleaned up when old"
      ],
      "developerVisibleActions": [
        "Stores code analysis results in a hidden .shadowwatch-cache directory",
        "Automatically retrieves cached analysis when available and valid",
        "Cache expires after 24 hours requiring fresh analysis",
        "Cache can be manually cleared to force new analysis",
        "Failed cache operations are logged but don't break functionality"
      ],
      "keyFunctions": [
        {
          "name": "constructor",
          "desc": "Initializes cache storage location",
          "inputs": "storagePath: string",
          "outputs": "AnalysisCache instance"
        },
        {
          "name": "get",
          "desc": "Retrieves cached analysis results for a workspace if valid",
          "inputs": "workspaceRoot: string",
          "outputs": "Promise<CodeAnalysis | null>"
        },
        {
          "name": "set",
          "desc": "Saves analysis results to cache with timestamp",
          "inputs": "workspaceRoot: string, data: CodeAnalysis",
          "outputs": "Promise<void>"
        },
        {
          "name": "clear",
          "desc": "Removes all cached analysis data",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "getCacheKey",
          "desc": "Generates a safe filename identifier from workspace path",
          "inputs": "workspaceRoot: string",
          "outputs": "string (base64 encoded safe filename)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "Improves extension performance by caching expensive code analysis results, preventing redundant analysis of the same codebase within a 24-hour window. This makes subsequent workspace loads faster and reduces computational overhead.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages persistent caching of code analysis results to improve performance by avoiding redundant analysis.\",\n  \"userVisibleActions\": [\n    \"Analysis results load faster when reopening a workspace (within 24 hours)\",\n    \"Previously analyzed code doesn't need to be re-analyzed immediately\",\n    \"Cache data is automatically cleaned up when old\"\n  ],\n  \"developerVisibleActions\": [\n    \"Stores code analysis results in a hidden .shadowwatch-cache directory\",\n    \"Automatically retrieves cached analysis when available and valid\",\n    \"Cache expires after 24 hours requiring fresh analysis\",\n    \"Cache can be manually cleared to force new analysis\",\n    \"Failed cache operations are logged but don't break functionality\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"constructor\",\n      \"desc\": \"Initializes cache storage location\",\n      \"inputs\": \"storagePath: string\",\n      \"outputs\": \"AnalysisCache instance\"\n    },\n    {\n      \"name\": \"get\",\n      \"desc\": \"Retrieves cached analysis results for a workspace if valid\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"Promise<CodeAnalysis | null>\"\n    },\n    {\n      \"name\": \"set\",\n      \"desc\": \"Saves analysis results to cache with timestamp\",\n      \"inputs\": \"workspaceRoot: string, data: CodeAnalysis\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all cached analysis data\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"getCacheKey\",\n      \"desc\": \"Generates a safe filename identifier from workspace path\",\n      \"inputs\": \"workspaceRoot: string\",\n      \"outputs\": \"string (base64 encoded safe filename)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"Improves extension performance by caching expensive code analysis results, preventing redundant analysis of the same codebase within a 24-hour window. This makes subsequent workspace loads faster and reduces computational overhead.\"\n}\n```"
    },
    {
      "file": "src/config/configurationManager.ts",
      "role": "Core Logic",
      "purpose": "Manages all Shadow Watch extension settings and notifies components when configuration changes occur",
      "userVisibleActions": [
        "User enables/disables Shadow Watch extension",
        "User toggles automatic analysis when saving files",
        "User toggles inline hints display in code editor",
        "User configures which LLM provider to use (OpenAI or Claude)",
        "User selects output format for LLM interactions (Cursor, ChatGPT, Generic, or Compact)",
        "User sets minimum severity level for showing diagnostics (Error, Warning, or Info)",
        "User changes any Shadow Watch setting in VS Code settings UI"
      ],
      "developerVisibleActions": [
        "Developer components can access all Shadow Watch configuration settings through type-safe getters",
        "Developer components can register callbacks to be notified when configuration changes",
        "Developer components can validate configuration settings before using them",
        "Developer can query whether the extension is enabled",
        "Developer can check if analysis should run on file save",
        "Developer can determine which LLM provider and format to use",
        "Developer can check severity threshold for filtering diagnostics"
      ],
      "keyFunctions": [
        {
          "name": "onConfigurationChange",
          "desc": "Registers a callback function to be invoked whenever Shadow Watch settings change",
          "inputs": "callback function with no parameters",
          "outputs": "void"
        },
        {
          "name": "removeConfigurationChangeListener",
          "desc": "Unregisters a previously registered configuration change callback",
          "inputs": "callback function to remove",
          "outputs": "void"
        },
        {
          "name": "enabled",
          "desc": "Returns whether the Shadow Watch extension is currently enabled",
          "inputs": "none (getter property)",
          "outputs": "boolean"
        },
        {
          "name": "analyzeOnSave",
          "desc": "Returns whether automatic analysis should run when files are saved",
          "inputs": "none (getter property)",
          "outputs": "boolean"
        },
        {
          "name": "showInlineHints",
          "desc": "Returns whether inline hints should be displayed in the code editor",
          "inputs": "none (getter property)",
          "outputs": "boolean"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety and consistency across the extension. It solves the problem of scattered configuration access and provides a reactive system where components can automatically respond to setting changes without manual polling.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages all Shadow Watch extension settings and notifies components when configuration changes occur\",\n  \"userVisibleActions\": [\n    \"User enables/disables Shadow Watch extension\",\n    \"User toggles automatic analysis when saving files\",\n    \"User toggles inline hints display in code editor\",\n    \"User configures which LLM provider to use (OpenAI or Claude)\",\n    \"User selects output format for LLM interactions (Cursor, ChatGPT, Generic, or Compact)\",\n    \"User sets minimum severity level for showing diagnostics (Error, Warning, or Info)\",\n    \"User changes any Shadow Watch setting in VS Code settings UI\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer components can access all Shadow Watch configuration settings through type-safe getters\",\n    \"Developer components can register callbacks to be notified when configuration changes\",\n    \"Developer components can validate configuration settings before using them\",\n    \"Developer can query whether the extension is enabled\",\n    \"Developer can check if analysis should run on file save\",\n    \"Developer can determine which LLM provider and format to use\",\n    \"Developer can check severity threshold for filtering diagnostics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"onConfigurationChange\",\n      \"desc\": \"Registers a callback function to be invoked whenever Shadow Watch settings change\",\n      \"inputs\": \"callback function with no parameters\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"removeConfigurationChangeListener\",\n      \"desc\": \"Unregisters a previously registered configuration change callback\",\n      \"inputs\": \"callback function to remove\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"enabled\",\n      \"desc\": \"Returns whether the Shadow Watch extension is currently enabled\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"analyzeOnSave\",\n      \"desc\": \"Returns whether automatic analysis should run when files are saved\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"showInlineHints\",\n      \"desc\": \"Returns whether inline hints should be displayed in the code editor\",\n      \"inputs\": \"none (getter property)\",\n      \"outputs\": \"boolean\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide a single, centralized point of access for all Shadow Watch configuration settings, ensuring type safety and consistency across the extension. It solves the problem of scattered configuration access and provides a reactive system where components can automatically respond to setting changes without manual polling.\"\n}\n```"
    },
    {
      "file": "src/context/analysisContextBuilder.ts",
      "role": "Core Logic",
      "purpose": "Converts code analysis data into a format suitable for LLM consumption and saves it to disk for future reference.",
      "userVisibleActions": [
        "Code analysis results are automatically saved to .shadow/docs/code-analysis.json for future use",
        "Analysis data is persisted across VS Code sessions"
      ],
      "developerVisibleActions": [
        "Transforms CodeAnalysis objects into AnalysisContext format that can be sent to LLM services",
        "Creates .shadow/docs directory structure if it doesn't exist",
        "Saves analysis with metadata including generation timestamp",
        "Enables analysis data to be reused without re-scanning the codebase"
      ],
      "keyFunctions": [
        {
          "name": "convertCodeAnalysisToContext",
          "desc": "Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption",
          "inputs": "analysis: CodeAnalysis (contains files, imports, entry points, metrics)",
          "outputs": "AnalysisContext (formatted data with files, imports, entry points, orphaned files, and totals)"
        },
        {
          "name": "saveCodeAnalysis",
          "desc": "Persists code analysis data to .shadow/docs/code-analysis.json with timestamp metadata",
          "inputs": "analysis: CodeAnalysis (code analysis data to save)",
          "outputs": "void (writes to file system)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../analyzer (CodeAnalysis, EntryPoint types)",
        "../llmService (AnalysisContext type)"
      ],
      "intent": "This file exists to bridge the gap between the code analyzer and LLM service by converting analysis data into LLM-friendly format and caching it on disk. This allows analysis results to be reused without re-scanning the entire codebase, improving performance and enabling offline access to previously generated analysis data.",
      "rawContent": "```json\n{\n  \"purpose\": \"Converts code analysis data into a format suitable for LLM consumption and saves it to disk for future reference.\",\n  \"userVisibleActions\": [\n    \"Code analysis results are automatically saved to .shadow/docs/code-analysis.json for future use\",\n    \"Analysis data is persisted across VS Code sessions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Transforms CodeAnalysis objects into AnalysisContext format that can be sent to LLM services\",\n    \"Creates .shadow/docs directory structure if it doesn't exist\",\n    \"Saves analysis with metadata including generation timestamp\",\n    \"Enables analysis data to be reused without re-scanning the codebase\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"convertCodeAnalysisToContext\",\n      \"desc\": \"Transforms CodeAnalysis data structure into AnalysisContext format suitable for LLM consumption\",\n      \"inputs\": \"analysis: CodeAnalysis (contains files, imports, entry points, metrics)\",\n      \"outputs\": \"AnalysisContext (formatted data with files, imports, entry points, orphaned files, and totals)\"\n    },\n    {\n      \"name\": \"saveCodeAnalysis\",\n      \"desc\": \"Persists code analysis data to .shadow/docs/code-analysis.json with timestamp metadata\",\n      \"inputs\": \"analysis: CodeAnalysis (code analysis data to save)\",\n      \"outputs\": \"void (writes to file system)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../analyzer (CodeAnalysis, EntryPoint types)\",\n    \"../llmService (AnalysisContext type)\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between the code analyzer and LLM service by converting analysis data into LLM-friendly format and caching it on disk. This allows analysis results to be reused without re-scanning the entire codebase, improving performance and enabling offline access to previously generated analysis data.\"\n}\n```"
    },
    {
      "file": "src/diagnosticsProvider.ts",
      "role": "Core Logic",
      "purpose": "Displays code insights as inline diagnostics (squiggly underlines) in the VS Code editor's Problems panel",
      "userVisibleActions": [
        "Shows warnings or errors under specific lines of code with squiggly underlines",
        "Displays insights in the Problems panel at the bottom of VS Code",
        "Highlights problematic code locations across multiple files",
        "Shows insight descriptions when hovering over underlined code",
        "Groups diagnostics by file in the Problems panel"
      ],
      "developerVisibleActions": [
        "Converts generated insights into VS Code diagnostic entries",
        "Updates the Problems panel whenever new insights are generated",
        "Maps insight severity levels to VS Code diagnostic severity (Error, Warning, Information, Hint)",
        "Clears all diagnostics when insights are refreshed",
        "Associates each diagnostic with its source file and line number",
        "Tags diagnostics with 'Shadow Watch' as the source"
      ],
      "keyFunctions": [
        {
          "name": "updateDiagnostics",
          "desc": "Updates all diagnostics across all files based on provided insights",
          "inputs": "Array of Insight objects",
          "outputs": "void (updates UI)"
        },
        {
          "name": "updateDiagnosticsForFile",
          "desc": "Updates diagnostics for a single specific file",
          "inputs": "File URI and array of Insight objects",
          "outputs": "void (updates UI)"
        },
        {
          "name": "clear",
          "desc": "Removes all diagnostics from the Problems panel",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "createDiagnostic",
          "desc": "Converts an insight into a VS Code diagnostic entry with range, severity, and metadata",
          "inputs": "Single Insight object",
          "outputs": "vscode.Diagnostic object"
        },
        {
          "name": "getSeverity",
          "desc": "Maps insight severity to VS Code diagnostic severity level",
          "inputs": "Insight severity string",
          "outputs": "vscode.DiagnosticSeverity enum"
        }
      ],
      "dependencies": [
        "vscode",
        "./insightGenerator"
      ],
      "intent": "Bridges the gap between Shadow Watch's code analysis insights and VS Code's native diagnostics system, making insights visible to users as familiar editor warnings and errors in the Problems panel",
      "rawContent": "```json\n{\n  \"purpose\": \"Displays code insights as inline diagnostics (squiggly underlines) in the VS Code editor's Problems panel\",\n  \"userVisibleActions\": [\n    \"Shows warnings or errors under specific lines of code with squiggly underlines\",\n    \"Displays insights in the Problems panel at the bottom of VS Code\",\n    \"Highlights problematic code locations across multiple files\",\n    \"Shows insight descriptions when hovering over underlined code\",\n    \"Groups diagnostics by file in the Problems panel\"\n  ],\n  \"developerVisibleActions\": [\n    \"Converts generated insights into VS Code diagnostic entries\",\n    \"Updates the Problems panel whenever new insights are generated\",\n    \"Maps insight severity levels to VS Code diagnostic severity (Error, Warning, Information, Hint)\",\n    \"Clears all diagnostics when insights are refreshed\",\n    \"Associates each diagnostic with its source file and line number\",\n    \"Tags diagnostics with 'Shadow Watch' as the source\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"updateDiagnostics\",\n      \"desc\": \"Updates all diagnostics across all files based on provided insights\",\n      \"inputs\": \"Array of Insight objects\",\n      \"outputs\": \"void (updates UI)\"\n    },\n    {\n      \"name\": \"updateDiagnosticsForFile\",\n      \"desc\": \"Updates diagnostics for a single specific file\",\n      \"inputs\": \"File URI and array of Insight objects\",\n      \"outputs\": \"void (updates UI)\"\n    },\n    {\n      \"name\": \"clear\",\n      \"desc\": \"Removes all diagnostics from the Problems panel\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"createDiagnostic\",\n      \"desc\": \"Converts an insight into a VS Code diagnostic entry with range, severity, and metadata\",\n      \"inputs\": \"Single Insight object\",\n      \"outputs\": \"vscode.Diagnostic object\"\n    },\n    {\n      \"name\": \"getSeverity\",\n      \"desc\": \"Maps insight severity to VS Code diagnostic severity level\",\n      \"inputs\": \"Insight severity string\",\n      \"outputs\": \"vscode.DiagnosticSeverity enum\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Bridges the gap between Shadow Watch's code analysis insights and VS Code's native diagnostics system, making insights visible to users as familiar editor warnings and errors in the Problems panel\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/commandRegistry.ts",
      "role": "Core Logic",
      "purpose": "Registers all VS Code commands for the extension, mapping user actions to their corresponding handlers",
      "userVisibleActions": [
        "Analyze entire workspace for insights",
        "Analyze current open file",
        "Copy all insights to clipboard",
        "Copy file-specific insights to clipboard",
        "Copy individual insight to clipboard",
        "Clear analysis cache",
        "Clear all extension data",
        "Open extension settings",
        "View latest analysis report",
        "View latest unit test report",
        "Switch between LLM providers (OpenAI, Anthropic, etc.)",
        "Copy menu structure to clipboard",
        "View current LLM provider status",
        "Navigate to product items in codebase",
        "Navigate to analysis items",
        "Show detailed information for product items",
        "Show detailed information for insights",
        "Show detailed information for unit test items"
      ],
      "developerVisibleActions": [
        "Provides centralized command registration separating concerns from main extension file",
        "Maps command IDs to handler functions for all extension commands",
        "Integrates with LLM services, code analyzer, insight generator, and UI providers",
        "Manages command lifecycle within VS Code extension context",
        "Handles navigation between different views (product navigator, analysis viewer, insights tree)",
        "Coordinates between cache management, diagnostics, and configuration systems"
      ],
      "keyFunctions": [
        {
          "name": "register",
          "desc": "Registers all VS Code commands with their corresponding handlers",
          "inputs": "VS Code extension context and extension components (analyzers, providers, caches)",
          "outputs": "void - commands are registered as side effect"
        }
      ],
      "dependencies": [
        "vscode",
        "llmIntegration",
        "CodeAnalyzer",
        "InsightGenerator",
        "LLMFormatter",
        "InsightsTreeProvider",
        "DiagnosticsProvider",
        "AnalysisCache",
        "AnalysisViewerProvider",
        "ProductNavItem",
        "configurationManager",
        "ExtensionComponents"
      ],
      "intent": "Separates command registration logic from the main extension file to improve code organization, maintainability, and testability by providing a single place to define all user-triggered commands and their handlers",
      "rawContent": "```json\n{\n  \"purpose\": \"Registers all VS Code commands for the extension, mapping user actions to their corresponding handlers\",\n  \"userVisibleActions\": [\n    \"Analyze entire workspace for insights\",\n    \"Analyze current open file\",\n    \"Copy all insights to clipboard\",\n    \"Copy file-specific insights to clipboard\",\n    \"Copy individual insight to clipboard\",\n    \"Clear analysis cache\",\n    \"Clear all extension data\",\n    \"Open extension settings\",\n    \"View latest analysis report\",\n    \"View latest unit test report\",\n    \"Switch between LLM providers (OpenAI, Anthropic, etc.)\",\n    \"Copy menu structure to clipboard\",\n    \"View current LLM provider status\",\n    \"Navigate to product items in codebase\",\n    \"Navigate to analysis items\",\n    \"Show detailed information for product items\",\n    \"Show detailed information for insights\",\n    \"Show detailed information for unit test items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides centralized command registration separating concerns from main extension file\",\n    \"Maps command IDs to handler functions for all extension commands\",\n    \"Integrates with LLM services, code analyzer, insight generator, and UI providers\",\n    \"Manages command lifecycle within VS Code extension context\",\n    \"Handles navigation between different views (product navigator, analysis viewer, insights tree)\",\n    \"Coordinates between cache management, diagnostics, and configuration systems\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"register\",\n      \"desc\": \"Registers all VS Code commands with their corresponding handlers\",\n      \"inputs\": \"VS Code extension context and extension components (analyzers, providers, caches)\",\n      \"outputs\": \"void - commands are registered as side effect\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"llmIntegration\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"LLMFormatter\",\n    \"InsightsTreeProvider\",\n    \"DiagnosticsProvider\",\n    \"AnalysisCache\",\n    \"AnalysisViewerProvider\",\n    \"ProductNavItem\",\n    \"configurationManager\",\n    \"ExtensionComponents\"\n  ],\n  \"intent\": \"Separates command registration logic from the main extension file to improve code organization, maintainability, and testability by providing a single place to define all user-triggered commands and their handlers\"\n}\n```"
    },
    {
      "file": "src/domain/bootstrap/extensionBootstrapper.ts",
      "role": "Core Logic",
      "purpose": "Initializes and configures all extension components during VS Code extension activation, setting up analyzers, watchers, providers, and UI elements.",
      "userVisibleActions": [
        "Status bar item appears showing extension state",
        "Tree views become available in sidebar (Insights, Analysis, Static Analysis, Unit Tests, Product Navigator, Reports)",
        "Diagnostics (warnings/errors) appear in Problems panel",
        "File change notifications trigger automatic re-analysis",
        "Reports viewer displays analysis reports",
        "Custom webviews render for different analysis types"
      ],
      "developerVisibleActions": [
        "Extension activates and all components initialize on workspace open",
        "File watcher monitors code changes and triggers analysis",
        "Cache system stores analysis results for performance",
        "Configuration manager loads user settings",
        "Error handler captures and logs failures during initialization",
        "State manager tracks LLM integration status",
        "Multiple tree providers populate different sidebar views",
        "Diagnostics provider integrates with VS Code's Problems panel"
      ],
      "keyFunctions": [
        {
          "name": "ExtensionComponents interface",
          "desc": "Defines all components that need to be initialized for the extension to function",
          "inputs": "N/A (interface definition)",
          "outputs": "Type definition including analyzer, generators, watchers, providers, cache, UI elements"
        },
        {
          "name": "bootstrap (implied)",
          "desc": "Orchestrates initialization of all extension components in correct order",
          "inputs": "vscode.ExtensionContext",
          "outputs": "ExtensionComponents object with all initialized services"
        }
      ],
      "dependencies": [
        "vscode",
        "../../analyzer (CodeAnalyzer)",
        "../../insightGenerator (InsightGenerator)",
        "../../llmFormatter (LLMFormatter)",
        "../../fileWatcher (FileWatcher)",
        "../../insightsTreeView (InsightsTreeProvider)",
        "../../diagnosticsProvider (DiagnosticsProvider)",
        "../../cache (AnalysisCache)",
        "../../llmIntegration",
        "../../productNavigator (ProductNavigatorProvider)",
        "../../analysisViewer (AnalysisViewerProvider, AnalysisItem)",
        "../../insightsViewer (InsightsViewerProvider, InsightItem)",
        "../../staticAnalysisViewer (StaticAnalysisViewerProvider, StaticAnalysisItem)",
        "../../unitTestsNavigator (UnitTestsNavigatorProvider, UnitTestItem)",
        "../../config/configurationManager",
        "../../utils/errorHandler (ErrorHandler)",
        "../../domain/services/fileWatcherService (FileWatcherService)",
        "../../ui/reportsViewer (ReportsViewer)",
        "../../reportsTreeProvider (ReportsTreeProvider, ReportTreeItem)",
        "../../state/llmStateManager"
      ],
      "intent": "This file exists to centralize and organize the complex initialization sequence required to start the VS Code extension. It solves the problem of managing multiple interdependent components (analyzers, UI providers, watchers, caches) that must be initialized in a specific order, making the activation logic maintainable and testable by separating it from the main extension entry point.",
      "rawContent": "```json\n{\n  \"purpose\": \"Initializes and configures all extension components during VS Code extension activation, setting up analyzers, watchers, providers, and UI elements.\",\n  \"userVisibleActions\": [\n    \"Status bar item appears showing extension state\",\n    \"Tree views become available in sidebar (Insights, Analysis, Static Analysis, Unit Tests, Product Navigator, Reports)\",\n    \"Diagnostics (warnings/errors) appear in Problems panel\",\n    \"File change notifications trigger automatic re-analysis\",\n    \"Reports viewer displays analysis reports\",\n    \"Custom webviews render for different analysis types\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates and all components initialize on workspace open\",\n    \"File watcher monitors code changes and triggers analysis\",\n    \"Cache system stores analysis results for performance\",\n    \"Configuration manager loads user settings\",\n    \"Error handler captures and logs failures during initialization\",\n    \"State manager tracks LLM integration status\",\n    \"Multiple tree providers populate different sidebar views\",\n    \"Diagnostics provider integrates with VS Code's Problems panel\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"ExtensionComponents interface\",\n      \"desc\": \"Defines all components that need to be initialized for the extension to function\",\n      \"inputs\": \"N/A (interface definition)\",\n      \"outputs\": \"Type definition including analyzer, generators, watchers, providers, cache, UI elements\"\n    },\n    {\n      \"name\": \"bootstrap (implied)\",\n      \"desc\": \"Orchestrates initialization of all extension components in correct order\",\n      \"inputs\": \"vscode.ExtensionContext\",\n      \"outputs\": \"ExtensionComponents object with all initialized services\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"../../analyzer (CodeAnalyzer)\",\n    \"../../insightGenerator (InsightGenerator)\",\n    \"../../llmFormatter (LLMFormatter)\",\n    \"../../fileWatcher (FileWatcher)\",\n    \"../../insightsTreeView (InsightsTreeProvider)\",\n    \"../../diagnosticsProvider (DiagnosticsProvider)\",\n    \"../../cache (AnalysisCache)\",\n    \"../../llmIntegration\",\n    \"../../productNavigator (ProductNavigatorProvider)\",\n    \"../../analysisViewer (AnalysisViewerProvider, AnalysisItem)\",\n    \"../../insightsViewer (InsightsViewerProvider, InsightItem)\",\n    \"../../staticAnalysisViewer (StaticAnalysisViewerProvider, StaticAnalysisItem)\",\n    \"../../unitTestsNavigator (UnitTestsNavigatorProvider, UnitTestItem)\",\n    \"../../config/configurationManager\",\n    \"../../utils/errorHandler (ErrorHandler)\",\n    \"../../domain/services/fileWatcherService (FileWatcherService)\",\n    \"../../ui/reportsViewer (ReportsViewer)\",\n    \"../../reportsTreeProvider (ReportsTreeProvider, ReportTreeItem)\",\n    \"../../state/llmStateManager\"\n  ],\n  \"intent\": \"This file exists to centralize and organize the complex initialization sequence required to start the VS Code extension. It solves the problem of managing multiple interdependent components (analyzers, UI providers, watchers, caches) that must be initialized in a specific order, making the activation logic maintainable and testable by separating it from the main extension entry point.\"\n}\n```"
    },
    {
      "file": "src/domain/formatters/documentationFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats product documentation and LLM insights into structured Markdown documents for human readability",
      "userVisibleActions": [
        "Generates comprehensive product documentation in Markdown format with timestamps",
        "Creates formatted sections for product overview, features, and user perspectives",
        "Displays documentation organized by interface type (GUI, CLI, API)",
        "Shows key features and main capabilities in bullet-point format",
        "Presents technical details including architecture, dependencies, and file structure",
        "Formats AI-generated insights with architectural patterns and recommendations",
        "Displays quality assessment scores and metrics",
        "Shows identified improvement suggestions and action items"
      ],
      "developerVisibleActions": [
        "Converts EnhancedProductDocumentation objects into readable Markdown documents",
        "Converts LLMInsights objects into structured Markdown reports",
        "Applies consistent formatting and section ordering to documentation",
        "Generates timestamps in both local and UTC formats",
        "Creates hierarchical document structure with headers and subheaders",
        "Formats lists and bullet points for features, dependencies, and insights",
        "Handles optional sections gracefully (only includes sections with content)",
        "Provides standardized documentation output format for the application"
      ],
      "keyFunctions": [
        {
          "name": "formatEnhancedDocsAsMarkdown",
          "desc": "Converts enhanced product documentation object into a comprehensive Markdown document",
          "inputs": "EnhancedProductDocumentation object containing overview, features, perspectives, architecture, etc.",
          "outputs": "Formatted Markdown string with sections for overview, features, user perspectives, technical details, and file structure"
        },
        {
          "name": "formatInsightsAsMarkdown",
          "desc": "Converts LLM-generated insights into a structured Markdown report",
          "inputs": "LLMInsights object containing architectural patterns, quality assessment, and recommendations",
          "outputs": "Formatted Markdown string with sections for key insights, architecture, quality scores, and improvement suggestions"
        }
      ],
      "dependencies": [
        "../../fileDocumentation (EnhancedProductDocumentation type)",
        "../../llmService (LLMInsights type)"
      ],
      "intent": "Separates documentation formatting logic from business logic to create consistent, human-readable Markdown output from structured data objects. Solves the problem of presenting complex product documentation and AI insights in a standardized, readable format that users can easily consume and understand.",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats product documentation and LLM insights into structured Markdown documents for human readability\",\n  \"userVisibleActions\": [\n    \"Generates comprehensive product documentation in Markdown format with timestamps\",\n    \"Creates formatted sections for product overview, features, and user perspectives\",\n    \"Displays documentation organized by interface type (GUI, CLI, API)\",\n    \"Shows key features and main capabilities in bullet-point format\",\n    \"Presents technical details including architecture, dependencies, and file structure\",\n    \"Formats AI-generated insights with architectural patterns and recommendations\",\n    \"Displays quality assessment scores and metrics\",\n    \"Shows identified improvement suggestions and action items\"\n  ],\n  \"developerVisibleActions\": [\n    \"Converts EnhancedProductDocumentation objects into readable Markdown documents\",\n    \"Converts LLMInsights objects into structured Markdown reports\",\n    \"Applies consistent formatting and section ordering to documentation\",\n    \"Generates timestamps in both local and UTC formats\",\n    \"Creates hierarchical document structure with headers and subheaders\",\n    \"Formats lists and bullet points for features, dependencies, and insights\",\n    \"Handles optional sections gracefully (only includes sections with content)\",\n    \"Provides standardized documentation output format for the application\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatEnhancedDocsAsMarkdown\",\n      \"desc\": \"Converts enhanced product documentation object into a comprehensive Markdown document\",\n      \"inputs\": \"EnhancedProductDocumentation object containing overview, features, perspectives, architecture, etc.\",\n      \"outputs\": \"Formatted Markdown string with sections for overview, features, user perspectives, technical details, and file structure\"\n    },\n    {\n      \"name\": \"formatInsightsAsMarkdown\",\n      \"desc\": \"Converts LLM-generated insights into a structured Markdown report\",\n      \"inputs\": \"LLMInsights object containing architectural patterns, quality assessment, and recommendations\",\n      \"outputs\": \"Formatted Markdown string with sections for key insights, architecture, quality scores, and improvement suggestions\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../fileDocumentation (EnhancedProductDocumentation type)\",\n    \"../../llmService (LLMInsights type)\"\n  ],\n  \"intent\": \"Separates documentation formatting logic from business logic to create consistent, human-readable Markdown output from structured data objects. Solves the problem of presenting complex product documentation and AI insights in a standardized, readable format that users can easily consume and understand.\"\n}\n```"
    },
    {
      "file": "src/domain/handlers/navigationHandler.ts",
      "role": "Core Logic",
      "purpose": "Handles navigation to files, functions, endpoints, and other code locations within the VS Code editor, displaying details about code items when clicked.",
      "userVisibleActions": [
        "Click on a file item to open that file in the editor",
        "Click on a function to jump to its definition in the source code",
        "Click on an endpoint to navigate to its implementation",
        "Click on an analysis item to view its details in the editor",
        "View error messages when navigation fails to find a file or location",
        "See the cursor positioned at the exact line and column of the selected code element"
      ],
      "developerVisibleActions": [
        "Navigates to product items (files, functions, endpoints) from navigation trees",
        "Opens files at specific line and column positions",
        "Handles navigation from analysis viewer items",
        "Resolves relative file paths against workspace root",
        "Converts absolute paths to proper file URIs",
        "Shows error messages when files cannot be opened",
        "Manages text document opening and editor display",
        "Handles navigation to entry points from code analysis"
      ],
      "keyFunctions": [
        {
          "name": "navigateToProductItem",
          "desc": "Opens files and navigates to specific code locations (functions, endpoints) from product navigation items",
          "inputs": "ProductNavItem containing file path, function name, and location data",
          "outputs": "Promise<void> - opens document in editor or shows error"
        },
        {
          "name": "navigateToAnalysisItem",
          "desc": "Navigates to code locations from analysis results, positioning cursor at specific lines",
          "inputs": "AnalysisItem with file path and line/column information",
          "outputs": "Promise<void> - opens document and sets cursor position"
        },
        {
          "name": "navigateToEntryPoint",
          "desc": "Jumps to entry point definitions in the codebase from analysis data",
          "inputs": "EntryPoint object with file location and position details",
          "outputs": "Promise<void> - navigates to entry point location"
        },
        {
          "name": "showItemDetails",
          "desc": "Displays detailed information about a selected code item",
          "inputs": "Product item or analysis item with metadata",
          "outputs": "void - shows details in appropriate VS Code panel"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "ProductNavItem from productNavigator",
        "AnalysisItem from analysisViewer",
        "EntryPoint from analyzer"
      ],
      "intent": "This file exists to centralize all navigation logic for the extension, separating the concern of 'going to code locations' from other extension functionality. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual source code files, handling path resolution, error cases, and editor positioning in one place.",
      "rawContent": "```json\n{\n  \"purpose\": \"Handles navigation to files, functions, endpoints, and other code locations within the VS Code editor, displaying details about code items when clicked.\",\n  \"userVisibleActions\": [\n    \"Click on a file item to open that file in the editor\",\n    \"Click on a function to jump to its definition in the source code\",\n    \"Click on an endpoint to navigate to its implementation\",\n    \"Click on an analysis item to view its details in the editor\",\n    \"View error messages when navigation fails to find a file or location\",\n    \"See the cursor positioned at the exact line and column of the selected code element\"\n  ],\n  \"developerVisibleActions\": [\n    \"Navigates to product items (files, functions, endpoints) from navigation trees\",\n    \"Opens files at specific line and column positions\",\n    \"Handles navigation from analysis viewer items\",\n    \"Resolves relative file paths against workspace root\",\n    \"Converts absolute paths to proper file URIs\",\n    \"Shows error messages when files cannot be opened\",\n    \"Manages text document opening and editor display\",\n    \"Handles navigation to entry points from code analysis\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"navigateToProductItem\",\n      \"desc\": \"Opens files and navigates to specific code locations (functions, endpoints) from product navigation items\",\n      \"inputs\": \"ProductNavItem containing file path, function name, and location data\",\n      \"outputs\": \"Promise<void> - opens document in editor or shows error\"\n    },\n    {\n      \"name\": \"navigateToAnalysisItem\",\n      \"desc\": \"Navigates to code locations from analysis results, positioning cursor at specific lines\",\n      \"inputs\": \"AnalysisItem with file path and line/column information\",\n      \"outputs\": \"Promise<void> - opens document and sets cursor position\"\n    },\n    {\n      \"name\": \"navigateToEntryPoint\",\n      \"desc\": \"Jumps to entry point definitions in the codebase from analysis data\",\n      \"inputs\": \"EntryPoint object with file location and position details\",\n      \"outputs\": \"Promise<void> - navigates to entry point location\"\n    },\n    {\n      \"name\": \"showItemDetails\",\n      \"desc\": \"Displays detailed information about a selected code item\",\n      \"inputs\": \"Product item or analysis item with metadata\",\n      \"outputs\": \"void - shows details in appropriate VS Code panel\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"ProductNavItem from productNavigator\",\n    \"AnalysisItem from analysisViewer\",\n    \"EntryPoint from analyzer\"\n  ],\n  \"intent\": \"This file exists to centralize all navigation logic for the extension, separating the concern of 'going to code locations' from other extension functionality. It solves the problem of navigating between different views (product navigator, analysis viewer) and the actual source code files, handling path resolution, error cases, and editor positioning in one place.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/promptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Centralizes and standardizes the construction of LLM prompts for all code analysis, documentation, and testing tasks across the application.",
      "userVisibleActions": [
        "Documentation generation with consistent structure and formatting",
        "Architecture analysis results with standardized depth and detail",
        "Test plan generation following project conventions",
        "Module and file summaries with consistent organization",
        "Product-level documentation that combines all analysis results"
      ],
      "developerVisibleActions": [
        "Call buildArchitecturePrompt() to generate prompts for analyzing code architecture patterns",
        "Call buildProductDocsPrompt() to create prompts for generating product documentation",
        "Call buildProductPurposePrompt() to analyze and extract product purpose from documentation",
        "Call buildFileAnalysisPrompt() to generate file-level analysis prompts with role context",
        "Call buildModuleRollupPrompt() to create module-level summary prompts from file summaries",
        "Call buildProductLevelPrompt() to generate comprehensive product documentation prompts",
        "Call buildPerFileTestPlanPrompt() to create test planning prompts for individual files",
        "Call buildTestCodeGenerationPrompt() to generate actual test code from test plans",
        "All prompts are returned as formatted strings ready for LLM consumption",
        "Prompts include context, code analysis, and metadata to guide LLM responses",
        "Token budgets and formatting instructions are embedded in generated prompts"
      ],
      "keyFunctions": [
        {
          "name": "buildArchitecturePrompt",
          "desc": "Creates a prompt for LLM to analyze code architecture including patterns, structure, and design decisions",
          "inputs": "AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper",
          "outputs": "Formatted string prompt for architecture analysis"
        },
        {
          "name": "buildProductDocsPrompt",
          "desc": "Generates a prompt for extracting product documentation from existing files and context",
          "inputs": "AnalysisContext",
          "outputs": "Formatted string prompt for documentation extraction"
        },
        {
          "name": "buildProductPurposePrompt",
          "desc": "Creates a prompt to analyze and determine the core purpose and goals of the product",
          "inputs": "EnhancedProductDocumentation, AnalysisContext",
          "outputs": "Formatted string prompt for purpose analysis"
        },
        {
          "name": "buildFileAnalysisPrompt",
          "desc": "Generates a prompt for analyzing individual code files including their role and behavior",
          "inputs": "FileInfo, file content string, role string",
          "outputs": "Formatted string prompt for file-level analysis"
        },
        {
          "name": "buildModuleRollupPrompt",
          "desc": "Creates a prompt for summarizing multiple file summaries into a cohesive module summary",
          "inputs": "Module path, module type, array of FileSummary objects",
          "outputs": "Formatted string prompt for module rollup"
        },
        {
          "name": "buildProductLevelPrompt",
          "desc": "Generates a comprehensive prompt for creating product-wide documentation from all analyses",
          "inputs": "FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper",
          "outputs": "Formatted string prompt for product documentation"
        },
        {
          "name": "buildPerFileTestPlanPrompt",
          "desc": "Creates a prompt for generating test plans for individual files based on their functions",
          "inputs": "File path, content, FunctionMetadata array, existing tests, language, test framework, optional project summary",
          "outputs": "Formatted string prompt for test planning"
        },
        {
          "name": "buildTestCodeGenerationPrompt",
          "desc": "Generates a prompt for creating actual test code from test plan specifications",
          "inputs": "Test plan item, source code, function code, language, test framework",
          "outputs": "Formatted string prompt for test code generation"
        }
      ],
      "dependencies": [
        "../../llmService",
        "../../analyzer",
        "../../fileDocumentation",
        "../../fileAccessHelper"
      ],
      "intent": "This file exists to eliminate duplication and ensure consistency across all LLM prompt construction. By centralizing prompt building, it ensures that all AI-driven analysis, documentation, and testing tasks receive properly formatted, context-rich prompts with consistent structure, token budgets, and instructions, making LLM responses more reliable and maintainable.",
      "rawContent": "```json\n{\n  \"purpose\": \"Centralizes and standardizes the construction of LLM prompts for all code analysis, documentation, and testing tasks across the application.\",\n  \"userVisibleActions\": [\n    \"Documentation generation with consistent structure and formatting\",\n    \"Architecture analysis results with standardized depth and detail\",\n    \"Test plan generation following project conventions\",\n    \"Module and file summaries with consistent organization\",\n    \"Product-level documentation that combines all analysis results\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildArchitecturePrompt() to generate prompts for analyzing code architecture patterns\",\n    \"Call buildProductDocsPrompt() to create prompts for generating product documentation\",\n    \"Call buildProductPurposePrompt() to analyze and extract product purpose from documentation\",\n    \"Call buildFileAnalysisPrompt() to generate file-level analysis prompts with role context\",\n    \"Call buildModuleRollupPrompt() to create module-level summary prompts from file summaries\",\n    \"Call buildProductLevelPrompt() to generate comprehensive product documentation prompts\",\n    \"Call buildPerFileTestPlanPrompt() to create test planning prompts for individual files\",\n    \"Call buildTestCodeGenerationPrompt() to generate actual test code from test plans\",\n    \"All prompts are returned as formatted strings ready for LLM consumption\",\n    \"Prompts include context, code analysis, and metadata to guide LLM responses\",\n    \"Token budgets and formatting instructions are embedded in generated prompts\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildArchitecturePrompt\",\n      \"desc\": \"Creates a prompt for LLM to analyze code architecture including patterns, structure, and design decisions\",\n      \"inputs\": \"AnalysisContext, optional CodeAnalysis, ProductDocumentation, ProductPurposeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for architecture analysis\"\n    },\n    {\n      \"name\": \"buildProductDocsPrompt\",\n      \"desc\": \"Generates a prompt for extracting product documentation from existing files and context\",\n      \"inputs\": \"AnalysisContext\",\n      \"outputs\": \"Formatted string prompt for documentation extraction\"\n    },\n    {\n      \"name\": \"buildProductPurposePrompt\",\n      \"desc\": \"Creates a prompt to analyze and determine the core purpose and goals of the product\",\n      \"inputs\": \"EnhancedProductDocumentation, AnalysisContext\",\n      \"outputs\": \"Formatted string prompt for purpose analysis\"\n    },\n    {\n      \"name\": \"buildFileAnalysisPrompt\",\n      \"desc\": \"Generates a prompt for analyzing individual code files including their role and behavior\",\n      \"inputs\": \"FileInfo, file content string, role string\",\n      \"outputs\": \"Formatted string prompt for file-level analysis\"\n    },\n    {\n      \"name\": \"buildModuleRollupPrompt\",\n      \"desc\": \"Creates a prompt for summarizing multiple file summaries into a cohesive module summary\",\n      \"inputs\": \"Module path, module type, array of FileSummary objects\",\n      \"outputs\": \"Formatted string prompt for module rollup\"\n    },\n    {\n      \"name\": \"buildProductLevelPrompt\",\n      \"desc\": \"Generates a comprehensive prompt for creating product-wide documentation from all analyses\",\n      \"inputs\": \"FileSummary array, ModuleSummary array, CodeAnalysis, FileAccessHelper\",\n      \"outputs\": \"Formatted string prompt for product documentation\"\n    },\n    {\n      \"name\": \"buildPerFileTestPlanPrompt\",\n      \"desc\": \"Creates a prompt for generating test plans for individual files based on their functions\",\n      \"inputs\": \"File path, content, FunctionMetadata array, existing tests, language, test framework, optional project summary\",\n      \"outputs\": \"Formatted string prompt for test planning\"\n    },\n    {\n      \"name\": \"buildTestCodeGenerationPrompt\",\n      \"desc\": \"Generates a prompt for creating actual test code from test plan specifications\",\n      \"inputs\": \"Test plan item, source code, function code, language, test framework\",\n      \"outputs\": \"Formatted string prompt for test code generation\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../llmService\",\n    \"../../analyzer\",\n    \"../../fileDocumentation\",\n    \"../../fileAccessHelper\"\n  ],\n  \"intent\": \"This file exists to eliminate duplication and ensure consistency across all LLM prompt construction. By centralizing prompt building, it ensures that all AI-driven analysis, documentation, and testing tasks receive properly formatted, context-rich prompts with consistent structure, token budgets, and instructions, making LLM responses more reliable and maintainable.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/refactoringPromptBuilder.ts",
      "role": "Core Logic",
      "purpose": "Generates detailed, structured prompts for LLM-based code refactoring analysis with function-level extraction plans and migration steps.",
      "userVisibleActions": [
        "Receives comprehensive refactoring recommendations for improving code structure",
        "Gets detailed extraction plans showing which functions should move to new files",
        "Sees step-by-step migration instructions for implementing refactoring changes",
        "Views before-and-after code examples for proposed refactorings",
        "Obtains function dependency analysis showing which functions call or are called by others"
      ],
      "developerVisibleActions": [
        "Builds prompts that request detailed refactoring analysis from LLM services",
        "Incorporates code analysis results, product documentation, and architecture insights into prompts",
        "Generates prompts with function-level metadata including signatures, parameters, and line ranges",
        "Creates extraction plans identifying source files, target files, and functions to move",
        "Includes migration steps and code examples in the refactoring instructions",
        "Constructs prompts that analyze function responsibilities and dependencies"
      ],
      "keyFunctions": [
        {
          "name": "buildDetailedRefactoringPrompt",
          "desc": "Creates a comprehensive prompt for LLM to generate detailed refactoring recommendations",
          "inputs": "context (analysis context), codeAnalysis (code structure), productDocs (optional product documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)",
          "outputs": "Formatted prompt string for LLM consumption"
        },
        {
          "name": "buildFunctionAnalysisSection",
          "desc": "Constructs the section of the prompt containing function-level analysis details",
          "inputs": "functionAnalyses (array of function metadata)",
          "outputs": "Formatted string section with function details"
        },
        {
          "name": "buildExtractionRequirementsSection",
          "desc": "Generates prompt section specifying what extraction plans should include",
          "inputs": "None",
          "outputs": "Formatted string with extraction requirements"
        },
        {
          "name": "buildBasePrompt",
          "desc": "Creates the foundational prompt structure with context and analysis data",
          "inputs": "context, codeAnalysis, productDocs, architectureInsights",
          "outputs": "Base prompt string"
        }
      ],
      "dependencies": [
        "../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)",
        "../../llmService (AnalysisContext, LLMInsights)",
        "../../fileDocumentation (EnhancedProductDocumentation)"
      ],
      "intent": "This file exists to systematically construct detailed, prescriptive prompts that guide LLMs in generating actionable refactoring recommendations. It solves the problem of getting high-quality, structured refactoring analysis by ensuring prompts include all necessary context: function metadata, dependencies, architectural insights, and explicit requirements for extraction plans and migration steps.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates detailed, structured prompts for LLM-based code refactoring analysis with function-level extraction plans and migration steps.\",\n  \"userVisibleActions\": [\n    \"Receives comprehensive refactoring recommendations for improving code structure\",\n    \"Gets detailed extraction plans showing which functions should move to new files\",\n    \"Sees step-by-step migration instructions for implementing refactoring changes\",\n    \"Views before-and-after code examples for proposed refactorings\",\n    \"Obtains function dependency analysis showing which functions call or are called by others\"\n  ],\n  \"developerVisibleActions\": [\n    \"Builds prompts that request detailed refactoring analysis from LLM services\",\n    \"Incorporates code analysis results, product documentation, and architecture insights into prompts\",\n    \"Generates prompts with function-level metadata including signatures, parameters, and line ranges\",\n    \"Creates extraction plans identifying source files, target files, and functions to move\",\n    \"Includes migration steps and code examples in the refactoring instructions\",\n    \"Constructs prompts that analyze function responsibilities and dependencies\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildDetailedRefactoringPrompt\",\n      \"desc\": \"Creates a comprehensive prompt for LLM to generate detailed refactoring recommendations\",\n      \"inputs\": \"context (analysis context), codeAnalysis (code structure), productDocs (optional product documentation), architectureInsights (optional LLM insights), functionAnalyses (optional function metadata)\",\n      \"outputs\": \"Formatted prompt string for LLM consumption\"\n    },\n    {\n      \"name\": \"buildFunctionAnalysisSection\",\n      \"desc\": \"Constructs the section of the prompt containing function-level analysis details\",\n      \"inputs\": \"functionAnalyses (array of function metadata)\",\n      \"outputs\": \"Formatted string section with function details\"\n    },\n    {\n      \"name\": \"buildExtractionRequirementsSection\",\n      \"desc\": \"Generates prompt section specifying what extraction plans should include\",\n      \"inputs\": \"None\",\n      \"outputs\": \"Formatted string with extraction requirements\"\n    },\n    {\n      \"name\": \"buildBasePrompt\",\n      \"desc\": \"Creates the foundational prompt structure with context and analysis data\",\n      \"inputs\": \"context, codeAnalysis, productDocs, architectureInsights\",\n      \"outputs\": \"Base prompt string\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (CodeAnalysis, FileInfo, FunctionMetadata)\",\n    \"../../llmService (AnalysisContext, LLMInsights)\",\n    \"../../fileDocumentation (EnhancedProductDocumentation)\"\n  ],\n  \"intent\": \"This file exists to systematically construct detailed, prescriptive prompts that guide LLMs in generating actionable refactoring recommendations. It solves the problem of getting high-quality, structured refactoring analysis by ensuring prompts include all necessary context: function metadata, dependencies, architectural insights, and explicit requirements for extraction plans and migration steps.\"\n}\n```"
    },
    {
      "file": "src/domain/prompts/testPrompts.ts",
      "role": "Core Logic",
      "purpose": "Provides LLM prompt builders for generating test configuration and test plans from codebase analysis",
      "userVisibleActions": [
        "Generates test setup recommendations when initializing test configuration",
        "Creates prioritized test plans based on code analysis",
        "Provides structured JSON responses for test framework selection",
        "Suggests mock requirements for external dependencies like VSCode API"
      ],
      "developerVisibleActions": [
        "Call buildSetupPrompt() with workspace root and file list to get test configuration recommendations",
        "Call buildPlanningPrompt() with analysis context and functions to generate test strategies",
        "Receive JSON-formatted responses specifying testing frameworks, dependencies, and configurations",
        "Get recommendations for test directory structure and required mock setups",
        "Obtain prioritized lists of functions to test based on complexity and code statistics"
      ],
      "keyFunctions": [
        {
          "name": "buildSetupPrompt",
          "desc": "Generates an LLM prompt that analyzes codebase and recommends test setup configuration",
          "inputs": "workspaceRoot: string, fileList: string[], packageJsonContent?: string",
          "outputs": "string (formatted prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements)"
        },
        {
          "name": "buildPlanningPrompt",
          "desc": "Creates an LLM prompt for generating prioritized test plans from analyzed functions",
          "inputs": "context: AnalysisContext, functions: any[], productDocs?: any, architectureInsights?: any",
          "outputs": "string (formatted prompt with function list and codebase statistics for test strategy generation)"
        }
      ],
      "dependencies": [
        "../../analyzer (AnalysisContext)",
        "../services/testing/types/testPlanTypes (TestableFunction)"
      ],
      "intent": "This file exists to bridge code analysis with LLM-powered test generation by constructing structured prompts that guide the LLM to produce actionable test configurations and strategies. It solves the problem of automating test setup decisions by providing the LLM with relevant codebase context in a format that produces consistent, parseable JSON responses.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides LLM prompt builders for generating test configuration and test plans from codebase analysis\",\n  \"userVisibleActions\": [\n    \"Generates test setup recommendations when initializing test configuration\",\n    \"Creates prioritized test plans based on code analysis\",\n    \"Provides structured JSON responses for test framework selection\",\n    \"Suggests mock requirements for external dependencies like VSCode API\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call buildSetupPrompt() with workspace root and file list to get test configuration recommendations\",\n    \"Call buildPlanningPrompt() with analysis context and functions to generate test strategies\",\n    \"Receive JSON-formatted responses specifying testing frameworks, dependencies, and configurations\",\n    \"Get recommendations for test directory structure and required mock setups\",\n    \"Obtain prioritized lists of functions to test based on complexity and code statistics\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Generates an LLM prompt that analyzes codebase and recommends test setup configuration\",\n      \"inputs\": \"workspaceRoot: string, fileList: string[], packageJsonContent?: string\",\n      \"outputs\": \"string (formatted prompt requesting JSON response with language, framework, dependencies, config files, test directory, and mock requirements)\"\n    },\n    {\n      \"name\": \"buildPlanningPrompt\",\n      \"desc\": \"Creates an LLM prompt for generating prioritized test plans from analyzed functions\",\n      \"inputs\": \"context: AnalysisContext, functions: any[], productDocs?: any, architectureInsights?: any\",\n      \"outputs\": \"string (formatted prompt with function list and codebase statistics for test strategy generation)\"\n    }\n  ],\n  \"dependencies\": [\n    \"../../analyzer (AnalysisContext)\",\n    \"../services/testing/types/testPlanTypes (TestableFunction)\"\n  ],\n  \"intent\": \"This file exists to bridge code analysis with LLM-powered test generation by constructing structured prompts that guide the LLM to produce actionable test configurations and strategies. It solves the problem of automating test setup decisions by providing the LLM with relevant codebase context in a format that produces consistent, parseable JSON responses.\"\n}\n```"
    },
    {
      "file": "src/domain/services/fileWatcherService.ts",
      "role": "Core Logic",
      "purpose": "Provides a centralized service for monitoring file system changes across the extension, consolidating all file watching functionality to eliminate duplication.",
      "userVisibleActions": [
        "Automatically detects when files are created in the workspace",
        "Automatically detects when files are modified in the workspace",
        "Automatically detects when files are deleted from the workspace",
        "Automatically responds when user saves a document in the editor",
        "Filters out specific files or patterns from being watched (e.g., ignoring certain directories)",
        "Triggers updates in various UI components when relevant files change"
      ],
      "developerVisibleActions": [
        "Register file watchers for specific file patterns (e.g., '**/*.md', '**/*.json')",
        "Receive notifications when files matching patterns are created, changed, or deleted",
        "Subscribe to document save events across all open documents",
        "Configure which file system events to monitor (create, change, delete)",
        "Set up ignore patterns to exclude certain files from being watched",
        "Clean up watchers when components are disposed",
        "Handle file change events asynchronously with custom logic",
        "Use a single service instance to avoid duplicate file watchers"
      ],
      "keyFunctions": [
        {
          "name": "watch",
          "desc": "Registers a file watcher for a specific pattern and returns a disposable to stop watching",
          "inputs": "id (string), pattern (glob or RelativePattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)",
          "outputs": "vscode.Disposable to stop the watcher"
        },
        {
          "name": "onDocumentSave",
          "desc": "Registers a handler to be called whenever any document is saved in the editor",
          "inputs": "handler (callback function accepting TextDocument)",
          "outputs": "vscode.Disposable to unregister the handler"
        },
        {
          "name": "dispose",
          "desc": "Cleans up all active file watchers and document save handlers",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getPatternKey",
          "desc": "Generates a unique key for a file pattern to avoid duplicate watchers",
          "inputs": "pattern (string or RelativePattern)",
          "outputs": "string key"
        },
        {
          "name": "shouldIgnore",
          "desc": "Determines if a file path should be ignored based on configured patterns",
          "inputs": "filePath (string), ignorePatterns (array of glob patterns)",
          "outputs": "boolean indicating whether to ignore the file"
        },
        {
          "name": "handleFileSystemEvent",
          "desc": "Processes file system events and dispatches them to registered handlers",
          "inputs": "uri (file URI), type (created/changed/deleted), patternKey (string)",
          "outputs": "void (triggers async handlers)"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs"
      ],
      "intent": "This file exists to eliminate code duplication across multiple extension components that need to watch for file changes. Previously, fileWatcher.ts, productNavigator.ts, and insightsViewer.ts each had their own file watching logic. By consolidating into a single service, the extension can efficiently manage file system monitoring, avoid redundant watchers, ensure consistent behavior, and make it easier to maintain file watching functionality across the entire codebase.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a centralized service for monitoring file system changes across the extension, consolidating all file watching functionality to eliminate duplication.\",\n  \"userVisibleActions\": [\n    \"Automatically detects when files are created in the workspace\",\n    \"Automatically detects when files are modified in the workspace\",\n    \"Automatically detects when files are deleted from the workspace\",\n    \"Automatically responds when user saves a document in the editor\",\n    \"Filters out specific files or patterns from being watched (e.g., ignoring certain directories)\",\n    \"Triggers updates in various UI components when relevant files change\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register file watchers for specific file patterns (e.g., '**/*.md', '**/*.json')\",\n    \"Receive notifications when files matching patterns are created, changed, or deleted\",\n    \"Subscribe to document save events across all open documents\",\n    \"Configure which file system events to monitor (create, change, delete)\",\n    \"Set up ignore patterns to exclude certain files from being watched\",\n    \"Clean up watchers when components are disposed\",\n    \"Handle file change events asynchronously with custom logic\",\n    \"Use a single service instance to avoid duplicate file watchers\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"watch\",\n      \"desc\": \"Registers a file watcher for a specific pattern and returns a disposable to stop watching\",\n      \"inputs\": \"id (string), pattern (glob or RelativePattern), handler (callback function), options (ignorePatterns, watchCreate, watchChange, watchDelete flags)\",\n      \"outputs\": \"vscode.Disposable to stop the watcher\"\n    },\n    {\n      \"name\": \"onDocumentSave\",\n      \"desc\": \"Registers a handler to be called whenever any document is saved in the editor\",\n      \"inputs\": \"handler (callback function accepting TextDocument)\",\n      \"outputs\": \"vscode.Disposable to unregister the handler\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up all active file watchers and document save handlers\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getPatternKey\",\n      \"desc\": \"Generates a unique key for a file pattern to avoid duplicate watchers\",\n      \"inputs\": \"pattern (string or RelativePattern)\",\n      \"outputs\": \"string key\"\n    },\n    {\n      \"name\": \"shouldIgnore\",\n      \"desc\": \"Determines if a file path should be ignored based on configured patterns\",\n      \"inputs\": \"filePath (string), ignorePatterns (array of glob patterns)\",\n      \"outputs\": \"boolean indicating whether to ignore the file\"\n    },\n    {\n      \"name\": \"handleFileSystemEvent\",\n      \"desc\": \"Processes file system events and dispatches them to registered handlers\",\n      \"inputs\": \"uri (file URI), type (created/changed/deleted), patternKey (string)\",\n      \"outputs\": \"void (triggers async handlers)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\"\n  ],\n  \"intent\": \"This file exists to eliminate code duplication across multiple extension components that need to watch for file changes. Previously, fileWatcher.ts, productNavigator.ts, and insightsViewer.ts each had their own file watching logic. By consolidating into a single service, the extension can efficiently manage file system monitoring, avoid redundant watchers, ensure consistent behavior, and make it easier to maintain file watching functionality across the entire codebase.\"\n}\n```"
    },
    {
      "file": "src/domain/services/incrementalAnalysisService.ts",
      "role": "Core Logic",
      "purpose": "Manages iterative LLM analysis by processing file and grep requests across multiple analysis iterations until completion or limit is reached",
      "userVisibleActions": [
        "Performs multi-step code analysis that progressively gathers more information",
        "Reads additional files when the AI needs more context",
        "Searches code using grep when the AI needs to find specific patterns",
        "Limits analysis to prevent infinite loops (max iterations)",
        "Shows progress through iteration callbacks during long-running analysis"
      ],
      "developerVisibleActions": [
        "Provides async iterator pattern for testable incremental analysis",
        "Executes file read requests from LLM responses",
        "Executes grep search requests from LLM responses",
        "Limits requests to 5 per iteration to prevent overload",
        "Maintains conversation history across iterations",
        "Returns structured results with iteration count and request history",
        "Notifies through callbacks when iterations start and complete",
        "Determines when to continue or stop iterations"
      ],
      "keyFunctions": [
        {
          "name": "processRequests",
          "desc": "Processes LLM file and grep requests to gather additional information",
          "inputs": "requests (LLMRequest[]), currentResult (any), messages (conversation history)",
          "outputs": "ProcessRequestsResult with additionalInfo string and updated messages array"
        },
        {
          "name": "readFiles",
          "desc": "Reads requested files through FileAccessHelper",
          "inputs": "file paths from LLM requests",
          "outputs": "formatted file content as additional info"
        },
        {
          "name": "performGrep",
          "desc": "Executes grep searches through FileAccessHelper",
          "inputs": "grep requests with patterns and paths",
          "outputs": "formatted search results as additional info"
        },
        {
          "name": "async iterator pattern",
          "desc": "Converts while loops to async iterator for iteration control",
          "inputs": "iteration callbacks and max iterations",
          "outputs": "IterationResult with result, iteration count, requests, and continuation flag"
        }
      ],
      "dependencies": [
        "FileAccessHelper",
        "LLMRequest types"
      ],
      "intent": "Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a testable, reusable service that handles the common pattern of LLM requesting additional files and performing searches during multi-step code analysis",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages iterative LLM analysis by processing file and grep requests across multiple analysis iterations until completion or limit is reached\",\n  \"userVisibleActions\": [\n    \"Performs multi-step code analysis that progressively gathers more information\",\n    \"Reads additional files when the AI needs more context\",\n    \"Searches code using grep when the AI needs to find specific patterns\",\n    \"Limits analysis to prevent infinite loops (max iterations)\",\n    \"Shows progress through iteration callbacks during long-running analysis\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides async iterator pattern for testable incremental analysis\",\n    \"Executes file read requests from LLM responses\",\n    \"Executes grep search requests from LLM responses\",\n    \"Limits requests to 5 per iteration to prevent overload\",\n    \"Maintains conversation history across iterations\",\n    \"Returns structured results with iteration count and request history\",\n    \"Notifies through callbacks when iterations start and complete\",\n    \"Determines when to continue or stop iterations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"processRequests\",\n      \"desc\": \"Processes LLM file and grep requests to gather additional information\",\n      \"inputs\": \"requests (LLMRequest[]), currentResult (any), messages (conversation history)\",\n      \"outputs\": \"ProcessRequestsResult with additionalInfo string and updated messages array\"\n    },\n    {\n      \"name\": \"readFiles\",\n      \"desc\": \"Reads requested files through FileAccessHelper\",\n      \"inputs\": \"file paths from LLM requests\",\n      \"outputs\": \"formatted file content as additional info\"\n    },\n    {\n      \"name\": \"performGrep\",\n      \"desc\": \"Executes grep searches through FileAccessHelper\",\n      \"inputs\": \"grep requests with patterns and paths\",\n      \"outputs\": \"formatted search results as additional info\"\n    },\n    {\n      \"name\": \"async iterator pattern\",\n      \"desc\": \"Converts while loops to async iterator for iteration control\",\n      \"inputs\": \"iteration callbacks and max iterations\",\n      \"outputs\": \"IterationResult with result, iteration count, requests, and continuation flag\"\n    }\n  ],\n  \"dependencies\": [\n    \"FileAccessHelper\",\n    \"LLMRequest types\"\n  ],\n  \"intent\": \"Eliminates code duplication from llmService.ts by extracting iterative analysis logic into a testable, reusable service that handles the common pattern of LLM requesting additional files and performing searches during multi-step code analysis\"\n}\n```"
    },
    {
      "file": "src/domain/services/testConfigurationService.ts",
      "role": "Core Logic",
      "purpose": "Automatically detects test framework configuration and identifies setup requirements to ensure generated tests work without manual user configuration",
      "userVisibleActions": [
        "Test framework is automatically detected from project files",
        "Missing test dependencies are identified and reported",
        "Configuration issues are detected and flagged",
        "Setup requirements are automatically determined",
        "Test configuration status is provided"
      ],
      "developerVisibleActions": [
        "Service scans workspace root for package.json and test configuration files",
        "Detects which test framework is in use (Jest, Mocha, Vitest, Pytest)",
        "Checks if test dependencies are installed",
        "Identifies missing dependencies that need to be installed",
        "Determines if TypeScript test support is configured",
        "Provides list of setup actions needed to make tests work",
        "Returns comprehensive test configuration status"
      ],
      "keyFunctions": [
        {
          "name": "detectTestConfiguration",
          "desc": "Analyzes workspace to detect test framework and configuration status",
          "inputs": "workspaceRoot: string (path to workspace)",
          "outputs": "TestConfigStatus (framework type, configuration state, missing dependencies, setup actions)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "SWLogger"
      ],
      "intent": "Eliminates the need for users to manually configure test environments by automatically detecting what test framework is being used, what's already configured, and what needs to be set up to make generated tests run successfully",
      "rawContent": "```json\n{\n  \"purpose\": \"Automatically detects test framework configuration and identifies setup requirements to ensure generated tests work without manual user configuration\",\n  \"userVisibleActions\": [\n    \"Test framework is automatically detected from project files\",\n    \"Missing test dependencies are identified and reported\",\n    \"Configuration issues are detected and flagged\",\n    \"Setup requirements are automatically determined\",\n    \"Test configuration status is provided\"\n  ],\n  \"developerVisibleActions\": [\n    \"Service scans workspace root for package.json and test configuration files\",\n    \"Detects which test framework is in use (Jest, Mocha, Vitest, Pytest)\",\n    \"Checks if test dependencies are installed\",\n    \"Identifies missing dependencies that need to be installed\",\n    \"Determines if TypeScript test support is configured\",\n    \"Provides list of setup actions needed to make tests work\",\n    \"Returns comprehensive test configuration status\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestConfiguration\",\n      \"desc\": \"Analyzes workspace to detect test framework and configuration status\",\n      \"inputs\": \"workspaceRoot: string (path to workspace)\",\n      \"outputs\": \"TestConfigStatus (framework type, configuration state, missing dependencies, setup actions)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"Eliminates the need for users to manually configure test environments by automatically detecting what test framework is being used, what's already configured, and what needs to be set up to make generated tests run successfully\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestGenerationService.ts",
      "role": "Core Logic",
      "purpose": "Generates unit tests for code functions in small batches using an LLM service, with progress tracking and execution validation.",
      "userVisibleActions": [
        "Progress updates showing current function being tested (e.g., 'Processing function 3 of 10: calculateTotal')",
        "Test generation results for each function with pass/fail status",
        "Error messages when test generation or execution fails",
        "Notifications about which functions have been successfully tested"
      ],
      "developerVisibleActions": [
        "Trigger test generation for a batch of functions by providing function metadata and workspace path",
        "Receive progress callbacks during batch processing showing which function is currently being processed",
        "Get structured test generation results including generated test code and execution status",
        "Access test state that tracks which functions have been processed and which remain",
        "View generated test code that can be saved to test files",
        "See whether generated tests pass or fail when executed",
        "Extract function source code from workspace files for test context"
      ],
      "keyFunctions": [
        {
          "name": "generateTestBatch",
          "desc": "Generates tests for multiple functions in a batch, calling LLM for each function and tracking progress",
          "inputs": "functions (array of TestableFunction), workspaceRoot (string), llmService (LLM service instance), onProgress (optional callback)",
          "outputs": "Map of function names to TestGenerationResult objects"
        },
        {
          "name": "extractFunctionSource",
          "desc": "Reads and extracts the source code of a specific function from the workspace files",
          "inputs": "func (TestableFunction), workspaceRoot (string)",
          "outputs": "Source code string for the function"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./types/testPlanTypes",
        "./types/testResultTypes",
        "../../prompts/testPrompts",
        "./testExecutionService",
        "../../../logger"
      ],
      "intent": "Enables incremental, batch-based test generation using LLMs to avoid overwhelming the system with too many simultaneous test generation requests. Provides progress tracking so developers can monitor which functions are being tested and get immediate feedback on test generation success or failure.",
      "rawContent": "```json\n{\n  \"purpose\": \"Generates unit tests for code functions in small batches using an LLM service, with progress tracking and execution validation.\",\n  \"userVisibleActions\": [\n    \"Progress updates showing current function being tested (e.g., 'Processing function 3 of 10: calculateTotal')\",\n    \"Test generation results for each function with pass/fail status\",\n    \"Error messages when test generation or execution fails\",\n    \"Notifications about which functions have been successfully tested\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test generation for a batch of functions by providing function metadata and workspace path\",\n    \"Receive progress callbacks during batch processing showing which function is currently being processed\",\n    \"Get structured test generation results including generated test code and execution status\",\n    \"Access test state that tracks which functions have been processed and which remain\",\n    \"View generated test code that can be saved to test files\",\n    \"See whether generated tests pass or fail when executed\",\n    \"Extract function source code from workspace files for test context\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateTestBatch\",\n      \"desc\": \"Generates tests for multiple functions in a batch, calling LLM for each function and tracking progress\",\n      \"inputs\": \"functions (array of TestableFunction), workspaceRoot (string), llmService (LLM service instance), onProgress (optional callback)\",\n      \"outputs\": \"Map of function names to TestGenerationResult objects\"\n    },\n    {\n      \"name\": \"extractFunctionSource\",\n      \"desc\": \"Reads and extracts the source code of a specific function from the workspace files\",\n      \"inputs\": \"func (TestableFunction), workspaceRoot (string)\",\n      \"outputs\": \"Source code string for the function\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./types/testPlanTypes\",\n    \"./types/testResultTypes\",\n    \"../../prompts/testPrompts\",\n    \"./testExecutionService\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"Enables incremental, batch-based test generation using LLMs to avoid overwhelming the system with too many simultaneous test generation requests. Provides progress tracking so developers can monitor which functions are being tested and get immediate feedback on test generation success or failure.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestPlanningService.ts",
      "role": "Core Logic",
      "purpose": "Creates prioritized test plans by analyzing code functions using LLM to determine which functions should be tested and in what order.",
      "userVisibleActions": [
        "Receives a test plan showing which functions in their codebase need testing",
        "Sees functions categorized by priority and complexity",
        "Gets count of testable vs non-testable functions",
        "Views function groups organized for testing strategy"
      ],
      "developerVisibleActions": [
        "Calls analyzeFunctions() to extract function metadata from code analysis results",
        "Invokes createTestPlan() to generate LLM-based test strategy with context, functions, and optional documentation",
        "Uses saveTestPlanToDisk() to persist the generated test plan to a file",
        "Receives structured TestPlan object containing function groups and testability assessment",
        "Sees logging output showing number of functions analyzed and how many are testable"
      ],
      "keyFunctions": [
        {
          "name": "analyzeFunctions",
          "desc": "Extracts and normalizes function information from code analysis results",
          "inputs": "codeAnalysis object containing functions array",
          "outputs": "Array of function metadata including name, file, line numbers, complexity, parameters, and return type"
        },
        {
          "name": "createTestPlan",
          "desc": "Generates a prioritized test plan by sending function data to LLM service",
          "inputs": "AnalysisContext, functions array, llmService, optional productDocs and architectureInsights",
          "outputs": "TestPlan object with function groups and testability metrics"
        },
        {
          "name": "saveTestPlanToDisk",
          "desc": "Persists the generated test plan to a JSON file in the analysis results directory",
          "inputs": "context (containing resultDir path) and testPlan object",
          "outputs": "void (writes file to disk)"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "./types/testPlanTypes",
        "../../prompts/testPrompts",
        "../../../analyzer",
        "../../../logger"
      ],
      "intent": "This service exists to automate test planning by leveraging LLM intelligence to analyze code functions and determine optimal testing strategies. It solves the problem of manually identifying which functions need testing and prioritizing test effort based on function complexity, parameters, and codebase context.",
      "rawContent": "```json\n{\n  \"purpose\": \"Creates prioritized test plans by analyzing code functions using LLM to determine which functions should be tested and in what order.\",\n  \"userVisibleActions\": [\n    \"Receives a test plan showing which functions in their codebase need testing\",\n    \"Sees functions categorized by priority and complexity\",\n    \"Gets count of testable vs non-testable functions\",\n    \"Views function groups organized for testing strategy\"\n  ],\n  \"developerVisibleActions\": [\n    \"Calls analyzeFunctions() to extract function metadata from code analysis results\",\n    \"Invokes createTestPlan() to generate LLM-based test strategy with context, functions, and optional documentation\",\n    \"Uses saveTestPlanToDisk() to persist the generated test plan to a file\",\n    \"Receives structured TestPlan object containing function groups and testability assessment\",\n    \"Sees logging output showing number of functions analyzed and how many are testable\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeFunctions\",\n      \"desc\": \"Extracts and normalizes function information from code analysis results\",\n      \"inputs\": \"codeAnalysis object containing functions array\",\n      \"outputs\": \"Array of function metadata including name, file, line numbers, complexity, parameters, and return type\"\n    },\n    {\n      \"name\": \"createTestPlan\",\n      \"desc\": \"Generates a prioritized test plan by sending function data to LLM service\",\n      \"inputs\": \"AnalysisContext, functions array, llmService, optional productDocs and architectureInsights\",\n      \"outputs\": \"TestPlan object with function groups and testability metrics\"\n    },\n    {\n      \"name\": \"saveTestPlanToDisk\",\n      \"desc\": \"Persists the generated test plan to a JSON file in the analysis results directory\",\n      \"inputs\": \"context (containing resultDir path) and testPlan object\",\n      \"outputs\": \"void (writes file to disk)\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./types/testPlanTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../analyzer\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This service exists to automate test planning by leveraging LLM intelligence to analyze code functions and determine optimal testing strategies. It solves the problem of manually identifying which functions need testing and prioritizing test effort based on function complexity, parameters, and codebase context.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestSetupService.ts",
      "role": "Core Logic",
      "purpose": "Detects the test environment and generates LLM-powered test setup configurations for different programming languages and frameworks.",
      "userVisibleActions": [
        "Automatically detects the project's testing framework and language",
        "Generates test configuration files based on the detected environment",
        "Creates test directory structure if missing",
        "Installs required testing dependencies",
        "Sets up appropriate test runners (Jest, pytest, JUnit, etc.)"
      ],
      "developerVisibleActions": [
        "Call detectTestEnvironment() to analyze project structure and identify language/framework",
        "Use LLM prompts to generate context-aware test setup plans",
        "Execute setup plans to install dependencies and create configuration files",
        "Receive structured TestEnvironment data showing what was detected",
        "Get TestSetupPlan with specific actions needed to configure testing",
        "Obtain SetupExecutionResult indicating success/failure of setup operations"
      ],
      "keyFunctions": [
        {
          "name": "detectTestEnvironment",
          "desc": "Analyzes workspace to detect primary language, testing framework, and existing test setup",
          "inputs": "workspaceRoot: string (path to project root)",
          "outputs": "TestEnvironment object containing language, framework, and configuration status"
        },
        {
          "name": "getAllFiles",
          "desc": "Recursively scans directory to find all files for language detection",
          "inputs": "directory path",
          "outputs": "Array of file paths"
        },
        {
          "name": "buildSetupPrompt",
          "desc": "Constructs LLM prompt for generating test setup configuration",
          "inputs": "TestEnvironment data",
          "outputs": "Formatted prompt string for LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "child_process",
        "./types/testSetupTypes",
        "../../prompts/testPrompts",
        "../../../logger"
      ],
      "intent": "This file exists to eliminate manual test setup by automatically detecting a project's programming environment and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, install dependencies, and create test structures for different languages and environments by using LLM intelligence to understand the project context and generate optimal setup plans.",
      "rawContent": "```json\n{\n  \"purpose\": \"Detects the test environment and generates LLM-powered test setup configurations for different programming languages and frameworks.\",\n  \"userVisibleActions\": [\n    \"Automatically detects the project's testing framework and language\",\n    \"Generates test configuration files based on the detected environment\",\n    \"Creates test directory structure if missing\",\n    \"Installs required testing dependencies\",\n    \"Sets up appropriate test runners (Jest, pytest, JUnit, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call detectTestEnvironment() to analyze project structure and identify language/framework\",\n    \"Use LLM prompts to generate context-aware test setup plans\",\n    \"Execute setup plans to install dependencies and create configuration files\",\n    \"Receive structured TestEnvironment data showing what was detected\",\n    \"Get TestSetupPlan with specific actions needed to configure testing\",\n    \"Obtain SetupExecutionResult indicating success/failure of setup operations\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"detectTestEnvironment\",\n      \"desc\": \"Analyzes workspace to detect primary language, testing framework, and existing test setup\",\n      \"inputs\": \"workspaceRoot: string (path to project root)\",\n      \"outputs\": \"TestEnvironment object containing language, framework, and configuration status\"\n    },\n    {\n      \"name\": \"getAllFiles\",\n      \"desc\": \"Recursively scans directory to find all files for language detection\",\n      \"inputs\": \"directory path\",\n      \"outputs\": \"Array of file paths\"\n    },\n    {\n      \"name\": \"buildSetupPrompt\",\n      \"desc\": \"Constructs LLM prompt for generating test setup configuration\",\n      \"inputs\": \"TestEnvironment data\",\n      \"outputs\": \"Formatted prompt string for LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"./types/testSetupTypes\",\n    \"../../prompts/testPrompts\",\n    \"../../../logger\"\n  ],\n  \"intent\": \"This file exists to eliminate manual test setup by automatically detecting a project's programming environment and generating appropriate test configurations. It solves the problem of developers needing to manually configure testing frameworks, install dependencies, and create test structures for different languages and environments by using LLM intelligence to understand the project context and generate optimal setup plans.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/llmTestValidationService.ts",
      "role": "Core Logic",
      "purpose": "Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution",
      "userVisibleActions": [
        "Tests are automatically run and validated",
        "Failing tests are detected and reported with detailed error messages",
        "Tests are automatically fixed through multiple retry attempts",
        "Test execution results show passed/failed counts and success rates",
        "Detailed test reports are generated showing which tests passed or failed"
      ],
      "developerVisibleActions": [
        "Trigger test validation for specific test files or entire workspace",
        "Configure maximum retry attempts for automatic test fixing",
        "Receive structured test execution results with pass/fail statistics",
        "Access detailed error messages and stack traces for failed tests",
        "Get feedback on which fix attempts succeeded or failed",
        "Review generated test reports with comprehensive test outcomes"
      ],
      "keyFunctions": [
        {
          "name": "runTests",
          "desc": "Executes all tests or a specific test file and captures results",
          "inputs": "workspaceRoot (string), optional testFile (string)",
          "outputs": "Array of TestExecutionResult objects with pass/fail statistics"
        },
        {
          "name": "fixFailingTest",
          "desc": "Attempts to automatically fix a failing test using LLM with retry logic",
          "inputs": "testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)",
          "outputs": "Object with success status, number of attempts, and final error if failed"
        },
        {
          "name": "buildFixPrompt",
          "desc": "Constructs an LLM prompt for fixing test failures based on error context",
          "inputs": "Test file content, execution results, error details",
          "outputs": "Formatted prompt string for LLM processing"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "TestExecutionService",
        "testResultTypes (TestExecutionResult, TestReport, TestReportSummary)",
        "testPrompts (buildFixPrompt)",
        "SWLogger"
      ],
      "intent": "This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.",
      "rawContent": "```json\n{\n  \"purpose\": \"Validates and automatically fixes failing tests using LLM-powered code generation and iterative execution\",\n  \"userVisibleActions\": [\n    \"Tests are automatically run and validated\",\n    \"Failing tests are detected and reported with detailed error messages\",\n    \"Tests are automatically fixed through multiple retry attempts\",\n    \"Test execution results show passed/failed counts and success rates\",\n    \"Detailed test reports are generated showing which tests passed or failed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Trigger test validation for specific test files or entire workspace\",\n    \"Configure maximum retry attempts for automatic test fixing\",\n    \"Receive structured test execution results with pass/fail statistics\",\n    \"Access detailed error messages and stack traces for failed tests\",\n    \"Get feedback on which fix attempts succeeded or failed\",\n    \"Review generated test reports with comprehensive test outcomes\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runTests\",\n      \"desc\": \"Executes all tests or a specific test file and captures results\",\n      \"inputs\": \"workspaceRoot (string), optional testFile (string)\",\n      \"outputs\": \"Array of TestExecutionResult objects with pass/fail statistics\"\n    },\n    {\n      \"name\": \"fixFailingTest\",\n      \"desc\": \"Attempts to automatically fix a failing test using LLM with retry logic\",\n      \"inputs\": \"testFilePath, executionResult, workspaceRoot, llmService, maxAttempts (default 3)\",\n      \"outputs\": \"Object with success status, number of attempts, and final error if failed\"\n    },\n    {\n      \"name\": \"buildFixPrompt\",\n      \"desc\": \"Constructs an LLM prompt for fixing test failures based on error context\",\n      \"inputs\": \"Test file content, execution results, error details\",\n      \"outputs\": \"Formatted prompt string for LLM processing\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"TestExecutionService\",\n    \"testResultTypes (TestExecutionResult, TestReport, TestReportSummary)\",\n    \"testPrompts (buildFixPrompt)\",\n    \"SWLogger\"\n  ],\n  \"intent\": \"This file solves the problem of manual test debugging by automating test validation and repair. When tests fail during development, it automatically detects failures, generates fix attempts using LLM intelligence, applies the fixes, and re-runs tests until they pass or max attempts are reached. This significantly reduces developer time spent debugging and fixing broken tests.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/testExecutionService.ts",
      "role": "Core Logic",
      "purpose": "Executes test suites (Jest, Mocha, Pytest) and captures their results in a structured format",
      "userVisibleActions": [
        "Run all tests in the workspace",
        "Run tests for a specific file",
        "View test execution results (passed, failed, error counts)",
        "See test execution duration",
        "View detailed error messages and stack traces for failed tests",
        "Get test coverage information when available"
      ],
      "developerVisibleActions": [
        "Call runJest() to execute Jest tests with optional file parameter",
        "Call runMocha() to execute Mocha tests with optional file parameter",
        "Call runPytest() to execute Python pytest with optional file parameter",
        "Receive TestExecutionResult array with status, counts, and error details",
        "Handle test execution errors and timeouts",
        "Parse JSON output from test runners automatically",
        "Access test coverage data from execution results"
      ],
      "keyFunctions": [
        {
          "name": "runJest",
          "desc": "Executes Jest tests for a specific file or entire workspace",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runMocha",
          "desc": "Executes Mocha tests for a specific file or entire workspace",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "runPytest",
          "desc": "Executes Python pytest for a specific file or entire workspace",
          "inputs": "workspaceRoot: string, testFile?: string",
          "outputs": "Promise<TestExecutionResult[]>"
        },
        {
          "name": "parseJestOutput",
          "desc": "Parses JSON output from Jest test execution into structured results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parseMochaOutput",
          "desc": "Parses JSON output from Mocha test execution into structured results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        },
        {
          "name": "parsePytestOutput",
          "desc": "Parses JSON output from pytest execution into structured results",
          "inputs": "stdout: string, stderr: string",
          "outputs": "TestExecutionResult[]"
        }
      ],
      "dependencies": [
        "child_process",
        "path",
        "./types/testResultTypes"
      ],
      "intent": "Provides a unified interface for executing different test frameworks (Jest, Mocha, Pytest) and converting their outputs into a consistent result format, enabling the extension to support multiple testing technologies with test execution, result tracking, and error reporting capabilities.",
      "rawContent": "```json\n{\n  \"purpose\": \"Executes test suites (Jest, Mocha, Pytest) and captures their results in a structured format\",\n  \"userVisibleActions\": [\n    \"Run all tests in the workspace\",\n    \"Run tests for a specific file\",\n    \"View test execution results (passed, failed, error counts)\",\n    \"See test execution duration\",\n    \"View detailed error messages and stack traces for failed tests\",\n    \"Get test coverage information when available\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call runJest() to execute Jest tests with optional file parameter\",\n    \"Call runMocha() to execute Mocha tests with optional file parameter\",\n    \"Call runPytest() to execute Python pytest with optional file parameter\",\n    \"Receive TestExecutionResult array with status, counts, and error details\",\n    \"Handle test execution errors and timeouts\",\n    \"Parse JSON output from test runners automatically\",\n    \"Access test coverage data from execution results\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"runJest\",\n      \"desc\": \"Executes Jest tests for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runMocha\",\n      \"desc\": \"Executes Mocha tests for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"runPytest\",\n      \"desc\": \"Executes Python pytest for a specific file or entire workspace\",\n      \"inputs\": \"workspaceRoot: string, testFile?: string\",\n      \"outputs\": \"Promise<TestExecutionResult[]>\"\n    },\n    {\n      \"name\": \"parseJestOutput\",\n      \"desc\": \"Parses JSON output from Jest test execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parseMochaOutput\",\n      \"desc\": \"Parses JSON output from Mocha test execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    },\n    {\n      \"name\": \"parsePytestOutput\",\n      \"desc\": \"Parses JSON output from pytest execution into structured results\",\n      \"inputs\": \"stdout: string, stderr: string\",\n      \"outputs\": \"TestExecutionResult[]\"\n    }\n  ],\n  \"dependencies\": [\n    \"child_process\",\n    \"path\",\n    \"./types/testResultTypes\"\n  ],\n  \"intent\": \"Provides a unified interface for executing different test frameworks (Jest, Mocha, Pytest) and converting their outputs into a consistent result format, enabling the extension to support multiple testing technologies with test execution, result tracking, and error reporting capabilities.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testPlanTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type structures for organizing and tracking automated test generation across codebases",
      "userVisibleActions": [
        "View test generation progress with phase indicators (setup, planning, generation, validation, complete)",
        "See total count of functions analyzed and how many are testable",
        "Track which functions have been tested and which failed",
        "Monitor test generation organized by function groups with priorities",
        "View detailed function information including complexity and dependencies"
      ],
      "developerVisibleActions": [
        "Define test plans with strategy selection and function grouping",
        "Structure testable functions with metadata (file location, line numbers, complexity, dependencies)",
        "Track test generation state across multiple phases with batch processing",
        "Group functions by priority for systematic test generation",
        "Record test failures with error messages and retry attempts",
        "Mark functions that require mocking based on dependencies",
        "Include function parameters and return types for accurate test generation"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a standardized type system for the test planning service to organize code analysis results, track test generation progress through multiple phases, and structure metadata needed for automated test creation across large codebases with proper prioritization and failure handling",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type structures for organizing and tracking automated test generation across codebases\",\n  \"userVisibleActions\": [\n    \"View test generation progress with phase indicators (setup, planning, generation, validation, complete)\",\n    \"See total count of functions analyzed and how many are testable\",\n    \"Track which functions have been tested and which failed\",\n    \"Monitor test generation organized by function groups with priorities\",\n    \"View detailed function information including complexity and dependencies\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define test plans with strategy selection and function grouping\",\n    \"Structure testable functions with metadata (file location, line numbers, complexity, dependencies)\",\n    \"Track test generation state across multiple phases with batch processing\",\n    \"Group functions by priority for systematic test generation\",\n    \"Record test failures with error messages and retry attempts\",\n    \"Mark functions that require mocking based on dependencies\",\n    \"Include function parameters and return types for accurate test generation\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a standardized type system for the test planning service to organize code analysis results, track test generation progress through multiple phases, and structure metadata needed for automated test creation across large codebases with proper prioritization and failure handling\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testResultTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript type definitions for test generation, validation, execution results, and reporting",
      "userVisibleActions": [
        "View test generation results showing which test files were created with their imports and mocks",
        "See test validation status indicating whether tests passed, failed, or encountered errors",
        "Review test execution results showing how many tests passed, failed, or had errors with duration",
        "Read test reports with summaries, pass rates, and recommendations for improvement",
        "Examine error details including test names, error messages, and stack traces when tests fail"
      ],
      "developerVisibleActions": [
        "Define structure for test generation output including file paths, imports, mocks, and test code",
        "Specify test validation results with status, fixed code, and remaining issues",
        "Structure test execution results with pass/fail counts and timing information",
        "Create test reports with summaries and recommendations",
        "Define mock statement format with explanations for generated test mocks",
        "Capture setup and teardown code for test initialization and cleanup"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a strongly-typed contract for test generation and validation workflows, ensuring consistent data structures across test creation, execution, and reporting phases. Enables type-safe handling of test results, error details, and test report generation throughout the testing service.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript type definitions for test generation, validation, execution results, and reporting\",\n  \"userVisibleActions\": [\n    \"View test generation results showing which test files were created with their imports and mocks\",\n    \"See test validation status indicating whether tests passed, failed, or encountered errors\",\n    \"Review test execution results showing how many tests passed, failed, or had errors with duration\",\n    \"Read test reports with summaries, pass rates, and recommendations for improvement\",\n    \"Examine error details including test names, error messages, and stack traces when tests fail\"\n  ],\n  \"developerVisibleActions\": [\n    \"Define structure for test generation output including file paths, imports, mocks, and test code\",\n    \"Specify test validation results with status, fixed code, and remaining issues\",\n    \"Structure test execution results with pass/fail counts and timing information\",\n    \"Create test reports with summaries and recommendations\",\n    \"Define mock statement format with explanations for generated test mocks\",\n    \"Capture setup and teardown code for test initialization and cleanup\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a strongly-typed contract for test generation and validation workflows, ensuring consistent data structures across test creation, execution, and reporting phases. Enables type-safe handling of test results, error details, and test report generation throughout the testing service.\"\n}\n```"
    },
    {
      "file": "src/domain/services/testing/types/testSetupTypes.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service.",
      "userVisibleActions": [
        "Test setup plans are created with specific testing frameworks and dependencies",
        "Configuration files are generated for the test environment",
        "Test directories are established in the project",
        "Dependencies are installed for testing frameworks",
        "Success or error messages are displayed after test setup execution"
      ],
      "developerVisibleActions": [
        "Provides type-safe structures for planning test setup with language, framework, and dependency information",
        "Enables detection of existing test environment features (package.json, tsconfig, jest config, test directories)",
        "Structures mock requirements with types and reasons for test isolation",
        "Returns execution results with lists of created files, installed dependencies, and any errors",
        "Supports identifying missing dependencies and existing test frameworks in the project"
      ],
      "keyFunctions": [],
      "dependencies": [],
      "intent": "Provides a type-safe contract for test setup operations, ensuring consistent data structures across the testing service for planning, environment detection, and execution reporting. This enables developers to reliably configure test environments with proper typing and validation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces for test setup configuration, environment detection, and execution results in the testing service.\",\n  \"userVisibleActions\": [\n    \"Test setup plans are created with specific testing frameworks and dependencies\",\n    \"Configuration files are generated for the test environment\",\n    \"Test directories are established in the project\",\n    \"Dependencies are installed for testing frameworks\",\n    \"Success or error messages are displayed after test setup execution\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides type-safe structures for planning test setup with language, framework, and dependency information\",\n    \"Enables detection of existing test environment features (package.json, tsconfig, jest config, test directories)\",\n    \"Structures mock requirements with types and reasons for test isolation\",\n    \"Returns execution results with lists of created files, installed dependencies, and any errors\",\n    \"Supports identifying missing dependencies and existing test frameworks in the project\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [],\n  \"intent\": \"Provides a type-safe contract for test setup operations, ensuring consistent data structures across the testing service for planning, environment detection, and execution reporting. This enables developers to reliably configure test environments with proper typing and validation.\"\n}\n```"
    },
    {
      "file": "src/extension.ts",
      "role": "Core Logic",
      "purpose": "Main entry point that activates the VSCode extension, initializes all components, and registers commands for code analysis and insight generation.",
      "userVisibleActions": [
        "Analyze current file to see code insights and structure",
        "Generate LLM-friendly documentation from code",
        "View analysis results in a tree view sidebar",
        "Navigate to code locations by clicking tree items",
        "See diagnostics and warnings for analyzed code",
        "Refresh analysis results manually",
        "Copy generated documentation to clipboard",
        "Open documentation in a webview panel",
        "Clear analysis cache",
        "Export insights to file",
        "Configure analysis settings",
        "View status bar indicator showing analysis state"
      ],
      "developerVisibleActions": [
        "Extension activates when VSCode starts or workspace opens",
        "File watcher monitors code changes and triggers re-analysis",
        "Analysis results are cached to improve performance",
        "Components are bootstrapped using dependency injection pattern",
        "Commands are registered through a command registry",
        "Tree view updates automatically when analysis completes",
        "Diagnostics panel shows code quality issues",
        "Configuration changes trigger re-initialization",
        "Error handling captures and reports failures",
        "Navigation handler manages code location jumping"
      ],
      "keyFunctions": [
        {
          "name": "activate",
          "desc": "Initializes and activates the extension, setting up all components and command handlers",
          "inputs": "context: vscode.ExtensionContext",
          "outputs": "void"
        },
        {
          "name": "deactivate",
          "desc": "Cleans up resources and disposes of components when extension is deactivated",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "./analyzer",
        "./insightGenerator",
        "./llmFormatter",
        "./fileWatcher",
        "./insightsTreeView",
        "./diagnosticsProvider",
        "./cache",
        "./llmIntegration",
        "./config/configurationManager",
        "./utils/errorHandler",
        "./ui/webview/webviewTemplateEngine",
        "./domain/bootstrap/extensionBootstrapper",
        "./domain/bootstrap/commandRegistry",
        "./domain/handlers/navigationHandler"
      ],
      "intent": "This file serves as the extension's main controller, orchestrating all features by initializing components, registering commands, and managing the lifecycle of the code analysis and insight generation functionality. It bridges user actions with the underlying analysis engine and presents results through multiple UI elements (tree view, webview, diagnostics, status bar).",
      "rawContent": "```json\n{\n  \"purpose\": \"Main entry point that activates the VSCode extension, initializes all components, and registers commands for code analysis and insight generation.\",\n  \"userVisibleActions\": [\n    \"Analyze current file to see code insights and structure\",\n    \"Generate LLM-friendly documentation from code\",\n    \"View analysis results in a tree view sidebar\",\n    \"Navigate to code locations by clicking tree items\",\n    \"See diagnostics and warnings for analyzed code\",\n    \"Refresh analysis results manually\",\n    \"Copy generated documentation to clipboard\",\n    \"Open documentation in a webview panel\",\n    \"Clear analysis cache\",\n    \"Export insights to file\",\n    \"Configure analysis settings\",\n    \"View status bar indicator showing analysis state\"\n  ],\n  \"developerVisibleActions\": [\n    \"Extension activates when VSCode starts or workspace opens\",\n    \"File watcher monitors code changes and triggers re-analysis\",\n    \"Analysis results are cached to improve performance\",\n    \"Components are bootstrapped using dependency injection pattern\",\n    \"Commands are registered through a command registry\",\n    \"Tree view updates automatically when analysis completes\",\n    \"Diagnostics panel shows code quality issues\",\n    \"Configuration changes trigger re-initialization\",\n    \"Error handling captures and reports failures\",\n    \"Navigation handler manages code location jumping\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"activate\",\n      \"desc\": \"Initializes and activates the extension, setting up all components and command handlers\",\n      \"inputs\": \"context: vscode.ExtensionContext\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"deactivate\",\n      \"desc\": \"Cleans up resources and disposes of components when extension is deactivated\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"./analyzer\",\n    \"./insightGenerator\",\n    \"./llmFormatter\",\n    \"./fileWatcher\",\n    \"./insightsTreeView\",\n    \"./diagnosticsProvider\",\n    \"./cache\",\n    \"./llmIntegration\",\n    \"./config/configurationManager\",\n    \"./utils/errorHandler\",\n    \"./ui/webview/webviewTemplateEngine\",\n    \"./domain/bootstrap/extensionBootstrapper\",\n    \"./domain/bootstrap/commandRegistry\",\n    \"./domain/handlers/navigationHandler\"\n  ],\n  \"intent\": \"This file serves as the extension's main controller, orchestrating all features by initializing components, registering commands, and managing the lifecycle of the code analysis and insight generation functionality. It bridges user actions with the underlying analysis engine and presents results through multiple UI elements (tree view, webview, diagnostics, status bar).\"\n}\n```"
    },
    {
      "file": "src/fileAccessHelper.ts",
      "role": "Core Logic",
      "purpose": "Provides file reading and grep search functionality to enable iterative LLM code analysis with structured request/response handling",
      "userVisibleActions": [
        "User requests to view file contents through LLM analysis",
        "User searches for code patterns across multiple files using grep",
        "User sees organized file listings grouped by folder",
        "User receives search results with line numbers and context",
        "User gets notified when search results are limited due to too many matches"
      ],
      "developerVisibleActions": [
        "Developer creates FileRequest or GrepRequest objects to access code",
        "Developer receives structured FileResponse with content and metadata",
        "Developer receives GrepResponse with matching lines and context",
        "Developer specifies file patterns to limit grep search scope",
        "Developer controls maximum number of search results returned",
        "Developer gets file listings organized by folder hierarchy",
        "Developer provides reasons for file/grep requests for transparency"
      ],
      "keyFunctions": [
        {
          "name": "getFileListing",
          "desc": "Returns organized file listing grouped by folders with sorting",
          "inputs": "Array of file objects with path, lines, and language",
          "outputs": "Formatted string showing files organized by directory"
        },
        {
          "name": "readFile",
          "desc": "Reads a file from the workspace and returns its contents",
          "inputs": "File path relative to workspace root",
          "outputs": "FileResponse with content, line count, and existence flag"
        },
        {
          "name": "grep",
          "desc": "Searches for pattern across files matching optional glob pattern",
          "inputs": "Search pattern, optional file pattern glob, max results limit",
          "outputs": "GrepResponse with matches including line numbers and context"
        },
        {
          "name": "processRequest",
          "desc": "Handles both file and grep requests based on request type",
          "inputs": "LLMRequest (either FileRequest or GrepRequest)",
          "outputs": "FileResponse or GrepResponse depending on request type"
        },
        {
          "name": "formatResponse",
          "desc": "Converts response objects to human-readable formatted text",
          "inputs": "FileResponse or GrepResponse object",
          "outputs": "Formatted string for display to user or LLM"
        }
      ],
      "dependencies": [
        "fs",
        "path"
      ],
      "intent": "This file exists to enable iterative LLM code analysis by providing a structured way to request and retrieve file contents or search for patterns across the codebase. It solves the problem of LLMs needing to explore and understand code incrementally without loading entire files upfront, supporting intelligent code navigation through grep searches and targeted file reading.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides file reading and grep search functionality to enable iterative LLM code analysis with structured request/response handling\",\n  \"userVisibleActions\": [\n    \"User requests to view file contents through LLM analysis\",\n    \"User searches for code patterns across multiple files using grep\",\n    \"User sees organized file listings grouped by folder\",\n    \"User receives search results with line numbers and context\",\n    \"User gets notified when search results are limited due to too many matches\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer creates FileRequest or GrepRequest objects to access code\",\n    \"Developer receives structured FileResponse with content and metadata\",\n    \"Developer receives GrepResponse with matching lines and context\",\n    \"Developer specifies file patterns to limit grep search scope\",\n    \"Developer controls maximum number of search results returned\",\n    \"Developer gets file listings organized by folder hierarchy\",\n    \"Developer provides reasons for file/grep requests for transparency\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFileListing\",\n      \"desc\": \"Returns organized file listing grouped by folders with sorting\",\n      \"inputs\": \"Array of file objects with path, lines, and language\",\n      \"outputs\": \"Formatted string showing files organized by directory\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads a file from the workspace and returns its contents\",\n      \"inputs\": \"File path relative to workspace root\",\n      \"outputs\": \"FileResponse with content, line count, and existence flag\"\n    },\n    {\n      \"name\": \"grep\",\n      \"desc\": \"Searches for pattern across files matching optional glob pattern\",\n      \"inputs\": \"Search pattern, optional file pattern glob, max results limit\",\n      \"outputs\": \"GrepResponse with matches including line numbers and context\"\n    },\n    {\n      \"name\": \"processRequest\",\n      \"desc\": \"Handles both file and grep requests based on request type\",\n      \"inputs\": \"LLMRequest (either FileRequest or GrepRequest)\",\n      \"outputs\": \"FileResponse or GrepResponse depending on request type\"\n    },\n    {\n      \"name\": \"formatResponse\",\n      \"desc\": \"Converts response objects to human-readable formatted text\",\n      \"inputs\": \"FileResponse or GrepResponse object\",\n      \"outputs\": \"Formatted string for display to user or LLM\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"This file exists to enable iterative LLM code analysis by providing a structured way to request and retrieve file contents or search for patterns across the codebase. It solves the problem of LLMs needing to explore and understand code incrementally without loading entire files upfront, supporting intelligent code navigation through grep searches and targeted file reading.\"\n}\n```"
    },
    {
      "file": "src/fileDocumentation.ts",
      "role": "Core Logic",
      "purpose": "Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.",
      "userVisibleActions": [
        "User receives structured documentation showing what each file does and why it exists",
        "User sees organized documentation by modules (API routes, CLI commands, workers, GUI views)",
        "User views product-level documentation with overviews, workflows, and problems solved",
        "User accesses categorized features, components, and capabilities descriptions",
        "User reads endpoint documentation with paths, methods, and descriptions",
        "User reviews command documentation with usage and descriptions",
        "User explores worker job flows and descriptions"
      ],
      "developerVisibleActions": [
        "Developer defines file summaries with role, purpose, and key functions",
        "Developer creates module summaries grouping related files by type",
        "Developer documents user-visible and developer-visible actions for each file",
        "Developer specifies file dependencies and intent",
        "Developer generates product documentation with architecture diagrams",
        "Developer structures documentation with titles, descriptions, and categories",
        "Developer organizes capabilities by user perspective (GUI, CLI, API, CI/CD)",
        "Developer includes raw LLM responses for documentation generation",
        "Developer maps endpoints, commands, and workers to their descriptions"
      ],
      "keyFunctions": [],
      "dependencies": [
        "fs",
        "path",
        "./analyzer"
      ],
      "intent": "This file exists to provide a standardized schema for organizing and structuring code documentation across multiple levels (file, module, product), enabling consistent documentation generation and making codebases easier to understand for both users and developers.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines TypeScript interfaces and data structures for organizing code documentation at file, module, and product levels.\",\n  \"userVisibleActions\": [\n    \"User receives structured documentation showing what each file does and why it exists\",\n    \"User sees organized documentation by modules (API routes, CLI commands, workers, GUI views)\",\n    \"User views product-level documentation with overviews, workflows, and problems solved\",\n    \"User accesses categorized features, components, and capabilities descriptions\",\n    \"User reads endpoint documentation with paths, methods, and descriptions\",\n    \"User reviews command documentation with usage and descriptions\",\n    \"User explores worker job flows and descriptions\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer defines file summaries with role, purpose, and key functions\",\n    \"Developer creates module summaries grouping related files by type\",\n    \"Developer documents user-visible and developer-visible actions for each file\",\n    \"Developer specifies file dependencies and intent\",\n    \"Developer generates product documentation with architecture diagrams\",\n    \"Developer structures documentation with titles, descriptions, and categories\",\n    \"Developer organizes capabilities by user perspective (GUI, CLI, API, CI/CD)\",\n    \"Developer includes raw LLM responses for documentation generation\",\n    \"Developer maps endpoints, commands, and workers to their descriptions\"\n  ],\n  \"keyFunctions\": [],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to provide a standardized schema for organizing and structuring code documentation across multiple levels (file, module, product), enabling consistent documentation generation and making codebases easier to understand for both users and developers.\"\n}\n```"
    },
    {
      "file": "src/fileWatcher.ts",
      "role": "Core Logic",
      "purpose": "Monitors file changes in the workspace and automatically triggers code analysis when files are saved",
      "userVisibleActions": [
        "Code analysis runs automatically when saving a file (if 'analyze on save' is enabled)",
        "Diagnostics and insights update in the UI after file saves",
        "Analysis waits until typing stops (debounced) to avoid interrupting workflow",
        "User can see when analysis is in progress or completed"
      ],
      "developerVisibleActions": [
        "File watcher starts when extension activates if 'analyzeOnSave' configuration is enabled",
        "Watches for document save events in VS Code",
        "Triggers code analysis pipeline on file saves",
        "Updates diagnostics provider with new analysis results",
        "Refreshes insights tree view after analysis completes",
        "Prevents concurrent analysis runs to avoid performance issues",
        "Implements debouncing to batch rapid file saves",
        "Cleans up resources when stopped or disposed"
      ],
      "keyFunctions": [
        {
          "name": "start",
          "desc": "Begins watching for file save events and enables automatic analysis",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "stop",
          "desc": "Stops watching for file saves and cancels pending analysis",
          "inputs": "None",
          "outputs": "void"
        },
        {
          "name": "onFileSaved",
          "desc": "Handles file save events and schedules analysis with debouncing",
          "inputs": "document: vscode.TextDocument",
          "outputs": "void"
        },
        {
          "name": "analyzeFile",
          "desc": "Executes the full analysis pipeline for a saved file and updates UI",
          "inputs": "document: vscode.TextDocument",
          "outputs": "Promise<void>"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file watcher resources and stops monitoring",
          "inputs": "None",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "CodeAnalyzer",
        "InsightGenerator",
        "DiagnosticsProvider",
        "InsightsTreeProvider",
        "ConfigurationManager",
        "ErrorHandler",
        "FileWatcherService"
      ],
      "intent": "This file exists to provide automatic, real-time code analysis by watching for file changes in the workspace. It solves the problem of keeping code insights and diagnostics up-to-date without requiring manual user intervention, while intelligently managing when and how often analysis runs to balance responsiveness with performance.",
      "rawContent": "```json\n{\n  \"purpose\": \"Monitors file changes in the workspace and automatically triggers code analysis when files are saved\",\n  \"userVisibleActions\": [\n    \"Code analysis runs automatically when saving a file (if 'analyze on save' is enabled)\",\n    \"Diagnostics and insights update in the UI after file saves\",\n    \"Analysis waits until typing stops (debounced) to avoid interrupting workflow\",\n    \"User can see when analysis is in progress or completed\"\n  ],\n  \"developerVisibleActions\": [\n    \"File watcher starts when extension activates if 'analyzeOnSave' configuration is enabled\",\n    \"Watches for document save events in VS Code\",\n    \"Triggers code analysis pipeline on file saves\",\n    \"Updates diagnostics provider with new analysis results\",\n    \"Refreshes insights tree view after analysis completes\",\n    \"Prevents concurrent analysis runs to avoid performance issues\",\n    \"Implements debouncing to batch rapid file saves\",\n    \"Cleans up resources when stopped or disposed\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"start\",\n      \"desc\": \"Begins watching for file save events and enables automatic analysis\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"stop\",\n      \"desc\": \"Stops watching for file saves and cancels pending analysis\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"onFileSaved\",\n      \"desc\": \"Handles file save events and schedules analysis with debouncing\",\n      \"inputs\": \"document: vscode.TextDocument\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Executes the full analysis pipeline for a saved file and updates UI\",\n      \"inputs\": \"document: vscode.TextDocument\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watcher resources and stops monitoring\",\n      \"inputs\": \"None\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"CodeAnalyzer\",\n    \"InsightGenerator\",\n    \"DiagnosticsProvider\",\n    \"InsightsTreeProvider\",\n    \"ConfigurationManager\",\n    \"ErrorHandler\",\n    \"FileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide automatic, real-time code analysis by watching for file changes in the workspace. It solves the problem of keeping code insights and diagnostics up-to-date without requiring manual user intervention, while intelligently managing when and how often analysis runs to balance responsiveness with performance.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileCache.ts",
      "role": "Core Logic",
      "purpose": "Caches file contents in memory to avoid redundant disk reads and improve performance when accessing the same files multiple times",
      "userVisibleActions": [
        "Faster file access when the same file is read multiple times",
        "Automatic updates when files change on disk",
        "Reduced disk activity and improved responsiveness"
      ],
      "developerVisibleActions": [
        "Request file content through the cache instead of direct file system access",
        "Files are automatically re-read when they change on disk",
        "Cache evicts least recently used files when memory limit is reached",
        "File changes are detected through file system watching",
        "Cache statistics track hits, misses, and evictions for monitoring"
      ],
      "keyFunctions": [
        {
          "name": "getFile",
          "desc": "Retrieves file content from cache if available and valid, otherwise reads from disk and caches it",
          "inputs": "filePath (string) - path to the file to read",
          "outputs": "Promise<string> - the file content as text"
        },
        {
          "name": "setupWatcher",
          "desc": "Sets up file system monitoring to automatically invalidate cached files when they change",
          "inputs": "none",
          "outputs": "void - creates file watcher in background"
        },
        {
          "name": "isStale",
          "desc": "Checks if a cached file has exceeded its time-to-live and needs refreshing",
          "inputs": "cached file entry with timestamp",
          "outputs": "boolean - true if cache entry is expired"
        },
        {
          "name": "evictIfNeeded",
          "desc": "Removes least recently used files from cache when total size exceeds the configured limit",
          "inputs": "none",
          "outputs": "void - modifies cache by removing old entries"
        },
        {
          "name": "invalidate",
          "desc": "Removes a specific file or all files from the cache",
          "inputs": "optional filePath (string) - specific file to remove, or all if omitted",
          "outputs": "void - removes entries from cache"
        },
        {
          "name": "getStats",
          "desc": "Returns cache performance metrics including hits, misses, and current size",
          "inputs": "none",
          "outputs": "CacheStats object with performance counters"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path"
      ],
      "intent": "Eliminates redundant file system reads by caching file contents in memory, improving performance when multiple components need to access the same files repeatedly. Ensures cache stays synchronized with file system changes through automatic invalidation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Caches file contents in memory to avoid redundant disk reads and improve performance when accessing the same files multiple times\",\n  \"userVisibleActions\": [\n    \"Faster file access when the same file is read multiple times\",\n    \"Automatic updates when files change on disk\",\n    \"Reduced disk activity and improved responsiveness\"\n  ],\n  \"developerVisibleActions\": [\n    \"Request file content through the cache instead of direct file system access\",\n    \"Files are automatically re-read when they change on disk\",\n    \"Cache evicts least recently used files when memory limit is reached\",\n    \"File changes are detected through file system watching\",\n    \"Cache statistics track hits, misses, and evictions for monitoring\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"getFile\",\n      \"desc\": \"Retrieves file content from cache if available and valid, otherwise reads from disk and caches it\",\n      \"inputs\": \"filePath (string) - path to the file to read\",\n      \"outputs\": \"Promise<string> - the file content as text\"\n    },\n    {\n      \"name\": \"setupWatcher\",\n      \"desc\": \"Sets up file system monitoring to automatically invalidate cached files when they change\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - creates file watcher in background\"\n    },\n    {\n      \"name\": \"isStale\",\n      \"desc\": \"Checks if a cached file has exceeded its time-to-live and needs refreshing\",\n      \"inputs\": \"cached file entry with timestamp\",\n      \"outputs\": \"boolean - true if cache entry is expired\"\n    },\n    {\n      \"name\": \"evictIfNeeded\",\n      \"desc\": \"Removes least recently used files from cache when total size exceeds the configured limit\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void - modifies cache by removing old entries\"\n    },\n    {\n      \"name\": \"invalidate\",\n      \"desc\": \"Removes a specific file or all files from the cache\",\n      \"inputs\": \"optional filePath (string) - specific file to remove, or all if omitted\",\n      \"outputs\": \"void - removes entries from cache\"\n    },\n    {\n      \"name\": \"getStats\",\n      \"desc\": \"Returns cache performance metrics including hits, misses, and current size\",\n      \"inputs\": \"none\",\n      \"outputs\": \"CacheStats object with performance counters\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\"\n  ],\n  \"intent\": \"Eliminates redundant file system reads by caching file contents in memory, improving performance when multiple components need to access the same files repeatedly. Ensures cache stays synchronized with file system changes through automatic invalidation.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/fileSystem/fileProcessor.ts",
      "role": "Core Logic",
      "purpose": "Consolidates and standardizes file processing logic across the codebase by providing reusable filtering, reading, and parallel processing capabilities.",
      "userVisibleActions": [
        "Files are automatically filtered to skip non-source directories (node_modules, .git, dist, build, etc.)",
        "Multiple files are processed in parallel for faster performance",
        "Files are read and processed with consistent error handling"
      ],
      "developerVisibleActions": [
        "Developer provides file paths and a processing function to handle file content",
        "Developer can customize file filtering by implementing IFileFilter interface",
        "Developer can customize file reading by implementing IFileReader interface",
        "Developer receives array of processed results from all files",
        "Developer can pass error context for better error tracking"
      ],
      "keyFunctions": [
        {
          "name": "shouldProcess",
          "desc": "Determines if a file should be processed based on filtering rules",
          "inputs": "filePath: string",
          "outputs": "boolean"
        },
        {
          "name": "readFile",
          "desc": "Reads file content from disk",
          "inputs": "filePath: string",
          "outputs": "Promise<string>"
        },
        {
          "name": "processFiles",
          "desc": "Processes multiple files in parallel with filtering and error handling",
          "inputs": "files: string[], processor: function, context?: ErrorContext",
          "outputs": "Promise<T[]>"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "ErrorHandler",
        "ErrorContext"
      ],
      "intent": "This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and processing by providing a single, reusable, and extensible file processing pipeline with built-in parallel processing and error handling.",
      "rawContent": "```json\n{\n  \"purpose\": \"Consolidates and standardizes file processing logic across the codebase by providing reusable filtering, reading, and parallel processing capabilities.\",\n  \"userVisibleActions\": [\n    \"Files are automatically filtered to skip non-source directories (node_modules, .git, dist, build, etc.)\",\n    \"Multiple files are processed in parallel for faster performance\",\n    \"Files are read and processed with consistent error handling\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer provides file paths and a processing function to handle file content\",\n    \"Developer can customize file filtering by implementing IFileFilter interface\",\n    \"Developer can customize file reading by implementing IFileReader interface\",\n    \"Developer receives array of processed results from all files\",\n    \"Developer can pass error context for better error tracking\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"shouldProcess\",\n      \"desc\": \"Determines if a file should be processed based on filtering rules\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"boolean\"\n    },\n    {\n      \"name\": \"readFile\",\n      \"desc\": \"Reads file content from disk\",\n      \"inputs\": \"filePath: string\",\n      \"outputs\": \"Promise<string>\"\n    },\n    {\n      \"name\": \"processFiles\",\n      \"desc\": \"Processes multiple files in parallel with filtering and error handling\",\n      \"inputs\": \"files: string[], processor: function, context?: ErrorContext\",\n      \"outputs\": \"Promise<T[]>\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"ErrorHandler\",\n    \"ErrorContext\"\n  ],\n  \"intent\": \"This file exists to eliminate duplicate file processing patterns across the codebase. It solves the problem of inconsistent file filtering, reading, and processing by providing a single, reusable, and extensible file processing pipeline with built-in parallel processing and error handling.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/persistence/analysisResultRepository.ts",
      "role": "Core Logic",
      "purpose": "Manages storage and retrieval of code analysis results including product documentation, architecture insights, and summaries to the .shadow directory.",
      "userVisibleActions": [
        "Generated documentation files are saved to timestamped directories in .shadow/docs",
        "Architecture insights are saved to timestamped directories in .shadow/architecture",
        "Individual file documentation is stored with metadata for tracking",
        "Analysis results are organized by run with unique identifiers",
        "Summary files and overview documentation are created for each analysis run"
      ],
      "developerVisibleActions": [
        "Initialize documentation runs with timestamped directories",
        "Save enhanced product documentation for individual files",
        "Store architecture insights and summaries",
        "Retrieve current run directories for accessing results",
        "Create structured output with metadata tracking",
        "Generate formatted documentation in markdown",
        "Manage incremental storage for documentation updates"
      ],
      "keyFunctions": [
        {
          "name": "initializeProductDocsRun",
          "desc": "Creates a new timestamped directory for storing product documentation results",
          "inputs": "workspaceRoot (string)",
          "outputs": "runDir path (string)"
        },
        {
          "name": "initializeArchitectureInsightsRun",
          "desc": "Creates a new timestamped directory for storing architecture analysis results",
          "inputs": "workspaceRoot (string)",
          "outputs": "runDir path (string)"
        },
        {
          "name": "saveProductDocumentation",
          "desc": "Saves enhanced product documentation for a file to the current run directory",
          "inputs": "filePath (string), documentation (EnhancedProductDocumentation), workspaceRoot (string)",
          "outputs": "saved file path (string)"
        },
        {
          "name": "saveArchitectureInsights",
          "desc": "Saves architecture insights and analysis summaries to the current run directory",
          "inputs": "insights (LLMInsights), workspaceRoot (string), summary (optional string)",
          "outputs": "saved file paths object"
        },
        {
          "name": "getCurrentProductDocsRunDir",
          "desc": "Returns the directory path of the current product documentation run",
          "inputs": "none",
          "outputs": "runDir path (string) or null"
        },
        {
          "name": "getCurrentArchitectureInsightsRunDir",
          "desc": "Returns the directory path of the current architecture insights run",
          "inputs": "none",
          "outputs": "runDir path (string) or null"
        },
        {
          "name": "resetProductDocsRun",
          "desc": "Clears the current product documentation run context",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "resetArchitectureInsightsRun",
          "desc": "Clears the current architecture insights run context",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "saveSummary",
          "desc": "Saves a summary file to the specified run directory",
          "inputs": "runDir (string), summary (string)",
          "outputs": "saved file path (string)"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "../../fileDocumentation",
        "../../llmService",
        "../../domain/formatters/documentationFormatter",
        "../../storage/incrementalStorage"
      ],
      "intent": "This file exists to separate persistence concerns from the LLM integration logic, providing a dedicated layer for storing and organizing analysis results in a structured, timestamped manner so that documentation and insights can be tracked across multiple analysis runs.",
      "rawContent": "```json\n{\n  \"purpose\": \"Manages storage and retrieval of code analysis results including product documentation, architecture insights, and summaries to the .shadow directory.\",\n  \"userVisibleActions\": [\n    \"Generated documentation files are saved to timestamped directories in .shadow/docs\",\n    \"Architecture insights are saved to timestamped directories in .shadow/architecture\",\n    \"Individual file documentation is stored with metadata for tracking\",\n    \"Analysis results are organized by run with unique identifiers\",\n    \"Summary files and overview documentation are created for each analysis run\"\n  ],\n  \"developerVisibleActions\": [\n    \"Initialize documentation runs with timestamped directories\",\n    \"Save enhanced product documentation for individual files\",\n    \"Store architecture insights and summaries\",\n    \"Retrieve current run directories for accessing results\",\n    \"Create structured output with metadata tracking\",\n    \"Generate formatted documentation in markdown\",\n    \"Manage incremental storage for documentation updates\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeProductDocsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing product documentation results\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"runDir path (string)\"\n    },\n    {\n      \"name\": \"initializeArchitectureInsightsRun\",\n      \"desc\": \"Creates a new timestamped directory for storing architecture analysis results\",\n      \"inputs\": \"workspaceRoot (string)\",\n      \"outputs\": \"runDir path (string)\"\n    },\n    {\n      \"name\": \"saveProductDocumentation\",\n      \"desc\": \"Saves enhanced product documentation for a file to the current run directory\",\n      \"inputs\": \"filePath (string), documentation (EnhancedProductDocumentation), workspaceRoot (string)\",\n      \"outputs\": \"saved file path (string)\"\n    },\n    {\n      \"name\": \"saveArchitectureInsights\",\n      \"desc\": \"Saves architecture insights and analysis summaries to the current run directory\",\n      \"inputs\": \"insights (LLMInsights), workspaceRoot (string), summary (optional string)\",\n      \"outputs\": \"saved file paths object\"\n    },\n    {\n      \"name\": \"getCurrentProductDocsRunDir\",\n      \"desc\": \"Returns the directory path of the current product documentation run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path (string) or null\"\n    },\n    {\n      \"name\": \"getCurrentArchitectureInsightsRunDir\",\n      \"desc\": \"Returns the directory path of the current architecture insights run\",\n      \"inputs\": \"none\",\n      \"outputs\": \"runDir path (string) or null\"\n    },\n    {\n      \"name\": \"resetProductDocsRun\",\n      \"desc\": \"Clears the current product documentation run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"resetArchitectureInsightsRun\",\n      \"desc\": \"Clears the current architecture insights run context\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"saveSummary\",\n      \"desc\": \"Saves a summary file to the specified run directory\",\n      \"inputs\": \"runDir (string), summary (string)\",\n      \"outputs\": \"saved file path (string)\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"../../fileDocumentation\",\n    \"../../llmService\",\n    \"../../domain/formatters/documentationFormatter\",\n    \"../../storage/incrementalStorage\"\n  ],\n  \"intent\": \"This file exists to separate persistence concerns from the LLM integration logic, providing a dedicated layer for storing and organizing analysis results in a structured, timestamped manner so that documentation and insights can be tracked across multiple analysis runs.\"\n}\n```"
    },
    {
      "file": "src/infrastructure/progressService.ts",
      "role": "Core Logic",
      "purpose": "Provides a standardized service for displaying progress notifications with messages and cancellation support throughout the application.",
      "userVisibleActions": [
        "See progress notifications with titles and messages during long-running operations",
        "View incremental progress updates as operations proceed",
        "Cancel operations in progress using a cancel button (when cancellable)",
        "See progress indicators in different locations (notification area, window, etc.)"
      ],
      "developerVisibleActions": [
        "Wrap async tasks with progress reporting using a simple API",
        "Report progress messages and optional increment values during task execution",
        "Access cancellation tokens to respond to user cancellation requests",
        "Configure progress notification title, cancellability, and display location",
        "Use either a simple string title or full options object for flexibility"
      ],
      "keyFunctions": [
        {
          "name": "withProgress",
          "desc": "Executes an async task while displaying a progress notification to the user",
          "inputs": "options (title string or ProgressOptions object), task function that receives a ProgressReporter",
          "outputs": "Promise resolving to the task result"
        },
        {
          "name": "report",
          "desc": "Updates the progress notification with a new message and optional increment",
          "inputs": "message (string), increment (optional number)",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode"
      ],
      "intent": "Reduces boilerplate code and ensures consistent progress reporting UX across the entire codebase by wrapping VSCode's native progress API with a simpler, standardized interface.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a standardized service for displaying progress notifications with messages and cancellation support throughout the application.\",\n  \"userVisibleActions\": [\n    \"See progress notifications with titles and messages during long-running operations\",\n    \"View incremental progress updates as operations proceed\",\n    \"Cancel operations in progress using a cancel button (when cancellable)\",\n    \"See progress indicators in different locations (notification area, window, etc.)\"\n  ],\n  \"developerVisibleActions\": [\n    \"Wrap async tasks with progress reporting using a simple API\",\n    \"Report progress messages and optional increment values during task execution\",\n    \"Access cancellation tokens to respond to user cancellation requests\",\n    \"Configure progress notification title, cancellability, and display location\",\n    \"Use either a simple string title or full options object for flexibility\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"withProgress\",\n      \"desc\": \"Executes an async task while displaying a progress notification to the user\",\n      \"inputs\": \"options (title string or ProgressOptions object), task function that receives a ProgressReporter\",\n      \"outputs\": \"Promise resolving to the task result\"\n    },\n    {\n      \"name\": \"report\",\n      \"desc\": \"Updates the progress notification with a new message and optional increment\",\n      \"inputs\": \"message (string), increment (optional number)\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\"\n  ],\n  \"intent\": \"Reduces boilerplate code and ensures consistent progress reporting UX across the entire codebase by wrapping VSCode's native progress API with a simpler, standardized interface.\"\n}\n```"
    },
    {
      "file": "src/insightGenerator.ts",
      "role": "Core Logic",
      "purpose": "Analyzes code and generates actionable insights about code quality, organization, and potential issues",
      "userVisibleActions": [
        "Receives warnings about large files exceeding 500 lines of code",
        "Gets notified about orphaned files that aren't imported anywhere",
        "Sees alerts for missing entry points in the codebase",
        "Receives warnings about circular dependencies between files",
        "Gets notified about 'god objects' (files with too many functions)",
        "Sees suggestions about potential dead code",
        "Receives insights about file organization issues",
        "Gets warnings about complex functions that may need refactoring"
      ],
      "developerVisibleActions": [
        "Call generateInsights() with code analysis to get all insights for the entire codebase",
        "Call generateInsightsForFile() to get insights for a specific file",
        "Receive structured Insight objects with severity levels (error, warning, info)",
        "Each insight includes title, description, category, file location, line number, and actionable suggestions",
        "Insights are categorized by type (Code Organization, Maintainability, Performance, etc.)",
        "Get code snippets included in insights when relevant"
      ],
      "keyFunctions": [
        {
          "name": "generateInsights",
          "desc": "Analyzes entire codebase and returns all detected issues and recommendations",
          "inputs": "CodeAnalysis object containing files, functions, and dependencies",
          "outputs": "Array of Insight objects with problems and suggestions"
        },
        {
          "name": "generateInsightsForFile",
          "desc": "Analyzes a specific file and returns insights relevant to that file only",
          "inputs": "CodeAnalysis object and file path string",
          "outputs": "Array of Insight objects filtered for the specified file"
        },
        {
          "name": "checkLargeFiles",
          "desc": "Detects files that exceed recommended line count thresholds",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about oversized files"
        },
        {
          "name": "checkOrphanedFiles",
          "desc": "Identifies files that aren't imported or used anywhere in the codebase",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about unused files"
        },
        {
          "name": "checkEntryPoints",
          "desc": "Verifies that the codebase has proper entry points defined",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about missing entry points"
        },
        {
          "name": "checkCircularDependencies",
          "desc": "Detects potential circular dependency patterns between files",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about circular dependencies"
        },
        {
          "name": "checkGodObjects",
          "desc": "Identifies files with excessive functions that violate single responsibility principle",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about files with too many responsibilities"
        },
        {
          "name": "checkDeadCode",
          "desc": "Detects potentially unused or unreachable code",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about dead code"
        },
        {
          "name": "checkFileOrganization",
          "desc": "Analyzes project structure and suggests organizational improvements",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about file organization issues"
        },
        {
          "name": "checkFunctionComplexity",
          "desc": "Identifies functions that are too complex and may need simplification",
          "inputs": "CodeAnalysis object",
          "outputs": "Array of insights about overly complex functions"
        }
      ],
      "dependencies": [
        "./analyzer"
      ],
      "intent": "This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, maintainability problems, and architectural concerns. It solves the problem of making sense of complex code metrics by categorizing issues, assigning severity levels, and providing specific suggestions for improvement.",
      "rawContent": "```json\n{\n  \"purpose\": \"Analyzes code and generates actionable insights about code quality, organization, and potential issues\",\n  \"userVisibleActions\": [\n    \"Receives warnings about large files exceeding 500 lines of code\",\n    \"Gets notified about orphaned files that aren't imported anywhere\",\n    \"Sees alerts for missing entry points in the codebase\",\n    \"Receives warnings about circular dependencies between files\",\n    \"Gets notified about 'god objects' (files with too many functions)\",\n    \"Sees suggestions about potential dead code\",\n    \"Receives insights about file organization issues\",\n    \"Gets warnings about complex functions that may need refactoring\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call generateInsights() with code analysis to get all insights for the entire codebase\",\n    \"Call generateInsightsForFile() to get insights for a specific file\",\n    \"Receive structured Insight objects with severity levels (error, warning, info)\",\n    \"Each insight includes title, description, category, file location, line number, and actionable suggestions\",\n    \"Insights are categorized by type (Code Organization, Maintainability, Performance, etc.)\",\n    \"Get code snippets included in insights when relevant\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"generateInsights\",\n      \"desc\": \"Analyzes entire codebase and returns all detected issues and recommendations\",\n      \"inputs\": \"CodeAnalysis object containing files, functions, and dependencies\",\n      \"outputs\": \"Array of Insight objects with problems and suggestions\"\n    },\n    {\n      \"name\": \"generateInsightsForFile\",\n      \"desc\": \"Analyzes a specific file and returns insights relevant to that file only\",\n      \"inputs\": \"CodeAnalysis object and file path string\",\n      \"outputs\": \"Array of Insight objects filtered for the specified file\"\n    },\n    {\n      \"name\": \"checkLargeFiles\",\n      \"desc\": \"Detects files that exceed recommended line count thresholds\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about oversized files\"\n    },\n    {\n      \"name\": \"checkOrphanedFiles\",\n      \"desc\": \"Identifies files that aren't imported or used anywhere in the codebase\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about unused files\"\n    },\n    {\n      \"name\": \"checkEntryPoints\",\n      \"desc\": \"Verifies that the codebase has proper entry points defined\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about missing entry points\"\n    },\n    {\n      \"name\": \"checkCircularDependencies\",\n      \"desc\": \"Detects potential circular dependency patterns between files\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about circular dependencies\"\n    },\n    {\n      \"name\": \"checkGodObjects\",\n      \"desc\": \"Identifies files with excessive functions that violate single responsibility principle\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about files with too many responsibilities\"\n    },\n    {\n      \"name\": \"checkDeadCode\",\n      \"desc\": \"Detects potentially unused or unreachable code\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about dead code\"\n    },\n    {\n      \"name\": \"checkFileOrganization\",\n      \"desc\": \"Analyzes project structure and suggests organizational improvements\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about file organization issues\"\n    },\n    {\n      \"name\": \"checkFunctionComplexity\",\n      \"desc\": \"Identifies functions that are too complex and may need simplification\",\n      \"inputs\": \"CodeAnalysis object\",\n      \"outputs\": \"Array of insights about overly complex functions\"\n    }\n  ],\n  \"dependencies\": [\n    \"./analyzer\"\n  ],\n  \"intent\": \"This file exists to transform raw code analysis data into actionable, human-readable insights that help developers identify code quality issues, maintainability problems, and architectural concerns. It solves the problem of making sense of complex code metrics by categorizing issues, assigning severity levels, and providing specific suggestions for improvement.\"\n}\n```"
    },
    {
      "file": "src/insightsTreeView.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view interface in VS Code's sidebar that displays code analysis insights, documentation status, and generated reports with timestamps and action buttons.",
      "userVisibleActions": [
        "View code analysis insights organized in a tree structure in the sidebar",
        "See status indicators (idle/generating/complete) for product documentation, insights, and unit tests",
        "Click on insight items to navigate to specific code locations",
        "Refresh the insights tree view to update the display",
        "Open generated reports (workspace, product, architecture, unit test) from the tree",
        "Copy insight descriptions to clipboard",
        "Generate product documentation, insights, unit tests, and analysis reports via tree item buttons",
        "Regenerate existing insights and documentation",
        "See timestamps showing when reports and documentation were last generated",
        "View dependency tree and architecture insights",
        "Access static analysis results through the tree view"
      ],
      "developerVisibleActions": [
        "Tree provider manages state for multiple report types (workspace, product, architecture, unit test)",
        "Persists timestamps and file paths across VS Code sessions using workspace state",
        "Tracks generation status for documentation, insights, unit tests, and analysis",
        "Handles LLM service integration for generating AI-powered insights",
        "Provides tree data structure with expandable/collapsible sections",
        "Manages navigation from tree items to code locations via file paths and line numbers",
        "Exposes refresh mechanism to update tree view when analysis completes",
        "Supports copying insight text to clipboard programmatically",
        "Validates existence of generated report files before displaying them",
        "Integrates with static analysis viewer component"
      ],
      "keyFunctions": [
        {
          "name": "refresh",
          "desc": "Triggers the tree view to reload and display updated insights and statuses",
          "inputs": "none",
          "outputs": "void (fires onDidChangeTreeData event)"
        },
        {
          "name": "setInsights",
          "desc": "Updates the insights data displayed in the tree view",
          "inputs": "insights: Insight[] - array of insight objects",
          "outputs": "void"
        },
        {
          "name": "getTreeItem",
          "desc": "Returns the VS Code tree item representation for a given tree node",
          "inputs": "element: TreeItem - tree node element",
          "outputs": "vscode.TreeItem or Thenable<vscode.TreeItem>"
        },
        {
          "name": "getChildren",
          "desc": "Returns child nodes for a given tree item or root nodes if no element provided",
          "inputs": "element?: TreeItem - optional parent tree item",
          "outputs": "TreeItem[] - array of child tree items"
        },
        {
          "name": "setProductDocsStatus",
          "desc": "Updates the product documentation generation status",
          "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setInsightsStatus",
          "desc": "Updates the insights generation status",
          "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setUnitTestStatus",
          "desc": "Updates the unit test generation status",
          "inputs": "status: 'idle' | 'generating' | 'complete', timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setAnalysisStatus",
          "desc": "Updates the analysis completion status",
          "inputs": "status: 'idle' | 'complete', timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setReportPath",
          "desc": "Sets the file path for a generated report",
          "inputs": "path: string, timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setWorkspaceReportPath",
          "desc": "Sets the file path for the workspace report",
          "inputs": "path: string, timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setProductReportPath",
          "desc": "Sets the file path for the product report",
          "inputs": "path: string, timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setArchitectureReportPath",
          "desc": "Sets the file path for the architecture report",
          "inputs": "path: string, timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setUnitTestReportPath",
          "desc": "Sets the file path for the unit test report",
          "inputs": "path: string, timestamp?: number",
          "outputs": "void"
        },
        {
          "name": "setLLMService",
          "desc": "Configures the LLM service for generating AI-powered insights",
          "inputs": "llmService: LLMService",
          "outputs": "void"
        },
        {
          "name": "setLLMInsights",
          "desc": "Updates the LLM-generated insights data",
          "inputs": "llmInsights: LLMInsights",
          "outputs": "void"
        },
        {
          "name": "setStaticAnalysisViewer",
          "desc": "Sets the static analysis viewer component for integration",
          "inputs": "viewer: any - static analysis viewer instance",
          "outputs": "void"
        },
        {
          "name": "loadPersistedState",
          "desc": "Restores previously saved timestamps and report paths from workspace storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "formatTimestamp",
          "desc": "Converts a timestamp number into a human-readable date/time string",
          "inputs": "timestamp: number",
          "outputs": "string - formatted date/time"
        }
      ],
      "dependencies": [
        "vscode",
        "insightGenerator",
        "llmFormatter",
        "llmService"
      ],
      "intent": "This file exists to provide a user-friendly sidebar interface in VS Code that visualizes code analysis results, tracks generation status of various documentation and test reports, and offers quick access to generated artifacts. It solves the problem of presenting complex analysis data in an organized, navigable tree structure with actionable buttons and status indicators, making it easy for developers to understand their codebase and access generated documentation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view interface in VS Code's sidebar that displays code analysis insights, documentation status, and generated reports with timestamps and action buttons.\",\n  \"userVisibleActions\": [\n    \"View code analysis insights organized in a tree structure in the sidebar\",\n    \"See status indicators (idle/generating/complete) for product documentation, insights, and unit tests\",\n    \"Click on insight items to navigate to specific code locations\",\n    \"Refresh the insights tree view to update the display\",\n    \"Open generated reports (workspace, product, architecture, unit test) from the tree\",\n    \"Copy insight descriptions to clipboard\",\n    \"Generate product documentation, insights, unit tests, and analysis reports via tree item buttons\",\n    \"Regenerate existing insights and documentation\",\n    \"See timestamps showing when reports and documentation were last generated\",\n    \"View dependency tree and architecture insights\",\n    \"Access static analysis results through the tree view\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree provider manages state for multiple report types (workspace, product, architecture, unit test)\",\n    \"Persists timestamps and file paths across VS Code sessions using workspace state\",\n    \"Tracks generation status for documentation, insights, unit tests, and analysis\",\n    \"Handles LLM service integration for generating AI-powered insights\",\n    \"Provides tree data structure with expandable/collapsible sections\",\n    \"Manages navigation from tree items to code locations via file paths and line numbers\",\n    \"Exposes refresh mechanism to update tree view when analysis completes\",\n    \"Supports copying insight text to clipboard programmatically\",\n    \"Validates existence of generated report files before displaying them\",\n    \"Integrates with static analysis viewer component\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Triggers the tree view to reload and display updated insights and statuses\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void (fires onDidChangeTreeData event)\"\n    },\n    {\n      \"name\": \"setInsights\",\n      \"desc\": \"Updates the insights data displayed in the tree view\",\n      \"inputs\": \"insights: Insight[] - array of insight objects\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Returns the VS Code tree item representation for a given tree node\",\n      \"inputs\": \"element: TreeItem - tree node element\",\n      \"outputs\": \"vscode.TreeItem or Thenable<vscode.TreeItem>\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns child nodes for a given tree item or root nodes if no element provided\",\n      \"inputs\": \"element?: TreeItem - optional parent tree item\",\n      \"outputs\": \"TreeItem[] - array of child tree items\"\n    },\n    {\n      \"name\": \"setProductDocsStatus\",\n      \"desc\": \"Updates the product documentation generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setInsightsStatus\",\n      \"desc\": \"Updates the insights generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestStatus\",\n      \"desc\": \"Updates the unit test generation status\",\n      \"inputs\": \"status: 'idle' | 'generating' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setAnalysisStatus\",\n      \"desc\": \"Updates the analysis completion status\",\n      \"inputs\": \"status: 'idle' | 'complete', timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setReportPath\",\n      \"desc\": \"Sets the file path for a generated report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setWorkspaceReportPath\",\n      \"desc\": \"Sets the file path for the workspace report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setProductReportPath\",\n      \"desc\": \"Sets the file path for the product report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setArchitectureReportPath\",\n      \"desc\": \"Sets the file path for the architecture report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setUnitTestReportPath\",\n      \"desc\": \"Sets the file path for the unit test report\",\n      \"inputs\": \"path: string, timestamp?: number\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMService\",\n      \"desc\": \"Configures the LLM service for generating AI-powered insights\",\n      \"inputs\": \"llmService: LLMService\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setLLMInsights\",\n      \"desc\": \"Updates the LLM-generated insights data\",\n      \"inputs\": \"llmInsights: LLMInsights\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"setStaticAnalysisViewer\",\n      \"desc\": \"Sets the static analysis viewer component for integration\",\n      \"inputs\": \"viewer: any - static analysis viewer instance\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadPersistedState\",\n      \"desc\": \"Restores previously saved timestamps and report paths from workspace storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"formatTimestamp\",\n      \"desc\": \"Converts a timestamp number into a human-readable date/time string\",\n      \"inputs\": \"timestamp: number\",\n      \"outputs\": \"string - formatted date/time\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"insightGenerator\",\n    \"llmFormatter\",\n    \"llmService\"\n  ],\n  \"intent\": \"This file exists to provide a user-friendly sidebar interface in VS Code that visualizes code analysis results, tracks generation status of various documentation and test reports, and offers quick access to generated artifacts. It solves the problem of presenting complex analysis data in an organized, navigable tree structure with actionable buttons and status indicators, making it easy for developers to understand their codebase and access generated documentation.\"\n}\n```"
    },
    {
      "file": "src/insightsViewer.ts",
      "role": "GUI View",
      "purpose": "Provides a tree view panel in VS Code that displays and allows browsing of AI-generated architecture insights about the codebase",
      "userVisibleActions": [
        "View architecture insights organized in a tree structure in the sidebar",
        "Browse different insight categories (Intent, Key Components, Data Flow, Entry Points, Architecture, Diagrams, Requirements, Recommendations)",
        "Click on insights to open related files or documentation",
        "See insights automatically update when analysis files change",
        "Open files directly from insight items that reference them",
        "View markdown documentation when clicking on insights",
        "See file paths and line numbers linked to specific insights",
        "Refresh insights view manually when needed"
      ],
      "developerVisibleActions": [
        "Tree view automatically watches .shadow/docs/architecture-insights.json for changes",
        "Tree view automatically watches .shadow/docs/PROJECT_PURPOSE.md for changes",
        "Insights data is loaded from architecture-insights.json file when available",
        "File system watchers trigger automatic refresh when insights files are modified",
        "Tree items are created with icons, descriptions, and navigation commands",
        "Clicking insight items triggers openFile command with file path and line number",
        "Purpose document changes trigger tree view refresh",
        "Provides TreeDataProvider interface for VS Code tree view integration"
      ],
      "keyFunctions": [
        {
          "name": "refresh",
          "desc": "Reloads insights from the file system and updates the tree view",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "loadInsights",
          "desc": "Reads architecture-insights.json file and parses it into insights object",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getChildren",
          "desc": "Returns tree items for a given parent node to populate the tree structure",
          "inputs": "element: InsightItem | undefined",
          "outputs": "Promise<InsightItem[]>"
        },
        {
          "name": "getTreeItem",
          "desc": "Converts an InsightItem into a VS Code TreeItem with visual properties",
          "inputs": "element: InsightItem",
          "outputs": "vscode.TreeItem"
        },
        {
          "name": "setupFileWatcher",
          "desc": "Creates file system watchers for insights and purpose files to auto-refresh view",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "getInsightIcon",
          "desc": "Returns appropriate icon for different insight types and categories",
          "inputs": "type: string",
          "outputs": "vscode.ThemeIcon"
        },
        {
          "name": "dispose",
          "desc": "Cleans up file watchers and resources when view is destroyed",
          "inputs": "none",
          "outputs": "void"
        }
      ],
      "dependencies": [
        "vscode",
        "path",
        "fs",
        "./llmService",
        "./domain/services/fileWatcherService"
      ],
      "intent": "This file exists to provide users with a visual, navigable tree interface in VS Code that displays AI-generated architecture insights about their codebase, making it easy to understand project structure, intent, and key components by browsing organized categories and clicking through to relevant files and documentation.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides a tree view panel in VS Code that displays and allows browsing of AI-generated architecture insights about the codebase\",\n  \"userVisibleActions\": [\n    \"View architecture insights organized in a tree structure in the sidebar\",\n    \"Browse different insight categories (Intent, Key Components, Data Flow, Entry Points, Architecture, Diagrams, Requirements, Recommendations)\",\n    \"Click on insights to open related files or documentation\",\n    \"See insights automatically update when analysis files change\",\n    \"Open files directly from insight items that reference them\",\n    \"View markdown documentation when clicking on insights\",\n    \"See file paths and line numbers linked to specific insights\",\n    \"Refresh insights view manually when needed\"\n  ],\n  \"developerVisibleActions\": [\n    \"Tree view automatically watches .shadow/docs/architecture-insights.json for changes\",\n    \"Tree view automatically watches .shadow/docs/PROJECT_PURPOSE.md for changes\",\n    \"Insights data is loaded from architecture-insights.json file when available\",\n    \"File system watchers trigger automatic refresh when insights files are modified\",\n    \"Tree items are created with icons, descriptions, and navigation commands\",\n    \"Clicking insight items triggers openFile command with file path and line number\",\n    \"Purpose document changes trigger tree view refresh\",\n    \"Provides TreeDataProvider interface for VS Code tree view integration\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"refresh\",\n      \"desc\": \"Reloads insights from the file system and updates the tree view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"loadInsights\",\n      \"desc\": \"Reads architecture-insights.json file and parses it into insights object\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getChildren\",\n      \"desc\": \"Returns tree items for a given parent node to populate the tree structure\",\n      \"inputs\": \"element: InsightItem | undefined\",\n      \"outputs\": \"Promise<InsightItem[]>\"\n    },\n    {\n      \"name\": \"getTreeItem\",\n      \"desc\": \"Converts an InsightItem into a VS Code TreeItem with visual properties\",\n      \"inputs\": \"element: InsightItem\",\n      \"outputs\": \"vscode.TreeItem\"\n    },\n    {\n      \"name\": \"setupFileWatcher\",\n      \"desc\": \"Creates file system watchers for insights and purpose files to auto-refresh view\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"getInsightIcon\",\n      \"desc\": \"Returns appropriate icon for different insight types and categories\",\n      \"inputs\": \"type: string\",\n      \"outputs\": \"vscode.ThemeIcon\"\n    },\n    {\n      \"name\": \"dispose\",\n      \"desc\": \"Cleans up file watchers and resources when view is destroyed\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"path\",\n    \"fs\",\n    \"./llmService\",\n    \"./domain/services/fileWatcherService\"\n  ],\n  \"intent\": \"This file exists to provide users with a visual, navigable tree interface in VS Code that displays AI-generated architecture insights about their codebase, making it easy to understand project structure, intent, and key components by browsing organized categories and clicking through to relevant files and documentation.\"\n}\n```"
    },
    {
      "file": "src/llmFormatter.ts",
      "role": "Core Logic",
      "purpose": "Formats code architecture insights into different output styles optimized for various AI assistants and display formats",
      "userVisibleActions": [
        "User receives formatted architecture issues grouped by severity (errors, warnings, info)",
        "User sees insights organized with emoji indicators ( for errors,  for warnings,  for info)",
        "User gets actionable prompts asking AI to prioritize issues and suggest fixes",
        "User can choose between different format styles: Cursor, ChatGPT, Compact, or Generic",
        "User sees file locations, specific issues, and improvement suggestions for each problem",
        "User receives a summary of total issues found in the codebase"
      ],
      "developerVisibleActions": [
        "Developer calls formatInsights() with an array of insights and a format type",
        "System transforms raw insight data into human-readable markdown text",
        "Different AI assistants receive optimized formatting (Cursor gets conversational prompts, ChatGPT gets structured sections, Compact gets minimal output)",
        "Insights are automatically grouped and sorted by severity level",
        "Each insight includes file path, rule violated, issue description, and improvement guidance",
        "Output includes actionable next steps tailored to the target AI assistant"
      ],
      "keyFunctions": [
        {
          "name": "formatInsights",
          "desc": "Formats a list of insights into the specified output format",
          "inputs": "insights: Insight[], format: string (default 'cursor')",
          "outputs": "Formatted string in markdown"
        },
        {
          "name": "formatForCursor",
          "desc": "Creates Cursor AI-optimized format with conversational prompts and grouped severity sections",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string with critical issues, warnings, info, and actionable requests"
        },
        {
          "name": "formatForChatGPT",
          "desc": "Creates ChatGPT-optimized format with structured analysis sections",
          "inputs": "insights: Insight[]",
          "outputs": "Markdown string with severity breakdown and detailed issue listings"
        },
        {
          "name": "formatCompact",
          "desc": "Creates minimal format with just issue counts and brief descriptions",
          "inputs": "insights: Insight[]",
          "outputs": "Compact markdown string with essential information only"
        },
        {
          "name": "formatGeneric",
          "desc": "Creates standard format suitable for any AI assistant or display",
          "inputs": "insights: Insight[]",
          "outputs": "Plain markdown string with severity sections and issue details"
        },
        {
          "name": "formatInsightForCursor",
          "desc": "Formats individual insight with file path, rule, and improvement guidance",
          "inputs": "insight: Insight",
          "outputs": "Formatted string for single insight"
        },
        {
          "name": "formatInsightForChatGPT",
          "desc": "Formats individual insight with numbered structure for ChatGPT",
          "inputs": "insight: Insight",
          "outputs": "Formatted string for single insight"
        },
        {
          "name": "formatInsightCompact",
          "desc": "Formats individual insight in minimal one-line format",
          "inputs": "insight: Insight",
          "outputs": "Compact string for single insight"
        },
        {
          "name": "formatInsightGeneric",
          "desc": "Formats individual insight in standard format",
          "inputs": "insight: Insight",
          "outputs": "Standard formatted string for single insight"
        }
      ],
      "dependencies": [
        "./insightGenerator"
      ],
      "intent": "Solves the problem of presenting technical code architecture issues in a way that's optimized for different AI assistants to understand and act upon, making it easier for users to get relevant help from their AI coding assistant of choice",
      "rawContent": "```json\n{\n  \"purpose\": \"Formats code architecture insights into different output styles optimized for various AI assistants and display formats\",\n  \"userVisibleActions\": [\n    \"User receives formatted architecture issues grouped by severity (errors, warnings, info)\",\n    \"User sees insights organized with emoji indicators ( for errors,  for warnings,  for info)\",\n    \"User gets actionable prompts asking AI to prioritize issues and suggest fixes\",\n    \"User can choose between different format styles: Cursor, ChatGPT, Compact, or Generic\",\n    \"User sees file locations, specific issues, and improvement suggestions for each problem\",\n    \"User receives a summary of total issues found in the codebase\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developer calls formatInsights() with an array of insights and a format type\",\n    \"System transforms raw insight data into human-readable markdown text\",\n    \"Different AI assistants receive optimized formatting (Cursor gets conversational prompts, ChatGPT gets structured sections, Compact gets minimal output)\",\n    \"Insights are automatically grouped and sorted by severity level\",\n    \"Each insight includes file path, rule violated, issue description, and improvement guidance\",\n    \"Output includes actionable next steps tailored to the target AI assistant\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"formatInsights\",\n      \"desc\": \"Formats a list of insights into the specified output format\",\n      \"inputs\": \"insights: Insight[], format: string (default 'cursor')\",\n      \"outputs\": \"Formatted string in markdown\"\n    },\n    {\n      \"name\": \"formatForCursor\",\n      \"desc\": \"Creates Cursor AI-optimized format with conversational prompts and grouped severity sections\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with critical issues, warnings, info, and actionable requests\"\n    },\n    {\n      \"name\": \"formatForChatGPT\",\n      \"desc\": \"Creates ChatGPT-optimized format with structured analysis sections\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Markdown string with severity breakdown and detailed issue listings\"\n    },\n    {\n      \"name\": \"formatCompact\",\n      \"desc\": \"Creates minimal format with just issue counts and brief descriptions\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Compact markdown string with essential information only\"\n    },\n    {\n      \"name\": \"formatGeneric\",\n      \"desc\": \"Creates standard format suitable for any AI assistant or display\",\n      \"inputs\": \"insights: Insight[]\",\n      \"outputs\": \"Plain markdown string with severity sections and issue details\"\n    },\n    {\n      \"name\": \"formatInsightForCursor\",\n      \"desc\": \"Formats individual insight with file path, rule, and improvement guidance\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightForChatGPT\",\n      \"desc\": \"Formats individual insight with numbered structure for ChatGPT\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Formatted string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightCompact\",\n      \"desc\": \"Formats individual insight in minimal one-line format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Compact string for single insight\"\n    },\n    {\n      \"name\": \"formatInsightGeneric\",\n      \"desc\": \"Formats individual insight in standard format\",\n      \"inputs\": \"insight: Insight\",\n      \"outputs\": \"Standard formatted string for single insight\"\n    }\n  ],\n  \"dependencies\": [\n    \"./insightGenerator\"\n  ],\n  \"intent\": \"Solves the problem of presenting technical code architecture issues in a way that's optimized for different AI assistants to understand and act upon, making it easier for users to get relevant help from their AI coding assistant of choice\"\n}\n```"
    },
    {
      "file": "src/llmIntegration.ts",
      "role": "Core Logic",
      "purpose": "Integrates LLM-powered code analysis features with VS Code UI components, managing initialization, commands, and state for insights, documentation, and test generation.",
      "userVisibleActions": [
        "Generate AI-powered code insights for the entire workspace",
        "Analyze specific code files or selected code snippets",
        "View generated insights in a tree view panel",
        "Generate product documentation from codebase analysis",
        "View formatted documentation in the output panel and webview",
        "Export documentation to markdown files",
        "Navigate through code structure and entry points",
        "View unit test analysis and coverage",
        "Generate unit tests using AI",
        "Clear cached insights and analysis results",
        "Configure LLM API settings (provider, API key, model)",
        "See analysis progress through status messages and progress bars"
      ],
      "developerVisibleActions": [
        "Register VS Code commands for triggering LLM analysis workflows",
        "Initialize LLM service with configuration from workspace settings",
        "Save and load analysis results to/from workspace storage",
        "Trigger tree view refreshes when data changes",
        "Handle errors and display user-friendly error messages",
        "Manage state across different analysis views and panels",
        "Coordinate between multiple UI providers (insights, documentation, tests)",
        "Execute analysis workflows with proper context and scope",
        "Format and present analysis results in multiple output formats",
        "Handle file system operations for saving/loading cached data"
      ],
      "keyFunctions": [
        {
          "name": "initializeLLMService",
          "desc": "Sets up the LLM service, output channels, and loads saved analysis data on extension startup",
          "inputs": "none",
          "outputs": "void"
        },
        {
          "name": "analyzeFull",
          "desc": "Performs comprehensive codebase analysis and generates insights for the entire workspace",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeFile",
          "desc": "Analyzes a specific file or currently active editor and generates insights",
          "inputs": "optional URI",
          "outputs": "Promise<void>"
        },
        {
          "name": "analyzeSelection",
          "desc": "Analyzes only the selected code in the active editor",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "generateProductDocumentation",
          "desc": "Creates formatted product documentation from code analysis results",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "exportDocumentation",
          "desc": "Saves generated documentation to markdown files in the workspace",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "clearInsights",
          "desc": "Removes all cached insights and analysis results from storage",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "generateUnitTests",
          "desc": "Uses AI to generate unit tests for selected code or active file",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "showInsights",
          "desc": "Displays the insights tree view panel in the VS Code sidebar",
          "inputs": "none",
          "outputs": "Promise<void>"
        },
        {
          "name": "configureAPISettings",
          "desc": "Opens configuration interface for setting LLM provider and API credentials",
          "inputs": "none",
          "outputs": "Promise<void>"
        }
      ],
      "dependencies": [
        "vscode",
        "fs",
        "path",
        "child_process",
        "util",
        "llmService",
        "insightsTreeView",
        "fileDocumentation",
        "analyzer",
        "productNavigator",
        "analysisViewer",
        "insightsViewer",
        "unitTestsNavigator",
        "logger",
        "state/llmStateManager",
        "context/analysisContextBuilder",
        "domain/formatters/documentationFormatter",
        "infrastructure/persistence/analysisResultRepository"
      ],
      "intent": "This file exists to bridge the gap between LLM-powered code analysis capabilities and VS Code's user interface, providing a complete integration layer that allows users to leverage AI for understanding codebases, generating documentation, and creating tests through familiar VS Code commands and UI components.",
      "rawContent": "```json\n{\n  \"purpose\": \"Integrates LLM-powered code analysis features with VS Code UI components, managing initialization, commands, and state for insights, documentation, and test generation.\",\n  \"userVisibleActions\": [\n    \"Generate AI-powered code insights for the entire workspace\",\n    \"Analyze specific code files or selected code snippets\",\n    \"View generated insights in a tree view panel\",\n    \"Generate product documentation from codebase analysis\",\n    \"View formatted documentation in the output panel and webview\",\n    \"Export documentation to markdown files\",\n    \"Navigate through code structure and entry points\",\n    \"View unit test analysis and coverage\",\n    \"Generate unit tests using AI\",\n    \"Clear cached insights and analysis results\",\n    \"Configure LLM API settings (provider, API key, model)\",\n    \"See analysis progress through status messages and progress bars\"\n  ],\n  \"developerVisibleActions\": [\n    \"Register VS Code commands for triggering LLM analysis workflows\",\n    \"Initialize LLM service with configuration from workspace settings\",\n    \"Save and load analysis results to/from workspace storage\",\n    \"Trigger tree view refreshes when data changes\",\n    \"Handle errors and display user-friendly error messages\",\n    \"Manage state across different analysis views and panels\",\n    \"Coordinate between multiple UI providers (insights, documentation, tests)\",\n    \"Execute analysis workflows with proper context and scope\",\n    \"Format and present analysis results in multiple output formats\",\n    \"Handle file system operations for saving/loading cached data\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"initializeLLMService\",\n      \"desc\": \"Sets up the LLM service, output channels, and loads saved analysis data on extension startup\",\n      \"inputs\": \"none\",\n      \"outputs\": \"void\"\n    },\n    {\n      \"name\": \"analyzeFull\",\n      \"desc\": \"Performs comprehensive codebase analysis and generates insights for the entire workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeFile\",\n      \"desc\": \"Analyzes a specific file or currently active editor and generates insights\",\n      \"inputs\": \"optional URI\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"analyzeSelection\",\n      \"desc\": \"Analyzes only the selected code in the active editor\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateProductDocumentation\",\n      \"desc\": \"Creates formatted product documentation from code analysis results\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"exportDocumentation\",\n      \"desc\": \"Saves generated documentation to markdown files in the workspace\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"clearInsights\",\n      \"desc\": \"Removes all cached insights and analysis results from storage\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"generateUnitTests\",\n      \"desc\": \"Uses AI to generate unit tests for selected code or active file\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"showInsights\",\n      \"desc\": \"Displays the insights tree view panel in the VS Code sidebar\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    },\n    {\n      \"name\": \"configureAPISettings\",\n      \"desc\": \"Opens configuration interface for setting LLM provider and API credentials\",\n      \"inputs\": \"none\",\n      \"outputs\": \"Promise<void>\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"fs\",\n    \"path\",\n    \"child_process\",\n    \"util\",\n    \"llmService\",\n    \"insightsTreeView\",\n    \"fileDocumentation\",\n    \"analyzer\",\n    \"productNavigator\",\n    \"analysisViewer\",\n    \"insightsViewer\",\n    \"unitTestsNavigator\",\n    \"logger\",\n    \"state/llmStateManager\",\n    \"context/analysisContextBuilder\",\n    \"domain/formatters/documentationFormatter\",\n    \"infrastructure/persistence/analysisResultRepository\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between LLM-powered code analysis capabilities and VS Code's user interface, providing a complete integration layer that allows users to leverage AI for understanding codebases, generating documentation, and creating tests through familiar VS Code commands and UI components.\"\n}\n```"
    },
    {
      "file": "src/llmSchemas.ts",
      "role": "Core Logic",
      "purpose": "Defines JSON schemas that structure and validate AI (Claude) responses for code analysis, ensuring parseable outputs without manual parsing.",
      "userVisibleActions": [
        "Receives structured analysis of product purpose and architecture rationale",
        "Gets organized lists of design decisions and user goals",
        "Sees formatted issue reports with titles, descriptions, and affected files",
        "Receives behavior descriptions with user-facing and developer-facing actions",
        "Gets dependency analysis with module relationships and purposes",
        "Sees intent explanations for why files exist and what problems they solve"
      ],
      "developerVisibleActions": [
        "Provides schema templates that guarantee valid JSON responses from Claude AI",
        "Enforces required fields in AI responses to prevent missing data",
        "Structures AI output into predictable formats for programmatic consumption",
        "Validates that AI responses include specific information categories",
        "Defines metadata fields for tracking analysis completeness and confidence",
        "Ensures AI responses distinguish between user-facing and developer-facing behavior",
        "Generates structured issue reports with severity levels and fix proposals"
      ],
      "keyFunctions": [
        {
          "name": "productPurposeAnalysisSchema",
          "desc": "Schema that structures AI analysis of product purpose and architecture decisions",
          "inputs": "Used by AI to format analysis results",
          "outputs": "Structured object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors"
        },
        {
          "name": "issueItemSchema",
          "desc": "Schema that formats individual code issues with titles, descriptions, and affected files",
          "inputs": "Used by AI to format issue detection results",
          "outputs": "Structured object with title, description, relevantFiles, relevantFunctions fields"
        },
        {
          "name": "behaviorItemSchema",
          "desc": "Schema that separates user-facing actions from developer-facing implementation details",
          "inputs": "Used by AI to categorize code behavior",
          "outputs": "Structured object with userVisibleActions and developerVisibleActions arrays"
        },
        {
          "name": "dependencyItemSchema",
          "desc": "Schema that documents module dependencies with their purposes and relationships",
          "inputs": "Used by AI to format dependency analysis",
          "outputs": "Structured object with module name, purpose, and usedBy/uses relationships"
        },
        {
          "name": "fileAnalysisSchema",
          "desc": "Comprehensive schema that combines purpose, behavior, dependencies, and intent analysis for a file",
          "inputs": "Used by AI to format complete file analysis",
          "outputs": "Structured object with purpose, behaviors, dependencies, intent, and metadata fields"
        }
      ],
      "dependencies": [],
      "intent": "Eliminates ambiguity in AI responses by defining strict JSON schemas that guarantee parseable, structured output for code analysis tasks, enabling reliable automated processing of AI-generated insights without manual parsing or error handling.",
      "rawContent": "```json\n{\n  \"purpose\": \"Defines JSON schemas that structure and validate AI (Claude) responses for code analysis, ensuring parseable outputs without manual parsing.\",\n  \"userVisibleActions\": [\n    \"Receives structured analysis of product purpose and architecture rationale\",\n    \"Gets organized lists of design decisions and user goals\",\n    \"Sees formatted issue reports with titles, descriptions, and affected files\",\n    \"Receives behavior descriptions with user-facing and developer-facing actions\",\n    \"Gets dependency analysis with module relationships and purposes\",\n    \"Sees intent explanations for why files exist and what problems they solve\"\n  ],\n  \"developerVisibleActions\": [\n    \"Provides schema templates that guarantee valid JSON responses from Claude AI\",\n    \"Enforces required fields in AI responses to prevent missing data\",\n    \"Structures AI output into predictable formats for programmatic consumption\",\n    \"Validates that AI responses include specific information categories\",\n    \"Defines metadata fields for tracking analysis completeness and confidence\",\n    \"Ensures AI responses distinguish between user-facing and developer-facing behavior\",\n    \"Generates structured issue reports with severity levels and fix proposals\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"productPurposeAnalysisSchema\",\n      \"desc\": \"Schema that structures AI analysis of product purpose and architecture decisions\",\n      \"inputs\": \"Used by AI to format analysis results\",\n      \"outputs\": \"Structured object with productPurpose, architectureRationale, designDecisions, userGoals, contextualFactors\"\n    },\n    {\n      \"name\": \"issueItemSchema\",\n      \"desc\": \"Schema that formats individual code issues with titles, descriptions, and affected files\",\n      \"inputs\": \"Used by AI to format issue detection results\",\n      \"outputs\": \"Structured object with title, description, relevantFiles, relevantFunctions fields\"\n    },\n    {\n      \"name\": \"behaviorItemSchema\",\n      \"desc\": \"Schema that separates user-facing actions from developer-facing implementation details\",\n      \"inputs\": \"Used by AI to categorize code behavior\",\n      \"outputs\": \"Structured object with userVisibleActions and developerVisibleActions arrays\"\n    },\n    {\n      \"name\": \"dependencyItemSchema\",\n      \"desc\": \"Schema that documents module dependencies with their purposes and relationships\",\n      \"inputs\": \"Used by AI to format dependency analysis\",\n      \"outputs\": \"Structured object with module name, purpose, and usedBy/uses relationships\"\n    },\n    {\n      \"name\": \"fileAnalysisSchema\",\n      \"desc\": \"Comprehensive schema that combines purpose, behavior, dependencies, and intent analysis for a file\",\n      \"inputs\": \"Used by AI to format complete file analysis\",\n      \"outputs\": \"Structured object with purpose, behaviors, dependencies, intent, and metadata fields\"\n    }\n  ],\n  \"dependencies\": [],\n  \"intent\": \"Eliminates ambiguity in AI responses by defining strict JSON schemas that guarantee parseable, structured output for code analysis tasks, enabling reliable automated processing of AI-generated insights without manual parsing or error handling.\"\n}\n```"
    },
    {
      "file": "src/llmService.ts",
      "role": "Core Logic",
      "purpose": "Provides AI-powered code analysis and documentation generation by coordinating LLM providers (OpenAI/Claude) to generate insights, summaries, and test plans for codebases.",
      "userVisibleActions": [
        "Generate intelligent product purpose analysis from codebase",
        "Create comprehensive documentation with architecture insights",
        "Generate unit test plans for code files",
        "Receive AI-powered refactoring suggestions for functions",
        "Get incremental analysis updates as code changes",
        "View module-level summaries and insights",
        "See file role classifications (entry point, core logic, etc.)",
        "Receive budget-aware analysis notifications"
      ],
      "developerVisibleActions": [
        "Call analyzeChatRequest() to get AI insights for chat interactions",
        "Use analyzeCodebase() to generate full codebase analysis with LLM insights",
        "Invoke analyzeProductPurpose() to extract high-level product goals",
        "Generate documentation via generateEnhancedProductDocumentation()",
        "Request test plans with generateUnitTestPlan()",
        "Get refactoring suggestions through analyzeForRefactoring()",
        "Configure LLM provider (OpenAI, Claude, Gemini) through settings",
        "Monitor token budget consumption across analysis operations",
        "Handle rate limiting and retry logic automatically",
        "Access parsed JSON responses from LLM outputs",
        "Receive structured analysis results with metadata"
      ],
      "keyFunctions": [
        {
          "name": "analyzeChatRequest",
          "desc": "Processes user chat requests and generates AI-powered responses about the codebase",
          "inputs": "userMessage (string), codebaseContext (analysis data), chatHistory (conversation array)",
          "outputs": "AI-generated response string addressing the user's question"
        },
        {
          "name": "analyzeCodebase",
          "desc": "Performs comprehensive codebase analysis using LLM to extract insights, patterns, and documentation",
          "inputs": "CodeAnalysis object with file structure and metadata",
          "outputs": "LLMInsights object with architectural patterns, tech stack, risks, and recommendations"
        },
        {
          "name": "analyzeProductPurpose",
          "desc": "Determines the high-level purpose and goals of the product from code analysis",
          "inputs": "CodeAnalysis with file summaries and structure",
          "outputs": "ProductPurposeAnalysis with purpose, rationale, and key capabilities"
        },
        {
          "name": "generateEnhancedProductDocumentation",
          "desc": "Creates detailed product documentation including purpose, architecture, and module descriptions",
          "inputs": "CodeAnalysis and optional ProductPurposeAnalysis",
          "outputs": "EnhancedProductDocumentation with comprehensive project documentation"
        },
        {
          "name": "generateUnitTestPlan",
          "desc": "Generates test plans with specific test cases for a code file",
          "inputs": "file path, file content, file role, module context",
          "outputs": "UnitTestPlan with test scenarios, coverage areas, and suggested test cases"
        },
        {
          "name": "analyzeForRefactoring",
          "desc": "Analyzes functions and provides refactoring suggestions to improve code quality",
          "inputs": "file path, file content, function metadata",
          "outputs": "RefactoringAnalysis with suggestions for improvements, complexity reduction, and best practices"
        },
        {
          "name": "callLLM",
          "desc": "Core method that handles all LLM API calls with rate limiting, retries, and response parsing",
          "inputs": "prompt, schema definition, token budget, provider selection",
          "outputs": "Parsed JSON response matching the requested schema"
        }
      ],
      "dependencies": [
        "vscode",
        "./fileDocumentation",
        "./analyzer",
        "./analysis/enhancedAnalyzer",
        "./llmSchemas",
        "./fileAccessHelper",
        "./logger",
        "./config/configurationManager",
        "./ai/providers/providerFactory",
        "./ai/llmResponseParser",
        "./ai/llmRateLimiter",
        "./ai/llmRetryHandler",
        "./domain/prompts/promptBuilder",
        "./domain/services/incrementalAnalysisService",
        "./domain/prompts/refactoringPromptBuilder",
        "./analysis/functionAnalyzer"
      ],
      "intent": "This file exists to bridge the gap between code analysis and AI-powered insights by managing all interactions with Large Language Models (OpenAI, Claude, Gemini). It solves the problem of extracting meaningful, human-readable insights from raw code structure by orchestrating LLM calls with proper rate limiting, retry logic, token budget management, and structured response parsing. It enables developers to get intelligent documentation, refactoring suggestions, test plans, and architectural insights without manually analyzing large codebases.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides AI-powered code analysis and documentation generation by coordinating LLM providers (OpenAI/Claude) to generate insights, summaries, and test plans for codebases.\",\n  \"userVisibleActions\": [\n    \"Generate intelligent product purpose analysis from codebase\",\n    \"Create comprehensive documentation with architecture insights\",\n    \"Generate unit test plans for code files\",\n    \"Receive AI-powered refactoring suggestions for functions\",\n    \"Get incremental analysis updates as code changes\",\n    \"View module-level summaries and insights\",\n    \"See file role classifications (entry point, core logic, etc.)\",\n    \"Receive budget-aware analysis notifications\"\n  ],\n  \"developerVisibleActions\": [\n    \"Call analyzeChatRequest() to get AI insights for chat interactions\",\n    \"Use analyzeCodebase() to generate full codebase analysis with LLM insights\",\n    \"Invoke analyzeProductPurpose() to extract high-level product goals\",\n    \"Generate documentation via generateEnhancedProductDocumentation()\",\n    \"Request test plans with generateUnitTestPlan()\",\n    \"Get refactoring suggestions through analyzeForRefactoring()\",\n    \"Configure LLM provider (OpenAI, Claude, Gemini) through settings\",\n    \"Monitor token budget consumption across analysis operations\",\n    \"Handle rate limiting and retry logic automatically\",\n    \"Access parsed JSON responses from LLM outputs\",\n    \"Receive structured analysis results with metadata\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"analyzeChatRequest\",\n      \"desc\": \"Processes user chat requests and generates AI-powered responses about the codebase\",\n      \"inputs\": \"userMessage (string), codebaseContext (analysis data), chatHistory (conversation array)\",\n      \"outputs\": \"AI-generated response string addressing the user's question\"\n    },\n    {\n      \"name\": \"analyzeCodebase\",\n      \"desc\": \"Performs comprehensive codebase analysis using LLM to extract insights, patterns, and documentation\",\n      \"inputs\": \"CodeAnalysis object with file structure and metadata\",\n      \"outputs\": \"LLMInsights object with architectural patterns, tech stack, risks, and recommendations\"\n    },\n    {\n      \"name\": \"analyzeProductPurpose\",\n      \"desc\": \"Determines the high-level purpose and goals of the product from code analysis\",\n      \"inputs\": \"CodeAnalysis with file summaries and structure\",\n      \"outputs\": \"ProductPurposeAnalysis with purpose, rationale, and key capabilities\"\n    },\n    {\n      \"name\": \"generateEnhancedProductDocumentation\",\n      \"desc\": \"Creates detailed product documentation including purpose, architecture, and module descriptions\",\n      \"inputs\": \"CodeAnalysis and optional ProductPurposeAnalysis\",\n      \"outputs\": \"EnhancedProductDocumentation with comprehensive project documentation\"\n    },\n    {\n      \"name\": \"generateUnitTestPlan\",\n      \"desc\": \"Generates test plans with specific test cases for a code file\",\n      \"inputs\": \"file path, file content, file role, module context\",\n      \"outputs\": \"UnitTestPlan with test scenarios, coverage areas, and suggested test cases\"\n    },\n    {\n      \"name\": \"analyzeForRefactoring\",\n      \"desc\": \"Analyzes functions and provides refactoring suggestions to improve code quality\",\n      \"inputs\": \"file path, file content, function metadata\",\n      \"outputs\": \"RefactoringAnalysis with suggestions for improvements, complexity reduction, and best practices\"\n    },\n    {\n      \"name\": \"callLLM\",\n      \"desc\": \"Core method that handles all LLM API calls with rate limiting, retries, and response parsing\",\n      \"inputs\": \"prompt, schema definition, token budget, provider selection\",\n      \"outputs\": \"Parsed JSON response matching the requested schema\"\n    }\n  ],\n  \"dependencies\": [\n    \"vscode\",\n    \"./fileDocumentation\",\n    \"./analyzer\",\n    \"./analysis/enhancedAnalyzer\",\n    \"./llmSchemas\",\n    \"./fileAccessHelper\",\n    \"./logger\",\n    \"./config/configurationManager\",\n    \"./ai/providers/providerFactory\",\n    \"./ai/llmResponseParser\",\n    \"./ai/llmRateLimiter\",\n    \"./ai/llmRetryHandler\",\n    \"./domain/prompts/promptBuilder\",\n    \"./domain/services/incrementalAnalysisService\",\n    \"./domain/prompts/refactoringPromptBuilder\",\n    \"./analysis/functionAnalyzer\"\n  ],\n  \"intent\": \"This file exists to bridge the gap between code analysis and AI-powered insights by managing all interactions with Large Language Models (OpenAI, Claude, Gemini). It solves the problem of extracting meaningful, human-readable insights from raw code structure by orchestrating LLM calls with proper rate limiting, retry logic, token budget management, and structured response parsing. It enables developers to get intelligent documentation, refactoring suggestions, test plans, and architectural insights without manually analyzing large codebases.\"\n}\n```"
    },
    {
      "file": "src/logger.ts",
      "role": "Core Logic",
      "purpose": "Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory",
      "userVisibleActions": [
        "Log files are created in the workspace's .shadow/logs directory",
        "A shadow-watch.log file accumulates timestamped entries of extension activity",
        "Logs persist across sessions for debugging and auditing purposes"
      ],
      "developerVisibleActions": [
        "Developers can call SWLogger.log() to write timestamped messages to the log file",
        "Developers can call SWLogger.section() to add formatted section headers to organize log entries",
        "Logging fails silently if the workspace is not available or file operations fail",
        "Log entries include ISO timestamp format for precise timing information"
      ],
      "keyFunctions": [
        {
          "name": "log",
          "desc": "Writes a timestamped message to the shadow-watch.log file",
          "inputs": "message: string - the text to log",
          "outputs": "void - no return value, writes to file system"
        },
        {
          "name": "section",
          "desc": "Adds a formatted section header to the log for organizing related entries",
          "inputs": "title: string - the section title",
          "outputs": "void - writes formatted header to log"
        },
        {
          "name": "getLogPath",
          "desc": "Determines the full file path where logs should be written",
          "inputs": "none",
          "outputs": "string | null - the log file path or null if no workspace is open"
        },
        {
          "name": "ensureDir",
          "desc": "Creates the directory structure if it doesn't exist",
          "inputs": "dir: string - directory path to create",
          "outputs": "void - creates directory recursively"
        }
      ],
      "dependencies": [
        "fs",
        "path",
        "vscode"
      ],
      "intent": "This file exists to provide centralized, file-based logging for the extension, allowing developers to track extension behavior and debug issues by writing persistent logs to the workspace. It solves the problem of needing visibility into extension operations without relying on console output or VS Code's output panel alone.",
      "rawContent": "```json\n{\n  \"purpose\": \"Provides logging functionality that writes timestamped messages to a log file in the workspace's .shadow/logs directory\",\n  \"userVisibleActions\": [\n    \"Log files are created in the workspace's .shadow/logs directory\",\n    \"A shadow-watch.log file accumulates timestamped entries of extension activity\",\n    \"Logs persist across sessions for debugging and auditing purposes\"\n  ],\n  \"developerVisibleActions\": [\n    \"Developers can call SWLogger.log() to write timestamped messages to the log file\",\n    \"Developers can call SWLogger.section() to add formatted section headers to organize log entries\",\n    \"Logging fails silently if the workspace is not available or file operations fail\",\n    \"Log entries include ISO timestamp format for precise timing information\"\n  ],\n  \"keyFunctions\": [\n    {\n      \"name\": \"log\",\n      \"desc\": \"Writes a timestamped message to the shadow-watch.log file\",\n      \"inputs\": \"message: string - the text to log\",\n      \"outputs\": \"void - no return value, writes to file system\"\n    },\n    {\n      \"name\": \"section\",\n      \"desc\": \"Adds a formatted section header to the log for organizing related entries\",\n      \"inputs\": \"title: string - the section title\",\n      \"outputs\": \"void - writes formatted header to log\"\n    },\n    {\n      \"name\": \"getLogPath\",\n      \"desc\": \"Determines the full file path where logs should be written\",\n      \"inputs\": \"none\",\n      \"outputs\": \"string | null - the log file path or null if no workspace is open\"\n    },\n    {\n      \"name\": \"ensureDir\",\n      \"desc\": \"Creates the directory structure if it doesn't exist\",\n      \"inputs\": \"dir: string - directory path to create\",\n      \"outputs\": \"void - creates directory recursively\"\n    }\n  ],\n  \"dependencies\": [\n    \"fs\",\n    \"path\",\n    \"vscode\"\n  ],\n  \"intent\": \"This file exists to provide centralized, file-based logging for the extension, allowing developers to track extension behavior and debug issues by writing persistent logs to the workspace. It solves the problem of needing visibility into extension operations without relying on console output or VS Code's output panel alone.\"\n}\n```"
    }
  ],
  "rawContent": "{\"overview\":\"Shadow Watch is a Visual Studio Code extension that provides AI-powered code intelligence and documentation generation for software development teams. It automatically analyzes codebases to understand their structure, purpose, and quality, then generates comprehensive documentation explaining what the code does and why it exists. Users can analyze individual files or entire projects, with results appearing as inline diagnostics, browsable tree views in the sidebar, and exportable markdown reports.\\n\\nThe extension integrates deeply with VS Code's interface, allowing developers to navigate seamlessly between analysis insights and source code locations. When users save files, Shadow Watch automatically re-analyzes the changes and updates its insights in real-time. The extension supports multiple AI providers (OpenAI GPT and Anthropic Claude) for generating documentation and architectural analysis, with configurable output formats optimized for different AI assistants and workflows.\\n\\nBeyond documentation, Shadow Watch helps development teams improve code quality by identifying architectural patterns, code smells, circular dependencies, orphaned files, and potential refactoring opportunities. It can generate unit test plans, create test code with proper mocks and assertions, validate tests by executing them, and automatically fix failing tests through iterative AI-powered corrections.\",\"whatItDoes\":[\"Analyzes codebases to generate product documentation explaining what applications do from a user perspective\",\"Creates module and file-level documentation describing code purpose, features, and capabilities\",\"Identifies architecture patterns, code quality issues, and potential improvement opportunities\",\"Generates unit test plans prioritized by function complexity and importance\",\"Creates unit test code with appropriate framework setup, mocks, and assertions\",\"Automatically validates and fixes failing tests through iterative AI corrections\",\"Displays inline diagnostics showing code issues as squiggly underlines in the editor\",\"Provides browsable tree views showing code structure, statistics, and analysis results\",\"Exports analysis results and documentation to markdown files for sharing\",\"Enables navigation from insights directly to relevant source code locations\",\"Monitors file changes and automatically updates analysis when files are saved\",\"Caches analysis results for fast repeated access without re-scanning\",\"Supports switching between OpenAI GPT and Anthropic Claude AI providers\",\"Formats documentation in multiple styles optimized for different AI assistants\"],\"userPerspective\":{\"gui\":[\"Browse code analysis results in a hierarchical tree view in the VS Code sidebar\",\"View inline diagnostics with squiggly underlines showing code quality issues in the Problems panel\",\"Click on analysis insights to jump directly to the relevant source code location\",\"See real-time progress indicators in the status bar during long-running analysis operations\",\"Review generated documentation in formatted markdown within VS Code\",\"Access action buttons to generate tests, analyze files, or export results\",\"View unit test reports showing passed/failed counts, execution duration, and coverage metrics\",\"Navigate between different analysis views including insights, architecture, and test results\"],\"cli\":[\"Execute extension commands through the VS Code command palette\",\"Trigger analysis on specific files or entire workspaces via keyboard shortcuts\",\"Switch between AI providers using command palette actions\",\"Copy generated insights and documentation to clipboard for external use\"],\"api\":[\"Configure AI provider settings (API keys, model selection) through VS Code settings\",\"Set diagnostic severity levels to control which issues appear in the Problems panel\",\"Enable or disable automatic analysis on file save\",\"Choose output format for AI-generated content (Cursor, ChatGPT, Generic, Compact)\",\"Specify LLM models for different providers through configuration\"],\"cicd\":[\"Export analysis results as markdown files for documentation repositories\",\"Generate test plans and test code that integrate with existing CI/CD test suites\",\"Produce architecture insights that can inform code review processes\",\"Create documentation artifacts suitable for version control and documentation systems\"]},\"workflowIntegration\":[\"Code review workflow: Analyze pull requests to identify quality issues and generate documentation for new features\",\"Documentation generation workflow: Automatically create and update product, module, and file-level documentation as code evolves\",\"Test-driven development workflow: Generate test plans and initial test code from existing functions, then validate and fix tests iteratively\",\"Refactoring workflow: Identify large or complex functions that should be extracted, with detailed migration instructions\",\"Architecture assessment workflow: Understand codebase structure, identify patterns, and spot architectural issues like circular dependencies\",\"Onboarding workflow: Generate comprehensive documentation to help new team members understand what the codebase does\",\"Quality assurance workflow: Continuously monitor code quality through automatic analysis on file save, with inline feedback\"],\"problemsSolved\":[\"Eliminates manual documentation writing by automatically generating comprehensive product and code documentation\",\"Reduces time spent understanding unfamiliar codebases by providing AI-generated summaries and architectural insights\",\"Prevents outdated documentation by automatically updating analysis when code changes\",\"Speeds up test creation by generating unit tests with proper setup, mocks, and assertions\",\"Reduces debugging time by automatically fixing failing tests through AI-powered corrections\",\"Improves code quality by identifying issues like circular dependencies, orphaned files, and code smells\",\"Accelerates code reviews by providing immediate insights into code structure and potential issues\",\"Simplifies onboarding by generating clear explanations of what code does from a user perspective\",\"Maintains consistent documentation quality across large codebases through standardized AI analysis\",\"Enables seamless navigation from analysis insights to source code, reducing context switching\"],\"architecture\":\"Shadow Watch follows a layered architecture with clear separation between infrastructure, domain logic, and user interface components. The infrastructure layer manages AI provider integration (OpenAI and Claude), file system access with caching, and persistent storage of analysis results. The domain layer contains the core business logic for code analysis, test generation, and documentation creation, organized into services that orchestrate complex workflows like incremental AI analysis and test validation. The UI layer provides VS Code integration through tree view providers, diagnostic providers, webview panels, and command handlers.\\n\\nThe extension uses a request-response pattern for AI interactions, where analysis operations make structured requests to language models and parse responses into typed objects. A rate limiter prevents API quota exhaustion, while a retry handler manages transient failures with exponential backoff. Code analysis flows through an AST-based parser that extracts function metadata, dependencies, and behavioral patterns, feeding this structured data into prompt builders that generate context-rich queries for the AI.\\n\\nState management is centralized through managers that track analysis progress, configuration changes, and test generation status. File watching services monitor the workspace for changes and trigger automatic re-analysis. Results are cached both in memory and on disk to avoid redundant processing. The architecture supports extensibility through provider factories and standardized interfaces, allowing new AI providers or analysis capabilities to be added without modifying existing components.\",\"titles\":[\"Shadow Watch Extension\",\"Code Analysis Tree View\",\"Architecture Insights\",\"Product Documentation Generator\",\"Module Documentation\",\"File Documentation\",\"Unit Test Generator\",\"Test Plan Creator\",\"Test Validator\",\"Automatic Test Fixer\",\"Inline Diagnostics\",\"Navigation Handler\",\"Incremental Analysis\",\"File Watcher\",\"Progress Notifications\",\"AI Provider Integration\",\"OpenAI Provider\",\"Claude Provider\",\"Rate Limiter\",\"Retry Handler\",\"Response Parser\",\"Enhanced Analyzer\",\"Function Analyzer\",\"Insight Generator\",\"Refactoring Recommendations\",\"Configuration Manager\",\"Documentation Formatter\",\"Prompt Builder\",\"Test Execution Service\",\"Analysis Cache\",\"File Cache\",\"Analysis Result Repository\",\"LLM Integration\",\"Command Registry\",\"Extension Bootstrapper\"],\"descriptions\":[{\"title\":\"Shadow Watch Extension\",\"description\":\"VS Code extension that provides AI-powered code intelligence, documentation generation, and automated testing capabilities for software development teams\",\"category\":\"feature\"},{\"title\":\"Code Analysis Tree View\",\"description\":\"Hierarchical sidebar view displaying code structure, statistics, and analysis results with clickable navigation to source locations\",\"category\":\"component\"},{\"title\":\"Architecture Insights\",\"description\":\"AI-generated analysis of codebase architecture patterns, dependencies, code quality issues, and improvement recommendations\",\"category\":\"feature\"},{\"title\":\"Product Documentation Generator\",\"description\":\"Automatically creates comprehensive documentation explaining what an application does from a user perspective, including features, workflows, and problems solved\",\"category\":\"feature\"},{\"title\":\"Module Documentation\",\"description\":\"Generates documentation for code modules describing their user-facing capabilities and how they contribute to the overall application\",\"category\":\"feature\"},{\"title\":\"File Documentation\",\"description\":\"Creates file-level documentation explaining the purpose, key functions, and role of individual source files\",\"category\":\"feature\"},{\"title\":\"Unit Test Generator\",\"description\":\"Automatically generates unit test code with proper framework setup, mocks, and assertions for functions in the codebase\",\"category\":\"feature\"},{\"title\":\"Test Plan Creator\",\"description\":\"Analyzes codebases to create prioritized test plans determining which functions should be tested and in what order based on complexity and importance\",\"category\":\"feature\"},{\"title\":\"Test Validator\",\"description\":\"Executes generated tests to verify they pass, capturing detailed results including pass/fail counts, execution duration, and error messages\",\"category\":\"feature\"},{\"title\":\"Automatic Test Fixer\",\"description\":\"Automatically repairs failing tests through iterative AI-powered corrections, analyzing failure messages and regenerating test code until tests pass\",\"category\":\"feature\"},{\"title\":\"Inline Diagnostics\",\"description\":\"Displays code quality issues and warnings as squiggly underlines in the editor with detailed messages in the Problems panel\",\"category\":\"feature\"},{\"title\":\"Navigation Handler\",\"description\":\"Manages seamless navigation from analysis results to source code locations, opening files and positioning the cursor at exact lines and columns\",\"category\":\"component\"},{\"title\":\"Incremental Analysis\",\"description\":\"Progressively gathers code context by making multiple AI requests, reading additional files and searching for patterns as needed to build comprehensive understanding\",\"category\":\"workflow\"},{\"title\":\"File Watcher\",\"description\":\"Monitors workspace for file changes (creation, modification, deletion) and automatically triggers re-analysis to keep insights current\",\"category\":\"component\"},{\"title\":\"Progress Notifications\",\"description\":\"Displays progress indicators with titles, messages, and cancellation support during long-running operations like analysis and test generation\",\"category\":\"component\"},{\"title\":\"AI Provider Integration\",\"description\":\"Unified interface for communicating with multiple AI language model providers (OpenAI GPT and Anthropic Claude) through a consistent API\",\"category\":\"integration\"},{\"title\":\"Rate Limiter\",\"description\":\"Prevents API quota exhaustion by tracking and controlling the frequency of requests to AI providers\",\"category\":\"component\"},{\"title\":\"Retry Handler\",\"description\":\"Automatically retries failed AI requests with exponential backoff when encountering transient errors like rate limits or network issues\",\"category\":\"component\"},{\"title\":\"Response Parser\",\"description\":\"Extracts structured data from AI text responses and converts them into typed objects for documentation, analysis, and test results\",\"category\":\"component\"},{\"title\":\"Enhanced Analyzer\",\"description\":\"Deep code analysis using Abstract Syntax Tree parsing to extract function metadata, dependencies, branches, and behavioral patterns from TypeScript and JavaScript files\",\"category\":\"module\"},{\"title\":\"Function Analyzer\",\"description\":\"Analyzes individual functions to extract signatures, parameters, return types, complexity metrics, and relationships for refactoring recommendations\",\"category\":\"module\"},{\"title\":\"Insight Generator\",\"description\":\"Generates actionable insights about code quality, organization, and potential issues by analyzing codebase structure and patterns\",\"category\":\"module\"},{\"title\":\"Refactoring Recommendations\",\"description\":\"Identifies functions that should be extracted to new files and provides detailed migration instructions with dependency analysis\",\"category\":\"feature\"},{\"title\":\"Configuration Manager\",\"description\":\"Manages all extension settings including AI provider selection, output format, automatic analysis, and diagnostic severity levels with real-time change notifications\",\"category\":\"component\"},{\"title\":\"Documentation Formatter\",\"description\":\"Converts raw analysis data into polished, human-readable Markdown documents with consistent structure and formatting\",\"category\":\"component\"},{\"title\":\"Prompt Builder\",\"description\":\"Constructs standardized prompts for all AI interactions including documentation generation, architecture analysis, test planning, and refactoring\",\"category\":\"component\"},{\"title\":\"Test Execution Service\",\"description\":\"Runs test suites using appropriate test frameworks (Jest, Mocha, Pytest) and captures structured results with pass/fail counts, durations, and error details\",\"category\":\"module\"},{\"title\":\"Analysis Cache\",\"description\":\"Stores analysis results in memory and on disk to avoid redundant processing and improve responsiveness during repeated access\",\"category\":\"component\"},{\"title\":\"File Cache\",\"description\":\"Caches file contents in memory with automatic invalidation on changes to eliminate redundant disk reads\",\"category\":\"component\"},{\"title\":\"Analysis Result Repository\",\"description\":\"Persists all analysis outputs including documentation and insights to the .shadow directory with unique identifiers and timestamps for historical tracking\",\"category\":\"component\"}],\"relevantFunctions\":[{\"name\":\"activate\",\"description\":\"Main entry point that initializes the VS Code extension, registers commands, sets up UI components, and starts file monitoring\",\"file\":\"src/extension.ts\",\"module\":\"extension\"},{\"name\":\"analyzeCodebase\",\"description\":\"Analyzes an entire workspace to generate product documentation, module summaries, and file-level documentation\",\"file\":\"src/extension.ts\",\"module\":\"extension\"},{\"name\":\"analyzeFile\",\"description\":\"Analyzes a single file to generate documentation describing its purpose and key functions\",\"file\":\"src/extension.ts\",\"module\":\"extension\"},{\"name\":\"generateArchitectureInsights\",\"description\":\"Creates AI-generated insights about codebase architecture, patterns, dependencies, and quality issues\",\"file\":\"src/llmService.ts\",\"module\":\"llmService\"},{\"name\":\"generateTestPlan\",\"description\":\"Analyzes functions to create a prioritized test plan determining which functions should be tested and in what order\",\"file\":\"src/domain/services/testing/llmTestPlanningService.ts\",\"module\":\"testing\"},{\"name\":\"generateTests\",\"description\":\"Generates unit test code for functions in batches with proper framework setup, mocks, and assertions\",\"file\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"module\":\"testing\"},{\"name\":\"validateAndFixTests\",\"description\":\"Executes tests and automatically fixes failures through iterative AI-powered corrections\",\"file\":\"src/domain/services/testing/llmTestValidationService.ts\",\"module\":\"testing\"},{\"name\":\"executeTests\",\"description\":\"Runs test suites using the appropriate framework and captures structured results\",\"file\":\"src/domain/services/testing/testExecutionService.ts\",\"module\":\"testing\"},{\"name\":\"analyzeFunction\",\"description\":\"Extracts detailed metadata about a function including signature, dependencies, complexity, and behavioral patterns\",\"file\":\"src/analysis/functionAnalyzer.ts\",\"module\":\"analysis\"},{\"name\":\"enhancedAnalyze\",\"description\":\"Performs deep AST-based analysis of TypeScript/JavaScript files to extract function metadata and relationships\",\"file\":\"src/analysis/enhancedAnalyzer.ts\",\"module\":\"analysis\"},{\"name\":\"navigateToCodeItem\",\"description\":\"Opens a file in the editor and positions the cursor at a specific line and column based on user selection\",\"file\":\"src/domain/handlers/navigationHandler.ts\",\"module\":\"handlers\"},{\"name\":\"buildProductDocumentationPrompt\",\"description\":\"Constructs an AI prompt for generating product documentation from codebase analysis\",\"file\":\"src/domain/prompts/promptBuilder.ts\",\"module\":\"prompts\"},{\"name\":\"buildRefactoringPrompt\",\"description\":\"Creates a detailed prompt for AI-based refactoring analysis with function extraction plans\",\"file\":\"src/domain/prompts/refactoringPromptBuilder.ts\",\"module\":\"prompts\"},{\"name\":\"performIncrementalAnalysis\",\"description\":\"Executes iterative AI analysis by processing file and grep requests across multiple rounds until completion\",\"file\":\"src/domain/services/incrementalAnalysisService.ts\",\"module\":\"services\"},{\"name\":\"watchWorkspace\",\"description\":\"Monitors workspace files for changes and triggers automatic re-analysis when files are saved\",\"file\":\"src/domain/services/fileWatcherService.ts\",\"module\":\"services\"},{\"name\":\"detectTestSetup\",\"description\":\"Automatically identifies the project's test framework configuration and missing dependencies\",\"file\":\"src/domain/services/testConfigurationService.ts\",\"module\":\"services\"},{\"name\":\"rateLimitedRequest\",\"description\":\"Enforces rate limits on AI API requests to prevent quota exhaustion\",\"file\":\"src/ai/llmRateLimiter.ts\",\"module\":\"ai\"},{\"name\":\"retryWithBackoff\",\"description\":\"Automatically retries failed AI requests with exponential backoff for transient errors\",\"file\":\"src/ai/llmRetryHandler.ts\",\"module\":\"ai\"},{\"name\":\"parseFileSummary\",\"description\":\"Extracts structured file documentation from AI text responses\",\"file\":\"src/ai/llmResponseParser.ts\",\"module\":\"ai\"},{\"name\":\"formatProductDocumentation\",\"description\":\"Converts product documentation data into formatted Markdown for human readability\",\"file\":\"src/domain/formatters/documentationFormatter.ts\",\"module\":\"formatters\"}],\"relevantDataStructures\":[{\"name\":\"ProductDocumentation\",\"description\":\"Structure representing comprehensive product documentation including overview, features, workflows, architecture, and examples\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"ModuleSummary\",\"description\":\"Structure describing a code module's user-facing capabilities and how it contributes to the application\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"FileSummary\",\"description\":\"Structure containing file-level documentation including purpose, key functions, and role\",\"type\":\"interface\",\"file\":\"src/fileDocumentation.ts\"},{\"name\":\"ArchitectureInsight\",\"description\":\"Structure containing AI-generated insights about codebase architecture, patterns, and quality issues\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"FunctionMetadata\",\"description\":\"Detailed metadata about a function including signature, dependencies, complexity, branches, and behavioral hints\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"TestPlan\",\"description\":\"Structure organizing functions to be tested with priorities, grouping, and metadata\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testPlanTypes.ts\"},{\"name\":\"TestGenerationResult\",\"description\":\"Results from test generation including generated code, validation status, and execution results\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestExecutionResult\",\"description\":\"Structured test execution results with pass/fail counts, duration, errors, and coverage information\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testResultTypes.ts\"},{\"name\":\"TestSetupConfig\",\"description\":\"Configuration for test environment including framework, dependencies, and execution settings\",\"type\":\"interface\",\"file\":\"src/domain/services/testing/types/testSetupTypes.ts\"},{\"name\":\"AnalysisRequest\",\"description\":\"Request for additional information during incremental analysis, either file content or grep search\",\"type\":\"interface\",\"file\":\"src/fileAccessHelper.ts\"},{\"name\":\"CodebaseStats\",\"description\":\"Statistics about a codebase including total files, lines of code, and entry points\",\"type\":\"interface\",\"file\":\"src/analyzer.ts\"},{\"name\":\"DiagnosticInfo\",\"description\":\"Information about a code quality issue for display in the Problems panel\",\"type\":\"interface\",\"file\":\"src/diagnosticsProvider.ts\"},{\"name\":\"LLMProviderConfig\",\"description\":\"Configuration for AI provider including model selection, temperature, and token limits\",\"type\":\"interface\",\"file\":\"src/ai/providers/ILLMProvider.ts\"},{\"name\":\"LLMMessage\",\"description\":\"Message structure for conversations with AI providers containing role and content\",\"type\":\"interface\",\"file\":\"src/ai/providers/ILLMProvider.ts\"}],\"relevantCodeFiles\":[{\"path\":\"src/extension.ts\",\"description\":\"Main extension entry point that initializes all components and registers commands\",\"purpose\":\"Activates the extension and coordinates between UI components, analyzers, and AI services\",\"role\":\"Extension orchestrator and command handler\"},{\"path\":\"src/llmService.ts\",\"description\":\"Core service coordinating AI-powered code analysis and documentation generation\",\"purpose\":\"Manages interactions with AI providers to generate insights, summaries, and test plans\",\"role\":\"AI orchestration and analysis coordination\"},{\"path\":\"src/llmIntegration.ts\",\"description\":\"Integration layer connecting AI features with VS Code UI components\",\"purpose\":\"Manages state, commands, and UI updates for AI-powered features\",\"role\":\"UI and AI feature integration\"},{\"path\":\"src/analyzer.ts\",\"description\":\"Core data structures and interfaces for code analysis results\",\"purpose\":\"Defines the contract for analysis data throughout the application\",\"role\":\"Type definitions and data models\"},{\"path\":\"src/analysis/enhancedAnalyzer.ts\",\"description\":\"Deep code analysis using AST parsing to extract function metadata\",\"purpose\":\"Performs static analysis of TypeScript/JavaScript code to understand structure and behavior\",\"role\":\"Code parsing and metadata extraction\"},{\"path\":\"src/insightsTreeView.ts\",\"description\":\"Tree view component displaying analysis insights and documentation in the sidebar\",\"purpose\":\"Provides browsable interface for viewing and navigating analysis results\",\"role\":\"UI component for insights visualization\"},{\"path\":\"src/domain/services/testing/llmTestGenerationService.ts\",\"description\":\"Service generating unit test code using AI\",\"purpose\":\"Creates test code with proper setup, mocks, and assertions for functions\",\"role\":\"Test code generation\"},{\"path\":\"src/domain/services/testing/llmTestValidationService.ts\",\"description\":\"Service validating and automatically fixing failing tests\",\"purpose\":\"Executes tests and iteratively corrects failures using AI\",\"role\":\"Test validation and correction\"},{\"path\":\"src/domain/handlers/navigationHandler.ts\",\"description\":\"Handler managing navigation from insights to source code\",\"purpose\":\"Opens files and positions cursor at specific locations when users click analysis results\",\"role\":\"Navigation and editor control\"},{\"path\":\"src/domain/prompts/promptBuilder.ts\",\"description\":\"Centralized prompt construction for all AI interactions\",\"purpose\":\"Standardizes how requests are formatted for different AI tasks\",\"role\":\"Prompt engineering and standardization\"},{\"path\":\"src/ai/providers/providerFactory.ts\",\"description\":\"Factory creating AI provider instances based on configuration\",\"purpose\":\"Enables switching between OpenAI and Claude providers\",\"role\":\"Provider instantiation and management\"},{\"path\":\"src/config/configurationManager.ts\",\"description\":\"Manager for all extension configuration and settings\",\"purpose\":\"Provides access to user settings and notifies components of changes\",\"role\":\"Configuration management and change notification\"},{\"path\":\"src/infrastructure/persistence/analysisResultRepository.ts\",\"description\":\"Repository persisting analysis results to disk\",\"purpose\":\"Saves documentation and insights to .shadow directory with timestamps\",\"role\":\"Data persistence and retrieval\"},{\"path\":\"src/cache.ts\",\"description\":\"Caching layer for analysis results\",\"purpose\":\"Stores analysis in memory and on disk to avoid redundant processing\",\"role\":\"Performance optimization through caching\"}],\"exampleInput\":{\"description\":\"Example configuration for analyzing a codebase and generating documentation\",\"json\":\"{\\\"workspace\\\":\\\"/Users/dev/my-project\\\",\\\"files\\\":[\\\"src/api/users.ts\\\",\\\"src/api/posts.ts\\\",\\\"src/models/user.ts\\\"],\\\"options\\\":{\\\"aiProvider\\\":\\\"openai\\\",\\\"model\\\":\\\"gpt-4\\\",\\\"generateTests\\\":true,\\\"analysisDepth\\\":\\\"detailed\\\",\\\"includeArchitecture\\\":true,\\\"outputFormat\\\":\\\"cursor\\\"}}\"},\"exampleOutput\":{\"description\":\"Example analysis result with product documentation and test generation results\",\"json\":\"{\\\"productDocumentation\\\":{\\\"name\\\":\\\"Blog API\\\",\\\"overview\\\":\\\"REST API for managing blog posts and user accounts with authentication and comment functionality\\\",\\\"features\\\":[\\\"User registration and authentication\\\",\\\"Create, read, update, delete blog posts\\\",\\\"Comment management on posts\\\",\\\"User profile management\\\"],\\\"architecture\\\":\\\"Three-tier architecture with Express.js API layer, business logic services, and PostgreSQL data layer\\\"},\\\"testResults\\\":{\\\"totalFunctions\\\":45,\\\"testsGenerated\\\":38,\\\"testsPassed\\\":35,\\\"testsFailed\\\":3,\\\"executionTime\\\":\\\"12.4s\\\",\\\"coverage\\\":\\\"87%\\\"},\\\"insights\\\":{\\\"patterns\\\":[\\\"RESTful API design\\\",\\\"Middleware authentication\\\",\\\"Repository pattern for data access\\\"],\\\"issues\\\":[\\\"Circular dependency between User and Post models\\\",\\\"Missing input validation in 3 endpoints\\\"],\\\"recommendations\\\":[\\\"Extract validation logic to separate module\\\",\\\"Add rate limiting to public endpoints\\\"]},\\\"timestamp\\\":\\\"2024-01-15T10:30:00Z\\\"}\"}}",
  "_metadata": {
    "generatedAt": "2025-11-20T02:50:45.256Z",
    "generatedAtLocal": "11/19/2025, 6:50:45 PM",
    "runId": "product-docs-2025-11-20T02-26-45-967Z"
  }
}